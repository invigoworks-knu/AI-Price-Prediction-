{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84d2eca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Ethereum data from Yahoo Finance...\n",
      "Successfully loaded 1336 days of data\n",
      "Price             Open        High         Low       Close      Volume\n",
      "Date                                                                  \n",
      "2017-11-09  308.644989  329.451996  307.056000  320.884003   893249984\n",
      "2017-11-10  320.670990  324.717987  294.541992  299.252991   885985984\n",
      "2017-11-11  298.585999  319.453003  298.191986  314.681000   842300992\n",
      "2017-11-12  314.690002  319.153015  298.513000  307.907990  1613479936\n",
      "2017-11-13  307.024994  328.415009  307.024994  316.716003  1041889984\n",
      "Downloading external market data...\n",
      "Warning: Could not download external data: If using all scalar values, you must pass an index\n",
      "None\n",
      "\n",
      "Calculating technical indicators...\n",
      "Final dataset: 1307 samples with 49 features\n",
      "\n",
      "Normalizing features with RobustScaler...\n",
      "Creating sequences (window=60)...\n",
      "Total sequences: 1247\n",
      "Sequence shape: (1247, 60, 49)\n",
      "\n",
      "Training samples: 997\n",
      "Test samples: 250\n",
      "Direction distribution: Up=500, Down=497\n",
      "\n",
      "Building improved hybrid model...\n",
      "WARNING:tensorflow:Layer gru_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_x1 (InputLayer)       [(None, 60, 24)]             0         []                            \n",
      "                                                                                                  \n",
      " input_x2 (InputLayer)       [(None, 60, 25)]             0         []                            \n",
      "                                                                                                  \n",
      " gru_9 (GRU)                 (None, 60, 256)              216576    ['input_x1[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_9 (LSTM)               (None, 60, 256)              288768    ['input_x2[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 60, 256)              1024      ['gru_9[0][0]']               \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, 60, 256)              1024      ['lstm_9[0][0]']              \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " gru_10 (GRU)                (None, 60, 256)              394752    ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " lstm_10 (LSTM)              (None, 60, 256)              525312    ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 60, 256)              1024      ['gru_10[0][0]']              \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (None, 60, 256)              1024      ['lstm_10[0][0]']             \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " gru_11 (GRU)                (None, 256)                  394752    ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " lstm_11 (LSTM)              (None, 256)                  525312    ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 256)                  1024      ['gru_11[0][0]']              \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (None, 256)                  1024      ['lstm_11[0][0]']             \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 128)                  32896     ['batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 128)                  32896     ['batch_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 128)                  0         ['dense_11[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 128)                  0         ['dense_12[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 256)                  0         ['dropout_7[0][0]',           \n",
      " )                                                                   'dropout_8[0][0]']           \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 128)                  32896     ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)         (None, 128)                  0         ['dense_13[0][0]']            \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, 64)                   8256      ['dropout_9[0][0]']           \n",
      "                                                                                                  \n",
      " price_output (Dense)        (None, 1)                    65        ['dense_14[0][0]']            \n",
      "                                                                                                  \n",
      " direction_output (Dense)    (None, 1)                    65        ['dense_14[0][0]']            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2458690 (9.38 MB)\n",
      "Trainable params: 2455618 (9.37 MB)\n",
      "Non-trainable params: 3072 (12.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Training model...\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 370\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, history\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 370\u001b[0m     model, history \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 282\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    272\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(\n\u001b[1;32m    273\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_direction_output_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    274\u001b[0m     factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    278\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    279\u001b[0m )\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 282\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX1_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX2_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43my_price_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_direction_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m    290\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEvaluating model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m y_pred_price, y_pred_direction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict([X1_test, X2_test])\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:905\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    902\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;66;03m# no_variable_creation function.\u001b[39;00m\n\u001b[0;32m--> 905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    909\u001b[0m   bound_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\n\u001b[1;32m    910\u001b[0m       \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds\n\u001b[1;32m    911\u001b[0m   )\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import accuracy_score, precision_recall_curve, auc, mean_absolute_percentage_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, GRU, Dense, Dropout, Concatenate, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_ethereum_data():\n",
    "    try:\n",
    "        import yfinance as yf\n",
    "        print(\"Downloading Ethereum data from Yahoo Finance...\")\n",
    "        eth = yf.download('ETH-USD', start='2016-03-10', end='2021-07-07', progress=False)\n",
    "\n",
    "        if isinstance(eth.columns, pd.MultiIndex):\n",
    "            eth.columns = eth.columns.droplevel(1)\n",
    "\n",
    "        eth = eth[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
    "        print(f\"Successfully loaded {len(eth)} days of data\")\n",
    "        return eth\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_external_data():\n",
    "    try:\n",
    "        import yfinance as yf\n",
    "        print(\"Downloading external market data...\")\n",
    "\n",
    "        gold = yf.download('GC=F', start='2016-03-10', end='2021-07-07', progress=False)\n",
    "        oil = yf.download('BZ=F', start='2016-03-10', end='2021-07-07', progress=False)\n",
    "        btc = yf.download('BTC-USD', start='2016-03-10', end='2021-07-07', progress=False)\n",
    "        spx = yf.download('^GSPC', start='2016-03-10', end='2021-07-07', progress=False)\n",
    "\n",
    "        if isinstance(gold.columns, pd.MultiIndex):\n",
    "            gold = gold['Close']\n",
    "        else:\n",
    "            gold = gold['Close']\n",
    "\n",
    "        if isinstance(oil.columns, pd.MultiIndex):\n",
    "            oil = oil['Close']\n",
    "        else:\n",
    "            oil = oil['Close']\n",
    "\n",
    "        if isinstance(btc.columns, pd.MultiIndex):\n",
    "            btc = btc['Close']\n",
    "        else:\n",
    "            btc = btc['Close']\n",
    "\n",
    "        if isinstance(spx.columns, pd.MultiIndex):\n",
    "            spx = spx['Close']\n",
    "        else:\n",
    "            spx = spx['Close']\n",
    "\n",
    "        external = pd.DataFrame({\n",
    "            'Gold_Close': gold,\n",
    "            'Oil_Close': oil,\n",
    "            'BTC_Close': btc,\n",
    "            'SPX': spx\n",
    "        })\n",
    "\n",
    "        return external\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not download external data: {e}\")\n",
    "        return None\n",
    "\n",
    "def calculate_technical_indicators(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    df['Returns'] = df['Close'].pct_change()\n",
    "    df['Log_Returns'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "\n",
    "    df['High_Low_Diff'] = df['High'] - df['Low']\n",
    "    df['Close_Open_Diff'] = df['Close'] - df['Open']\n",
    "\n",
    "    for period in [7, 14, 21, 30]:\n",
    "        df[f'MA_{period}'] = df['Close'].rolling(window=period).mean()\n",
    "        df[f'STD_{period}'] = df['Close'].rolling(window=period).std()\n",
    "\n",
    "        df[f'Upper_BB_{period}'] = df[f'MA_{period}'] + (df[f'STD_{period}'] * 2)\n",
    "        df[f'Lower_BB_{period}'] = df[f'MA_{period}'] - (df[f'STD_{period}'] * 2)\n",
    "\n",
    "    df['EMA_12'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    df['EMA_26'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    df['MACD'] = df['EMA_12'] - df['EMA_26']\n",
    "    df['Signal_Line'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "    df['RSI_14'] = calculate_rsi(df['Close'], 14)\n",
    "    df['RSI_21'] = calculate_rsi(df['Close'], 21)\n",
    "\n",
    "    df['Vol_MA_7'] = df['Volume'].rolling(window=7).mean()\n",
    "    df['Vol_MA_30'] = df['Volume'].rolling(window=30).mean()\n",
    "\n",
    "    for lag in [1, 2, 3, 5, 7, 14]:\n",
    "        df[f'Close_Lag_{lag}'] = df['Close'].shift(lag)\n",
    "        df[f'Returns_Lag_{lag}'] = df['Returns'].shift(lag)\n",
    "\n",
    "    df['Momentum_5'] = df['Close'] - df['Close'].shift(5)\n",
    "    df['Momentum_10'] = df['Close'] - df['Close'].shift(10)\n",
    "\n",
    "    df['ROC_5'] = ((df['Close'] - df['Close'].shift(5)) / df['Close'].shift(5)) * 100\n",
    "    df['ROC_10'] = ((df['Close'] - df['Close'].shift(10)) / df['Close'].shift(10)) * 100\n",
    "\n",
    "    return df\n",
    "\n",
    "def calculate_rsi(series, period=14):\n",
    "    delta = series.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "def create_sequences(data, target_col_idx, n_steps=60):\n",
    "    X, y_price, y_direction = [], [], []\n",
    "\n",
    "    for i in range(n_steps, len(data)):\n",
    "        X.append(data[i-n_steps:i])\n",
    "\n",
    "        current_price = data[i, target_col_idx]\n",
    "        y_price.append(current_price)\n",
    "\n",
    "        if i < len(data) - 1:\n",
    "            next_price = data[i+1, target_col_idx]\n",
    "            direction = 1 if next_price > current_price else 0\n",
    "        else:\n",
    "            direction = y_direction[-1] if len(y_direction) > 0 else 0\n",
    "        y_direction.append(direction)\n",
    "\n",
    "    return np.array(X), np.array(y_price), np.array(y_direction)\n",
    "\n",
    "def build_hybrid_model(n_steps, n_features):\n",
    "    n_features_x1 = n_features // 2\n",
    "    n_features_x2 = n_features - n_features_x1\n",
    "\n",
    "    input_x1 = Input(shape=(n_steps, n_features_x1), name='input_x1')\n",
    "    gru1 = GRU(256, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)(input_x1)\n",
    "    bn1 = BatchNormalization()(gru1)\n",
    "    gru2 = GRU(256, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)(bn1)\n",
    "    bn2 = BatchNormalization()(gru2)\n",
    "    gru3 = GRU(256, return_sequences=False, dropout=0.1, recurrent_dropout=0.1)(bn2)\n",
    "    bn3 = BatchNormalization()(gru3)\n",
    "    mlp_x1 = Dense(128, activation='relu')(bn3)\n",
    "    dropout1 = Dropout(0.2)(mlp_x1)\n",
    "\n",
    "    input_x2 = Input(shape=(n_steps, n_features_x2), name='input_x2')\n",
    "    lstm1 = LSTM(256, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)(input_x2)\n",
    "    bn4 = BatchNormalization()(lstm1)\n",
    "    lstm2 = LSTM(256, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)(bn4)\n",
    "    bn5 = BatchNormalization()(lstm2)\n",
    "    lstm3 = LSTM(256, return_sequences=False, dropout=0.1, recurrent_dropout=0.1)(bn5)\n",
    "    bn6 = BatchNormalization()(lstm3)\n",
    "    mlp_x2 = Dense(128, activation='relu')(bn6)\n",
    "    dropout2 = Dropout(0.2)(mlp_x2)\n",
    "\n",
    "    concatenated = Concatenate()([dropout1, dropout2])\n",
    "    shared_dense1 = Dense(128, activation='relu')(concatenated)\n",
    "    dropout3 = Dropout(0.2)(shared_dense1)\n",
    "    shared_dense2 = Dense(64, activation='relu')(dropout3)\n",
    "\n",
    "    price_output = Dense(1, activation='linear', name='price_output')(shared_dense2)\n",
    "    direction_output = Dense(1, activation='sigmoid', name='direction_output')(shared_dense2)\n",
    "\n",
    "    model = Model(\n",
    "        inputs=[input_x1, input_x2],\n",
    "        outputs=[price_output, direction_output]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "def calculate_pr_auc(y_true, y_pred_proba):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)\n",
    "    return auc(recall, precision)\n",
    "\n",
    "def main():\n",
    "\n",
    "    eth_data = load_ethereum_data()\n",
    "    if eth_data is None:\n",
    "        return\n",
    "\n",
    "    print(eth_data.head())\n",
    "    external_data = load_external_data()\n",
    "\n",
    "    print(external_data)\n",
    "    if external_data is not None:\n",
    "        df = eth_data.join(external_data, how='inner')\n",
    "        print(f\"Combined with external data: {len(df)} samples\")\n",
    "    else:\n",
    "        df = eth_data\n",
    "\n",
    "    print(\"\\nCalculating technical indicators...\")\n",
    "    df = calculate_technical_indicators(df)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    print(f\"Final dataset: {len(df)} samples with {len(df.columns)} features\")\n",
    "\n",
    "    feature_columns = df.columns.tolist()\n",
    "    close_idx = feature_columns.index('Close')\n",
    "\n",
    "    print(\"\\nNormalizing features with RobustScaler...\")\n",
    "    scaler = RobustScaler()\n",
    "    scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "    price_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    price_scaler.fit(df[['Close']])\n",
    "\n",
    "    print(\"Creating sequences (window=60)...\")\n",
    "    n_steps = 60\n",
    "    X, y_price, y_direction = create_sequences(scaled_data, close_idx, n_steps)\n",
    "\n",
    "    print(f\"Total sequences: {len(X)}\")\n",
    "    print(f\"Sequence shape: {X.shape}\")\n",
    "\n",
    "    n_features = X.shape[2]\n",
    "    n_features_x1 = n_features // 2\n",
    "    n_features_x2 = n_features - n_features_x1\n",
    "\n",
    "    X1 = X[:, :, :n_features_x1]\n",
    "    X2 = X[:, :, n_features_x1:]\n",
    "\n",
    "    split_idx = int(len(X) * 0.8)\n",
    "\n",
    "    X1_train, X1_test = X1[:split_idx], X1[split_idx:]\n",
    "    X2_train, X2_test = X2[:split_idx], X2[split_idx:]\n",
    "    y_price_train, y_price_test = y_price[:split_idx], y_price[split_idx:]\n",
    "    y_direction_train, y_direction_test = y_direction[:split_idx], y_direction[split_idx:]\n",
    "\n",
    "    print(f\"\\nTraining samples: {len(X1_train)}\")\n",
    "    print(f\"Test samples: {len(X1_test)}\")\n",
    "\n",
    "    up_count = np.sum(y_direction_train)\n",
    "    down_count = len(y_direction_train) - up_count\n",
    "    print(f\"Direction distribution: Up={up_count}, Down={down_count}\")\n",
    "\n",
    "    print(\"\\nBuilding improved hybrid model...\")\n",
    "    model = build_hybrid_model(n_steps, n_features)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0005),\n",
    "        loss={\n",
    "            'price_output': 'huber',\n",
    "            'direction_output': 'binary_crossentropy'\n",
    "        },\n",
    "        loss_weights={\n",
    "            'price_output': 0.3,\n",
    "            'direction_output': 0.7\n",
    "        },\n",
    "        metrics={\n",
    "            'price_output': ['mae'],\n",
    "            'direction_output': ['accuracy']\n",
    "        }\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_direction_output_accuracy',\n",
    "        patience=15,\n",
    "        mode='max',\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_direction_output_accuracy',\n",
    "        factor=0.5,\n",
    "        patience=7,\n",
    "        min_lr=1e-7,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(\"\\nTraining model...\")\n",
    "    history = model.fit(\n",
    "        [X1_train, X2_train],\n",
    "        [y_price_train, y_direction_train],\n",
    "        validation_split=0.2,\n",
    "        epochs=150,\n",
    "        batch_size=64,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(\"\\nEvaluating model...\")\n",
    "    y_pred_price, y_pred_direction = model.predict([X1_test, X2_test])\n",
    "\n",
    "    y_pred_price_scaled = price_scaler.inverse_transform(y_pred_price.reshape(-1, 1)).flatten()\n",
    "    y_test_price_scaled = price_scaler.inverse_transform(y_price_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "    mape = mean_absolute_percentage_error(y_test_price_scaled, y_pred_price_scaled) * 100\n",
    "    rmse = calculate_rmse(y_test_price_scaled, y_pred_price_scaled)\n",
    "\n",
    "    y_pred_direction_binary = (y_pred_direction > 0.5).astype(int).flatten()\n",
    "    accuracy = accuracy_score(y_direction_test, y_pred_direction_binary)\n",
    "    pr_auc = calculate_pr_auc(y_direction_test, y_pred_direction.flatten())\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Model Evaluation Results\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Regression Metrics:\")\n",
    "    print(f\"  MAPE: {mape:.2f}%\")\n",
    "    print(f\"  RMSE: ${rmse:.2f}\")\n",
    "    print(f\"  Mean Price: ${np.mean(y_test_price_scaled):.2f}\")\n",
    "    print(f\"\\nClassification Metrics:\")\n",
    "    print(f\"  Accuracy: {accuracy*100:.2f}%\")\n",
    "    print(f\"  PR-AUC: {pr_auc:.3f}\")\n",
    "    print(\"\\nPaper Results (Ethereum):\")\n",
    "    print(f\"  MAPE: 3.17%\")\n",
    "    print(f\"  RMSE: $82.03\")\n",
    "    print(f\"  Accuracy: 90.26%\")\n",
    "    print(f\"  PR-AUC: 0.930\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    print(\"\\nSimulating trading strategy...\")\n",
    "    capital = 10000\n",
    "    position = 0\n",
    "    buy_price = 0\n",
    "    trades = 0\n",
    "    wins = 0\n",
    "\n",
    "    for i in range(len(y_pred_direction_binary) - 1):\n",
    "        if y_pred_direction_binary[i] == 1 and position == 0:\n",
    "            position = 1\n",
    "            buy_price = y_test_price_scaled[i]\n",
    "            trades += 1\n",
    "        elif y_pred_direction_binary[i] == 0 and position == 1:\n",
    "            position = 0\n",
    "            sell_price = y_test_price_scaled[i]\n",
    "            profit = (sell_price - buy_price) / buy_price\n",
    "            capital *= (1 + profit)\n",
    "            if profit > 0:\n",
    "                wins += 1\n",
    "\n",
    "    profitability = ((capital - 10000) / 10000) * 100\n",
    "    win_rate = (wins / trades * 100) if trades > 0 else 0\n",
    "\n",
    "    print(f\"\\nTrading Simulation Results:\")\n",
    "    print(f\"  Initial Capital: $10,000.00\")\n",
    "    print(f\"  Final Capital: ${capital:,.2f}\")\n",
    "    print(f\"  Profitability: {profitability:.2f}%\")\n",
    "    print(f\"  Number of Trades: {trades}\")\n",
    "    print(f\"  Win Rate: {win_rate:.2f}%\")\n",
    "    print(f\"\\n  Paper Result: 69% profitability (6 months)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    model.save('ethereum_improved_model.h5')\n",
    "    print(\"\\nModel saved as 'ethereum_improved_model.h5'\")\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'True_Price': y_test_price_scaled,\n",
    "        'Predicted_Price': y_pred_price_scaled,\n",
    "        'True_Direction': y_direction_test,\n",
    "        'Predicted_Direction': y_pred_direction_binary,\n",
    "        'Prediction_Probability': y_pred_direction.flatten()\n",
    "    })\n",
    "    results_df.to_csv('improved_predictions.csv', index=False)\n",
    "    print(\"Predictions saved as 'improved_predictions.csv'\")\n",
    "\n",
    "    return model, history\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model, history = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f675c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5c0052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ec26e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Ethereum Price Prediction\n",
      "======================================================================\n",
      "\n",
      "[1] Data Collection\n",
      "Ethereum: 1737 samples\n",
      "\n",
      "[2] Bitcoin Data\n",
      "Combined: 1737 samples\n",
      "\n",
      "[3] Feature Engineering\n",
      "Features: 39, Samples: 1688\n",
      "\n",
      "[4] Normalization\n",
      "X: (1688, 38), y: (1688,)\n",
      "\n",
      "[5] Feature Selection\n",
      "Phase I: 23 features\n",
      "Phase II: 23 features\n",
      "\n",
      "[6] Sequences\n",
      "X: (1681, 7, 23), y: (1681,)\n",
      "\n",
      "[7] Split\n",
      "Train: 1344, Test: 337\n",
      "\n",
      "[8] Training\n",
      "\n",
      "[9] Evaluation\n",
      "Price MAE: 0.0432\n",
      "Price MAPE: 9.63%\n",
      "\n",
      "[10] Predictions\n",
      "Direction Accuracy: 51.34%\n",
      "\n",
      "Detailed Metrics:\n",
      "MAE: $165.91\n",
      "RMSE: $198.53\n",
      "MAPE: 5.74%\n",
      "RÂ²: 0.9482\n",
      "\n",
      "Predictions:\n",
      "    Actual    Predicted  Difference  Diff_Pct  Direction_Pred  \\\n",
      "0  2511.49  2688.680176 -177.190176 -7.055181               1   \n",
      "1  2494.23  2627.786621 -133.556621 -5.354623               1   \n",
      "2  2457.73  2620.535400 -162.805400 -6.624218               1   \n",
      "3  2398.21  2584.179443 -185.969443 -7.754510               1   \n",
      "4  2422.55  2551.811035 -129.261035 -5.335743               1   \n",
      "5  2721.87  2562.510010  159.359990  5.854798               1   \n",
      "6  2895.47  2823.662842   71.807158  2.479983               1   \n",
      "7  2961.75  2969.477051   -7.727051 -0.260895               1   \n",
      "8  3126.21  3096.199463   30.010537  0.959965               1   \n",
      "9  3183.21  3242.882324  -59.672324 -1.874596               1   \n",
      "\n",
      "   Direction_Actual  \n",
      "0                 0  \n",
      "1                 0  \n",
      "2                 0  \n",
      "3                 0  \n",
      "4                 1  \n",
      "5                 1  \n",
      "6                 1  \n",
      "7                 1  \n",
      "8                 1  \n",
      "9                 1  \n",
      "\n",
      "Saved: ethereum_predictions.csv\n",
      "\n",
      "======================================================================\n",
      "Complete\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def fetch_ethereum_binance():\n",
    "    \"\"\"Binance API\"\"\"\n",
    "    import requests\n",
    "    import time\n",
    "    \n",
    "    url = \"https://api.binance.com/api/v3/klines\"\n",
    "    start_time = int(datetime(2021, 1, 1).timestamp() * 1000)\n",
    "    end_time = int(datetime.now().timestamp() * 1000)\n",
    "    \n",
    "    all_data = []\n",
    "    current_start = start_time\n",
    "    \n",
    "    while current_start < end_time:\n",
    "        params = {\n",
    "            'symbol': 'ETHUSDT',\n",
    "            'interval': '1d',\n",
    "            'startTime': current_start,\n",
    "            'limit': 1000\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=10)\n",
    "            data = response.json()\n",
    "            \n",
    "            if not data or not isinstance(data, list):\n",
    "                break\n",
    "                \n",
    "            all_data.extend(data)\n",
    "            \n",
    "            if len(data) < 1000:\n",
    "                break\n",
    "                \n",
    "            current_start = data[-1][0] + 1\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            break\n",
    "    \n",
    "    if not all_data:\n",
    "        return None\n",
    "        \n",
    "    df = pd.DataFrame(all_data, columns=[\n",
    "        'timestamp', 'open', 'high', 'low', 'close', 'volume',\n",
    "        'close_time', 'quote_volume', 'trades', 'taker_buy_base',\n",
    "        'taker_buy_quote', 'ignore'\n",
    "    ])\n",
    "    \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    \n",
    "    for col in ['open', 'high', 'low', 'close', 'volume']:\n",
    "        df[col] = df[col].astype(float)\n",
    "    \n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fetch_bitcoin_binance():\n",
    "    \"\"\"Bitcoin data\"\"\"\n",
    "    import requests\n",
    "    import time\n",
    "    \n",
    "    url = \"https://api.binance.com/api/v3/klines\"\n",
    "    start_time = int(datetime(2021, 1, 1).timestamp() * 1000)\n",
    "    end_time = int(datetime.now().timestamp() * 1000)\n",
    "    \n",
    "    all_data = []\n",
    "    current_start = start_time\n",
    "    \n",
    "    while current_start < end_time:\n",
    "        params = {\n",
    "            'symbol': 'BTCUSDT',\n",
    "            'interval': '1d',\n",
    "            'startTime': current_start,\n",
    "            'limit': 1000\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=10)\n",
    "            data = response.json()\n",
    "            \n",
    "            if not data or not isinstance(data, list):\n",
    "                break\n",
    "                \n",
    "            all_data.extend(data)\n",
    "            \n",
    "            if len(data) < 1000:\n",
    "                break\n",
    "                \n",
    "            current_start = data[-1][0] + 1\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return None\n",
    "    \n",
    "    if not all_data:\n",
    "        return None\n",
    "        \n",
    "    df = pd.DataFrame(all_data, columns=[\n",
    "        'timestamp', 'open', 'high', 'low', 'close', 'volume',\n",
    "        'close_time', 'quote_volume', 'trades', 'taker_buy_base',\n",
    "        'taker_buy_quote', 'ignore'\n",
    "    ])\n",
    "    \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    df = df[['timestamp', 'close']]\n",
    "    df['close'] = df['close'].astype(float)\n",
    "    df.rename(columns={'close': 'btc_close'}, inplace=True)\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def compute_pps_scores(X, y):\n",
    "    \"\"\"PPS calculation\"\"\"\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn.metrics import r2_score\n",
    "    \n",
    "    pps_scores = {}\n",
    "    for col in X.columns:\n",
    "        try:\n",
    "            model = DecisionTreeRegressor(max_depth=4, random_state=42)\n",
    "            X_col = X[col].values.reshape(-1, 1)\n",
    "            model.fit(X_col, y)\n",
    "            preds = model.predict(X_col)\n",
    "            score = max(0, r2_score(y, preds))\n",
    "            pps_scores[col] = score\n",
    "        except:\n",
    "            pps_scores[col] = 0\n",
    "    \n",
    "    return pps_scores\n",
    "\n",
    "def compute_correlation(X, y):\n",
    "    \"\"\"Pearson correlation\"\"\"\n",
    "    correlations = {}\n",
    "    for col in X.columns:\n",
    "        try:\n",
    "            corr = np.corrcoef(X[col], y)[0, 1]\n",
    "            correlations[col] = abs(corr) if not np.isnan(corr) else 0\n",
    "        except:\n",
    "            correlations[col] = 0\n",
    "    return correlations\n",
    "\n",
    "def feature_engineering(df):\n",
    "    \"\"\"Feature engineering\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    df['returns'] = df['close'].pct_change()\n",
    "    df['log_returns'] = np.log(df['close'] / df['close'].shift(1))\n",
    "    df['volatility'] = df['returns'].rolling(window=7).std()\n",
    "    df['momentum'] = df['close'] - df['close'].shift(5)\n",
    "    df['volume_change'] = df['volume'].pct_change()\n",
    "    \n",
    "    df['ma_7'] = df['close'].rolling(window=7).mean()\n",
    "    df['ma_21'] = df['close'].rolling(window=21).mean()\n",
    "    df['ma_50'] = df['close'].rolling(window=50).mean()\n",
    "    \n",
    "    df['ema_12'] = df['close'].ewm(span=12, adjust=False).mean()\n",
    "    df['ema_26'] = df['close'].ewm(span=26, adjust=False).mean()\n",
    "    \n",
    "    delta = df['close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    rs = gain / loss\n",
    "    df['rsi'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    df['macd'] = df['ema_12'] - df['ema_26']\n",
    "    df['macd_signal'] = df['macd'].ewm(span=9, adjust=False).mean()\n",
    "    \n",
    "    high_low = df['high'] - df['low']\n",
    "    high_close = np.abs(df['high'] - df['close'].shift())\n",
    "    low_close = np.abs(df['low'] - df['close'].shift())\n",
    "    ranges = pd.concat([high_low, high_close, low_close], axis=1)\n",
    "    true_range = np.max(ranges, axis=1)\n",
    "    df['atr'] = true_range.rolling(14).mean()\n",
    "    \n",
    "    df['bb_middle'] = df['close'].rolling(window=20).mean()\n",
    "    bb_std = df['close'].rolling(window=20).std()\n",
    "    df['bb_upper'] = df['bb_middle'] + (bb_std * 2)\n",
    "    df['bb_lower'] = df['bb_middle'] - (bb_std * 2)\n",
    "    \n",
    "    for lag in range(1, 8):\n",
    "        df[f'close_lag_{lag}'] = df['close'].shift(lag)\n",
    "        df[f'volume_lag_{lag}'] = df['volume'].shift(lag)\n",
    "    \n",
    "    df['price_range'] = df['high'] - df['low']\n",
    "    df['price_change'] = df['close'] - df['open']\n",
    "    \n",
    "    return df\n",
    "\n",
    "def adaptive_feature_selection(X, y, pps_threshold=0.2, corr_threshold=0.05):\n",
    "    \"\"\"Adaptive feature selection\"\"\"\n",
    "    pps_scores = compute_pps_scores(X, y)\n",
    "    selected_phase1 = [col for col, score in pps_scores.items() if score >= pps_threshold]\n",
    "    \n",
    "    print(f\"Phase I: {len(selected_phase1)} features\")\n",
    "    \n",
    "    if len(selected_phase1) == 0:\n",
    "        selected_phase1 = list(X.columns)\n",
    "    \n",
    "    X_phase1 = X[selected_phase1]\n",
    "    correlations = compute_correlation(X_phase1, y)\n",
    "    selected_phase2 = [col for col, corr in correlations.items() if corr >= corr_threshold]\n",
    "    \n",
    "    print(f\"Phase II: {len(selected_phase2)} features\")\n",
    "    \n",
    "    if len(selected_phase2) == 0:\n",
    "        selected_phase2 = selected_phase1[:20]\n",
    "    \n",
    "    return selected_phase2\n",
    "\n",
    "def create_sequences(data, target, timesteps=7):\n",
    "    \"\"\"Create sequences\"\"\"\n",
    "    X, y, y_direction = [], [], []\n",
    "    \n",
    "    for i in range(timesteps, len(data)):\n",
    "        X.append(data[i-timesteps:i])\n",
    "        y.append(target[i])\n",
    "        direction = 1 if target[i] > target[i-1] else 0\n",
    "        y_direction.append(direction)\n",
    "    \n",
    "    return np.array(X), np.array(y), np.array(y_direction)\n",
    "\n",
    "def build_model(input_shape):\n",
    "    \"\"\"Build model\"\"\"\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    \n",
    "    input_layer = layers.Input(shape=(input_shape[1], input_shape[2]))\n",
    "    \n",
    "    gru1 = layers.GRU(256, return_sequences=True)(input_layer)\n",
    "    gru2 = layers.GRU(256, return_sequences=True)(gru1)\n",
    "    gru3 = layers.GRU(256, return_sequences=False)(gru2)\n",
    "    \n",
    "    lstm1 = layers.LSTM(256, return_sequences=True)(input_layer)\n",
    "    lstm2 = layers.LSTM(256, return_sequences=True)(lstm1)\n",
    "    lstm3 = layers.LSTM(256, return_sequences=False)(lstm2)\n",
    "    \n",
    "    concatenated = layers.Concatenate()([gru3, lstm3])\n",
    "    \n",
    "    dense_reg = layers.Dense(128, activation='relu')(concatenated)\n",
    "    dropout_reg = layers.Dropout(0.1)(dense_reg)\n",
    "    output_reg = layers.Dense(1, name='price_forecast')(dropout_reg)\n",
    "    \n",
    "    dense_cls = layers.Dense(128, activation='relu')(concatenated)\n",
    "    dropout_cls = layers.Dropout(0.1)(dense_cls)\n",
    "    output_cls = layers.Dense(1, activation='sigmoid', name='direction_classification')(dropout_cls)\n",
    "    \n",
    "    model = keras.Model(inputs=input_layer, outputs=[output_reg, output_cls])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss={'price_forecast': 'mse', 'direction_classification': 'binary_crossentropy'},\n",
    "        loss_weights={'price_forecast': 0.5, 'direction_classification': 0.5},\n",
    "        metrics={'price_forecast': ['mae', 'mape'], 'direction_classification': ['accuracy']}\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Ethereum Price Prediction\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n[1] Data Collection\")\n",
    "eth_df = fetch_ethereum_binance()\n",
    "\n",
    "if eth_df is None or len(eth_df) == 0:\n",
    "    print(\"API unavailable\")\n",
    "else:\n",
    "    print(f\"Ethereum: {len(eth_df)} samples\")\n",
    "    \n",
    "    print(\"\\n[2] Bitcoin Data\")\n",
    "    btc_df = fetch_bitcoin_binance()\n",
    "    if btc_df is not None:\n",
    "        eth_df = eth_df.join(btc_df, how='inner')\n",
    "        print(f\"Combined: {len(eth_df)} samples\")\n",
    "    \n",
    "    print(\"\\n[3] Feature Engineering\")\n",
    "    eth_df = feature_engineering(eth_df)\n",
    "    eth_df = eth_df.dropna()\n",
    "    print(f\"Features: {len(eth_df.columns)}, Samples: {len(eth_df)}\")\n",
    "    \n",
    "    if len(eth_df) > 0:\n",
    "        print(\"\\n[4] Normalization\")\n",
    "        scaler_features = MinMaxScaler()\n",
    "        scaler_target = MinMaxScaler()\n",
    "        \n",
    "        feature_cols = [col for col in eth_df.columns if col != 'close']\n",
    "        X_raw = eth_df[feature_cols]\n",
    "        y_raw = eth_df['close'].values\n",
    "        \n",
    "        X_norm = pd.DataFrame(\n",
    "            scaler_features.fit_transform(X_raw),\n",
    "            columns=feature_cols,\n",
    "            index=eth_df.index\n",
    "        )\n",
    "        y_norm = scaler_target.fit_transform(y_raw.reshape(-1, 1)).flatten()\n",
    "        print(f\"X: {X_norm.shape}, y: {y_norm.shape}\")\n",
    "        \n",
    "        print(\"\\n[5] Feature Selection\")\n",
    "        selected = adaptive_feature_selection(X_norm, y_norm)\n",
    "        X_selected = X_norm[selected]\n",
    "        \n",
    "        print(\"\\n[6] Sequences\")\n",
    "        X_seq, y_seq, y_dir = create_sequences(X_selected.values, y_norm, 7)\n",
    "        print(f\"X: {X_seq.shape}, y: {y_seq.shape}\")\n",
    "        \n",
    "        print(\"\\n[7] Split\")\n",
    "        split = int(len(X_seq) * 0.8)\n",
    "        X_train, X_test = X_seq[:split], X_seq[split:]\n",
    "        y_train, y_test = y_seq[:split], y_seq[split:]\n",
    "        y_dir_train, y_dir_test = y_dir[:split], y_dir[split:]\n",
    "        print(f\"Train: {X_train.shape[0]}, Test: {X_test.shape[0]}\")\n",
    "        \n",
    "        print(\"\\n[8] Training\")\n",
    "        model = build_model(X_train.shape)\n",
    "        history = model.fit(\n",
    "            X_train,\n",
    "            {'price_forecast': y_train, 'direction_classification': y_dir_train},\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            validation_split=0.2,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        print(\"\\n[9] Evaluation\")\n",
    "        results = model.evaluate(\n",
    "            X_test,\n",
    "            {'price_forecast': y_test, 'direction_classification': y_dir_test},\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        print(f\"Price MAE: {results[3]:.4f}\")\n",
    "        print(f\"Price MAPE: {results[4]:.2f}%\")\n",
    "        \n",
    "        print(\"\\n[10] Predictions\")\n",
    "        preds = model.predict(X_test, verbose=0)\n",
    "        y_pred = preds[0].flatten()\n",
    "        y_pred_dir = preds[1].flatten()\n",
    "        \n",
    "        y_pred_orig = scaler_target.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n",
    "        y_test_orig = scaler_target.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        direction_accuracy = np.mean((y_pred_dir > 0.5).astype(int) == y_dir_test)\n",
    "        print(f\"Direction Accuracy: {direction_accuracy*100:.2f}%\")\n",
    "        \n",
    "        from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "        \n",
    "        mae = mean_absolute_error(y_test_orig, y_pred_orig)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred_orig))\n",
    "        mape = np.mean(np.abs((y_test_orig - y_pred_orig) / y_test_orig)) * 100\n",
    "        r2 = r2_score(y_test_orig, y_pred_orig)\n",
    "        \n",
    "        print(f\"\\nDetailed Metrics:\")\n",
    "        print(f\"MAE: ${mae:.2f}\")\n",
    "        print(f\"RMSE: ${rmse:.2f}\")\n",
    "        print(f\"MAPE: {mape:.2f}%\")\n",
    "        print(f\"RÂ²: {r2:.4f}\")\n",
    "        \n",
    "        results_df = pd.DataFrame({\n",
    "            'Actual': y_test_orig,\n",
    "            'Predicted': y_pred_orig,\n",
    "            'Difference': y_test_orig - y_pred_orig,\n",
    "            'Diff_Pct': ((y_test_orig - y_pred_orig) / y_test_orig * 100),\n",
    "            'Direction_Pred': (y_pred_dir > 0.5).astype(int),\n",
    "            'Direction_Actual': y_dir_test\n",
    "        })\n",
    "        \n",
    "        print(\"\\nPredictions:\")\n",
    "        print(results_df.head(10))\n",
    "        \n",
    "        results_df.to_csv('ethereum_predictions.csv', index=False)\n",
    "        print(\"\\nSaved: ethereum_predictions.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Complete\")\n",
    "print(\"=\" * 70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

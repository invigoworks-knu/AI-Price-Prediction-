{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfa697c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Starting Data Collection Pipeline (Fix V3)\n",
      "============================================================\n",
      "[1/7] Collecting Upbit Data (KST)...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import requests\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "from binance.client import Client\n",
    "import pytz\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 설정 ---\n",
    "START_DATE = \"2019-01-01\"\n",
    "END_DATE = (datetime.today() + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "OUTPUT_DIR = \"./macro_data_4h\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "KST = pytz.timezone('Asia/Seoul')\n",
    "UTC = pytz.UTC\n",
    "\n",
    "UPBIT_CRYPTO_TICKERS = {\n",
    "    'KRW-BTC': ('BTC', 'BTC'), 'KRW-ETH': ('ETH', 'ETH'), 'KRW-XRP': ('XRP', 'XRP'),\n",
    "    'KRW-SOL': ('SOL', 'SOL'), 'KRW-ADA': ('ADA', 'ADA'), 'KRW-DOGE': ('DOGE', 'DOGE'),\n",
    "    'KRW-AVAX': ('AVAX', 'AVAX'), 'KRW-DOT': ('DOT', 'DOT')\n",
    "}\n",
    "\n",
    "MACRO_TICKERS = {\n",
    "    'DX-Y.NYB': 'DXY', 'GC=F': 'GOLD', '^VIX': 'VIX', '^GSPC': 'SP500'\n",
    "}\n",
    "\n",
    "# 주소는 그대로 사용\n",
    "DEFI_PROTOCOLS = {\n",
    "    'eth_chain': 'https://api.llama.fi/v2/historicalChainTvl/Ethereum',\n",
    "    'makerdao': 'https://api.llama.fi/protocol/makerdao',\n",
    "    'lido': 'https://api.llama.fi/protocol/lido',\n",
    "    'aave': 'https://api.llama.fi/protocol/aave',\n",
    "    'uniswap': 'https://api.llama.fi/protocol/uniswap-v3', # 데이터 큼\n",
    "    'curve-dex': 'https://api.llama.fi/protocol/curve-dex' # 데이터 큼\n",
    "}\n",
    "\n",
    "# --- 공통 함수 ---\n",
    "def get_session():\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "        \"Accept\": \"application/json\"\n",
    "    })\n",
    "    retry = Retry(total=5, backoff_factor=2, status_forcelist=[429, 500, 502, 503, 504])\n",
    "    session.mount('https://', HTTPAdapter(max_retries=retry))\n",
    "    return session\n",
    "\n",
    "def save_df(df, filename):\n",
    "    if df is not None and not df.empty:\n",
    "        path = os.path.join(OUTPUT_DIR, filename)\n",
    "        df.to_csv(path, index=False)\n",
    "        print(f\"  - Saved: {filename} ({len(df)} rows)\")\n",
    "    else:\n",
    "        print(f\"  - Warning: {filename} is empty or failed.\")\n",
    "\n",
    "# --- [수정됨] 2. 바이낸스 수집 (Timestamp 에러 해결) ---\n",
    "def collect_binance_crypto_4h():\n",
    "    print(f\"[2/7] Collecting Binance Data (UTC->KST)...\")\n",
    "    client = Client(\"\", \"\") # 키 없어도 됨\n",
    "    symbols = ['BTCUSDT', 'ETHUSDT', 'XRPUSDT', 'SOLUSDT', 'ADAUSDT', 'DOGEUSDT', 'AVAXUSDT', 'DOTUSDT']\n",
    "    merged_df = None\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        try:\n",
    "            # 1. 데이터 가져오기\n",
    "            klines = client.get_historical_klines(symbol, Client.KLINE_INTERVAL_4HOUR, START_DATE, END_DATE)\n",
    "            if not klines:\n",
    "                print(f\"  - {symbol}: No data\")\n",
    "                continue\n",
    "                \n",
    "            # 2. DataFrame 생성 (모두 문자열 상태)\n",
    "            df = pd.DataFrame(klines, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume', 'ct', 'qv', 'tr', 'tbb', 'tbq', 'ig'])\n",
    "            \n",
    "            # 3. Timestamp 변환 (Datetime 객체로 변환)\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "            df['timestamp'] = df['timestamp'].dt.tz_localize(UTC).dt.tz_convert(KST).dt.tz_localize(None)\n",
    "            \n",
    "            # 4. [핵심 수정] 필요한 컬럼만 '따로' 숫자로 변환 (전체 변환 X)\n",
    "            coin = symbol.replace('USDT', '')\n",
    "            df_final = df[['timestamp']].copy() # 타임스탬프 복사\n",
    "            \n",
    "            # pd.to_numeric으로 안전하게 숫자 변환\n",
    "            df_final[f'{coin}_Binance_Close'] = pd.to_numeric(df['close'], errors='coerce')\n",
    "            df_final[f'{coin}_Binance_Volume'] = pd.to_numeric(df['volume'], errors='coerce')\n",
    "            \n",
    "            # 5. 병합\n",
    "            if merged_df is None:\n",
    "                merged_df = df_final\n",
    "            else:\n",
    "                merged_df = pd.merge(merged_df, df_final, on='timestamp', how='outer')\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  - {symbol} Failed: {str(e)}\")\n",
    "            \n",
    "    if merged_df is not None:\n",
    "        save_df(merged_df.sort_values('timestamp'), \"binance_4h_kst.csv\")\n",
    "\n",
    "\n",
    "def collect_defi_tvl_safe():\n",
    "    print(f\"[7/7] Collecting DeFi TVL (Direct API)...\")\n",
    "    session = get_session()\n",
    "    \n",
    "    for name, url in DEFI_PROTOCOLS.items():\n",
    "        try:\n",
    "            print(f\"  - Fetching {name}...\", end=\" \")\n",
    "            time.sleep(2) # 요청 간격\n",
    "            \n",
    "            # [핵심 수정] 데이터가 큰 Uniswap/Curve를 위해 timeout을 120초로 연장\n",
    "            resp = session.get(url, timeout=120) \n",
    "            resp.raise_for_status()\n",
    "            data = resp.json()\n",
    "            \n",
    "            # 데이터 파싱\n",
    "            if name == 'eth_chain':\n",
    "                records = data\n",
    "                val_key = 'tvl'\n",
    "            else:\n",
    "                # Protocol은 전체 체인 데이터라 Ethereum만 발라내야 함\n",
    "                records = data.get('chainTvls', {}).get('Ethereum', {}).get('tvl', [])\n",
    "                val_key = 'totalLiquidityUSD'\n",
    "\n",
    "            if not records:\n",
    "                print(\"No data found.\")\n",
    "                continue\n",
    "\n",
    "            # DataFrame 변환\n",
    "            df = pd.DataFrame(records)\n",
    "            df['timestamp'] = pd.to_datetime(df['date'], unit='s').dt.tz_localize(UTC).dt.tz_convert(KST).dt.tz_localize(None)\n",
    "            df = df.set_index('timestamp').sort_index()\n",
    "            \n",
    "            # 4시간 봉으로 보간 (Interpolation)\n",
    "            df_4h = df[val_key].resample('4H').interpolate(method='linear').reset_index()\n",
    "            df_4h.columns = ['timestamp', f'{name}_tvl']\n",
    "            \n",
    "            save_df(df_4h, f\"{name}_tvl_4h.csv\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed: {str(e)[:50]}\") # 에러 메시지 짧게 출력\n",
    "\n",
    "    # USDT Market Cap\n",
    "    try:\n",
    "        print(f\"  - Fetching USDT Mcap...\", end=\" \")\n",
    "        time.sleep(2)\n",
    "        resp = session.get(\"https://stablecoins.llama.fi/stablecoincharts/ethereum?stablecoin=1\", timeout=60)\n",
    "        df = pd.DataFrame(resp.json())\n",
    "        df['timestamp'] = pd.to_datetime(df['date'], unit='s').dt.tz_localize(UTC).dt.tz_convert(KST).dt.tz_localize(None)\n",
    "        df = df.set_index('timestamp')['totalCirculating'].resample('4H').interpolate().reset_index()\n",
    "        df.columns = ['timestamp', 'usdt_eth_mcap']\n",
    "        save_df(df, \"usdt_eth_mcap_4h.csv\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed: {str(e)[:50]}\")\n",
    "\n",
    "# --- 나머지 함수들 (기존 정상 작동 코드) ---\n",
    "def collect_upbit_crypto_prices_4h():\n",
    "    print(f\"[1/7] Collecting Upbit Data (KST)...\")\n",
    "    session = get_session()\n",
    "    start_dt = pd.to_datetime(START_DATE)\n",
    "    merged_df = None\n",
    "    for market, (symbol, _) in UPBIT_CRYPTO_TICKERS.items():\n",
    "        try:\n",
    "            all_candles = []\n",
    "            to_date = None\n",
    "            while True:\n",
    "                params = {'market': market, 'count': 200}\n",
    "                if to_date: params['to'] = to_date\n",
    "                resp = session.get(\"https://api.upbit.com/v1/candles/minutes/240\", params=params, timeout=10)\n",
    "                resp.raise_for_status()\n",
    "                candles = resp.json()\n",
    "                if not candles: break\n",
    "                all_candles.extend(candles)\n",
    "                last_date = pd.to_datetime(candles[-1]['candle_date_time_kst'])\n",
    "                if last_date <= start_dt: break\n",
    "                to_date = candles[-1]['candle_date_time_utc']\n",
    "                time.sleep(0.05)\n",
    "            if all_candles:\n",
    "                df = pd.DataFrame(all_candles)\n",
    "                df['timestamp'] = pd.to_datetime(df['candle_date_time_kst']).dt.tz_localize(None)\n",
    "                df = df.rename(columns={'trade_price': f'{symbol}_Close', 'candle_acc_trade_volume': f'{symbol}_Volume'})\n",
    "                df = df[['timestamp', f'{symbol}_Close', f'{symbol}_Volume']].sort_values('timestamp')\n",
    "                df = df[df['timestamp'] >= start_dt]\n",
    "                merged_df = df if merged_df is None else pd.merge(merged_df, df, on='timestamp', how='outer')\n",
    "        except Exception as e: print(f\"  - {symbol} Failed: {e}\")\n",
    "    if merged_df is not None: save_df(merged_df.sort_values('timestamp'), \"crypto_4h_kst.csv\")\n",
    "\n",
    "def collect_macro_indicators_4h():\n",
    "    print(f\"[3/7] Collecting Macro Indicators (yfinance)...\")\n",
    "    for ticker, name in MACRO_TICKERS.items():\n",
    "        try:\n",
    "            df = yf.download(ticker, start=START_DATE, end=END_DATE, interval='1d', progress=False)\n",
    "            if df.empty: continue\n",
    "            if isinstance(df.columns, pd.MultiIndex): df = df.xs('Close', level=0, axis=1)\n",
    "            df.index = df.index.tz_localize(None) if df.index.tz is None else df.index.tz_convert(KST).tz_localize(None)\n",
    "            df_4h = df.resample('4H').ffill()\n",
    "            df_4h = df_4h[df_4h.index >= pd.to_datetime(START_DATE)]\n",
    "            df_4h.columns = [name]\n",
    "            save_df(df_4h.reset_index(), f\"{name}_4h.csv\")\n",
    "        except Exception: pass\n",
    "\n",
    "def collect_fear_greed_4h():\n",
    "    print(f\"[4/7] Collecting Fear & Greed Index...\")\n",
    "    try:\n",
    "        resp = get_session().get(\"https://api.alternative.me/fng/?limit=4000&format=json\", timeout=10)\n",
    "        df = pd.DataFrame(resp.json()['data'])\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s').dt.tz_localize(UTC).dt.tz_convert(KST).dt.tz_localize(None)\n",
    "        df = df.set_index('timestamp').sort_index()\n",
    "        df_4h = df['value'].astype(float).resample('4H').ffill().reset_index().rename(columns={'value': 'fear_greed'})\n",
    "        save_df(df_4h, \"fear_greed_4h.csv\")\n",
    "    except Exception: pass\n",
    "\n",
    "def collect_funding_rate_4h():\n",
    "    print(f\"[5/7] Collecting ETH Funding Rate...\")\n",
    "    try:\n",
    "        client = Client(\"\", \"\")\n",
    "        funding_rates = []\n",
    "        start_ts = int(pd.to_datetime(START_DATE).timestamp() * 1000)\n",
    "        end_ts = int(pd.to_datetime(END_DATE).timestamp() * 1000)\n",
    "        while start_ts < end_ts:\n",
    "            rates = client.futures_funding_rate(symbol='ETHUSDT', startTime=start_ts, limit=1000)\n",
    "            if not rates: break\n",
    "            funding_rates.extend(rates)\n",
    "            start_ts = rates[-1]['fundingTime'] + 1\n",
    "            time.sleep(0.1)\n",
    "        df = pd.DataFrame(funding_rates)\n",
    "        df['timestamp'] = pd.to_datetime(df['fundingTime'], unit='ms').dt.tz_localize(UTC).dt.tz_convert(KST).dt.tz_localize(None)\n",
    "        df = df[['timestamp', 'fundingRate']].astype({'fundingRate': float}).sort_values('timestamp')\n",
    "        save_df(df, \"eth_funding_rate_8h.csv\")\n",
    "    except Exception: pass\n",
    "\n",
    "def collect_eth_metrics_safe():\n",
    "    print(f\"[6/7] Collecting ETH Metrics (yfinance)...\")\n",
    "    try:\n",
    "        df = yf.download(\"ETH-USD\", start=START_DATE, end=END_DATE, interval=\"1d\", progress=False)\n",
    "        if isinstance(df.columns, pd.MultiIndex): df = df.xs('Close', level=0, axis=1)\n",
    "        df.index = df.index.tz_localize(None) if df.index.tz is None else df.index.tz_convert(KST).tz_localize(None)\n",
    "        df_4h = df.resample('4H').ffill()\n",
    "        df_4h = df_4h[df_4h.index >= pd.to_datetime(START_DATE)]\n",
    "        path = os.path.join(OUTPUT_DIR, \"eth_metrics_4h.csv\")\n",
    "        df_4h.to_csv(path)\n",
    "        print(f\"  - Saved: eth_metrics_4h.csv ({len(df_4h)} rows)\")\n",
    "    except Exception: pass\n",
    "\n",
    "# --- 메인 실행 ---\n",
    "print(\"=\"*60)\n",
    "print(\"Starting Data Collection Pipeline (Fix V3)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "collect_upbit_crypto_prices_4h()\n",
    "collect_binance_crypto_4h() # 수정된 버전 실행\n",
    "collect_macro_indicators_4h()\n",
    "collect_fear_greed_4h()\n",
    "collect_funding_rate_4h()\n",
    "collect_eth_metrics_safe()\n",
    "collect_defi_tvl_safe() # 수정된 버전 실행\n",
    "\n",
    "print(\"\\nPipeline Completed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d0774aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ETH Price Prediction - 4H Data Collection Pipeline (UTC Aligned)\n",
      "================================================================================\n",
      "\n",
      "[1/7] Collecting 4H cryptocurrency prices from Upbit (KST)...\n",
      "  - BTC: 15134 4H candles\n",
      "  - ETH: 15134 4H candles\n",
      "  - XRP: 15134 4H candles\n",
      "  - SOL: 9023 4H candles\n",
      "  - ADA: 15134 4H candles\n",
      "  - DOGE: 10421 4H candles\n",
      "  - AVAX: 8326 4H candles\n",
      "  - DOT: 11273 4H candles\n",
      "  Saved: ./macro_data_4h/crypto_4h_kst.csv\n",
      "\n",
      "[2/7] Collecting 4H data from Binance (UTC->KST)...\n",
      "  - BTC: 15128 4H candles\n",
      "  - ETH: 15128 4H candles\n",
      "  - XRP: 15128 4H candles\n",
      "  - SOL: 11604 4H candles\n",
      "  - ADA: 15128 4H candles\n",
      "  - DOGE: 14018 4H candles\n",
      "  - AVAX: 11352 4H candles\n",
      "  - DOT: 11558 4H candles\n",
      "  Saved: ./macro_data_4h/binance_4h_kst.csv\n",
      "\n",
      "[3/7] Collecting and resampling macro indicators to 4H (KST)...\n",
      "  - DXY: 15121 4H candles\n",
      "  - GOLD: 15121 4H candles\n",
      "  - VIX: 15121 4H candles\n",
      "  - SP500: 15121 4H candles\n",
      "\n",
      "[4/7] Collecting Fear & Greed Index (interpolated to 4H, KST)...\n",
      "  - Fear & Greed: 17137 4H candles\n",
      "\n",
      "[5/7] Collecting ETH funding rate (8H intervals, KST)...\n",
      "  - Funding Rate: 6576 8H intervals\n",
      "\n",
      "[6/7] Collecting ETH metrics from CoinGecko (KST)...\n",
      "  - CoinGecko: Failed (HTTPSConnectionPool(host='api.coingecko.com', port=443): Max retries exceeded with url: /api/v3/coin)\n",
      "\n",
      "[7/7] Collecting DeFi TVL (interpolated to 4H, KST)...\n",
      "  - ETH Chain TVL: 17899 4H candles\n",
      "  - makerdao: 15115 4H candles\n",
      "  - lido: 10819 4H candles\n",
      "    ...Retry 1/5 after 5s (HTTPSConnectionPool(host='api....)\n",
      "  - aave: 12103 4H candles\n",
      "    ...Retry 1/5 after 5s (HTTPSConnectionPool(host='api....)\n",
      "    ...Retry 2/5 after 10s (HTTPSConnectionPool(host='api....)\n",
      "    ...Retry 3/5 after 15s (HTTPSConnectionPool(host='api....)\n",
      "    ...Retry 4/5 after 20s (HTTPSConnectionPool(host='api....)\n",
      "  - uniswap: 15487 4H candles\n",
      "    ...Retry 1/5 after 5s (HTTPSConnectionPool(host='api....)\n",
      "  - curve-dex: 12709 4H candles\n",
      "  - USDT ETH Mcap: 17521 4H candles\n",
      "\n",
      "================================================================================\n",
      "4H Data collection completed!\n",
      "Output directory: ./macro_data_4h\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "import yfinance as yf\n",
    "from binance.client import Client\n",
    "from defillama2 import DefiLlama\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "START_DATE = \"2019-01-01\"\n",
    "END_DATE = (datetime.today() + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "OUTPUT_DIR = \"./macro_data_4h\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# 한국 시간대 설정\n",
    "KST = pytz.timezone('Asia/Seoul')\n",
    "UTC = pytz.UTC\n",
    "\n",
    "UPBIT_CRYPTO_TICKERS = {\n",
    "    'KRW-BTC': ('BTC', 'BTC'),\n",
    "    'KRW-ETH': ('ETH', 'ETH'),\n",
    "    'KRW-XRP': ('XRP', 'XRP'),\n",
    "    'KRW-SOL': ('SOL', 'SOL'),\n",
    "    'KRW-ADA': ('ADA', 'ADA'),\n",
    "    'KRW-DOGE': ('DOGE', 'DOGE'),\n",
    "    'KRW-AVAX': ('AVAX', 'AVAX'),\n",
    "    'KRW-DOT': ('DOT', 'DOT')\n",
    "}\n",
    "\n",
    "MACRO_TICKERS = {\n",
    "    'DX-Y.NYB': 'DXY',\n",
    "    'GC=F': 'GOLD',\n",
    "    '^VIX': 'VIX',\n",
    "    '^GSPC': 'SP500'\n",
    "}\n",
    "\n",
    "DEFI_PROTOCOLS = ['makerdao', 'lido', 'aave', 'uniswap', 'curve-dex']\n",
    "\n",
    "# 재시도 로직이 포함된 세션 생성 함수 (User-Agent 추가)\n",
    "def get_retry_session(retries=5, backoff_factor=2, status_forcelist=(429, 500, 502, 503, 504)):\n",
    "    session = requests.Session()\n",
    "    # 차단 방지를 위한 User-Agent 헤더 추가\n",
    "    session.headers.update({\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    })\n",
    "    retry = Retry(\n",
    "        total=retries,\n",
    "        read=retries,\n",
    "        connect=retries,\n",
    "        backoff_factor=backoff_factor,\n",
    "        status_forcelist=status_forcelist,\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    return session\n",
    "\n",
    "def collect_upbit_crypto_prices_4h():\n",
    "    \"\"\"업비트 4시간봉 암호화폐 가격 수집 (KST 기준)\"\"\"\n",
    "    print(f\"\\n[1/7] Collecting 4H cryptocurrency prices from Upbit (KST)...\")\n",
    "    session = get_retry_session()\n",
    "    \n",
    "    start_dt = pd.to_datetime(START_DATE)\n",
    "    merged_df = None\n",
    "    \n",
    "    for market, (symbol, _) in UPBIT_CRYPTO_TICKERS.items():\n",
    "        try:\n",
    "            all_candles = []\n",
    "            to_date = None\n",
    "            \n",
    "            while True:\n",
    "                url = f\"https://api.upbit.com/v1/candles/minutes/240\"\n",
    "                params = {'market': market, 'count': 200}\n",
    "                if to_date:\n",
    "                    params['to'] = to_date\n",
    "                \n",
    "                response = session.get(url, params=params, timeout=10)\n",
    "                response.raise_for_status()\n",
    "                candles = response.json()\n",
    "                \n",
    "                if not candles:\n",
    "                    break\n",
    "                \n",
    "                all_candles.extend(candles)\n",
    "                oldest_date = pd.to_datetime(candles[-1]['candle_date_time_kst'])\n",
    "                \n",
    "                if oldest_date <= start_dt:\n",
    "                    break\n",
    "                \n",
    "                to_date = candles[-1]['candle_date_time_utc']\n",
    "                time.sleep(0.1)\n",
    "            \n",
    "            if not all_candles:\n",
    "                print(f\"  - {symbol}: No data\")\n",
    "                continue\n",
    "            \n",
    "            df = pd.DataFrame(all_candles)\n",
    "            df['timestamp'] = pd.to_datetime(df['candle_date_time_kst'])\n",
    "            df['timestamp'] = df['timestamp'].dt.tz_localize(None)\n",
    "            \n",
    "            df = df.rename(columns={\n",
    "                'opening_price': f'{symbol}_Open',\n",
    "                'high_price': f'{symbol}_High',\n",
    "                'low_price': f'{symbol}_Low',\n",
    "                'trade_price': f'{symbol}_Close',\n",
    "                'candle_acc_trade_volume': f'{symbol}_Volume'\n",
    "            })\n",
    "            \n",
    "            df = df[['timestamp', f'{symbol}_Open', f'{symbol}_High', \n",
    "                    f'{symbol}_Low', f'{symbol}_Close', f'{symbol}_Volume']]\n",
    "            df = df.sort_values('timestamp')\n",
    "            df = df[df['timestamp'] >= start_dt]\n",
    "            \n",
    "            if merged_df is None:\n",
    "                merged_df = df\n",
    "            else:\n",
    "                merged_df = pd.merge(merged_df, df, on='timestamp', how='outer')\n",
    "            \n",
    "            print(f\"  - {symbol}: {len(df)} 4H candles\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  - {symbol}: Failed ({str(e)[:50]})\")\n",
    "    \n",
    "    if merged_df is not None:\n",
    "        merged_df = merged_df.sort_values('timestamp')\n",
    "        output_path = os.path.join(OUTPUT_DIR, \"crypto_4h_kst.csv\")\n",
    "        merged_df.to_csv(output_path, index=False)\n",
    "        print(f\"  Saved: {output_path}\")\n",
    "\n",
    "def collect_binance_crypto_4h():\n",
    "    \"\"\"바이낸스에서 4시간봉 데이터 수집 (UTC -> KST 변환)\"\"\"\n",
    "    print(f\"\\n[2/7] Collecting 4H data from Binance (UTC->KST)...\")\n",
    "    \n",
    "    # API 키가 없어도 공개 데이터는 수집 가능할 수 있으나, 제한이 있을 수 있음\n",
    "    client = Client(\"\", \"\")\n",
    "    symbols = ['BTCUSDT', 'ETHUSDT', 'XRPUSDT', 'SOLUSDT', 'ADAUSDT', \n",
    "               'DOGEUSDT', 'AVAXUSDT', 'DOTUSDT']\n",
    "    \n",
    "    merged_df = None\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        try:\n",
    "            coin_name = symbol.replace('USDT', '')\n",
    "            klines = client.get_historical_klines(\n",
    "                symbol, \n",
    "                Client.KLINE_INTERVAL_4HOUR,\n",
    "                START_DATE,\n",
    "                END_DATE\n",
    "            )\n",
    "            \n",
    "            df = pd.DataFrame(klines, columns=[\n",
    "                'timestamp', 'open', 'high', 'low', 'close', 'volume',\n",
    "                'close_time', 'quote_volume', 'trades', 'taker_buy_base',\n",
    "                'taker_buy_quote', 'ignore'\n",
    "            ])\n",
    "            \n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "            df['timestamp'] = df['timestamp'].dt.tz_localize(UTC).dt.tz_convert(KST)\n",
    "            df['timestamp'] = df['timestamp'].dt.tz_localize(None)\n",
    "            df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']]\n",
    "            \n",
    "            for col in ['open', 'high', 'low', 'close', 'volume']:\n",
    "                df[col] = df[col].astype(float)\n",
    "            \n",
    "            df = df.rename(columns={\n",
    "                'open': f'{coin_name}_Binance_Open',\n",
    "                'high': f'{coin_name}_Binance_High',\n",
    "                'low': f'{coin_name}_Binance_Low',\n",
    "                'close': f'{coin_name}_Binance_Close',\n",
    "                'volume': f'{coin_name}_Binance_Volume'\n",
    "            })\n",
    "            \n",
    "            if merged_df is None:\n",
    "                merged_df = df\n",
    "            else:\n",
    "                merged_df = pd.merge(merged_df, df, on='timestamp', how='outer')\n",
    "            \n",
    "            print(f\"  - {coin_name}: {len(df)} 4H candles\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  - {symbol}: Failed ({str(e)[:50]})\")\n",
    "    \n",
    "    if merged_df is not None:\n",
    "        output_path = os.path.join(OUTPUT_DIR, \"binance_4h_kst.csv\")\n",
    "        merged_df.to_csv(output_path, index=False)\n",
    "        print(f\"  Saved: {output_path}\")\n",
    "\n",
    "def collect_macro_indicators_4h():\n",
    "    \"\"\"거시경제 지표 수집 (1일 -> 4시간)\"\"\"\n",
    "    print(f\"\\n[3/7] Collecting and resampling macro indicators to 4H (KST)...\")\n",
    "    \n",
    "    for ticker, name in MACRO_TICKERS.items():\n",
    "        try:\n",
    "            df = yf.download(ticker, start=START_DATE, end=END_DATE, \n",
    "                           interval='1d', progress=False)\n",
    "            \n",
    "            if df.empty:\n",
    "                print(f\"  - {name}: No data available\")\n",
    "                continue\n",
    "            \n",
    "            if isinstance(df.columns, pd.MultiIndex):\n",
    "                df = df.xs('Close', level=0, axis=1)\n",
    "            else:\n",
    "                df = df[['Close']]\n",
    "                \n",
    "            df.index = pd.to_datetime(df.index)\n",
    "            \n",
    "            if df.index.tz is None:\n",
    "                df.index = df.index.tz_localize(UTC)\n",
    "            else:\n",
    "                df.index = df.index.tz_convert(UTC)\n",
    "            \n",
    "            df.index = df.index.tz_convert(KST)\n",
    "            df.index = df.index.tz_localize(None)\n",
    "            \n",
    "            df_4h = df.resample('4H').ffill()\n",
    "            df_4h = df_4h[df_4h.index >= pd.to_datetime(START_DATE)]\n",
    "            \n",
    "            df_4h.columns = [name]\n",
    "            df_4h.index.name = 'timestamp'\n",
    "            \n",
    "            output_path = os.path.join(OUTPUT_DIR, f\"{name}_4h.csv\")\n",
    "            df_4h.to_csv(output_path)\n",
    "            print(f\"  - {name}: {len(df_4h)} 4H candles\")\n",
    "        except Exception as e:\n",
    "            print(f\"  - {name}: Failed ({str(e)[:50]})\")\n",
    "\n",
    "def collect_fear_greed_4h():\n",
    "    \"\"\"Fear & Greed Index (4H, KST)\"\"\"\n",
    "    print(f\"\\n[4/7] Collecting Fear & Greed Index (interpolated to 4H, KST)...\")\n",
    "    session = get_retry_session()\n",
    "    \n",
    "    try:\n",
    "        url = \"https://api.alternative.me/fng/?limit=4000&format=json\"\n",
    "        response = session.get(url, timeout=10)\n",
    "        data = response.json()['data']\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "        df['timestamp'] = df['timestamp'].dt.tz_localize(UTC).dt.tz_convert(KST)\n",
    "        df['timestamp'] = df['timestamp'].dt.tz_localize(None)\n",
    "        df = df[['timestamp', 'value']].rename(columns={'value': 'fear_greed'})\n",
    "        df['fear_greed'] = df['fear_greed'].astype(float)\n",
    "        df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "        \n",
    "        df = df.set_index('timestamp')\n",
    "        df_4h = df.resample('4H').ffill().reset_index()\n",
    "        \n",
    "        output_path = os.path.join(OUTPUT_DIR, \"fear_greed_4h.csv\")\n",
    "        df_4h.to_csv(output_path, index=False)\n",
    "        print(f\"  - Fear & Greed: {len(df_4h)} 4H candles\")\n",
    "    except Exception as e:\n",
    "        print(f\"  - Fear & Greed: Failed ({str(e)[:50]})\")\n",
    "\n",
    "def collect_funding_rate_4h():\n",
    "    \"\"\"ETH 펀딩비 (8H -> KST)\"\"\"\n",
    "    print(f\"\\n[5/7] Collecting ETH funding rate (8H intervals, KST)...\")\n",
    "    \n",
    "    try:\n",
    "        client = Client(\"\", \"\")\n",
    "        funding_rates = []\n",
    "        \n",
    "        start_time = int(datetime.strptime(START_DATE, \"%Y-%m-%d\").timestamp() * 1000)\n",
    "        end_time = int(datetime.strptime(END_DATE, \"%Y-%m-%d\").timestamp() * 1000)\n",
    "        current_ts = start_time\n",
    "        \n",
    "        while current_ts < end_time:\n",
    "            rates = client.futures_funding_rate(\n",
    "                symbol='ETHUSDT',\n",
    "                startTime=current_ts,\n",
    "                limit=1000\n",
    "            )\n",
    "            if not rates:\n",
    "                break\n",
    "            funding_rates.extend(rates)\n",
    "            current_ts = rates[-1]['fundingTime'] + 1\n",
    "            time.sleep(0.1)\n",
    "        \n",
    "        df = pd.DataFrame(funding_rates)\n",
    "        df['timestamp'] = pd.to_datetime(df['fundingTime'], unit='ms')\n",
    "        df['timestamp'] = df['timestamp'].dt.tz_localize(UTC).dt.tz_convert(KST)\n",
    "        df['timestamp'] = df['timestamp'].dt.tz_localize(None)\n",
    "        df['fundingRate'] = df['fundingRate'].astype(float)\n",
    "        df = df[['timestamp', 'fundingRate']].sort_values('timestamp')\n",
    "        \n",
    "        output_path = os.path.join(OUTPUT_DIR, \"eth_funding_rate_8h.csv\")\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"  - Funding Rate: {len(df)} 8H intervals\")\n",
    "    except Exception as e:\n",
    "        print(f\"  - Funding Rate: Failed ({str(e)[:50]})\")\n",
    "\n",
    "def collect_coingecko_eth_metrics():\n",
    "    \"\"\"CoinGecko 메트릭 수집 (Retry 로직 강화 및 타임아웃 연장)\"\"\"\n",
    "    print(f\"\\n[6/7] Collecting ETH metrics from CoinGecko (KST)...\")\n",
    "    session = get_retry_session()\n",
    "    \n",
    "    try:\n",
    "        url = \"https://api.coingecko.com/api/v3/coins/ethereum/market_chart\"\n",
    "        params = {\n",
    "            'vs_currency': 'usd',\n",
    "            'days': 'max',\n",
    "            'interval': 'daily'\n",
    "        }\n",
    "        \n",
    "        # 타임아웃을 30초로 증가\n",
    "        response = session.get(url, params=params, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'timestamp': [pd.to_datetime(x[0], unit='ms') for x in data['prices']],\n",
    "            'market_cap': [x[1] for x in data['market_caps']],\n",
    "            'total_volume': [x[1] for x in data['total_volumes']]\n",
    "        })\n",
    "        \n",
    "        df['timestamp'] = df['timestamp'].dt.tz_localize(UTC).dt.tz_convert(KST)\n",
    "        df['timestamp'] = df['timestamp'].dt.tz_localize(None)\n",
    "        \n",
    "        df = df.set_index('timestamp')\n",
    "        df_4h = df.resample('4H').interpolate(method='linear').reset_index()\n",
    "        \n",
    "        output_path = os.path.join(OUTPUT_DIR, \"eth_coingecko_4h.csv\")\n",
    "        df_4h.to_csv(output_path, index=False)\n",
    "        print(f\"  - ETH Market Data: {len(df_4h)} 4H candles\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  - CoinGecko: Failed ({str(e)[:100]})\")\n",
    "\n",
    "def safe_tz_convert(date_series, target_tz):\n",
    "    \"\"\"타임존 유무를 확인하여 안전하게 변환하는 헬퍼 함수\"\"\"\n",
    "    if date_series.dt.tz is None:\n",
    "        return date_series.dt.tz_localize(UTC).dt.tz_convert(target_tz)\n",
    "    else:\n",
    "        return date_series.dt.tz_convert(target_tz)\n",
    "\n",
    "def collect_defi_tvl_4h():\n",
    "    \"\"\"DeFi TVL 수집 (Retry 대기시간 증가 및 예외 처리 강화)\"\"\"\n",
    "    print(f\"\\n[7/7] Collecting DeFi TVL (interpolated to 4H, KST)...\")\n",
    "    \n",
    "    obj = DefiLlama()\n",
    "    \n",
    "    # Retry 래퍼 함수 (Exponential Backoff 적용)\n",
    "    def run_with_retry(func, *args, retries=5):\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                return func(*args)\n",
    "            except Exception as e:\n",
    "                if attempt == retries - 1:\n",
    "                    raise e\n",
    "                # 5, 10, 15, 20, 25초 대기 (Uniswap 같은 큰 데이터 타임아웃 방지)\n",
    "                sleep_time = 5 * (attempt + 1)\n",
    "                print(f\"    ...Retry {attempt+1}/{retries} after {sleep_time}s ({str(e)[:30]}...)\")\n",
    "                time.sleep(sleep_time)\n",
    "    \n",
    "    # 1. Ethereum Chain TVL\n",
    "    try:\n",
    "        df = run_with_retry(obj.get_chain_hist_tvl, 'Ethereum')\n",
    "        df = df.reset_index().rename(columns={'tvl': 'eth_chain_tvl'})\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        \n",
    "        df['date'] = safe_tz_convert(df['date'], KST)\n",
    "        df['date'] = df['date'].dt.tz_localize(None)\n",
    "        \n",
    "        df = df.set_index('date')\n",
    "        df_4h = df.resample('4H').interpolate(method='linear').reset_index()\n",
    "        df_4h = df_4h.rename(columns={'date': 'timestamp'})\n",
    "        \n",
    "        output_path = os.path.join(OUTPUT_DIR, 'eth_chain_tvl_4h.csv')\n",
    "        df_4h.to_csv(output_path, index=False)\n",
    "        print(f\"  - ETH Chain TVL: {len(df_4h)} 4H candles\")\n",
    "    except Exception as e:\n",
    "        print(f\"  - ETH Chain TVL: Failed ({str(e)[:50]})\")\n",
    "    \n",
    "    # 2. Protocol TVL\n",
    "    for protocol in DEFI_PROTOCOLS:\n",
    "        try:\n",
    "            tvl_dict = run_with_retry(obj.get_protocol_hist_tvl_by_chain, protocol)\n",
    "            \n",
    "            if 'Ethereum' in tvl_dict:\n",
    "                df = tvl_dict['Ethereum'].reset_index()\n",
    "                df = df.rename(columns={'tvl': f'{protocol}_eth_tvl'})\n",
    "                df['date'] = pd.to_datetime(df['date'])\n",
    "                \n",
    "                df['date'] = safe_tz_convert(df['date'], KST)\n",
    "                df['date'] = df['date'].dt.tz_localize(None)\n",
    "                \n",
    "                df = df.set_index('date')\n",
    "                df_4h = df.resample('4H').interpolate(method='linear').reset_index()\n",
    "                df_4h = df_4h.rename(columns={'date': 'timestamp'})\n",
    "                \n",
    "                output_path = os.path.join(OUTPUT_DIR, f'{protocol}_eth_tvl_4h.csv')\n",
    "                df_4h.to_csv(output_path, index=False)\n",
    "                print(f\"  - {protocol}: {len(df_4h)} 4H candles\")\n",
    "            else:\n",
    "                print(f\"  - {protocol}: No Ethereum data\")\n",
    "        except Exception as e:\n",
    "            print(f\"  - {protocol}: Failed ({str(e)[:50]})\")\n",
    "    \n",
    "    # 3. USDT Market Cap\n",
    "    try:\n",
    "        df = run_with_retry(obj.get_stablecoin_hist_mcap_on_a_chain, 1, 'ethereum')\n",
    "        df = df.reset_index().rename(columns={'mcap': 'usdt_eth_mcap'})\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        \n",
    "        df['date'] = safe_tz_convert(df['date'], KST)\n",
    "        df['date'] = df['date'].dt.tz_localize(None)\n",
    "        \n",
    "        df = df.set_index('date')\n",
    "        df_4h = df.resample('4H').interpolate(method='linear').reset_index()\n",
    "        df_4h = df_4h.rename(columns={'date': 'timestamp'})\n",
    "        \n",
    "        output_path = os.path.join(OUTPUT_DIR, 'usdt_eth_mcap_4h.csv')\n",
    "        df_4h.to_csv(output_path, index=False)\n",
    "        print(f\"  - USDT ETH Mcap: {len(df_4h)} 4H candles\")\n",
    "    except Exception as e:\n",
    "        print(f\"  - USDT ETH Mcap: Failed ({str(e)[:50]})\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ETH Price Prediction - 4H Data Collection Pipeline (UTC Aligned)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "collect_upbit_crypto_prices_4h()\n",
    "collect_binance_crypto_4h()\n",
    "collect_macro_indicators_4h()\n",
    "collect_fear_greed_4h()\n",
    "collect_funding_rate_4h()\n",
    "collect_coingecko_eth_metrics()\n",
    "collect_defi_tvl_4h()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"4H Data collection completed!\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc36941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "OUTPUT_DIR = \"./macro_data_4h\"\n",
    "\n",
    "def merge_all_datasets():\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Starting Data Merge Process...\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "\n",
    "    base_file = os.path.join(OUTPUT_DIR, \"crypto_4h_kst.csv\")\n",
    "    \n",
    "    if not os.path.exists(base_file):\n",
    "        print(f\"Error: Base file {base_file} not found!\")\n",
    "        return\n",
    "\n",
    "    df_master = pd.read_csv(base_file)\n",
    "    df_master['timestamp'] = pd.to_datetime(df_master['timestamp'])\n",
    "    df_master = df_master.sort_values('timestamp')\n",
    "    \n",
    "    print(f\"Base Dataset (Binance): {df_master.shape} rows loaded.\")\n",
    "    print(f\"Range: {df_master['timestamp'].min()} ~ {df_master['timestamp'].max()}\")\n",
    "\n",
    "    # 2. 나머지 모든 CSV 파일 찾기\n",
    "    all_files = glob.glob(os.path.join(OUTPUT_DIR, \"*.csv\"))\n",
    "    \n",
    "    for file_path in all_files:\n",
    "        # 기준 파일은 건너뜀\n",
    "        if file_path == base_file:\n",
    "            continue\n",
    "            \n",
    "        file_name = os.path.basename(file_path)\n",
    "        print(f\"Merging {file_name}...\", end=\" \")\n",
    "        \n",
    "        try:\n",
    "            # 파일 로드\n",
    "            df_temp = pd.read_csv(file_path)\n",
    "            df_temp['timestamp'] = pd.to_datetime(df_temp['timestamp'])\n",
    "            \n",
    "            df_master = pd.merge(df_master, df_temp, on='timestamp', how='left')\n",
    "            print(\"Done.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed! ({str(e)})\")\n",
    "\n",
    "\n",
    "    print(\"\\nFilling missing values (Forward Fill)...\")\n",
    "    df_master = df_master.ffill()\n",
    "    \n",
    "    # 4. 최종 저장\n",
    "    final_path = \"./final_dataset_4h_kst.csv\"\n",
    "    df_master.to_csv(final_path, index=False)\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Merge Completed! Final Shape: {df_master.shape}\")\n",
    "    print(f\"Saved to: {final_path}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "# 실행\n",
    "merge_all_datasets()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

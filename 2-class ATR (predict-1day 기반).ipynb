{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "758590ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 19:10:01.953456: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-26 19:10:01.953492: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-26 19:10:01.954806: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-26 19:10:01.961845: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-26 19:10:02.772951: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ‚öôÔ∏è Í∏∞Î≥∏ ÎùºÏù¥Î∏åÎü¨Î¶¨ Î∞è ÏãúÏä§ÌÖú Ïú†Ìã∏Î¶¨Ìã∞\n",
    "# ============================================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "import time\n",
    "import json\n",
    "import joblib\n",
    "import traceback\n",
    "from dotenv import load_dotenv\n",
    "from collections import Counter\n",
    "from numba import jit # JIT Ïª¥ÌååÏùºÎü¨\n",
    "from datetime import datetime, timedelta # ÎÇ†Ïßú/ÏãúÍ∞Ñ Ï≤òÎ¶¨\n",
    "\n",
    "# ============================================================================\n",
    "# üìä Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ Î∞è Î∂ÑÏÑù\n",
    "# ============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta # Í∏∞Ïà†Ï†Å Î∂ÑÏÑù ÎùºÏù¥Î∏åÎü¨Î¶¨\n",
    "\n",
    "# ============================================================================\n",
    "# üìà Î®∏Ïã†Îü¨Îãù (Scikit-learn)\n",
    "# ============================================================================\n",
    "\n",
    "# üìå Ï†ÑÏ≤òÎ¶¨ Î∞è ÏÑ†ÌÉù\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest, RFE,\n",
    "    mutual_info_classif, mutual_info_regression\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler,MinMaxScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight # ÌÅ¥ÎûòÏä§ Î∂àÍ∑†Ìòï Ï≤òÎ¶¨\n",
    "\n",
    "# üìå Î™®Îç∏ (Í∏∞Î≥∏)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neural_network import MLPClassifier # Multi-layer Perceptron\n",
    "\n",
    "# üìå Î™®Îç∏ (ÏïôÏÉÅÎ∏î)\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier, AdaBoostRegressor,\n",
    "    BaggingClassifier, BaggingRegressor,\n",
    "    ExtraTreesClassifier, ExtraTreesRegressor,\n",
    "    GradientBoostingClassifier, GradientBoostingRegressor,\n",
    "    HistGradientBoostingClassifier, # ÌûàÏä§ÌÜ†Í∑∏Îû® Í∏∞Î∞ò GB\n",
    "    RandomForestClassifier, RandomForestRegressor,\n",
    "    StackingClassifier, StackingRegressor,\n",
    "    VotingClassifier, VotingRegressor\n",
    ")\n",
    "\n",
    "# üìå ÌèâÍ∞Ä ÏßÄÌëú\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, # Î∂ÑÎ•ò\n",
    "    mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error, # ÌöåÍ∑Ä\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# üöÄ Î∂ÄÏä§ÌåÖ Í≥ÑÏó¥ Î™®Îç∏\n",
    "# ============================================================================\n",
    "import optuna # ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏµúÏ†ÅÌôî\n",
    "\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from lightgbm.callback import early_stopping\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "# ============================================================================\n",
    "# üß† Îî•Îü¨Îãù (TensorFlow/Keras)\n",
    "# ============================================================================\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    # Í∏∞Î≥∏\n",
    "    Input, Dense, Flatten, Dropout, Activation,\n",
    "    # RNN/ÏãúÌÄÄÏä§\n",
    "    LSTM, GRU, SimpleRNN, Bidirectional, TimeDistributed, RepeatVector,\n",
    "    # CNN\n",
    "    Conv1D, MaxPooling1D, AveragePooling1D,\n",
    "    GlobalAveragePooling1D, GlobalMaxPooling1D,\n",
    "    # Ï†ïÍ∑úÌôî\n",
    "    BatchNormalization, LayerNormalization,\n",
    "    # Ïú†Ìã∏Î¶¨Ìã∞\n",
    "    Concatenate, Add, Multiply, Lambda, Reshape, Permute\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1_l2, l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# ============================================================================\n",
    "# ‚è±Ô∏è ÏãúÍ≥ÑÏó¥ Î∂ÑÏÑù (Statsmodels)\n",
    "# ============================================================================\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "\n",
    "# ============================================================================\n",
    "# ‚ö° PyTorch (ÏÑ†ÌÉùÏ†Å)\n",
    "# ============================================================================\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "except ImportError:\n",
    "    # PyTorchÍ∞Ä ÏÑ§ÏπòÎêòÏßÄ ÏïäÏùÄ Í≤ΩÏö∞ Î¨¥Ïãú\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c1edbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================================\n",
    "# 1. Ïú†Ìã∏Î¶¨Ìã∞ Ìï®Ïàò (ÏßÄÌëú Ï∂îÍ∞ÄÏö©)\n",
    "# ==========================================================================\n",
    "\n",
    "def add_indicator_to_df(df_ta, indicator):\n",
    "    \"\"\"pandas_ta ÏßÄÌëú Í≤∞Í≥ºÎ•º DataFrameÏóê ÏïàÏ†ÑÌïòÍ≤å Ï∂îÍ∞Ä\"\"\"\n",
    "    if indicator is None:\n",
    "        return\n",
    "\n",
    "    if isinstance(indicator, pd.DataFrame) and not indicator.empty:\n",
    "        for col in indicator.columns:\n",
    "            df_ta[col] = indicator[col]\n",
    "    elif isinstance(indicator, pd.Series) and not indicator.empty:\n",
    "        colname = indicator.name if indicator.name else 'Unnamed'\n",
    "        df_ta[colname] = indicator\n",
    "\n",
    "def safe_add(df_ta, func, *args, **kwargs):\n",
    "    \"\"\"ÏßÄÌëú ÏÉùÏÑ± Ïãú Ïò§Î•ò Î∞©ÏßÄÎ•º ÏúÑÌïú ÎûòÌçº Ìï®Ïàò\"\"\"\n",
    "    try:\n",
    "        result = func(*args, **kwargs)\n",
    "        add_indicator_to_df(df_ta, result)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "# ==========================================================================\n",
    "# 2. Í∏∞Ïà†Ï†Å ÏßÄÌëú ÏÉùÏÑ± (Sniper Optimization)\n",
    "# ==========================================================================\n",
    "\n",
    "def calculate_technical_indicators(df):\n",
    "    \"\"\"\n",
    "    [1Ïñµ ÌòÑÎ¨º Ìà¨ÏûêÏö© ÏµúÏ†ÅÌôî ÏßÄÌëú]\n",
    "    - Ï§ëÎ≥µ ÏßÄÌëú(TEMA, DEMA Îì±) Ï†úÍ±∞\n",
    "    - Swing High/Low Breakout(ÎèåÌåå Îß§Îß§) ÏßÄÌëú Ï∂îÍ∞Ä\n",
    "    \"\"\"\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    df_ta = df.copy()\n",
    "\n",
    "    close = df['ETH_Close']\n",
    "    high = df.get('ETH_High', close)\n",
    "    low = df.get('ETH_Low', close)\n",
    "    volume = df.get('ETH_Volume', pd.Series(index=df.index, data=1))\n",
    "    open_ = df.get('ETH_Open', close)\n",
    "\n",
    "    # 1. [Î≥ÄÎèôÏÑ±] ATR Î∞è Î≥ºÎ¶∞Ï†Ä Î∞¥Îìú\n",
    "    df_ta['ATR_14'] = ta.atr(high, low, close, length=14)\n",
    "    bb = ta.bbands(close, length=20, std=2)\n",
    "    if bb is not None:\n",
    "        df_ta['BB_WIDTH'] = bb.iloc[:, 2]  # Bandwidth\n",
    "\n",
    "    # 2. [Ï∂îÏÑ∏] Ïã†Î¢∞ÎèÑ ÎÜíÏùÄ Ïù¥ÌèâÏÑ†Îßå Ïú†ÏßÄ\n",
    "    df_ta['SMA_20'] = ta.sma(close, length=20)\n",
    "    df_ta['SMA_50'] = ta.sma(close, length=50)\n",
    "    df_ta['EMA_12'] = ta.ema(close, length=12)\n",
    "    \n",
    "    # Ï∂îÏÑ∏ Ï†êÏàò (Ï†ïÎ∞∞Ïó¥ Ïó¨Î∂Ä)\n",
    "    df_ta['TREND_SCORE'] = (close > df_ta['SMA_20']).astype(int) + (df_ta['SMA_20'] > df_ta['SMA_50']).astype(int)\n",
    "\n",
    "    # 3. [Î™®Î©òÌÖÄ] RSI, MACD\n",
    "    df_ta['RSI_14'] = ta.rsi(close, length=14)\n",
    "    safe_add(df_ta, ta.macd, close, fast=12, slow=26, signal=9)\n",
    "\n",
    "    # 4. [Í±∞ÎûòÎüâ] OBV, MFI, ÏÉÅÎåÄ Í±∞ÎûòÎüâ\n",
    "    df_ta['OBV'] = ta.obv(close, volume)\n",
    "    df_ta['MFI_14'] = ta.mfi(high, low, close, volume, length=14)\n",
    "    df_ta['VOLUME_RATIO'] = volume / (volume.rolling(20).mean() + 1e-8)\n",
    "\n",
    "    # 5. [Ìå®ÌÑ¥] ÏúóÍº¨Î¶¨/ÏïÑÎû´Íº¨Î¶¨\n",
    "    df_ta['UPPER_SHADOW'] = (high - np.maximum(close, open_)) / (high - low + 1e-9)\n",
    "    df_ta['LOWER_SHADOW'] = (np.minimum(close, open_) - low) / (high - low + 1e-9)\n",
    "\n",
    "    # 6. [ÌïµÏã¨] Swing Breakout (Ï†ÄÌï≠/ÏßÄÏßÄ ÎèåÌåå)\n",
    "    for window in [5, 20, 60]:\n",
    "        swing_high = high.rolling(window).max().shift(1)\n",
    "        swing_low = low.rolling(window).min().shift(1)\n",
    "        \n",
    "        # ÏúÑÏπò (1.0 ÎèåÌåå Ïãú Îß§Ïàò Ïã†Ìò∏)\n",
    "        df_ta[f'PRICE_VS_HIGH_{window}d'] = close / (swing_high + 1e-9)\n",
    "        df_ta[f'PRICE_VS_LOW_{window}d'] = close / (swing_low + 1e-9)\n",
    "        \n",
    "        # ÎèåÌåå Í∞ïÎèÑ (ATR ÎåÄÎπÑ)\n",
    "        df_ta[f'BREAKOUT_STR_{window}d'] = (close - swing_high) / (df_ta['ATR_14'] + 1e-9)\n",
    "\n",
    "    return df_ta\n",
    "\n",
    "# ==========================================================================\n",
    "# 3. ÌååÏÉù Î≥ÄÏàò Î∞è Ï†ÑÏ≤òÎ¶¨ Ìï®Ïàò \n",
    "# ==========================================================================\n",
    "\n",
    "def add_enhanced_cross_crypto_features(df):\n",
    "    df_enhanced = df.copy()\n",
    "    df_enhanced['eth_return'] = df['ETH_Close'].pct_change().fillna(0)\n",
    "    \n",
    "    if 'BTC_Close' in df.columns:\n",
    "        df_enhanced['btc_return'] = df['BTC_Close'].pct_change().fillna(0)\n",
    "        # ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ\n",
    "        for window in [7, 30]:\n",
    "            df_enhanced[f'eth_btc_corr_{window}d'] = (\n",
    "                df_enhanced['eth_return'].rolling(window).corr(df_enhanced['btc_return'])\n",
    "            ).fillna(0)\n",
    "        # Ïä§ÌîÑÎ†àÎìú\n",
    "        df_enhanced['eth_btc_spread'] = df_enhanced['eth_return'] - df_enhanced['btc_return']\n",
    "        \n",
    "    return df_enhanced\n",
    "\n",
    "def add_price_lag_features_first(df):\n",
    "    \"\"\"Í∞ÄÍ≤© Ìå®ÌÑ¥ ÌïôÏäµÏö© Lag\"\"\"\n",
    "    df_new = df.copy()\n",
    "    close = df['ETH_Close']\n",
    "    # ÌïµÏã¨Ï†ÅÏù∏ 1, 2, 3, 5, 10Ïùº Ï†ÑÎßå ÌôïÏù∏\n",
    "    for lag in [1, 2, 3, 5, 10]:\n",
    "        df_new[f'return_lag{lag}'] = close.pct_change(periods=lag).shift(1)\n",
    "    return df_new\n",
    "\n",
    "def add_interaction_features(df):\n",
    "    df_interact = df.copy()\n",
    "    # Í±∞ÎûòÎüâ Ïã§Î¶∞ ÏßÄÌëú ÌôïÏù∏\n",
    "    if 'RSI_14' in df.columns and 'VOLUME_RATIO' in df.columns:\n",
    "        df_interact['RSI_Volume_Strength'] = df['RSI_14'] * df['VOLUME_RATIO']\n",
    "    return df_interact\n",
    "\n",
    "def add_volatility_regime_features(df):\n",
    "    df_regime = df.copy()\n",
    "    # Î≥ÄÎèôÏÑ± Ï≤¥Ï†ú ÌôïÏù∏\n",
    "    if 'ATR_14' in df.columns:\n",
    "        atr_ma = df['ATR_14'].rolling(20).mean()\n",
    "        df_regime['high_volatility_regime'] = (df['ATR_14'] > atr_ma).astype(int)\n",
    "    return df_regime\n",
    "\n",
    "def add_percentile_features(df):\n",
    "    df_pct = df.copy()\n",
    "    # ÌòÑÏû¨ Í∞ÄÍ≤© ÏúÑÏπò (Îû≠ÌÅ¨)\n",
    "    if 'ETH_Close' in df.columns:\n",
    "        df_pct['price_rank_250d'] = df['ETH_Close'].rolling(250).rank(pct=True)\n",
    "    return df_pct\n",
    "\n",
    "def preprocess_non_stationary_features(df):\n",
    "    \"\"\"Ïô∏Î∂Ä Îç∞Ïù¥ÌÑ∞(TVL Îì±) Ï†ïÍ∑úÌôî\"\"\"\n",
    "    df_proc = df.copy()\n",
    "    \n",
    "    prefixes_to_transform = [\n",
    "        'eth_', 'aave_', 'lido_', 'makerdao_', 'uniswap_', 'curve_', 'chain_',\n",
    "        'l2_', 'sp500_', 'gold_', 'dxy_', 'vix_', 'usdt_'\n",
    "    ]\n",
    "    \n",
    "    exclude_prefixes = ['fg_', 'funding_']\n",
    "    exclude_keywords = [\n",
    "        '_pct_', '_ratio', '_lag', '_volatility', '_corr', '_beta', '_spread',\n",
    "        'eth_return', 'btc_return', 'eth_log_return',\n",
    "        'RSI', 'MFI', 'CCI', 'ADX', 'BOP', 'AROON', 'PRICE_VS', 'BREAKOUT'\n",
    "    ]\n",
    "    \n",
    "    cols_to_transform = []\n",
    "    for col in df_proc.columns:\n",
    "        col_lower = col.lower()\n",
    "        if col.startswith(tuple(prefixes_to_transform)):\n",
    "            if not col.startswith(tuple(exclude_prefixes)):\n",
    "                if not any(k.lower() in col_lower for k in exclude_keywords):\n",
    "                    cols_to_transform.append(col)\n",
    "                    \n",
    "    cols_to_drop = []\n",
    "    for col in cols_to_transform:\n",
    "        series = df_proc[col].fillna(method='ffill').replace(0, 1e-9)\n",
    "        # 1Ïùº Î≥ÄÌôîÏú®\n",
    "        df_proc[f'{col}_pct_1d'] = series.pct_change(1)\n",
    "        # 30Ïùº Ïù¥ÎèôÌèâÍ∑† ÎåÄÎπÑ ÎπÑÏú®\n",
    "        ma_30 = series.rolling(window=30, min_periods=10).mean()\n",
    "        df_proc[f'{col}_ma30_ratio'] = series / (ma_30 + 1e-9)\n",
    "        cols_to_drop.append(col)\n",
    "\n",
    "    df_proc = df_proc.drop(columns=cols_to_drop, errors='ignore')\n",
    "    df_proc = df_proc.replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    \n",
    "    return df_proc\n",
    "\n",
    "# ==========================================================================\n",
    "# 4. Í≤∞Ï∏°Ïπò Î∞è Ï¥àÍ∏∞ Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ (Burn-in)\n",
    "# ==========================================================================\n",
    "\n",
    "def handle_missing_values_paper_based(df_clean, train_start_date, is_train=True, train_stats=None):\n",
    "    \"\"\"Ï¥àÍ∏∞ 200Ïùº Îç∞Ïù¥ÌÑ∞ Ï†úÍ±∞ (ÏïàÏ†ïÏÑ± ÌôïÎ≥¥)\"\"\"\n",
    "    burn_in_period = 200\n",
    "    if len(df_clean) > burn_in_period:\n",
    "        df_clean = df_clean.sort_values('date').reset_index(drop=True)\n",
    "        df_clean = df_clean.iloc[burn_in_period:].reset_index(drop=True)\n",
    "\n",
    "    if isinstance(train_start_date, str):\n",
    "        train_start_date = pd.to_datetime(train_start_date)\n",
    "    df_clean = df_clean[df_clean['date'] >= train_start_date].reset_index(drop=True)\n",
    "    \n",
    "    target_cols = ['next_log_return', 'next_direction', 'next_close','next_open', \n",
    "                   'take_profit_price', 'stop_loss_price', 'exit_reason']\n",
    "    feature_cols = [col for col in df_clean.columns if col not in target_cols + ['date']]\n",
    "    \n",
    "    df_clean[feature_cols] = df_clean[feature_cols].fillna(method='ffill').fillna(0)\n",
    "    df_clean[feature_cols] = df_clean[feature_cols].replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    if is_train:\n",
    "        return df_clean, {}\n",
    "    else:\n",
    "        return df_clean\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "# 5. Îç∞Ïù¥ÌÑ∞ ÎàÑÏàò Î∞©ÏßÄ Î∞è Ï†ïÏ†ú\n",
    "# ==========================================================================\n",
    "\n",
    "def remove_raw_prices_and_transform(df, target_type, method):\n",
    "    df_transformed = df.copy()\n",
    "    \n",
    "    if 'eth_log_return' not in df_transformed.columns:\n",
    "        df_transformed['eth_log_return'] = np.log(df['ETH_Close'] / df['ETH_Close'].shift(1))\n",
    "    \n",
    "    remove_patterns = ['_Close', '_Open', '_High', '_Low', '_Volume']\n",
    "    keep_keywords = [\n",
    "        '_lag', '_position', '_ratio', '_range', '_change', '_corr', '_volatility', '_obv',\n",
    "        'PRICE_VS', 'BREAKOUT', 'UPPER_SHADOW', 'LOWER_SHADOW', 'BB_WIDTH'\n",
    "    ]\n",
    "    \n",
    "    cols_to_remove = [\n",
    "        col for col in df_transformed.columns\n",
    "        if any(p in col for p in remove_patterns)\n",
    "        and not any(d in col.lower() for d in [k.lower() for k in keep_keywords])\n",
    "    ]\n",
    "    df_transformed.drop(cols_to_remove, axis=1, inplace=True)\n",
    "\n",
    "    return_cols = [col for col in df_transformed.columns if 'return' in col.lower() and 'next' not in col]\n",
    "    if return_cols:\n",
    "        df_transformed[return_cols] = df_transformed[return_cols].fillna(0)\n",
    "\n",
    "    return df_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f66d6d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "\n",
    "@jit(nopython=True)\n",
    "def compute_targets_with_hourly_numba(\n",
    "    daily_dates_ts,\n",
    "    daily_atr,\n",
    "    hourly_dates_ts,\n",
    "    hourly_open,\n",
    "    hourly_high,\n",
    "    hourly_low,\n",
    "    lookahead_days,\n",
    "    profit_mult,\n",
    "    stop_mult\n",
    "):\n",
    "    n = len(daily_dates_ts)\n",
    "    targets = np.full(n, -1, dtype=np.int32)\n",
    "    entry_prices = np.full(n, np.nan)\n",
    "    tp_prices = np.full(n, np.nan)\n",
    "    sl_prices = np.full(n, np.nan)\n",
    "    \n",
    "    one_day_ms = 86400000\n",
    "    lookahead_ms = lookahead_days * one_day_ms\n",
    "    \n",
    "    h_start = 0\n",
    "    \n",
    "    for i in range(n - 1):\n",
    "        atr = daily_atr[i]\n",
    "        if np.isnan(atr) or atr <= 0:\n",
    "            continue\n",
    "        \n",
    "        entry_start_ts = daily_dates_ts[i] + one_day_ms\n",
    "        entry_end_ts = entry_start_ts + lookahead_ms\n",
    "        \n",
    "        first_entry_idx = -1\n",
    "        for h in range(h_start, len(hourly_dates_ts)):\n",
    "            if hourly_dates_ts[h] >= entry_start_ts:\n",
    "                first_entry_idx = h\n",
    "                h_start = h\n",
    "                break\n",
    "        \n",
    "        if first_entry_idx == -1:\n",
    "            continue\n",
    "        \n",
    "        entry_price = hourly_open[first_entry_idx]\n",
    "        tp = entry_price + (atr * profit_mult)\n",
    "        sl = entry_price - (atr * stop_mult)\n",
    "        \n",
    "        entry_prices[i] = entry_price\n",
    "        tp_prices[i] = tp\n",
    "        sl_prices[i] = sl\n",
    "        \n",
    "        result = 0\n",
    "        for h in range(first_entry_idx, len(hourly_dates_ts)):\n",
    "            if hourly_dates_ts[h] >= entry_end_ts:\n",
    "                break\n",
    "            \n",
    "            if hourly_low[h] <= sl:\n",
    "                result = 0\n",
    "                break\n",
    "            if hourly_high[h] >= tp:\n",
    "                result = 1\n",
    "                break\n",
    "        \n",
    "        targets[i] = result\n",
    "    \n",
    "    return targets, entry_prices, tp_prices, sl_prices\n",
    "\n",
    "\n",
    "def create_targets(df, hourly_df, lookahead=5, profit_mult=1.5, stop_mult=1.0, **kwargs):\n",
    "    df_target = df.copy()\n",
    "    hourly_df = hourly_df.copy()\n",
    "    \n",
    "    df_target['date'] = pd.to_datetime(df_target['date'])\n",
    "    hourly_df['datetime'] = pd.to_datetime(hourly_df['datetime'])\n",
    "    \n",
    "    hourly_df['datetime'] = hourly_df['datetime'] + pd.Timedelta(hours=9)\n",
    "    \n",
    "    hourly_df.columns = hourly_df.columns.str.lower()\n",
    "    \n",
    "    required_hourly_cols = ['datetime', 'open', 'high', 'low']\n",
    "    for col in required_hourly_cols:\n",
    "        if col not in hourly_df.columns:\n",
    "            raise ValueError(f\"1ÏãúÍ∞ÑÎ¥â Îç∞Ïù¥ÌÑ∞Ïóê '{col}' Ïª¨ÎüºÏù¥ ÏóÜÏäµÎãàÎã§. ÌòÑÏû¨ Ïª¨Îüº: {hourly_df.columns.tolist()}\")\n",
    "    \n",
    "    required_daily_cols = ['date', 'ETH_High', 'ETH_Low', 'ETH_Close']\n",
    "    for col in required_daily_cols:\n",
    "        if col not in df_target.columns:\n",
    "            raise ValueError(f\"ÏùºÎ¥â Îç∞Ïù¥ÌÑ∞Ïóê '{col}' Ïª¨ÎüºÏù¥ ÏóÜÏäµÎãàÎã§. ÌòÑÏû¨ Ïª¨Îüº: {df_target.columns.tolist()}\")\n",
    "    \n",
    "    if 'ATR_14' not in df_target.columns:\n",
    "        df_target['ATR_14'] = ta.atr(\n",
    "            df_target['ETH_High'], df_target['ETH_Low'], df_target['ETH_Close'], length=14\n",
    "        )\n",
    "    \n",
    "    df_target = df_target.sort_values('date').reset_index(drop=True)\n",
    "    hourly_df = hourly_df.sort_values('datetime').reset_index(drop=True)\n",
    "    \n",
    "    daily_min = df_target['date'].min()\n",
    "    daily_max = df_target['date'].max()\n",
    "    hourly_min = hourly_df['datetime'].min()\n",
    "    hourly_max = hourly_df['datetime'].max()\n",
    "    \n",
    "    print(f\"ÏùºÎ¥â Í∏∞Í∞Ñ: {daily_min.date()} ~ {daily_max.date()}\")\n",
    "    print(f\"1ÏãúÍ∞ÑÎ¥â Í∏∞Í∞Ñ (KST Î≥ÄÌôò ÌõÑ): {hourly_min} ~ {hourly_max}\")\n",
    "    \n",
    "    if hourly_min > daily_min + pd.Timedelta(days=1):\n",
    "        print(f\"[Í≤ΩÍ≥†] 1ÏãúÍ∞ÑÎ¥â ÏãúÏûëÏùº({hourly_min})Ïù¥ ÏùºÎ¥â ÏãúÏûëÏùº({daily_min}) Ïù¥ÌõÑÏûÖÎãàÎã§. Ï¥àÎ∞ò ÌÉÄÍ≤ü ÏÜêÏã§ Î∞úÏÉù.\")\n",
    "    \n",
    "    daily_dates_ts = df_target['date'].astype(np.int64).values // 10**6\n",
    "    daily_atr = df_target['ATR_14'].fillna(method='ffill').fillna(0).to_numpy()\n",
    "    \n",
    "    hourly_dates_ts = hourly_df['datetime'].astype(np.int64).values // 10**6\n",
    "    hourly_open = hourly_df['open'].astype(np.float64).to_numpy()\n",
    "    hourly_high = hourly_df['high'].astype(np.float64).to_numpy()\n",
    "    hourly_low = hourly_df['low'].astype(np.float64).to_numpy()\n",
    "    \n",
    "    targets, entry_prices, tp_prices, sl_prices = compute_targets_with_hourly_numba(\n",
    "        daily_dates_ts, daily_atr,\n",
    "        hourly_dates_ts, hourly_open, hourly_high, hourly_low,\n",
    "        lookahead, profit_mult, stop_mult\n",
    "    )\n",
    "    \n",
    "    df_target['next_direction'] = targets\n",
    "    df_target['real_entry_price'] = entry_prices\n",
    "    df_target['take_profit_price'] = tp_prices\n",
    "    df_target['stop_loss_price'] = sl_prices\n",
    "    \n",
    "    df_target['next_close'] = df_target['ETH_Close'].shift(-1)\n",
    "    df_target['next_open'] = df_target['ETH_Open'].shift(-1)\n",
    "    df_target['next_log_return'] = np.log(df_target['next_close'] / (df_target['next_open'] + 1e-9))\n",
    "    \n",
    "    if lookahead > 0:\n",
    "        df_target = df_target.iloc[:-lookahead]\n",
    "    \n",
    "    valid_before = len(df_target)\n",
    "    df_target = df_target[df_target['next_direction'] != -1].reset_index(drop=True)\n",
    "    valid_after = len(df_target)\n",
    "    \n",
    "    removed = valid_before - valid_after\n",
    "    win = (df_target['next_direction'] == 1).sum()\n",
    "    lose = (df_target['next_direction'] == 0).sum()\n",
    "    total = win + lose\n",
    "    \n",
    "    print(f\"Ïú†Ìö® ÏÉòÌîå: {valid_after}/{valid_before} (Ï†úÍ±∞: {removed})\")\n",
    "    print(f\"Win: {win} | Lose: {lose} | Win Rate: {win/total:.2%}\" if total > 0 else \"ÌÉÄÍ≤ü ÏÉùÏÑ± Ïã§Ìå®\")\n",
    "    \n",
    "    return df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d525e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_verified(X_train, y_train, task='class', top_n=20, verbose=True):\n",
    "    if task == 'class':\n",
    "        mi_scores = mutual_info_classif(X_train, y_train, random_state=42, n_neighbors=3)\n",
    "    else:\n",
    "        mi_scores = mutual_info_regression(X_train, y_train, random_state=42, n_neighbors=3)\n",
    "    mi_idx = np.argsort(mi_scores)[::-1][:top_n]\n",
    "    mi_features = X_train.columns[mi_idx].tolist()\n",
    "    \n",
    "    estimator = LGBMClassifier(n_estimators=100, random_state=42, verbose=-1) if task == 'class' else LGBMRegressor(n_estimators=100, random_state=42, verbose=-1)\n",
    "    rfe = RFE(estimator=estimator, n_features_to_select=top_n, step=0.1, verbose=0)\n",
    "    rfe.fit(X_train, y_train)\n",
    "    rfe_features = X_train.columns[rfe.support_].tolist()\n",
    "\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42, n_jobs=-1) if task == 'class' else RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    rf_idx = np.argsort(rf_model.feature_importances_)[::-1][:top_n]\n",
    "    rf_features = X_train.columns[rf_idx].tolist()\n",
    "    \n",
    "    all_features = mi_features + rfe_features + rf_features\n",
    "    feature_votes = Counter(all_features)\n",
    "    selected_features = [feat for feat, _ in feature_votes.most_common(top_n)]\n",
    "    \n",
    "    if len(selected_features) < top_n:\n",
    "        remaining = top_n - len(selected_features)\n",
    "        for feat in mi_features:\n",
    "            if feat not in selected_features:\n",
    "                selected_features.append(feat)\n",
    "                remaining -= 1\n",
    "                if remaining == 0: break\n",
    "    \n",
    "    return selected_features, {}\n",
    "\n",
    "def select_features_multi_target(X_train, y_train, target_type='direction', top_n=20):\n",
    "    atr_col_name = 'ATR_14'\n",
    "    if target_type == 'direction':\n",
    "        selected, stats = select_features_verified(X_train, y_train['next_direction'], task='class', top_n=top_n)\n",
    "        \n",
    "        if atr_col_name not in selected and atr_col_name in X_train.columns:\n",
    "            if len(selected) > 0: selected.pop()\n",
    "            selected.insert(0, atr_col_name)\n",
    "            \n",
    "    print(f\"\\n[Feature Selection] Top {len(selected)} Features Selected:\")\n",
    "    print(f\" -> {', '.join(selected)}\")\n",
    "    return selected, stats\n",
    "\n",
    "def process_single_split(split_data, target_type='direction', top_n=20, fold_idx=None, trend_params=None): \n",
    "    \n",
    "    train_df = split_data['train'] \n",
    "    val_df = split_data['val'] \n",
    "    test_df = split_data['test'] \n",
    "    fold_type = split_data.get('fold_type', 'unknown')\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\" Processing Fold {fold_idx} ({fold_type})\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\" Train Period: {train_df['date'].min().date()} ~ {train_df['date'].max().date()} (N={len(train_df)})\")\n",
    "    print(f\" Val   Period: {val_df['date'].min().date()} ~ {val_df['date'].max().date()} (N={len(val_df)})\")\n",
    "    print(f\" Test  Period: {test_df['date'].min().date()} ~ {test_df['date'].max().date()} (N={len(test_df)})\")\n",
    "\n",
    "    train_processed, missing_stats = handle_missing_values_paper_based(train_df, train_df['date'].min(), is_train=True)\n",
    "    val_processed = handle_missing_values_paper_based(val_df, val_df['date'].min(), is_train=False, train_stats=missing_stats)\n",
    "    test_processed = handle_missing_values_paper_based(test_df, test_df['date'].min(), is_train=False, train_stats=missing_stats)\n",
    "\n",
    "    target_cols = [\n",
    "        'next_direction', 'next_log_return', 'next_close', 'next_open', \n",
    "        'take_profit_price', 'stop_loss_price', \n",
    "        'ATR_14', 'real_entry_price' \n",
    "    ]\n",
    "\n",
    "    train_processed = train_processed.dropna(subset=target_cols).reset_index(drop=True)\n",
    "    val_processed = val_processed.dropna(subset=target_cols).reset_index(drop=True)\n",
    "    test_processed = test_processed.dropna(subset=target_cols).reset_index(drop=True)\n",
    "\n",
    "    # [ÏàòÏ†ï 4] ATR_14Îäî ÌîºÏ≤òÎ°úÎèÑ Ïç®Ïïº ÌïòÎØÄÎ°ú exclude_colsÏóêÏÑú Ï†úÏô∏\n",
    "    exclude_cols = [col for col in target_cols if col != 'ATR_14'] + ['date']\n",
    "    feature_cols = [col for col in train_processed.columns if col not in exclude_cols]\n",
    "    \n",
    "    X_train = train_processed[feature_cols]\n",
    "    y_train = train_processed[target_cols]\n",
    "\n",
    "    X_val = val_processed[feature_cols]\n",
    "    y_val = val_processed[target_cols]\n",
    "\n",
    "    X_test = test_processed[feature_cols]\n",
    "    y_test = test_processed[target_cols]\n",
    "\n",
    "    balance = y_train['next_direction'].value_counts(normalize=True).to_dict()\n",
    "    print(f\"[Class Balance] Train Set: {balance}\")\n",
    "\n",
    "    selected_features, selection_stats = select_features_multi_target(\n",
    "        X_train, y_train, target_type=target_type, top_n=top_n\n",
    "    )\n",
    "\n",
    "    X_train_sel = X_train[selected_features]\n",
    "    X_val_sel = X_val[selected_features]\n",
    "    X_test_sel = X_test[selected_features]\n",
    "\n",
    "    # ==================================================================\n",
    "    # [ÏàòÏ†ï 1] MinMaxScaler (-1 ~ 1) Ï†ÅÏö©\n",
    "    # ==================================================================\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "    X_train_scaled = scaler.fit_transform(X_train_sel)\n",
    "    X_val_scaled = scaler.transform(X_val_sel)\n",
    "    X_test_scaled = scaler.transform(X_test_sel)\n",
    "\n",
    "    # ==================================================================\n",
    "    # [ÏàòÏ†ï 2] Numpy Î∞∞Ïó¥ÏùÑ DataFrameÏúºÎ°ú Î≥µÍµ¨ (LGBM Í≤ΩÍ≥† Ìï¥Í≤∞)\n",
    "    # ==================================================================\n",
    "    X_train_final = pd.DataFrame(X_train_scaled, columns=selected_features)\n",
    "    X_val_final = pd.DataFrame(X_val_scaled, columns=selected_features)\n",
    "    X_test_final = pd.DataFrame(X_test_scaled, columns=selected_features)\n",
    "\n",
    "    # MLÏö© Raw Îç∞Ïù¥ÌÑ∞ (ÌïÑÏöîÏãú ÏÇ¨Ïö©, Ïó¨Í∏∞ÏÑ† ÏÑ†ÌÉùÏÇ¨Ìï≠)\n",
    "    X_train_raw = X_train_sel \n",
    "\n",
    "    if trend_params is None:\n",
    "        trend_params = {}\n",
    "\n",
    "    result = {\n",
    "        'train': {\n",
    "            # [ÏàòÏ†ï 3] Î™®Îì† ÌÇ§Í∞Ä MinMax Scaled Îç∞Ïù¥ÌÑ∞Î•º Í∞ÄÎ¶¨ÌÇ§Í≤å Ìï®\n",
    "            'X_robust': X_train_final,   \n",
    "            'X_standard': X_train_final, \n",
    "            'X_minmax': X_train_final,\n",
    "            'X_raw': X_train_raw,\n",
    "            'y': y_train.reset_index(drop=True), \n",
    "            'dates': train_processed['date'].reset_index(drop=True) \n",
    "        },\n",
    "        'val': {\n",
    "            'X_robust': X_val_final,\n",
    "            'X_standard': X_val_final,\n",
    "            'X_minmax': X_val_final,\n",
    "            'X_raw': X_val_sel,\n",
    "            'y': y_val.reset_index(drop=True), \n",
    "            'dates': val_processed['date'].reset_index(drop=True)\n",
    "        },\n",
    "        'test': {\n",
    "            'X_robust': X_test_final,\n",
    "            'X_standard': X_test_final,\n",
    "            'X_minmax': X_test_final,\n",
    "            'X_raw': X_test_sel,\n",
    "            'y': y_test.reset_index(drop=True),\n",
    "            'dates': test_processed['date'].reset_index(drop=True)\n",
    "        },\n",
    "        'scaler': scaler, \n",
    "        'stats': {\n",
    "            'robust_scaler': scaler, \n",
    "            'standard_scaler': scaler,\n",
    "            'minmax_scaler': scaler,\n",
    "            'selected_features': selected_features,\n",
    "            'selection_stats': selection_stats,\n",
    "            'missing_stats': missing_stats,  \n",
    "            'target_type': target_type,\n",
    "            'target_cols': target_cols,\n",
    "            'fold_type': fold_type,\n",
    "            'fold_idx': fold_idx,\n",
    "            'trend_window': trend_params.get('trend_window', 120),\n",
    "            'trend_analysis_points': trend_params.get('trend_analysis_points', 5)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def split_walk_forward_method(df, train_start_date, final_test_start='2025-01-01', \n",
    "                              initial_train_size=800, val_size=150, test_size=150, \n",
    "                              step=150, gap_size=7):\n",
    "    \n",
    "    df_period = df[df['date'] >= train_start_date].copy()\n",
    "    df_period = df_period.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    if isinstance(final_test_start, str):\n",
    "        final_test_start = pd.to_datetime(final_test_start)\n",
    "    \n",
    "    total_days = len(df_period)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Reverse Rolling Walk-Forward + Final Holdout\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Total period: {df_period['date'].min().date()} ~ {df_period['date'].max().date()} ({total_days} days)\")\n",
    "    print(f\"Rolling train: {initial_train_size}d | Val: {val_size}d | Test: {test_size}d | Gap: {gap_size}d\")\n",
    "    print(f\"Final holdout test: {final_test_start.date()} ~ {df_period['date'].max().date()}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # ========== 1. Walk-Forward Folds (Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞Î°ú rolling) ==========\n",
    "    folds = []\n",
    "    current_test_end = total_days\n",
    "    \n",
    "    while True:\n",
    "        test_end_idx = current_test_end\n",
    "        test_start_idx = test_end_idx - test_size\n",
    "        \n",
    "        val_end_idx = test_start_idx - gap_size\n",
    "        val_start_idx = val_end_idx - val_size\n",
    "        \n",
    "        train_end_idx = val_start_idx - gap_size\n",
    "        train_start_idx = train_end_idx - initial_train_size\n",
    "        \n",
    "        if train_start_idx < 0:\n",
    "            break\n",
    "        \n",
    "        train_fold = df_period.iloc[train_start_idx:train_end_idx].copy()\n",
    "        val_fold = df_period.iloc[val_start_idx:val_end_idx].copy()\n",
    "        test_fold = df_period.iloc[test_start_idx:test_end_idx].copy()\n",
    "        \n",
    "        folds.append({\n",
    "            'train': train_fold,\n",
    "            'val': val_fold,\n",
    "            'test': test_fold,\n",
    "            'fold_type': 'walk_forward_rolling_reverse'\n",
    "        })\n",
    "        \n",
    "        current_test_end = test_start_idx - gap_size\n",
    "    \n",
    "    folds.reverse()\n",
    "    \n",
    "    # Ìè¥Îìú Ïù∏Îç±Ïä§ Ìï†Îãπ\n",
    "    for idx, fold in enumerate(folds):\n",
    "        fold['fold_idx'] = idx + 1\n",
    "        print(f\"Fold {fold['fold_idx']} (walk_forward_rolling)\")\n",
    "        print(f\"  Train: {len(fold['train']):4d}d  {fold['train']['date'].min().date()} ~ {fold['train']['date'].max().date()}\")\n",
    "        print(f\"  Val:   {len(fold['val']):4d}d  {fold['val']['date'].min().date()} ~ {fold['val']['date'].max().date()}\")\n",
    "        print(f\"  Test:  {len(fold['test']):4d}d  {fold['test']['date'].min().date()} ~ {fold['test']['date'].max().date()}\\n\")\n",
    "    \n",
    "    # ========== 2. Final Holdout (2025-01-01 Ïù¥ÌõÑ Ï†ÑÏ≤¥Î•º Î≥ÑÎèÑ ÌÖåÏä§Ìä∏) ==========\n",
    "    final_test_df = df_period[df_period['date'] >= final_test_start].copy()\n",
    "    \n",
    "    if len(final_test_df) > 0:\n",
    "        # Final holdoutÏùò train/valÏùÄ final_test_start ÏßÅÏ†Ñ Îç∞Ïù¥ÌÑ∞ ÏÇ¨Ïö©\n",
    "        pre_final_df = df_period[df_period['date'] < final_test_start].copy()\n",
    "        \n",
    "        if len(pre_final_df) >= (initial_train_size + val_size + gap_size):\n",
    "            # Ï∂©Î∂ÑÌïú Îç∞Ïù¥ÌÑ∞Í∞Ä ÏûàÏúºÎ©¥ Ï†ïÏÉÅÏ†ÅÏúºÎ°ú train/val Íµ¨ÏÑ±\n",
    "            final_val_end_idx = len(pre_final_df)\n",
    "            final_val_start_idx = final_val_end_idx - val_size\n",
    "            final_train_end_idx = final_val_start_idx - gap_size\n",
    "            final_train_start_idx = final_train_end_idx - initial_train_size\n",
    "            \n",
    "            if final_train_start_idx < 0:\n",
    "                final_train_start_idx = 0\n",
    "            \n",
    "            final_train_data = pre_final_df.iloc[final_train_start_idx:final_train_end_idx].copy()\n",
    "            final_val_data = pre_final_df.iloc[final_val_start_idx:final_val_end_idx].copy()\n",
    "        else:\n",
    "            # Îç∞Ïù¥ÌÑ∞ Î∂ÄÏ°± Ïãú Í∞ÄÎä•Ìïú ÎßåÌÅº ÏÇ¨Ïö©\n",
    "            split_point = int(len(pre_final_df) * 0.8)\n",
    "            final_train_data = pre_final_df.iloc[:split_point].copy()\n",
    "            final_val_data = pre_final_df.iloc[split_point:].copy()\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Fold {len(folds) + 1} (final_holdout - 2025 Ï†ÑÏ≤¥ Î≥ÑÎèÑ ÌèâÍ∞Ä)\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"  Train: {len(final_train_data):4d}d  {final_train_data['date'].min().date()} ~ {final_train_data['date'].max().date()}\")\n",
    "        print(f\"  Val:   {len(final_val_data):4d}d  {final_val_data['date'].min().date()} ~ {final_val_data['date'].max().date()}\")\n",
    "        print(f\"  Test:  {len(final_test_df):4d}d  {final_test_df['date'].min().date()} ~ {final_test_df['date'].max().date()}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        folds.append({\n",
    "            'train': final_train_data,\n",
    "            'val': final_val_data,\n",
    "            'test': final_test_df,\n",
    "            'fold_idx': len(folds) + 1,\n",
    "            'fold_type': 'final_holdout'\n",
    "        })\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Created {len(folds)} folds total\")\n",
    "    print(f\"  - {len(folds)-1} walk-forward folds\")\n",
    "    print(f\"  - 1 final holdout fold (2025 Ï†ÑÏ≤¥)\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return folds\n",
    "\n",
    "\n",
    "def build_complete_pipeline_corrected(df_raw,df_hour, train_start_date, **kwargs): \n",
    "    \n",
    "    \n",
    "    print(f\"\\n Pipeline Started... (Train Start: {train_start_date})\")\n",
    "\n",
    "    df = df_raw.copy()\n",
    "    lookahead = kwargs.get('lookahead_candles', kwargs.get('lookahead', 5))\n",
    "    profit_mult = kwargs.get('atr_multiplier_profit', 2.0)\n",
    "    stop_mult = kwargs.get('atr_multiplier_stop', 1.0)\n",
    "\n",
    "    df = add_price_lag_features_first(df)\n",
    "    df = calculate_technical_indicators(df)\n",
    "    df = add_enhanced_cross_crypto_features(df)\n",
    "    df = add_volatility_regime_features(df)\n",
    "    df = add_interaction_features(df)\n",
    "    df = add_percentile_features(df)\n",
    "    df = preprocess_non_stationary_features(df)\n",
    "\n",
    "    df = create_targets(df, df_hour,\n",
    "        lookahead=lookahead, \n",
    "        profit_mult=profit_mult, \n",
    "        stop_mult=stop_mult\n",
    "    )\n",
    "\n",
    "    df = remove_raw_prices_and_transform(df, 'direction', 'tvt')\n",
    "    print(df.shape)\n",
    "    splits = split_walk_forward_method(\n",
    "        df, \n",
    "        train_start_date=train_start_date,\n",
    "        final_test_start=kwargs.get('final_test_start', '2025-01-01'),\n",
    "        initial_train_size=800,\n",
    "        val_size=150,\n",
    "        test_size=150,\n",
    "        step=150,\n",
    "        gap_size=lookahead\n",
    "    )\n",
    "    print(f\" Data Split Completed. Total {len(splits)} folds generated.\")\n",
    "\n",
    "    result = []\n",
    "    for fold in splits:\n",
    "        res = process_single_split(\n",
    "            fold, \n",
    "            top_n=kwargs.get('top_n', 20), \n",
    "            fold_idx=fold['fold_idx']\n",
    "        )\n",
    "        result.append(res)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "222e4c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "class DirectionModels:\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_class_weights(y_train):\n",
    "        classes = np.unique(y_train)\n",
    "        weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "        return dict(zip(classes, weights))\n",
    "\n",
    "    @staticmethod\n",
    "    def random_forest(X_train, y_train, X_val, y_val):\n",
    "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "        \n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 300, 1000),\n",
    "                'max_depth': trial.suggest_int('max_depth', 4, 12),\n",
    "                'min_samples_split': trial.suggest_int('min_samples_split', 20, 150),\n",
    "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 10, 60),\n",
    "                'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "                'ccp_alpha': trial.suggest_float('ccp_alpha', 1e-4, 1e-2, log=True),\n",
    "                'class_weight': 'balanced',\n",
    "                'random_state': 42,\n",
    "                'n_jobs': -1\n",
    "            }\n",
    "            \n",
    "            model = RandomForestClassifier(**params)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            val_preds = model.predict(X_val)\n",
    "            return precision_score(y_val, val_preds, pos_label=1, zero_division=0)\n",
    "\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(objective, n_trials=20)\n",
    "        \n",
    "        best_model = RandomForestClassifier(**study.best_params, class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "        best_model.fit(X_train, y_train)\n",
    "        \n",
    "        train_preds = best_model.predict(X_train)\n",
    "        val_preds = best_model.predict(X_val)\n",
    "        print(f\"  [RandomForest] Train Acc: {accuracy_score(y_train, train_preds):.4f} | Precision: {precision_score(y_train, train_preds, pos_label=1, zero_division=0):.4f}\")\n",
    "        print(f\"  [RandomForest] Val   Acc: {accuracy_score(y_val, val_preds):.4f} | Precision: {precision_score(y_val, val_preds, pos_label=1, zero_division=0):.4f}\")\n",
    "        \n",
    "        return best_model\n",
    "\n",
    "    @staticmethod\n",
    "    def lightgbm(X_train, y_train, X_val, y_val):\n",
    "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'n_estimators': 1000,\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.05, log=True),\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "                'max_depth': trial.suggest_int('max_depth', 4, 10),\n",
    "                'min_child_samples': trial.suggest_int('min_child_samples', 30, 150),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 0.9),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.9),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 1e-2, 10.0, log=True),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 1e-2, 10.0, log=True),\n",
    "                'objective': 'binary',\n",
    "                'metric': 'binary_logloss',\n",
    "                'class_weight': 'balanced',\n",
    "                'verbosity': -1,\n",
    "                'n_jobs': -1,\n",
    "                'random_state': 42\n",
    "            }\n",
    "            \n",
    "            model = LGBMClassifier(**params)\n",
    "            callbacks = [lgb.early_stopping(stopping_rounds=30, verbose=False)]\n",
    "            model.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=callbacks)\n",
    "            \n",
    "            val_preds = model.predict(X_val)\n",
    "            return precision_score(y_val, val_preds, pos_label=1, zero_division=0)\n",
    "\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(objective, n_trials=25)\n",
    "        \n",
    "        best_params = study.best_params\n",
    "        best_params.update({\n",
    "            'n_estimators': 1000, \n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss', \n",
    "            'class_weight': 'balanced', \n",
    "            'verbosity': -1, \n",
    "            'n_jobs': -1, \n",
    "            'random_state': 42\n",
    "        })\n",
    "        \n",
    "        final_model = LGBMClassifier(**best_params)\n",
    "        final_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)])\n",
    "        \n",
    "        train_preds = final_model.predict(X_train)\n",
    "        val_preds = final_model.predict(X_val)\n",
    "        print(f\"  [LightGBM] Train Acc: {accuracy_score(y_train, train_preds):.4f} | Precision: {precision_score(y_train, train_preds, pos_label=1, zero_division=0):.4f}\")\n",
    "        print(f\"  [LightGBM] Val   Acc: {accuracy_score(y_val, val_preds):.4f} | Precision: {precision_score(y_val, val_preds, pos_label=1, zero_division=0):.4f}\")\n",
    "        \n",
    "        return final_model\n",
    "\n",
    "    @staticmethod\n",
    "    def xgboost(X_train, y_train, X_val, y_val):\n",
    "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "        \n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'n_estimators': 1000,\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.05, log=True),\n",
    "                'max_depth': trial.suggest_int('max_depth', 4, 10),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 2, 15),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 0.9),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.9),\n",
    "                'gamma': trial.suggest_float('gamma', 0.5, 10.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 1e-2, 10.0, log=True),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 1e-2, 10.0, log=True),\n",
    "                'objective': 'binary:logistic',\n",
    "                'eval_metric': 'logloss',\n",
    "                'tree_method': 'hist',\n",
    "                'early_stopping_rounds': 30,\n",
    "                'random_state': 42,\n",
    "                'n_jobs': -1\n",
    "            }\n",
    "            \n",
    "            model = XGBClassifier(**params)\n",
    "            model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "            \n",
    "            val_preds = model.predict(X_val)\n",
    "            return precision_score(y_val, val_preds, pos_label=1, zero_division=0)\n",
    "\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(objective, n_trials=25)\n",
    "        \n",
    "        best_params = study.best_params\n",
    "        best_params.update({\n",
    "            'n_estimators': 1000, \n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'logloss', \n",
    "            'tree_method': 'hist', \n",
    "            'early_stopping_rounds': 50,\n",
    "            'random_state': 42, \n",
    "            'n_jobs': -1\n",
    "        })\n",
    "        \n",
    "        final_model = XGBClassifier(**best_params)\n",
    "        final_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "        \n",
    "        train_preds = final_model.predict(X_train)\n",
    "        val_preds = final_model.predict(X_val)\n",
    "        print(f\"  [XGBoost] Train Acc: {accuracy_score(y_train, train_preds):.4f} | Precision: {precision_score(y_train, train_preds, pos_label=1, zero_division=0):.4f}\")\n",
    "        print(f\"  [XGBoost] Val   Acc: {accuracy_score(y_val, val_preds):.4f} | Precision: {precision_score(y_val, val_preds, pos_label=1, zero_division=0):.4f}\")\n",
    "        \n",
    "        return final_model\n",
    "\n",
    "    @staticmethod\n",
    "    def catboost(X_train, y_train, X_val, y_val):\n",
    "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "        \n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'iterations': 1000,\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.05, log=True),\n",
    "                'depth': trial.suggest_int('depth', 4, 9),\n",
    "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 2, 15),\n",
    "                'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "                'loss_function': 'Logloss',\n",
    "                'eval_metric': 'Logloss',\n",
    "                'auto_class_weights': 'Balanced',\n",
    "                'logging_level': 'Silent',\n",
    "                'random_seed': 42,\n",
    "                'od_type': 'Iter',\n",
    "                'od_wait': 30,\n",
    "                'allow_writing_files': False\n",
    "            }\n",
    "            \n",
    "            model = CatBoostClassifier(**params)\n",
    "            model.fit(X_train, y_train, eval_set=(X_val, y_val))\n",
    "            \n",
    "            val_preds = model.predict(X_val)\n",
    "            return precision_score(y_val, val_preds, pos_label=1, zero_division=0)\n",
    "\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(objective, n_trials=20)\n",
    "        \n",
    "        best_params = study.best_params\n",
    "        best_params.update({\n",
    "            'iterations': 1000, \n",
    "            'loss_function': 'Logloss', \n",
    "            'eval_metric': 'Logloss',\n",
    "            'auto_class_weights': 'Balanced', \n",
    "            'logging_level': 'Silent',\n",
    "            'random_seed': 42, \n",
    "            'od_type': 'Iter', \n",
    "            'od_wait': 50, \n",
    "            'allow_writing_files': False\n",
    "        })\n",
    "        \n",
    "        final_model = CatBoostClassifier(**best_params)\n",
    "        final_model.fit(X_train, y_train, eval_set=(X_val, y_val))\n",
    "        \n",
    "        train_preds = final_model.predict(X_train)\n",
    "        val_preds = final_model.predict(X_val)\n",
    "        print(f\"  [CatBoost] Train Acc: {accuracy_score(y_train, train_preds):.4f} | Precision: {precision_score(y_train, train_preds, pos_label=1, zero_division=0):.4f}\")\n",
    "        print(f\"  [CatBoost] Val   Acc: {accuracy_score(y_val, val_preds):.4f} | Precision: {precision_score(y_val, val_preds, pos_label=1, zero_division=0):.4f}\")\n",
    "        \n",
    "        return final_model\n",
    "\n",
    "    @staticmethod\n",
    "    def lstm(X_train, y_train, X_val, y_val, input_shape):\n",
    "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "        class_weights = DirectionModels.get_class_weights(y_train)\n",
    "\n",
    "        def objective(trial):\n",
    "            tf.keras.backend.clear_session()\n",
    "            \n",
    "            units = trial.suggest_int('units', 32, 128, step=16)\n",
    "            dropout_rate = trial.suggest_float('dropout', 0.3, 0.6)\n",
    "            l2_reg = trial.suggest_float('l2_reg', 1e-4, 1e-1, log=True)\n",
    "            lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "            \n",
    "            model = Sequential([\n",
    "                Input(shape=input_shape),\n",
    "                LSTM(units, return_sequences=False, \n",
    "                     kernel_regularizer=l1_l2(l2=l2_reg),\n",
    "                     recurrent_regularizer=l1_l2(l2=l2_reg)),\n",
    "                BatchNormalization(),\n",
    "                Dropout(dropout_rate),\n",
    "                Dense(units // 2, activation='relu', kernel_regularizer=l1_l2(l2=l2_reg)),\n",
    "                Dropout(dropout_rate),\n",
    "                Dense(1, activation='sigmoid')\n",
    "            ])\n",
    "            \n",
    "            model.compile(\n",
    "                optimizer=Adam(learning_rate=lr),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "            \n",
    "            es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "            \n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                validation_data=(X_val, y_val),\n",
    "                epochs=20,\n",
    "                batch_size=64,\n",
    "                class_weight=class_weights,\n",
    "                callbacks=[es],\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            val_probs = model.predict(X_val, verbose=0).flatten()\n",
    "            val_preds = (val_probs >= 0.5).astype(int)\n",
    "            return precision_score(y_val, val_preds, pos_label=1, zero_division=0)\n",
    "\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(objective, n_trials=20)\n",
    "        \n",
    "        best = study.best_params\n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "        final_model = Sequential([\n",
    "            Input(shape=input_shape),\n",
    "            LSTM(best['units'], return_sequences=False,\n",
    "                 kernel_regularizer=l1_l2(l2=best['l2_reg']),\n",
    "                 recurrent_regularizer=l1_l2(l2=best['l2_reg'])),\n",
    "            BatchNormalization(),\n",
    "            Dropout(best['dropout']),\n",
    "            Dense(best['units'] // 2, activation='relu', kernel_regularizer=l1_l2(l2=best['l2_reg'])),\n",
    "            Dropout(best['dropout']),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        \n",
    "        final_model.compile(\n",
    "            optimizer=Adam(learning_rate=best['lr']),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        final_es = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "        final_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "        \n",
    "        final_model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=50,\n",
    "            batch_size=64,\n",
    "            class_weight=class_weights,\n",
    "            callbacks=[final_es, final_lr],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        train_probs = final_model.predict(X_train, verbose=0).flatten()\n",
    "        val_probs = final_model.predict(X_val, verbose=0).flatten()\n",
    "        train_preds = (train_probs >= 0.5).astype(int)\n",
    "        val_preds = (val_probs >= 0.5).astype(int)\n",
    "        print(f\"  [LSTM] Train Acc: {accuracy_score(y_train, train_preds):.4f} | Precision: {precision_score(y_train, train_preds, pos_label=1, zero_division=0):.4f}\")\n",
    "        print(f\"  [LSTM] Val   Acc: {accuracy_score(y_val, val_preds):.4f} | Precision: {precision_score(y_val, val_preds, pos_label=1, zero_division=0):.4f}\")\n",
    "        \n",
    "        return final_model\n",
    "    \n",
    "    \n",
    "ML_MODELS_CLASSIFICATION = [\n",
    "    {'index': 1, 'name': 'CatBoost', 'func': DirectionModels.catboost, 'needs_val': True},\n",
    "    {'index': 2, 'name': 'RandomForest', 'func': DirectionModels.random_forest, 'needs_val': True},\n",
    "    {'index': 3, 'name': 'LightGBM', 'func': DirectionModels.lightgbm, 'needs_val': True},\n",
    "    {'index': 4, 'name': 'XGBoost', 'func': DirectionModels.xgboost, 'needs_val': True}\n",
    "]\n",
    "\n",
    "DL_MODELS_CLASSIFICATION = [\n",
    "    #{'index': 9, 'name': 'LSTM', 'func': DirectionModels.lstm, 'needs_val': True},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9cf7452",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    def __init__(self, save_models=False):\n",
    "        self.results = []\n",
    "        self.predictions = {}\n",
    "        self.models = {} if save_models else None\n",
    "        self.save_models = save_models\n",
    "        self.best_thresholds = {}\n",
    "\n",
    "    def optimize_threshold(self, y_true, buy_prob, min_trades=5, reward_risk_ratio=2.0):\n",
    "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "        def objective(trial):\n",
    "            th = trial.suggest_float('threshold', 0.2, 0.9)\n",
    "            preds = (buy_prob >= th).astype(int)\n",
    "            n_trades = np.sum(preds == 1)\n",
    "            \n",
    "            if n_trades < min_trades:\n",
    "                return -99999.0 \n",
    "            \n",
    "            wins = np.sum((preds == 1) & (y_true == 1))\n",
    "            losses = n_trades - wins\n",
    "            \n",
    "            total_return = (wins * reward_risk_ratio) - (losses * 1.0)\n",
    "            return total_return\n",
    "\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(objective, n_trials=30) \n",
    "        return study.best_params['threshold'], study.best_value\n",
    "\n",
    "    def _calculate_metrics(self, y_true, buy_prob, dataset_name, threshold, reward_risk_ratio):\n",
    "        metrics = {}\n",
    "        \n",
    "        preds = (buy_prob >= threshold).astype(int)\n",
    "        n_trades = np.sum(preds == 1)\n",
    "        \n",
    "        if n_trades > 0:\n",
    "            wins = np.sum((preds == 1) & (y_true == 1))\n",
    "            losses = n_trades - wins\n",
    "            \n",
    "            win_rate = wins / n_trades\n",
    "            total_return_r = (wins * reward_risk_ratio) - (losses * 1.0)\n",
    "            profit_factor = (wins * reward_risk_ratio) / (losses * 1.0) if losses > 0 else 99.0\n",
    "            expectancy = total_return_r / n_trades\n",
    "        else:\n",
    "            win_rate = 0.0\n",
    "            expectancy = 0.0\n",
    "            total_return_r = 0.0\n",
    "            profit_factor = 0.0\n",
    "            wins = 0\n",
    "            losses = 0\n",
    "            \n",
    "        # [Ï§ëÏöî] Ïó¨Í∏∞ÏÑú Ïª¨ÎüºÎ™ÖÏù¥ '{dataset_name}_Expectancy'Î°ú ÏÉùÏÑ±Îê©ÎãàÎã§.\n",
    "        metrics[f'{dataset_name}_Trades'] = n_trades\n",
    "        metrics[f'{dataset_name}_Wins'] = wins\n",
    "        metrics[f'{dataset_name}_Losses'] = losses\n",
    "        metrics[f'{dataset_name}_WinRate'] = win_rate\n",
    "        metrics[f'{dataset_name}_Expectancy'] = expectancy\n",
    "        metrics[f'{dataset_name}_TotalReturn_R'] = total_return_r\n",
    "        metrics[f'{dataset_name}_ProfitFactor'] = profit_factor\n",
    "            \n",
    "        return metrics\n",
    "\n",
    "    def _extract_target(self, y_data):\n",
    "        if isinstance(y_data, pd.DataFrame):\n",
    "            if 'next_direction' in y_data.columns:\n",
    "                return y_data['next_direction'].values.astype(int)\n",
    "            return y_data.iloc[:, 0].values.astype(int)\n",
    "        elif isinstance(y_data, pd.Series):\n",
    "            return y_data.values.astype(int)\n",
    "        elif isinstance(y_data, np.ndarray):\n",
    "            if y_data.ndim > 1:\n",
    "                return y_data[:, 0].astype(int)\n",
    "            return y_data.astype(int)\n",
    "        return np.array(y_data).astype(int)\n",
    "\n",
    "    def evaluate_model(self, model, X_train, y_train, X_val, y_val, X_test, y_test, \n",
    "                       test_dates, test_prices, test_atr, model_name,\n",
    "                       is_deep_learning=False, profit_mult=1.5, stop_mult=1.0):\n",
    "        \n",
    "        rr_ratio = profit_mult / stop_mult if stop_mult > 0 else 1.5\n",
    "\n",
    "        if is_deep_learning:\n",
    "            train_prob = model.predict(X_train, verbose=0).flatten()\n",
    "            val_prob = model.predict(X_val, verbose=0).flatten()\n",
    "            test_prob = model.predict(X_test, verbose=0).flatten()\n",
    "        else:\n",
    "            train_prob = model.predict_proba(X_train)[:, 1]\n",
    "            val_prob = model.predict_proba(X_val)[:, 1]\n",
    "            test_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        y_train_arr = self._extract_target(y_train)\n",
    "        y_val_arr = self._extract_target(y_val)\n",
    "        y_test_arr = self._extract_target(y_test)\n",
    "\n",
    "        best_th, best_val_return = self.optimize_threshold(y_val_arr, val_prob, min_trades=5, reward_risk_ratio=rr_ratio)\n",
    "        self.best_thresholds[model_name] = best_th\n",
    "        \n",
    "        train_metrics = self._calculate_metrics(y_train_arr, train_prob, 'Train', best_th, rr_ratio)\n",
    "        val_metrics = self._calculate_metrics(y_val_arr, val_prob, 'Val', best_th, rr_ratio)\n",
    "        test_metrics = self._calculate_metrics(y_test_arr, test_prob, 'Test', best_th, rr_ratio)\n",
    "        \n",
    "        result = {'Model': model_name, 'Threshold': best_th, 'RR_Ratio': rr_ratio}\n",
    "        result.update(train_metrics)\n",
    "        result.update(val_metrics)\n",
    "        result.update(test_metrics)\n",
    "        \n",
    "        self.results.append(result)\n",
    "        \n",
    "        test_preds = (test_prob >= best_th).astype(int)\n",
    "        \n",
    "        if hasattr(test_prices, 'values'): test_prices = test_prices.values\n",
    "        if hasattr(test_atr, 'values'): test_atr = test_atr.values\n",
    "        test_prices = np.array(test_prices).reshape(-1)\n",
    "        test_atr = np.array(test_atr).reshape(-1)\n",
    "\n",
    "        tp_prices = test_prices + (test_atr * profit_mult)\n",
    "        sl_prices = test_prices - (test_atr * stop_mult)\n",
    "        \n",
    "        self.predictions[model_name] = pd.DataFrame({\n",
    "            'date': test_dates,\n",
    "            'actual': y_test_arr,\n",
    "            'pred': test_preds,\n",
    "            'prob': test_prob,\n",
    "            'entry_price': test_prices,\n",
    "            'tp_price': tp_prices,\n",
    "            'sl_price': sl_prices,\n",
    "            'atr': test_atr\n",
    "        })\n",
    "        \n",
    "        if self.save_models and self.models is not None:\n",
    "            self.models[model_name] = model\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def get_summary_dataframe(self):\n",
    "        return pd.DataFrame(self.results)\n",
    "    \n",
    "    def get_predictions_dict(self):\n",
    "        return self.predictions\n",
    "    \n",
    "    def get_models_dict(self):\n",
    "        return self.models or {}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. ModelTrainer Class (Î™®Îç∏ ÌïôÏäµ ÎûòÌçº)\n",
    "# -----------------------------------------------------------------------------\n",
    "class ModelTrainer:\n",
    "    def __init__(self, evaluator, lookback=30):\n",
    "        self.evaluator = evaluator\n",
    "        self.lookback = lookback\n",
    "    \n",
    "    def create_sequences(self, X, y, lookback):\n",
    "        Xs, ys = [], []\n",
    "        for i in range(lookback, len(X)):\n",
    "            Xs.append(X[i-lookback:i])\n",
    "            ys.append(y[i])\n",
    "        return np.array(Xs), np.array(ys)\n",
    "    \n",
    "    def _prepare_target(self, y_data):\n",
    "        if isinstance(y_data, pd.DataFrame):\n",
    "            if 'next_direction' in y_data.columns:\n",
    "                return y_data['next_direction'].values.astype(int)\n",
    "            return y_data.iloc[:, 0].values.astype(int)\n",
    "        elif isinstance(y_data, pd.Series):\n",
    "            return y_data.values.astype(int)\n",
    "        return np.array(y_data).astype(int)\n",
    "\n",
    "    def train_all_models(self, X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "                         test_dates, test_prices, test_atr,\n",
    "                         profit_mult, stop_mult,\n",
    "                         ml_models=None, dl_models=None):\n",
    "        \n",
    "        y_train_arr = self._prepare_target(y_train)\n",
    "        y_val_arr = self._prepare_target(y_val)\n",
    "        y_test_arr = self._prepare_target(y_test)\n",
    "        \n",
    "        # ML Models\n",
    "        if ml_models:\n",
    "            for config in ml_models:\n",
    "                try:\n",
    "                    if config['needs_val']:\n",
    "                        model = config['func'](X_train, y_train_arr, X_val, y_val_arr)\n",
    "                    else:\n",
    "                        model = config['func'](X_train, y_train_arr)\n",
    "                        \n",
    "                    self.evaluator.evaluate_model(\n",
    "                        model, X_train, y_train_arr, X_val, y_val_arr, X_test, y_test_arr,\n",
    "                        test_dates, test_prices, test_atr,\n",
    "                        config['name'],\n",
    "                        is_deep_learning=False,\n",
    "                        profit_mult=profit_mult,\n",
    "                        stop_mult=stop_mult\n",
    "                    )\n",
    "                    del model\n",
    "                    gc.collect()\n",
    "                except Exception as e:\n",
    "                    print(f\"[Error] {config['name']}: {str(e)}\")\n",
    "                    traceback.print_exc()\n",
    "\n",
    "        # DL Models\n",
    "        if dl_models:\n",
    "            X_train_seq, y_train_seq = self.create_sequences(X_train, y_train_arr, self.lookback)\n",
    "            X_val_seq, y_val_seq = self.create_sequences(X_val, y_val_arr, self.lookback)\n",
    "            X_test_seq, y_test_seq = self.create_sequences(X_test, y_test_arr, self.lookback)\n",
    "            \n",
    "            test_dates_seq = test_dates[self.lookback:]\n",
    "            test_prices_seq = test_prices[self.lookback:]\n",
    "            test_atr_seq = test_atr[self.lookback:]\n",
    "            \n",
    "            input_shape = (X_train_seq.shape[1], X_train_seq.shape[2])\n",
    "            \n",
    "            for config in dl_models:\n",
    "                try:\n",
    "                    tf.keras.backend.clear_session()\n",
    "                    model = config['func'](X_train_seq, y_train_seq, X_val_seq, y_val_seq, input_shape)\n",
    "                    \n",
    "                    self.evaluator.evaluate_model(\n",
    "                        model, X_train_seq, y_train_seq, X_val_seq, y_val_seq, X_test_seq, y_test_seq,\n",
    "                        test_dates_seq, test_prices_seq, test_atr_seq,\n",
    "                        config['name'],\n",
    "                        is_deep_learning=True,\n",
    "                        profit_mult=profit_mult,\n",
    "                        stop_mult=stop_mult\n",
    "                    )\n",
    "                    del model\n",
    "                    tf.keras.backend.clear_session()\n",
    "                    gc.collect()\n",
    "                except Exception as e:\n",
    "                    print(f\"[Error] {config['name']}: {str(e)}\")\n",
    "                    traceback.print_exc()\n",
    "\n",
    "\n",
    "def save_fold_results(fold_idx, fold_type, evaluator, trial_name, fold_data):\n",
    "    base_dir = f\"model_results/{datetime.now().strftime('%Y-%m-%d')}/{trial_name}/fold_{fold_idx}_{fold_type}\"\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    \n",
    "    summary = evaluator.get_summary_dataframe()\n",
    "    summary.to_csv(f\"{base_dir}/fold_summary.csv\", index=False)\n",
    "    \n",
    "    for name, df in evaluator.get_predictions_dict().items():\n",
    "        df.to_csv(f\"{base_dir}/predictions_{name}.csv\", index=False)\n",
    "        \n",
    "    for name, model in evaluator.get_models_dict().items():\n",
    "        try:\n",
    "            if isinstance(model, tf.keras.Model):\n",
    "                model.save(f\"{base_dir}/model_{name}.h5\")\n",
    "            else:\n",
    "                joblib.dump(model, f\"{base_dir}/model_{name}.pkl\")\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] Failed to save {name}: {e}\")\n",
    "            \n",
    "    if 'scaler' in fold_data:\n",
    "        joblib.dump(fold_data['scaler'], f\"{base_dir}/scaler.pkl\")\n",
    "        \n",
    "    meta_data = {\n",
    "        'selected_features': fold_data['stats']['selected_features'],\n",
    "        'target_cols': fold_data['stats']['target_cols'],\n",
    "        'fold_idx': fold_idx,\n",
    "        'fold_type': fold_type,\n",
    "        'trial_name': trial_name,\n",
    "        'best_thresholds': evaluator.best_thresholds\n",
    "    }\n",
    "    \n",
    "    with open(f\"{base_dir}/metadata.json\", 'w') as f:\n",
    "        json.dump(meta_data, f, indent=4)\n",
    "            \n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcd35896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optuna_optimization(df_merged, df_hour, n_trials=30):\n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    RESULT_DIR = f\"model_results/{TIMESTAMP}\"\n",
    "    os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "    \n",
    "    LOG_PATH = f\"{RESULT_DIR}/optuna_log.csv\"\n",
    "    \n",
    "    # [Ïô∏Î∂Ä Î≥ÄÏàò] Í∏∞Ï°¥ Î°úÍ∑∏ Î°úÎìú\n",
    "    existing_history = pd.DataFrame()\n",
    "    if os.path.exists(LOG_PATH):\n",
    "        try:\n",
    "            existing_history = pd.read_csv(LOG_PATH)\n",
    "            print(f\"\\n[Resume] Loaded {len(existing_history)} existing trials from {LOG_PATH}\")\n",
    "        except Exception:\n",
    "            print(\"\\n[Warning] Log file exists but could not be read.\")\n",
    "\n",
    "    if not os.path.exists(LOG_PATH):\n",
    "        with open(LOG_PATH, \"w\") as f:\n",
    "            f.write(\"trial,lookahead,profit_mult,stop_mult,score\\n\")\n",
    "\n",
    "    def objective(trial):\n",
    "        # [ÏàòÏ†ï] nonlocal ÏÑ†Ïñ∏ÏùÑ Î∞òÎìúÏãú Ìï®Ïàò ÏµúÏÉÅÎã®Ïóê ÏúÑÏπòÏãúÏºúÏïº Ìï©ÎãàÎã§.\n",
    "        nonlocal existing_history \n",
    "        \n",
    "        lookahead = trial.suggest_int('lookahead', 5, 15)\n",
    "        p_mult = trial.suggest_float('profit_mult', 1.5, 2.0, step=0.1)\n",
    "        s_mult = trial.suggest_float('stop_mult', 0.8, 1.0, step=0.1)\n",
    "        \n",
    "        # 1. Ï§ëÎ≥µ Ï≤¥ÌÅ¨ (Î®ºÏ†Ä ÏàòÌñâ)\n",
    "        if not existing_history.empty:\n",
    "            mask = (\n",
    "                (existing_history['lookahead'] == lookahead) &\n",
    "                (np.isclose(existing_history['profit_mult'], p_mult, atol=1e-5)) &\n",
    "                (np.isclose(existing_history['stop_mult'], s_mult, atol=1e-5))\n",
    "            )\n",
    "            \n",
    "            if mask.any():\n",
    "                past_score = existing_history.loc[mask, 'score'].values[0]\n",
    "                print(f\"\\n[Skip] Found existing result for L={lookahead}, P={p_mult:.1f}, S={s_mult:.1f}. Score: {past_score:.4f}\")\n",
    "                return past_score\n",
    "\n",
    "        # 2. Ïã†Í∑ú Ïã§Ìñâ\n",
    "        unique_id = datetime.now().strftime('%H%M%S')\n",
    "        trial_name = f\"trial_{trial.number}_{unique_id}_L{lookahead}_P{p_mult:.1f}_S{s_mult:.1f}\"\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\" Starting NEW {trial_name}\")\n",
    "        \n",
    "        try:\n",
    "            pipeline_result = build_complete_pipeline_corrected(\n",
    "                df_raw=df_merged,\n",
    "                df_hour=df_hour,\n",
    "                train_start_date='2020-01-01',\n",
    "                final_test_start='2025-01-01',\n",
    "                lookahead_candles=lookahead,\n",
    "                atr_multiplier_profit=p_mult,\n",
    "                atr_multiplier_stop=s_mult,\n",
    "                top_n=20\n",
    "            )\n",
    "            \n",
    "            fold_scores = []\n",
    "            \n",
    "            for i, fold_data in enumerate(pipeline_result):\n",
    "                fold_idx = fold_data['stats']['fold_idx']\n",
    "                fold_type = fold_data['stats']['fold_type']\n",
    "                \n",
    "                print(f\"\\n   >> Running Fold {fold_idx}/{len(pipeline_result)} ({fold_type})\")\n",
    "                \n",
    "                evaluator = ModelEvaluator(save_models=True)\n",
    "                trainer = ModelTrainer(evaluator, lookback=30)\n",
    "                \n",
    "                test_prices = fold_data['test']['y']['real_entry_price'].values\n",
    "                test_atr = fold_data['test']['y']['ATR_14'].values\n",
    "                \n",
    "                trainer.train_all_models(\n",
    "                    fold_data['train']['X_robust'],\n",
    "                    fold_data['train']['y'],\n",
    "                    fold_data['val']['X_robust'],\n",
    "                    fold_data['val']['y'],   \n",
    "                    fold_data['test']['X_robust'],\n",
    "                    fold_data['test']['y'],  \n",
    "                    fold_data['test']['dates'].values,\n",
    "                    test_prices,\n",
    "                    test_atr,\n",
    "                    p_mult,\n",
    "                    s_mult,\n",
    "                    ml_models=ML_MODELS_CLASSIFICATION,\n",
    "                    dl_models=DL_MODELS_CLASSIFICATION\n",
    "                )\n",
    "                \n",
    "                summary = save_fold_results(fold_idx, fold_type, evaluator, trial_name, fold_data)\n",
    "                \n",
    "                # [Ï†êÏàò Î°úÏßÅ ÏàòÏ†ï Ï†ÅÏö©Îê®]\n",
    "                target_metric = 'Test_Expectancy'\n",
    "                if target_metric in summary.columns:\n",
    "                    score = summary[target_metric].mean()\n",
    "                else:\n",
    "                    score = 0.0\n",
    "                    \n",
    "                fold_scores.append(score)\n",
    "                \n",
    "                del evaluator, trainer\n",
    "                gc.collect()\n",
    "            \n",
    "            final_score = np.mean(fold_scores) if fold_scores else 0.0\n",
    "            print(f\"\\n === Trial Finished. Final Score: {final_score:.4f}R ===\")\n",
    "            \n",
    "            # Î°úÍ∑∏ ÌååÏùº Í∏∞Î°ù\n",
    "            with open(LOG_PATH, \"a\") as f:\n",
    "                f.write(f\"{trial.number},{lookahead},{p_mult},{s_mult},{final_score}\\n\")\n",
    "            \n",
    "            # Î©îÎ™®Î¶¨ DataFrame ÏóÖÎç∞Ïù¥Ìä∏\n",
    "            new_row = pd.DataFrame([[trial.number, lookahead, p_mult, s_mult, final_score]], \n",
    "                                   columns=['trial','lookahead','profit_mult','stop_mult','score'])\n",
    "            \n",
    "            if existing_history.empty:\n",
    "                existing_history = new_row\n",
    "            else:\n",
    "                existing_history = pd.concat([existing_history, new_row], ignore_index=True)\n",
    "                \n",
    "            return final_score\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" [Error] Trial Failed: {e}\")\n",
    "            traceback.print_exc()\n",
    "            return 0.0\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    print(f\"\\n[Optuna] Starting optimization with {n_trials} trials...\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    \n",
    "    print(\"\\n[Optuna] Optimization Completed!\")\n",
    "    print(\"Best Params:\", study.best_params)\n",
    "    return study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83d2facf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-26 19:10:05,609] A new study created in memory with name: no-name-288317e3-017f-405a-a7fe-f609feda012a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GPU Detected & Memory Growth Set!\n",
      "Loaded Data: 2351 rows (2019-06-15 ~ 2025-11-20)\n",
      "\n",
      "[Resume] Loaded 21 existing trials from model_results/2025-11-26/optuna_log.csv\n",
      "\n",
      "[Optuna] Starting optimization with 30 trials...\n",
      "\n",
      "================================================================================\n",
      " Starting NEW trial_0_191005_L13_P1.8_S0.8\n",
      "\n",
      " Pipeline Started... (Train Start: 2020-01-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_256137/1210223439.py:54: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_ta['EMA_12'] = ta.ema(close, length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏùºÎ¥â Í∏∞Í∞Ñ: 2019-06-15 ~ 2025-11-20\n",
      "1ÏãúÍ∞ÑÎ¥â Í∏∞Í∞Ñ (KST Î≥ÄÌôò ÌõÑ): 2020-01-01 09:00:00 ~ 2025-11-23 08:00:00\n",
      "[Í≤ΩÍ≥†] 1ÏãúÍ∞ÑÎ¥â ÏãúÏûëÏùº(2020-01-01 09:00:00)Ïù¥ ÏùºÎ¥â ÏãúÏûëÏùº(2019-06-15 00:00:00) Ïù¥ÌõÑÏûÖÎãàÎã§. Ï¥àÎ∞ò ÌÉÄÍ≤ü ÏÜêÏã§ Î∞úÏÉù.\n",
      "Ïú†Ìö® ÏÉòÌîå: 2325/2338 (Ï†úÍ±∞: 13)\n",
      "Win: 684 | Lose: 1641 | Win Rate: 29.42%\n",
      "(2325, 85)\n",
      "\n",
      "================================================================================\n",
      "Reverse Rolling Walk-Forward + Final Holdout\n",
      "================================================================================\n",
      "Total period: 2020-01-01 ~ 2025-11-07 (2138 days)\n",
      "Rolling train: 800d | Val: 150d | Test: 150d | Gap: 13d\n",
      "Final holdout test: 2025-01-01 ~ 2025-11-07\n",
      "================================================================================\n",
      "\n",
      "Fold 1 (walk_forward_rolling)\n",
      "  Train:  800d  2020-02-04 ~ 2022-04-13\n",
      "  Val:    150d  2022-04-27 ~ 2022-09-23\n",
      "  Test:   150d  2022-10-07 ~ 2023-03-05\n",
      "\n",
      "Fold 2 (walk_forward_rolling)\n",
      "  Train:  800d  2020-07-16 ~ 2022-09-23\n",
      "  Val:    150d  2022-10-07 ~ 2023-03-05\n",
      "  Test:   150d  2023-03-19 ~ 2023-08-15\n",
      "\n",
      "Fold 3 (walk_forward_rolling)\n",
      "  Train:  800d  2020-12-26 ~ 2023-03-05\n",
      "  Val:    150d  2023-03-19 ~ 2023-08-15\n",
      "  Test:   150d  2023-08-29 ~ 2024-01-25\n",
      "\n",
      "Fold 4 (walk_forward_rolling)\n",
      "  Train:  800d  2021-06-07 ~ 2023-08-15\n",
      "  Val:    150d  2023-08-29 ~ 2024-01-25\n",
      "  Test:   150d  2024-02-08 ~ 2024-07-06\n",
      "\n",
      "Fold 5 (walk_forward_rolling)\n",
      "  Train:  800d  2021-11-17 ~ 2024-01-25\n",
      "  Val:    150d  2024-02-08 ~ 2024-07-06\n",
      "  Test:   150d  2024-07-20 ~ 2024-12-16\n",
      "\n",
      "Fold 6 (walk_forward_rolling)\n",
      "  Train:  800d  2022-04-29 ~ 2024-07-06\n",
      "  Val:    150d  2024-07-20 ~ 2024-12-16\n",
      "  Test:   150d  2024-12-30 ~ 2025-05-28\n",
      "\n",
      "Fold 7 (walk_forward_rolling)\n",
      "  Train:  800d  2022-10-09 ~ 2024-12-16\n",
      "  Val:    150d  2024-12-30 ~ 2025-05-28\n",
      "  Test:   150d  2025-06-11 ~ 2025-11-07\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Fold 8 (final_holdout - 2025 Ï†ÑÏ≤¥ Î≥ÑÎèÑ ÌèâÍ∞Ä)\n",
      "================================================================================\n",
      "  Train:  800d  2022-05-14 ~ 2024-07-21\n",
      "  Val:    150d  2024-08-04 ~ 2024-12-31\n",
      "  Test:   311d  2025-01-01 ~ 2025-11-07\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Created 8 folds total\n",
      "  - 7 walk-forward folds\n",
      "  - 1 final holdout fold (2025 Ï†ÑÏ≤¥)\n",
      "================================================================================\n",
      "\n",
      " Data Split Completed. Total 8 folds generated.\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 1 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-02-04 ~ 2022-04-13 (N=800)\n",
      " Val   Period: 2022-04-27 ~ 2022-09-23 (N=150)\n",
      " Test  Period: 2022-10-07 ~ 2023-03-05 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.625, 1: 0.375}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, SMA_20, usdt_totalMintedUSD_ma30_ratio, usdt_totalUnreleased_ma30_ratio, eth_return, btc_return, BB_WIDTH, MACD_12_26_9, EMA_12, BREAKOUT_STR_5d, eth_log_return, BREAKOUT_STR_20d, RSI_14, UPPER_SHADOW, gold_GOLD_ma30_ratio, dxy_DXY_ma30_ratio, MACDS_12_26_9, l2_arbitrum_tvl_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 2 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-07-16 ~ 2022-09-23 (N=800)\n",
      " Val   Period: 2022-10-07 ~ 2023-03-05 (N=150)\n",
      " Test  Period: 2023-03-19 ~ 2023-08-15 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.69, 1: 0.31}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, eth_return, MACDS_12_26_9, PRICE_VS_LOW_20d, BB_WIDTH, MACD_12_26_9, chain_eth_chain_tvl_ma30_ratio, eth_log_return, PRICE_VS_HIGH_5d, BREAKOUT_STR_5d, PRICE_VS_HIGH_20d, btc_return, OBV, UPPER_SHADOW, LOWER_SHADOW, PRICE_VS_LOW_60d, eth_btc_corr_7d, usdt_totalUnreleased_ma30_ratio, SMA_20\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 3 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-12-26 ~ 2023-03-05 (N=800)\n",
      " Val   Period: 2023-03-19 ~ 2023-08-15 (N=150)\n",
      " Test  Period: 2023-08-29 ~ 2024-01-25 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.72, 1: 0.28}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, eth_return, BREAKOUT_STR_5d, l2_arbitrum_tvl_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, SMA_20, eth_log_return, MACDS_12_26_9, eth_btc_spread, PRICE_VS_LOW_5d, EMA_12, btc_return, PRICE_VS_HIGH_5d, l2_optimism_tvl_ma30_ratio, UPPER_SHADOW, PRICE_VS_LOW_60d, eth_btc_corr_7d, usdt_totalCirculating_ma30_ratio, usdt_totalMintedUSD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 4 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-06-07 ~ 2023-08-15 (N=800)\n",
      " Val   Period: 2023-08-29 ~ 2024-01-25 (N=150)\n",
      " Test  Period: 2024-02-08 ~ 2024-07-06 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.745, 1: 0.255}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_20, btc_return, usdt_totalCirculating_ma30_ratio, usdt_totalMintedUSD_ma30_ratio, eth_return, usdt_totalUnreleased_ma30_ratio, SMA_50, BB_WIDTH, EMA_12, usdt_totalCirculatingUSD_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, eth_log_return, UPPER_SHADOW, LOWER_SHADOW, BREAKOUT_STR_5d, PRICE_VS_LOW_20d, eth_btc_corr_30d, l2_optimism_tvl_ma30_ratio, MACDS_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 5 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-11-17 ~ 2024-01-25 (N=800)\n",
      " Val   Period: 2024-02-08 ~ 2024-07-06 (N=150)\n",
      " Test  Period: 2024-07-20 ~ 2024-12-16 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7133333333333334, 1: 0.2866666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, btc_return, BREAKOUT_STR_5d, usdt_totalUnreleased_ma30_ratio, eth_return, PRICE_VS_HIGH_5d, gold_GOLD_ma30_ratio, dxy_DXY_ma30_ratio, lido_lido_eth_tvl_ma30_ratio, SMA_20, SMA_50, eth_log_return, MACDS_12_26_9, usdt_totalMintedUSD_ma30_ratio, usdt_totalCirculatingUSD_ma30_ratio, return_lag10, MFI_14, UPPER_SHADOW, LOWER_SHADOW, BB_WIDTH\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 6 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-04-29 ~ 2024-07-06 (N=800)\n",
      " Val   Period: 2024-07-20 ~ 2024-12-16 (N=150)\n",
      " Test  Period: 2024-12-30 ~ 2025-05-28 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6916666666666667, 1: 0.30833333333333335}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_20, SMA_50, BB_WIDTH, eth_return, BREAKOUT_STR_5d, btc_return, dxy_DXY_ma30_ratio, EMA_12, eth_btc_corr_30d, eth_log_return, OBV, PRICE_VS_HIGH_5d, PRICE_VS_HIGH_20d, UPPER_SHADOW, BREAKOUT_STR_20d, usdt_totalUnreleased_ma30_ratio, uniswap_uniswap_eth_tvl_ma30_ratio, sp500_SP500_ma30_ratio, gold_GOLD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 7 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-10-09 ~ 2024-12-16 (N=800)\n",
      " Val   Period: 2024-12-30 ~ 2025-05-28 (N=150)\n",
      " Test  Period: 2025-06-11 ~ 2025-11-07 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6966666666666667, 1: 0.30333333333333334}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, EMA_12, MACDS_12_26_9, usdt_totalBridgedToUSD_ma30_ratio, l2_base_tvl_ma30_ratio, eth_return, btc_return, SMA_50, SMA_20, BB_WIDTH, eth_btc_corr_30d, usdt_totalCirculating_ma30_ratio, eth_log_return, eth_btc_corr_7d, PRICE_VS_HIGH_5d, usdt_totalUnreleased_ma30_ratio, curve_curve-dex_eth_tvl_ma30_ratio, l2_zksync era_tvl_ma30_ratio, gold_GOLD_ma30_ratio, price_rank_250d\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 8 (final_holdout)\n",
      "================================================================================\n",
      " Train Period: 2022-05-14 ~ 2024-07-21 (N=800)\n",
      " Val   Period: 2024-08-04 ~ 2024-12-31 (N=150)\n",
      " Test  Period: 2025-01-01 ~ 2025-11-07 (N=311)\n",
      "[Class Balance] Train Set: {0: 0.685, 1: 0.315}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, EMA_12, eth_btc_corr_30d, eth_return, btc_return, PRICE_VS_HIGH_5d, dxy_DXY_ma30_ratio, BREAKOUT_STR_20d, SMA_20, BB_WIDTH, eth_log_return, OBV, BREAKOUT_STR_5d, PRICE_VS_HIGH_20d, usdt_totalBridgedToUSD_ma30_ratio, ATR_14, UPPER_SHADOW, usdt_totalUnreleased_ma30_ratio, sp500_SP500_ma30_ratio, gold_GOLD_ma30_ratio\n",
      "\n",
      "   >> Running Fold 1/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8917 | Precision: 0.7920\n",
      "  [CatBoost] Val   Acc: 0.6200 | Precision: 0.3088\n",
      "  [RandomForest] Train Acc: 0.7217 | Precision: 0.6082\n",
      "  [RandomForest] Val   Acc: 0.6667 | Precision: 0.3390\n",
      "  [LightGBM] Train Acc: 0.7300 | Precision: 0.6198\n",
      "  [LightGBM] Val   Acc: 0.6800 | Precision: 0.3559\n",
      "  [XGBoost] Train Acc: 0.6983 | Precision: 0.8667\n",
      "  [XGBoost] Val   Acc: 0.8067 | Precision: 0.6250\n",
      "\n",
      "   >> Running Fold 2/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8667 | Precision: 0.7246\n",
      "  [CatBoost] Val   Acc: 0.5733 | Precision: 0.3696\n",
      "  [RandomForest] Train Acc: 0.7383 | Precision: 0.5573\n",
      "  [RandomForest] Val   Acc: 0.6200 | Precision: 0.3836\n",
      "  [LightGBM] Train Acc: 0.7500 | Precision: 0.5714\n",
      "  [LightGBM] Val   Acc: 0.6467 | Precision: 0.4085\n",
      "  [XGBoost] Train Acc: 0.7750 | Precision: 0.9048\n",
      "  [XGBoost] Val   Acc: 0.7533 | Precision: 0.6364\n",
      "\n",
      "   >> Running Fold 3/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8217 | Precision: 0.6473\n",
      "  [CatBoost] Val   Acc: 0.6867 | Precision: 0.4167\n",
      "  [RandomForest] Train Acc: 0.8567 | Precision: 0.7228\n",
      "  [RandomForest] Val   Acc: 0.7400 | Precision: 0.5000\n",
      "  [LightGBM] Train Acc: 0.7583 | Precision: 0.5525\n",
      "  [LightGBM] Val   Acc: 0.7467 | Precision: 0.5116\n",
      "  [XGBoost] Train Acc: 0.7533 | Precision: 1.0000\n",
      "  [XGBoost] Val   Acc: 0.7467 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 4/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8333 | Precision: 0.6293\n",
      "  [CatBoost] Val   Acc: 0.7267 | Precision: 0.6304\n",
      "  [RandomForest] Train Acc: 0.7817 | Precision: 0.5519\n",
      "  [RandomForest] Val   Acc: 0.7067 | Precision: 0.5882\n",
      "  [LightGBM] Train Acc: 0.8600 | Precision: 0.6651\n",
      "  [LightGBM] Val   Acc: 0.7333 | Precision: 0.6857\n",
      "  [XGBoost] Train Acc: 0.8317 | Precision: 0.9643\n",
      "  [XGBoost] Val   Acc: 0.6533 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 5/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7700 | Precision: 0.5726\n",
      "  [CatBoost] Val   Acc: 0.6933 | Precision: 0.4576\n",
      "  [RandomForest] Train Acc: 0.7833 | Precision: 0.5946\n",
      "  [RandomForest] Val   Acc: 0.6800 | Precision: 0.4364\n",
      "  [LightGBM] Train Acc: 0.9250 | Precision: 0.8159\n",
      "  [LightGBM] Val   Acc: 0.7133 | Precision: 0.4722\n",
      "  [XGBoost] Train Acc: 0.7600 | Precision: 0.8333\n",
      "  [XGBoost] Val   Acc: 0.7533 | Precision: 0.6667\n",
      "\n",
      "   >> Running Fold 6/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7667 | Precision: 0.5889\n",
      "  [CatBoost] Val   Acc: 0.6933 | Precision: 0.4677\n",
      "  [RandomForest] Train Acc: 0.7350 | Precision: 0.5496\n",
      "  [RandomForest] Val   Acc: 0.6800 | Precision: 0.4559\n",
      "  [LightGBM] Train Acc: 0.8100 | Precision: 0.6578\n",
      "  [LightGBM] Val   Acc: 0.7000 | Precision: 0.4776\n",
      "  [XGBoost] Train Acc: 0.7450 | Precision: 0.9000\n",
      "  [XGBoost] Val   Acc: 0.7200 | Precision: 0.5000\n",
      "\n",
      "   >> Running Fold 7/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7833 | Precision: 0.6057\n",
      "  [CatBoost] Val   Acc: 0.6667 | Precision: 0.2545\n",
      "  [RandomForest] Train Acc: 0.7867 | Precision: 0.6134\n",
      "  [RandomForest] Val   Acc: 0.6800 | Precision: 0.2549\n",
      "  [LightGBM] Train Acc: 0.7567 | Precision: 0.5726\n",
      "  [LightGBM] Val   Acc: 0.6933 | Precision: 0.2982\n",
      "  [XGBoost] Train Acc: 0.7500 | Precision: 0.9211\n",
      "  [XGBoost] Val   Acc: 0.8533 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 8/8 (final_holdout)\n",
      "  [CatBoost] Train Acc: 0.7533 | Precision: 0.5837\n",
      "  [CatBoost] Val   Acc: 0.7200 | Precision: 0.5161\n",
      "  [RandomForest] Train Acc: 0.7450 | Precision: 0.5698\n",
      "  [RandomForest] Val   Acc: 0.6600 | Precision: 0.4493\n",
      "  [LightGBM] Train Acc: 0.8100 | Precision: 0.6744\n",
      "  [LightGBM] Val   Acc: 0.6867 | Precision: 0.4783\n",
      "  [XGBoost] Train Acc: 0.7833 | Precision: 0.9275\n",
      "  [XGBoost] Val   Acc: 0.6733 | Precision: 0.4286\n",
      "\n",
      " === Trial Finished. Final Score: 0.4286R ===\n",
      "\n",
      "================================================================================\n",
      " Starting NEW trial_1_191737_L14_P1.7_S1.0\n",
      "\n",
      " Pipeline Started... (Train Start: 2020-01-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_256137/1210223439.py:54: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_ta['EMA_12'] = ta.ema(close, length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏùºÎ¥â Í∏∞Í∞Ñ: 2019-06-15 ~ 2025-11-20\n",
      "1ÏãúÍ∞ÑÎ¥â Í∏∞Í∞Ñ (KST Î≥ÄÌôò ÌõÑ): 2020-01-01 09:00:00 ~ 2025-11-23 08:00:00\n",
      "[Í≤ΩÍ≥†] 1ÏãúÍ∞ÑÎ¥â ÏãúÏûëÏùº(2020-01-01 09:00:00)Ïù¥ ÏùºÎ¥â ÏãúÏûëÏùº(2019-06-15 00:00:00) Ïù¥ÌõÑÏûÖÎãàÎã§. Ï¥àÎ∞ò ÌÉÄÍ≤ü ÏÜêÏã§ Î∞úÏÉù.\n",
      "Ïú†Ìö® ÏÉòÌîå: 2324/2337 (Ï†úÍ±∞: 13)\n",
      "Win: 825 | Lose: 1499 | Win Rate: 35.50%\n",
      "(2324, 85)\n",
      "\n",
      "================================================================================\n",
      "Reverse Rolling Walk-Forward + Final Holdout\n",
      "================================================================================\n",
      "Total period: 2020-01-01 ~ 2025-11-06 (2137 days)\n",
      "Rolling train: 800d | Val: 150d | Test: 150d | Gap: 14d\n",
      "Final holdout test: 2025-01-01 ~ 2025-11-06\n",
      "================================================================================\n",
      "\n",
      "Fold 1 (walk_forward_rolling)\n",
      "  Train:  800d  2020-01-26 ~ 2022-04-04\n",
      "  Val:    150d  2022-04-19 ~ 2022-09-15\n",
      "  Test:   150d  2022-09-30 ~ 2023-02-26\n",
      "\n",
      "Fold 2 (walk_forward_rolling)\n",
      "  Train:  800d  2020-07-08 ~ 2022-09-15\n",
      "  Val:    150d  2022-09-30 ~ 2023-02-26\n",
      "  Test:   150d  2023-03-13 ~ 2023-08-09\n",
      "\n",
      "Fold 3 (walk_forward_rolling)\n",
      "  Train:  800d  2020-12-19 ~ 2023-02-26\n",
      "  Val:    150d  2023-03-13 ~ 2023-08-09\n",
      "  Test:   150d  2023-08-24 ~ 2024-01-20\n",
      "\n",
      "Fold 4 (walk_forward_rolling)\n",
      "  Train:  800d  2021-06-01 ~ 2023-08-09\n",
      "  Val:    150d  2023-08-24 ~ 2024-01-20\n",
      "  Test:   150d  2024-02-04 ~ 2024-07-02\n",
      "\n",
      "Fold 5 (walk_forward_rolling)\n",
      "  Train:  800d  2021-11-12 ~ 2024-01-20\n",
      "  Val:    150d  2024-02-04 ~ 2024-07-02\n",
      "  Test:   150d  2024-07-17 ~ 2024-12-13\n",
      "\n",
      "Fold 6 (walk_forward_rolling)\n",
      "  Train:  800d  2022-04-25 ~ 2024-07-02\n",
      "  Val:    150d  2024-07-17 ~ 2024-12-13\n",
      "  Test:   150d  2024-12-28 ~ 2025-05-26\n",
      "\n",
      "Fold 7 (walk_forward_rolling)\n",
      "  Train:  800d  2022-10-06 ~ 2024-12-13\n",
      "  Val:    150d  2024-12-28 ~ 2025-05-26\n",
      "  Test:   150d  2025-06-10 ~ 2025-11-06\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Fold 8 (final_holdout - 2025 Ï†ÑÏ≤¥ Î≥ÑÎèÑ ÌèâÍ∞Ä)\n",
      "================================================================================\n",
      "  Train:  800d  2022-05-13 ~ 2024-07-20\n",
      "  Val:    150d  2024-08-04 ~ 2024-12-31\n",
      "  Test:   310d  2025-01-01 ~ 2025-11-06\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Created 8 folds total\n",
      "  - 7 walk-forward folds\n",
      "  - 1 final holdout fold (2025 Ï†ÑÏ≤¥)\n",
      "================================================================================\n",
      "\n",
      " Data Split Completed. Total 8 folds generated.\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 1 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-01-26 ~ 2022-04-04 (N=800)\n",
      " Val   Period: 2022-04-19 ~ 2022-09-15 (N=150)\n",
      " Test  Period: 2022-09-30 ~ 2023-02-26 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.5616666666666666, 1: 0.43833333333333335}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, MACDS_12_26_9, eth_return, btc_return, SMA_20, BB_WIDTH, MACD_12_26_9, EMA_12, eth_log_return, ATR_14, usdt_totalMintedUSD_ma30_ratio, BREAKOUT_STR_5d, RSI_14, eth_btc_corr_30d, usdt_totalUnreleased_ma30_ratio, uniswap_uniswap_eth_tvl_ma30_ratio, gold_GOLD_ma30_ratio, dxy_DXY_ma30_ratio, funding_fundingRate, usdt_totalCirculatingUSD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 2 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-07-08 ~ 2022-09-15 (N=800)\n",
      " Val   Period: 2022-09-30 ~ 2023-02-26 (N=150)\n",
      " Test  Period: 2023-03-13 ~ 2023-08-09 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6333333333333333, 1: 0.36666666666666664}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, BB_WIDTH, eth_return, PRICE_VS_LOW_60d, MACD_12_26_9, MACDS_12_26_9, eth_log_return, PRICE_VS_LOW_20d, btc_return, usdt_totalMintedUSD_ma30_ratio, BREAKOUT_STR_20d, ATR_14, EMA_12, OBV, usdt_totalUnreleased_ma30_ratio, uniswap_uniswap_eth_tvl_ma30_ratio, dxy_DXY_ma30_ratio, SMA_20, chain_eth_chain_tvl_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 3 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-12-19 ~ 2023-02-26 (N=800)\n",
      " Val   Period: 2023-03-13 ~ 2023-08-09 (N=150)\n",
      " Test  Period: 2023-08-24 ~ 2024-01-20 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6733333333333333, 1: 0.32666666666666666}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, eth_return, eth_btc_spread, BREAKOUT_STR_5d, PRICE_VS_LOW_60d, usdt_totalBridgedToUSD_ma30_ratio, SMA_20, eth_log_return, l2_arbitrum_tvl_ma30_ratio, MACD_12_26_9, btc_return, MACDS_12_26_9, PRICE_VS_HIGH_5d, UPPER_SHADOW, eth_btc_corr_7d, eth_btc_corr_30d, usdt_totalMintedUSD_ma30_ratio, chain_eth_chain_tvl_ma30_ratio, BB_WIDTH\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 4 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-06-01 ~ 2023-08-09 (N=800)\n",
      " Val   Period: 2023-08-24 ~ 2024-01-20 (N=150)\n",
      " Test  Period: 2024-02-04 ~ 2024-07-02 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6966666666666667, 1: 0.30333333333333334}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, SMA_20, btc_return, usdt_totalBridgedToUSD_ma30_ratio, usdt_totalCirculating_ma30_ratio, eth_return, usdt_totalUnreleased_ma30_ratio, BB_WIDTH, MACD_12_26_9, EMA_12, eth_log_return, usdt_totalCirculatingUSD_ma30_ratio, UPPER_SHADOW, eth_btc_corr_30d, usdt_totalMintedUSD_ma30_ratio, curve_curve-dex_eth_tvl_ma30_ratio, l2_optimism_tvl_ma30_ratio, gold_GOLD_ma30_ratio, MACDS_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 5 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-11-12 ~ 2024-01-20 (N=800)\n",
      " Val   Period: 2024-02-04 ~ 2024-07-02 (N=150)\n",
      " Test  Period: 2024-07-17 ~ 2024-12-13 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6433333333333333, 1: 0.3566666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, gold_GOLD_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, btc_return, MACDS_12_26_9, usdt_totalUnreleased_ma30_ratio, BREAKOUT_STR_5d, SMA_20, l2_zksync era_tvl_ma30_ratio, eth_btc_corr_30d, MACDH_12_26_9, LOWER_SHADOW, eth_return, eth_btc_corr_7d, l2_optimism_tvl_ma30_ratio, BB_WIDTH, MACD_12_26_9, EMA_12, PRICE_VS_HIGH_60d, ATR_14\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 6 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-04-25 ~ 2024-07-02 (N=800)\n",
      " Val   Period: 2024-07-17 ~ 2024-12-13 (N=150)\n",
      " Test  Period: 2024-12-28 ~ 2025-05-26 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.625, 1: 0.375}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, SMA_20, eth_btc_corr_30d, l2_zksync era_tvl_ma30_ratio, ATR_14, btc_return, gold_GOLD_ma30_ratio, eth_return, BB_WIDTH, EMA_12, OBV, PRICE_VS_HIGH_5d, dxy_DXY_ma30_ratio, eth_log_return, l2_base_tvl_ma30_ratio, BREAKOUT_STR_5d, BREAKOUT_STR_20d, usdt_totalUnreleased_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, l2_optimism_tvl_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 7 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-10-06 ~ 2024-12-13 (N=800)\n",
      " Val   Period: 2024-12-28 ~ 2025-05-26 (N=150)\n",
      " Test  Period: 2025-06-10 ~ 2025-11-06 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6316666666666667, 1: 0.36833333333333335}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, EMA_12, eth_btc_corr_30d, l2_base_tvl_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, price_rank_250d, btc_return, BB_WIDTH, SMA_20, usdt_totalCirculating_ma30_ratio, usdt_totalCirculatingUSD_ma30_ratio, MFI_14, vix_VIX_ma30_ratio, PRICE_VS_LOW_20d, eth_return, lido_lido_eth_tvl_ma30_ratio, gold_GOLD_ma30_ratio, MACDS_12_26_9, makerdao_makerdao_eth_tvl_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 8 (final_holdout)\n",
      "================================================================================\n",
      " Train Period: 2022-05-13 ~ 2024-07-20 (N=800)\n",
      " Val   Period: 2024-08-04 ~ 2024-12-31 (N=150)\n",
      " Test  Period: 2025-01-01 ~ 2025-11-06 (N=310)\n",
      "[Class Balance] Train Set: {0: 0.6183333333333333, 1: 0.38166666666666665}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> EMA_12, l2_base_tvl_ma30_ratio, btc_return, gold_GOLD_ma30_ratio, PRICE_VS_HIGH_5d, eth_return, SMA_50, SMA_20, BB_WIDTH, OBV, eth_btc_corr_30d, ATR_14, usdt_totalBridgedToUSD_ma30_ratio, eth_log_return, BREAKOUT_STR_20d, usdt_totalUnreleased_ma30_ratio, lido_lido_eth_tvl_ma30_ratio, l2_optimism_tvl_ma30_ratio, sp500_SP500_ma30_ratio, price_rank_250d\n",
      "\n",
      "   >> Running Fold 1/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7700 | Precision: 0.6972\n",
      "  [CatBoost] Val   Acc: 0.6467 | Precision: 0.3919\n",
      "  [RandomForest] Train Acc: 0.7283 | Precision: 0.6773\n",
      "  [RandomForest] Val   Acc: 0.6800 | Precision: 0.4068\n",
      "  [LightGBM] Train Acc: 0.7600 | Precision: 0.6977\n",
      "  [LightGBM] Val   Acc: 0.6800 | Precision: 0.4068\n",
      "  [XGBoost] Train Acc: 0.7800 | Precision: 0.8701\n",
      "  [XGBoost] Val   Acc: 0.7667 | Precision: 0.5238\n",
      "\n",
      "   >> Running Fold 2/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8617 | Precision: 0.7605\n",
      "  [CatBoost] Val   Acc: 0.6333 | Precision: 0.4521\n",
      "  [RandomForest] Train Acc: 0.7650 | Precision: 0.6586\n",
      "  [RandomForest] Val   Acc: 0.6267 | Precision: 0.4394\n",
      "  [LightGBM] Train Acc: 0.7417 | Precision: 0.6285\n",
      "  [LightGBM] Val   Acc: 0.6467 | Precision: 0.4667\n",
      "  [XGBoost] Train Acc: 0.6683 | Precision: 0.9565\n",
      "  [XGBoost] Val   Acc: 0.7000 | Precision: 0.7143\n",
      "\n",
      "   >> Running Fold 3/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8067 | Precision: 0.6739\n",
      "  [CatBoost] Val   Acc: 0.6667 | Precision: 0.5600\n",
      "  [RandomForest] Train Acc: 0.7367 | Precision: 0.5731\n",
      "  [RandomForest] Val   Acc: 0.6467 | Precision: 0.5263\n",
      "  [LightGBM] Train Acc: 0.7733 | Precision: 0.6304\n",
      "  [LightGBM] Val   Acc: 0.6800 | Precision: 0.6053\n",
      "  [XGBoost] Train Acc: 0.7217 | Precision: 0.8537\n",
      "  [XGBoost] Val   Acc: 0.6333 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 4/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8233 | Precision: 0.6712\n",
      "  [CatBoost] Val   Acc: 0.6800 | Precision: 0.7347\n",
      "  [RandomForest] Train Acc: 0.8967 | Precision: 0.7885\n",
      "  [RandomForest] Val   Acc: 0.6667 | Precision: 0.7234\n",
      "  [LightGBM] Train Acc: 0.8567 | Precision: 0.7069\n",
      "  [LightGBM] Val   Acc: 0.7067 | Precision: 0.7755\n",
      "  [XGBoost] Train Acc: 0.8483 | Precision: 0.9333\n",
      "  [XGBoost] Val   Acc: 0.5467 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 5/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9583 | Precision: 0.9127\n",
      "  [CatBoost] Val   Acc: 0.6867 | Precision: 0.5106\n",
      "  [RandomForest] Train Acc: 0.8417 | Precision: 0.7621\n",
      "  [RandomForest] Val   Acc: 0.6933 | Precision: 0.5185\n",
      "  [LightGBM] Train Acc: 0.8017 | Precision: 0.6877\n",
      "  [LightGBM] Val   Acc: 0.6867 | Precision: 0.5085\n",
      "  [XGBoost] Train Acc: 0.7217 | Precision: 0.8852\n",
      "  [XGBoost] Val   Acc: 0.6733 | Precision: 0.4615\n",
      "\n",
      "   >> Running Fold 6/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7900 | Precision: 0.6800\n",
      "  [CatBoost] Val   Acc: 0.6600 | Precision: 0.5000\n",
      "  [RandomForest] Train Acc: 0.8067 | Precision: 0.7189\n",
      "  [RandomForest] Val   Acc: 0.6800 | Precision: 0.5238\n",
      "  [LightGBM] Train Acc: 0.8217 | Precision: 0.7379\n",
      "  [LightGBM] Val   Acc: 0.6800 | Precision: 0.5246\n",
      "  [XGBoost] Train Acc: 0.7650 | Precision: 0.8281\n",
      "  [XGBoost] Val   Acc: 0.7067 | Precision: 0.7059\n",
      "\n",
      "   >> Running Fold 7/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8933 | Precision: 0.7985\n",
      "  [CatBoost] Val   Acc: 0.6667 | Precision: 0.4462\n",
      "  [RandomForest] Train Acc: 0.7917 | Precision: 0.6860\n",
      "  [RandomForest] Val   Acc: 0.6467 | Precision: 0.4074\n",
      "  [LightGBM] Train Acc: 0.7767 | Precision: 0.6761\n",
      "  [LightGBM] Val   Acc: 0.6933 | Precision: 0.4681\n",
      "  [XGBoost] Train Acc: 0.7867 | Precision: 0.8843\n",
      "  [XGBoost] Val   Acc: 0.7267 | Precision: 0.5500\n",
      "\n",
      "   >> Running Fold 8/8 (final_holdout)\n",
      "  [CatBoost] Train Acc: 0.8117 | Precision: 0.7214\n",
      "  [CatBoost] Val   Acc: 0.6600 | Precision: 0.5246\n",
      "  [RandomForest] Train Acc: 0.7817 | Precision: 0.6960\n",
      "  [RandomForest] Val   Acc: 0.6467 | Precision: 0.5082\n",
      "  [LightGBM] Train Acc: 0.8100 | Precision: 0.7386\n",
      "  [LightGBM] Val   Acc: 0.6600 | Precision: 0.5224\n",
      "  [XGBoost] Train Acc: 0.7383 | Precision: 0.9615\n",
      "  [XGBoost] Val   Acc: 0.6733 | Precision: 0.6667\n",
      "\n",
      " === Trial Finished. Final Score: 0.5500R ===\n",
      "\n",
      "[Skip] Found existing result for L=5, P=1.8, S=0.9. Score: 0.3509\n",
      "\n",
      "================================================================================\n",
      " Starting NEW trial_3_192453_L8_P2.0_S0.9\n",
      "\n",
      " Pipeline Started... (Train Start: 2020-01-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_256137/1210223439.py:54: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_ta['EMA_12'] = ta.ema(close, length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏùºÎ¥â Í∏∞Í∞Ñ: 2019-06-15 ~ 2025-11-20\n",
      "1ÏãúÍ∞ÑÎ¥â Í∏∞Í∞Ñ (KST Î≥ÄÌôò ÌõÑ): 2020-01-01 09:00:00 ~ 2025-11-23 08:00:00\n",
      "[Í≤ΩÍ≥†] 1ÏãúÍ∞ÑÎ¥â ÏãúÏûëÏùº(2020-01-01 09:00:00)Ïù¥ ÏùºÎ¥â ÏãúÏûëÏùº(2019-06-15 00:00:00) Ïù¥ÌõÑÏûÖÎãàÎã§. Ï¥àÎ∞ò ÌÉÄÍ≤ü ÏÜêÏã§ Î∞úÏÉù.\n",
      "Ïú†Ìö® ÏÉòÌîå: 2330/2343 (Ï†úÍ±∞: 13)\n",
      "Win: 565 | Lose: 1765 | Win Rate: 24.25%\n",
      "(2330, 85)\n",
      "\n",
      "================================================================================\n",
      "Reverse Rolling Walk-Forward + Final Holdout\n",
      "================================================================================\n",
      "Total period: 2020-01-01 ~ 2025-11-12 (2143 days)\n",
      "Rolling train: 800d | Val: 150d | Test: 150d | Gap: 8d\n",
      "Final holdout test: 2025-01-01 ~ 2025-11-12\n",
      "================================================================================\n",
      "\n",
      "Fold 1 (walk_forward_rolling)\n",
      "  Train:  800d  2020-03-20 ~ 2022-05-28\n",
      "  Val:    150d  2022-06-06 ~ 2022-11-02\n",
      "  Test:   150d  2022-11-11 ~ 2023-04-09\n",
      "\n",
      "Fold 2 (walk_forward_rolling)\n",
      "  Train:  800d  2020-08-25 ~ 2022-11-02\n",
      "  Val:    150d  2022-11-11 ~ 2023-04-09\n",
      "  Test:   150d  2023-04-18 ~ 2023-09-14\n",
      "\n",
      "Fold 3 (walk_forward_rolling)\n",
      "  Train:  800d  2021-01-30 ~ 2023-04-09\n",
      "  Val:    150d  2023-04-18 ~ 2023-09-14\n",
      "  Test:   150d  2023-09-23 ~ 2024-02-19\n",
      "\n",
      "Fold 4 (walk_forward_rolling)\n",
      "  Train:  800d  2021-07-07 ~ 2023-09-14\n",
      "  Val:    150d  2023-09-23 ~ 2024-02-19\n",
      "  Test:   150d  2024-02-28 ~ 2024-07-26\n",
      "\n",
      "Fold 5 (walk_forward_rolling)\n",
      "  Train:  800d  2021-12-12 ~ 2024-02-19\n",
      "  Val:    150d  2024-02-28 ~ 2024-07-26\n",
      "  Test:   150d  2024-08-04 ~ 2024-12-31\n",
      "\n",
      "Fold 6 (walk_forward_rolling)\n",
      "  Train:  800d  2022-05-19 ~ 2024-07-26\n",
      "  Val:    150d  2024-08-04 ~ 2024-12-31\n",
      "  Test:   150d  2025-01-09 ~ 2025-06-07\n",
      "\n",
      "Fold 7 (walk_forward_rolling)\n",
      "  Train:  800d  2022-10-24 ~ 2024-12-31\n",
      "  Val:    150d  2025-01-09 ~ 2025-06-07\n",
      "  Test:   150d  2025-06-16 ~ 2025-11-12\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Fold 8 (final_holdout - 2025 Ï†ÑÏ≤¥ Î≥ÑÎèÑ ÌèâÍ∞Ä)\n",
      "================================================================================\n",
      "  Train:  800d  2022-05-19 ~ 2024-07-26\n",
      "  Val:    150d  2024-08-04 ~ 2024-12-31\n",
      "  Test:   316d  2025-01-01 ~ 2025-11-12\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Created 8 folds total\n",
      "  - 7 walk-forward folds\n",
      "  - 1 final holdout fold (2025 Ï†ÑÏ≤¥)\n",
      "================================================================================\n",
      "\n",
      " Data Split Completed. Total 8 folds generated.\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 1 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-03-20 ~ 2022-05-28 (N=800)\n",
      " Val   Period: 2022-06-06 ~ 2022-11-02 (N=150)\n",
      " Test  Period: 2022-11-11 ~ 2023-04-09 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.695, 1: 0.305}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, MACD_12_26_9, OBV, BREAKOUT_STR_5d, btc_return, BB_WIDTH, SMA_20, EMA_12, MACDS_12_26_9, PRICE_VS_LOW_20d, chain_eth_chain_tvl_ma30_ratio, fg_fear_greed, PRICE_VS_LOW_60d, UPPER_SHADOW, eth_return, eth_btc_corr_7d, usdt_totalUnreleased_ma30_ratio, gold_GOLD_ma30_ratio, vix_VIX_pct_1d\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 2 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-08-25 ~ 2022-11-02 (N=800)\n",
      " Val   Period: 2022-11-11 ~ 2023-04-09 (N=150)\n",
      " Test  Period: 2023-04-18 ~ 2023-09-14 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7516666666666667, 1: 0.24833333333333332}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, BREAKOUT_STR_5d, PRICE_VS_LOW_20d, eth_return, MACD_12_26_9, SMA_20, BREAKOUT_STR_20d, PRICE_VS_HIGH_5d, MACDS_12_26_9, eth_log_return, btc_return, PRICE_VS_HIGH_20d, RSI_14, eth_btc_corr_7d, sp500_SP500_ma30_ratio, OBV, PRICE_VS_LOW_5d, PRICE_VS_LOW_60d, usdt_totalMintedUSD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 3 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-01-30 ~ 2023-04-09 (N=800)\n",
      " Val   Period: 2023-04-18 ~ 2023-09-14 (N=150)\n",
      " Test  Period: 2023-09-23 ~ 2024-02-19 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7833333333333333, 1: 0.21666666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, eth_return, usdt_totalCirculating_ma30_ratio, BREAKOUT_STR_5d, PRICE_VS_LOW_60d, BB_WIDTH, SMA_20, eth_log_return, MACD_12_26_9, l2_arbitrum_tvl_ma30_ratio, PRICE_VS_HIGH_5d, btc_return, UPPER_SHADOW, PRICE_VS_LOW_5d, eth_btc_corr_7d, usdt_totalMintedUSD_ma30_ratio, vix_VIX_ma30_ratio, EMA_12, MACDS_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 4 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-07-07 ~ 2023-09-14 (N=800)\n",
      " Val   Period: 2023-09-23 ~ 2024-02-19 (N=150)\n",
      " Test  Period: 2024-02-28 ~ 2024-07-26 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.795, 1: 0.205}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_20, BB_WIDTH, usdt_totalCirculating_ma30_ratio, btc_return, eth_return, usdt_totalMintedUSD_ma30_ratio, BREAKOUT_STR_5d, usdt_totalUnreleased_ma30_ratio, SMA_50, eth_log_return, usdt_totalCirculatingUSD_ma30_ratio, eth_btc_spread, UPPER_SHADOW, PRICE_VS_LOW_20d, usdt_totalBridgedToUSD_ma30_ratio, makerdao_makerdao_eth_tvl_ma30_ratio, MACDS_12_26_9, MACDH_12_26_9, vix_VIX_pct_1d\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 5 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-12-12 ~ 2024-02-19 (N=800)\n",
      " Val   Period: 2024-02-28 ~ 2024-07-26 (N=150)\n",
      " Test  Period: 2024-08-04 ~ 2024-12-31 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7383333333333333, 1: 0.26166666666666666}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, eth_return, btc_return, BREAKOUT_STR_5d, gold_GOLD_ma30_ratio, eth_log_return, EMA_12, BB_WIDTH, PRICE_VS_HIGH_60d, ATR_14, fg_fear_greed, PRICE_VS_HIGH_5d, usdt_totalBridgedToUSD_ma30_ratio, UPPER_SHADOW, eth_btc_corr_7d, usdt_totalCirculating_pct_1d, curve_curve-dex_eth_tvl_ma30_ratio, l2_arbitrum_tvl_ma30_ratio, SMA_20, l2_zksync era_tvl_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 6 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-05-19 ~ 2024-07-26 (N=800)\n",
      " Val   Period: 2024-08-04 ~ 2024-12-31 (N=150)\n",
      " Test  Period: 2025-01-09 ~ 2025-06-07 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7383333333333333, 1: 0.26166666666666666}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_20, SMA_50, EMA_12, btc_return, eth_return, ATR_14, BREAKOUT_STR_5d, gold_GOLD_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, BB_WIDTH, OBV, eth_log_return, l2_base_tvl_ma30_ratio, PRICE_VS_HIGH_5d, UPPER_SHADOW, BREAKOUT_STR_20d, usdt_totalCirculating_pct_1d, l2_arbitrum_tvl_ma30_ratio, sp500_SP500_ma30_ratio, l2_zksync era_tvl_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 7 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-10-24 ~ 2024-12-31 (N=800)\n",
      " Val   Period: 2025-01-09 ~ 2025-06-07 (N=150)\n",
      " Test  Period: 2025-06-16 ~ 2025-11-12 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.76, 1: 0.24}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> EMA_12, ATR_14, btc_return, BREAKOUT_STR_5d, usdt_totalCirculating_ma30_ratio, eth_return, SMA_50, BB_WIDTH, SMA_20, MACDS_12_26_9, PRICE_VS_HIGH_5d, l2_base_tvl_ma30_ratio, fg_fear_greed, PRICE_VS_LOW_60d, sp500_SP500_ma30_ratio, PRICE_VS_HIGH_60d, PRICE_VS_HIGH_20d, UPPER_SHADOW, BREAKOUT_STR_20d, usdt_totalCirculating_pct_1d\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 8 (final_holdout)\n",
      "================================================================================\n",
      " Train Period: 2022-05-19 ~ 2024-07-26 (N=800)\n",
      " Val   Period: 2024-08-04 ~ 2024-12-31 (N=150)\n",
      " Test  Period: 2025-01-01 ~ 2025-11-12 (N=316)\n",
      "[Class Balance] Train Set: {0: 0.7383333333333333, 1: 0.26166666666666666}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_20, SMA_50, EMA_12, btc_return, eth_return, ATR_14, BREAKOUT_STR_5d, gold_GOLD_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, BB_WIDTH, OBV, eth_log_return, l2_base_tvl_ma30_ratio, PRICE_VS_HIGH_5d, UPPER_SHADOW, BREAKOUT_STR_20d, usdt_totalCirculating_pct_1d, l2_arbitrum_tvl_ma30_ratio, sp500_SP500_ma30_ratio, l2_zksync era_tvl_ma30_ratio\n",
      "\n",
      "   >> Running Fold 1/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9883 | Precision: 0.9632\n",
      "  [CatBoost] Val   Acc: 0.6800 | Precision: 0.4028\n",
      "  [RandomForest] Train Acc: 0.7583 | Precision: 0.5798\n",
      "  [RandomForest] Val   Acc: 0.5000 | Precision: 0.3010\n",
      "  [LightGBM] Train Acc: 0.7783 | Precision: 0.5962\n",
      "  [LightGBM] Val   Acc: 0.5533 | Precision: 0.3187\n",
      "  [XGBoost] Train Acc: 0.7500 | Precision: 0.9714\n",
      "  [XGBoost] Val   Acc: 0.8000 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 2/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9083 | Precision: 0.7423\n",
      "  [CatBoost] Val   Acc: 0.5533 | Precision: 0.3214\n",
      "  [RandomForest] Train Acc: 0.7500 | Precision: 0.4979\n",
      "  [RandomForest] Val   Acc: 0.5667 | Precision: 0.3205\n",
      "  [LightGBM] Train Acc: 0.7250 | Precision: 0.4626\n",
      "  [LightGBM] Val   Acc: 0.6267 | Precision: 0.3390\n",
      "  [XGBoost] Train Acc: 0.7633 | Precision: 1.0000\n",
      "  [XGBoost] Val   Acc: 0.7533 | Precision: 0.5000\n",
      "\n",
      "   >> Running Fold 3/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9833 | Precision: 0.9286\n",
      "  [CatBoost] Val   Acc: 0.8600 | Precision: 0.5000\n",
      "  [RandomForest] Train Acc: 0.8483 | Precision: 0.6114\n",
      "  [RandomForest] Val   Acc: 0.8267 | Precision: 0.4000\n",
      "  [LightGBM] Train Acc: 0.7833 | Precision: 0.5000\n",
      "  [LightGBM] Val   Acc: 0.8467 | Precision: 0.4286\n",
      "  [XGBoost] Train Acc: 0.8283 | Precision: 0.9091\n",
      "  [XGBoost] Val   Acc: 0.8667 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 4/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8450 | Precision: 0.5806\n",
      "  [CatBoost] Val   Acc: 0.6800 | Precision: 0.6327\n",
      "  [RandomForest] Train Acc: 0.8950 | Precision: 0.6948\n",
      "  [RandomForest] Val   Acc: 0.6733 | Precision: 0.6364\n",
      "  [LightGBM] Train Acc: 0.6917 | Precision: 0.3789\n",
      "  [LightGBM] Val   Acc: 0.6867 | Precision: 0.6061\n",
      "  [XGBoost] Train Acc: 0.8600 | Precision: 0.9149\n",
      "  [XGBoost] Val   Acc: 0.6133 | Precision: 0.8000\n",
      "\n",
      "   >> Running Fold 5/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8150 | Precision: 0.6027\n",
      "  [CatBoost] Val   Acc: 0.6000 | Precision: 0.2424\n",
      "  [RandomForest] Train Acc: 0.7333 | Precision: 0.4940\n",
      "  [RandomForest] Val   Acc: 0.6067 | Precision: 0.2676\n",
      "  [LightGBM] Train Acc: 0.8367 | Precision: 0.6482\n",
      "  [LightGBM] Val   Acc: 0.6533 | Precision: 0.2759\n",
      "  [XGBoost] Train Acc: 0.7550 | Precision: 1.0000\n",
      "  [XGBoost] Val   Acc: 0.8333 | Precision: 0.6667\n",
      "\n",
      "   >> Running Fold 6/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9617 | Precision: 0.8764\n",
      "  [CatBoost] Val   Acc: 0.7267 | Precision: 0.3962\n",
      "  [RandomForest] Train Acc: 0.7833 | Precision: 0.5590\n",
      "  [RandomForest] Val   Acc: 0.6800 | Precision: 0.3594\n",
      "  [LightGBM] Train Acc: 0.8017 | Precision: 0.5864\n",
      "  [LightGBM] Val   Acc: 0.6733 | Precision: 0.3538\n",
      "  [XGBoost] Train Acc: 0.7417 | Precision: 1.0000\n",
      "  [XGBoost] Val   Acc: 0.8067 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 7/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9967 | Precision: 0.9863\n",
      "  [CatBoost] Val   Acc: 0.8067 | Precision: 0.2400\n",
      "  [RandomForest] Train Acc: 0.8100 | Precision: 0.5735\n",
      "  [RandomForest] Val   Acc: 0.7400 | Precision: 0.2195\n",
      "  [LightGBM] Train Acc: 0.7900 | Precision: 0.5429\n",
      "  [LightGBM] Val   Acc: 0.7000 | Precision: 0.2157\n",
      "  [XGBoost] Train Acc: 0.7867 | Precision: 0.9444\n",
      "  [XGBoost] Val   Acc: 0.9000 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 8/8 (final_holdout)\n",
      "  [CatBoost] Train Acc: 0.9683 | Precision: 0.8920\n",
      "  [CatBoost] Val   Acc: 0.7133 | Precision: 0.3818\n",
      "  [RandomForest] Train Acc: 0.7550 | Precision: 0.5208\n",
      "  [RandomForest] Val   Acc: 0.6800 | Precision: 0.3594\n",
      "  [LightGBM] Train Acc: 0.7983 | Precision: 0.5826\n",
      "  [LightGBM] Val   Acc: 0.6733 | Precision: 0.3623\n",
      "  [XGBoost] Train Acc: 0.7517 | Precision: 1.0000\n",
      "  [XGBoost] Val   Acc: 0.8000 | Precision: 0.5000\n",
      "\n",
      " === Trial Finished. Final Score: 0.2898R ===\n",
      "\n",
      "================================================================================\n",
      " Starting NEW trial_4_193536_L7_P1.7_S0.8\n",
      "\n",
      " Pipeline Started... (Train Start: 2020-01-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_256137/1210223439.py:54: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_ta['EMA_12'] = ta.ema(close, length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏùºÎ¥â Í∏∞Í∞Ñ: 2019-06-15 ~ 2025-11-20\n",
      "1ÏãúÍ∞ÑÎ¥â Í∏∞Í∞Ñ (KST Î≥ÄÌôò ÌõÑ): 2020-01-01 09:00:00 ~ 2025-11-23 08:00:00\n",
      "[Í≤ΩÍ≥†] 1ÏãúÍ∞ÑÎ¥â ÏãúÏûëÏùº(2020-01-01 09:00:00)Ïù¥ ÏùºÎ¥â ÏãúÏûëÏùº(2019-06-15 00:00:00) Ïù¥ÌõÑÏûÖÎãàÎã§. Ï¥àÎ∞ò ÌÉÄÍ≤ü ÏÜêÏã§ Î∞úÏÉù.\n",
      "Ïú†Ìö® ÏÉòÌîå: 2331/2344 (Ï†úÍ±∞: 13)\n",
      "Win: 606 | Lose: 1725 | Win Rate: 26.00%\n",
      "(2331, 85)\n",
      "\n",
      "================================================================================\n",
      "Reverse Rolling Walk-Forward + Final Holdout\n",
      "================================================================================\n",
      "Total period: 2020-01-01 ~ 2025-11-13 (2144 days)\n",
      "Rolling train: 800d | Val: 150d | Test: 150d | Gap: 7d\n",
      "Final holdout test: 2025-01-01 ~ 2025-11-13\n",
      "================================================================================\n",
      "\n",
      "Fold 1 (walk_forward_rolling)\n",
      "  Train:  800d  2020-03-29 ~ 2022-06-06\n",
      "  Val:    150d  2022-06-14 ~ 2022-11-10\n",
      "  Test:   150d  2022-11-18 ~ 2023-04-16\n",
      "\n",
      "Fold 2 (walk_forward_rolling)\n",
      "  Train:  800d  2020-09-02 ~ 2022-11-10\n",
      "  Val:    150d  2022-11-18 ~ 2023-04-16\n",
      "  Test:   150d  2023-04-24 ~ 2023-09-20\n",
      "\n",
      "Fold 3 (walk_forward_rolling)\n",
      "  Train:  800d  2021-02-06 ~ 2023-04-16\n",
      "  Val:    150d  2023-04-24 ~ 2023-09-20\n",
      "  Test:   150d  2023-09-28 ~ 2024-02-24\n",
      "\n",
      "Fold 4 (walk_forward_rolling)\n",
      "  Train:  800d  2021-07-13 ~ 2023-09-20\n",
      "  Val:    150d  2023-09-28 ~ 2024-02-24\n",
      "  Test:   150d  2024-03-03 ~ 2024-07-30\n",
      "\n",
      "Fold 5 (walk_forward_rolling)\n",
      "  Train:  800d  2021-12-17 ~ 2024-02-24\n",
      "  Val:    150d  2024-03-03 ~ 2024-07-30\n",
      "  Test:   150d  2024-08-07 ~ 2025-01-03\n",
      "\n",
      "Fold 6 (walk_forward_rolling)\n",
      "  Train:  800d  2022-05-23 ~ 2024-07-30\n",
      "  Val:    150d  2024-08-07 ~ 2025-01-03\n",
      "  Test:   150d  2025-01-11 ~ 2025-06-09\n",
      "\n",
      "Fold 7 (walk_forward_rolling)\n",
      "  Train:  800d  2022-10-27 ~ 2025-01-03\n",
      "  Val:    150d  2025-01-11 ~ 2025-06-09\n",
      "  Test:   150d  2025-06-17 ~ 2025-11-13\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Fold 8 (final_holdout - 2025 Ï†ÑÏ≤¥ Î≥ÑÎèÑ ÌèâÍ∞Ä)\n",
      "================================================================================\n",
      "  Train:  800d  2022-05-20 ~ 2024-07-27\n",
      "  Val:    150d  2024-08-04 ~ 2024-12-31\n",
      "  Test:   317d  2025-01-01 ~ 2025-11-13\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Created 8 folds total\n",
      "  - 7 walk-forward folds\n",
      "  - 1 final holdout fold (2025 Ï†ÑÏ≤¥)\n",
      "================================================================================\n",
      "\n",
      " Data Split Completed. Total 8 folds generated.\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 1 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-03-29 ~ 2022-06-06 (N=800)\n",
      " Val   Period: 2022-06-14 ~ 2022-11-10 (N=150)\n",
      " Test  Period: 2022-11-18 ~ 2023-04-16 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.685, 1: 0.315}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, EMA_12, OBV, eth_return, btc_return, BB_WIDTH, SMA_20, BREAKOUT_STR_5d, eth_log_return, MACDS_12_26_9, usdt_totalMintedUSD_ma30_ratio, return_lag2, RSI_14, BREAKOUT_STR_20d, UPPER_SHADOW, PRICE_VS_HIGH_5d, eth_btc_corr_7d, usdt_totalUnreleased_ma30_ratio, gold_GOLD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 2 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-09-02 ~ 2022-11-10 (N=800)\n",
      " Val   Period: 2022-11-18 ~ 2023-04-16 (N=150)\n",
      " Test  Period: 2023-04-24 ~ 2023-09-20 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7416666666666667, 1: 0.25833333333333336}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, eth_return, PRICE_VS_LOW_20d, btc_return, RSI_14, SMA_50, BB_WIDTH, BREAKOUT_STR_5d, PRICE_VS_HIGH_5d, eth_log_return, eth_btc_spread, BREAKOUT_STR_20d, MACDS_12_26_9, EMA_12, OBV, UPPER_SHADOW, LOWER_SHADOW, PRICE_VS_LOW_60d, usdt_totalUnreleased_ma30_ratio, sp500_SP500_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 3 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-02-06 ~ 2023-04-16 (N=800)\n",
      " Val   Period: 2023-04-24 ~ 2023-09-20 (N=150)\n",
      " Test  Period: 2023-09-28 ~ 2024-02-24 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7583333333333333, 1: 0.24166666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> eth_return, BREAKOUT_STR_5d, MACDH_12_26_9, SMA_50, eth_log_return, BB_WIDTH, usdt_totalBridgedToUSD_ma30_ratio, SMA_20, PRICE_VS_HIGH_5d, l2_arbitrum_tvl_ma30_ratio, PRICE_VS_LOW_5d, btc_return, PRICE_VS_HIGH_20d, usdt_totalCirculating_ma30_ratio, l2_optimism_tvl_ma30_ratio, ATR_14, RSI_14, UPPER_SHADOW, BREAKOUT_STR_20d, PRICE_VS_LOW_60d\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 4 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-07-13 ~ 2023-09-20 (N=800)\n",
      " Val   Period: 2023-09-28 ~ 2024-02-24 (N=150)\n",
      " Test  Period: 2024-03-03 ~ 2024-07-30 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7716666666666666, 1: 0.22833333333333333}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, eth_return, SMA_20, btc_return, usdt_totalCirculating_ma30_ratio, usdt_totalMintedUSD_ma30_ratio, BREAKOUT_STR_5d, eth_log_return, BB_WIDTH, vix_VIX_pct_1d, PRICE_VS_HIGH_5d, usdt_totalBridgedToUSD_ma30_ratio, eth_btc_spread, sp500_SP500_pct_1d, gold_GOLD_ma30_ratio, UPPER_SHADOW, LOWER_SHADOW, PRICE_VS_LOW_20d, usdt_totalUnreleased_ma30_ratio, curve_curve-dex_eth_tvl_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 5 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-12-17 ~ 2024-02-24 (N=800)\n",
      " Val   Period: 2024-03-03 ~ 2024-07-30 (N=150)\n",
      " Test  Period: 2024-08-07 ~ 2025-01-03 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7183333333333334, 1: 0.2816666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, eth_return, PRICE_VS_HIGH_5d, MACDS_12_26_9, gold_GOLD_ma30_ratio, eth_log_return, BREAKOUT_STR_5d, btc_return, usdt_totalCirculatingUSD_ma30_ratio, usdt_totalCirculating_ma30_ratio, PRICE_VS_HIGH_20d, UPPER_SHADOW, LOWER_SHADOW, eth_btc_corr_7d, usdt_totalUnreleased_ma30_ratio, curve_curve-dex_eth_tvl_ma30_ratio, dxy_DXY_ma30_ratio, SMA_20, BB_WIDTH\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 6 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-05-23 ~ 2024-07-30 (N=800)\n",
      " Val   Period: 2024-08-07 ~ 2025-01-03 (N=150)\n",
      " Test  Period: 2025-01-11 ~ 2025-06-09 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7166666666666667, 1: 0.2833333333333333}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, btc_return, eth_return, gold_GOLD_ma30_ratio, BREAKOUT_STR_20d, PRICE_VS_HIGH_5d, SMA_20, EMA_12, BB_WIDTH, eth_log_return, OBV, usdt_totalCirculating_ma30_ratio, BREAKOUT_STR_5d, UPPER_SHADOW, usdt_totalUnreleased_ma30_ratio, l2_arbitrum_tvl_ma30_ratio, dxy_DXY_ma30_ratio, dxy_DXY_pct_1d, MACDS_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 7 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-10-27 ~ 2025-01-03 (N=800)\n",
      " Val   Period: 2025-01-11 ~ 2025-06-09 (N=150)\n",
      " Test  Period: 2025-06-17 ~ 2025-11-13 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7333333333333333, 1: 0.26666666666666666}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> EMA_12, MACDS_12_26_9, eth_return, btc_return, l2_base_tvl_ma30_ratio, SMA_50, SMA_20, BB_WIDTH, usdt_totalBridgedToUSD_ma30_ratio, usdt_totalCirculating_ma30_ratio, eth_log_return, MFI_14, ATR_14, PRICE_VS_HIGH_5d, BREAKOUT_STR_20d, lido_lido_eth_tvl_ma30_ratio, gold_GOLD_ma30_ratio, PRICE_VS_LOW_60d, makerdao_makerdao_eth_tvl_ma30_ratio, return_lag2\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 8 (final_holdout)\n",
      "================================================================================\n",
      " Train Period: 2022-05-20 ~ 2024-07-27 (N=800)\n",
      " Val   Period: 2024-08-04 ~ 2024-12-31 (N=150)\n",
      " Test  Period: 2025-01-01 ~ 2025-11-13 (N=317)\n",
      "[Class Balance] Train Set: {0: 0.715, 1: 0.285}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, btc_return, eth_return, gold_GOLD_ma30_ratio, BREAKOUT_STR_20d, PRICE_VS_HIGH_5d, SMA_50, SMA_20, EMA_12, BB_WIDTH, eth_log_return, OBV, dxy_DXY_pct_1d, usdt_totalCirculating_ma30_ratio, BREAKOUT_STR_5d, l2_base_tvl_ma30_ratio, UPPER_SHADOW, eth_btc_corr_7d, l2_arbitrum_tvl_ma30_ratio, dxy_DXY_ma30_ratio\n",
      "\n",
      "   >> Running Fold 1/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9800 | Precision: 0.9403\n",
      "  [CatBoost] Val   Acc: 0.6933 | Precision: 0.4030\n",
      "  [RandomForest] Train Acc: 0.7483 | Precision: 0.5779\n",
      "  [RandomForest] Val   Acc: 0.6200 | Precision: 0.3378\n",
      "  [LightGBM] Train Acc: 0.7300 | Precision: 0.5665\n",
      "  [LightGBM] Val   Acc: 0.7667 | Precision: 0.4667\n",
      "  [XGBoost] Train Acc: 0.7200 | Precision: 0.7838\n",
      "  [XGBoost] Val   Acc: 0.8133 | Precision: 0.6667\n",
      "\n",
      "   >> Running Fold 2/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9283 | Precision: 0.7947\n",
      "  [CatBoost] Val   Acc: 0.7067 | Precision: 0.5091\n",
      "  [RandomForest] Train Acc: 0.7667 | Precision: 0.5339\n",
      "  [RandomForest] Val   Acc: 0.6667 | Precision: 0.4615\n",
      "  [LightGBM] Train Acc: 0.8450 | Precision: 0.6476\n",
      "  [LightGBM] Val   Acc: 0.6667 | Precision: 0.4615\n",
      "  [XGBoost] Train Acc: 0.8000 | Precision: 0.8571\n",
      "  [XGBoost] Val   Acc: 0.7267 | Precision: 0.7000\n",
      "\n",
      "   >> Running Fold 3/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7717 | Precision: 0.5182\n",
      "  [CatBoost] Val   Acc: 0.7133 | Precision: 0.3077\n",
      "  [RandomForest] Train Acc: 0.7767 | Precision: 0.5263\n",
      "  [RandomForest] Val   Acc: 0.7133 | Precision: 0.3077\n",
      "  [LightGBM] Train Acc: 0.8100 | Precision: 0.5749\n",
      "  [LightGBM] Val   Acc: 0.7533 | Precision: 0.3333\n",
      "  [XGBoost] Train Acc: 0.7917 | Precision: 0.9545\n",
      "  [XGBoost] Val   Acc: 0.8067 | Precision: 0.3333\n",
      "\n",
      "   >> Running Fold 4/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7700 | Precision: 0.4977\n",
      "  [CatBoost] Val   Acc: 0.6867 | Precision: 0.6452\n",
      "  [RandomForest] Train Acc: 0.7583 | Precision: 0.4815\n",
      "  [RandomForest] Val   Acc: 0.6867 | Precision: 0.6452\n",
      "  [LightGBM] Train Acc: 0.8050 | Precision: 0.5459\n",
      "  [LightGBM] Val   Acc: 0.7267 | Precision: 0.6818\n",
      "  [XGBoost] Train Acc: 0.7817 | Precision: 1.0000\n",
      "  [XGBoost] Val   Acc: 0.5933 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 5/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7633 | Precision: 0.5538\n",
      "  [CatBoost] Val   Acc: 0.6067 | Precision: 0.2609\n",
      "  [RandomForest] Train Acc: 0.7367 | Precision: 0.5217\n",
      "  [RandomForest] Val   Acc: 0.6267 | Precision: 0.2656\n",
      "  [LightGBM] Train Acc: 0.7717 | Precision: 0.5661\n",
      "  [LightGBM] Val   Acc: 0.6667 | Precision: 0.2857\n",
      "  [XGBoost] Train Acc: 0.7350 | Precision: 0.9167\n",
      "  [XGBoost] Val   Acc: 0.8333 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 6/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8800 | Precision: 0.7248\n",
      "  [CatBoost] Val   Acc: 0.6867 | Precision: 0.4000\n",
      "  [RandomForest] Train Acc: 0.7550 | Precision: 0.5477\n",
      "  [RandomForest] Val   Acc: 0.6533 | Precision: 0.3750\n",
      "  [LightGBM] Train Acc: 0.8167 | Precision: 0.6339\n",
      "  [LightGBM] Val   Acc: 0.7000 | Precision: 0.4082\n",
      "  [XGBoost] Train Acc: 0.7533 | Precision: 1.0000\n",
      "  [XGBoost] Val   Acc: 0.7600 | Precision: 0.5000\n",
      "\n",
      "   >> Running Fold 7/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8550 | Precision: 0.6622\n",
      "  [CatBoost] Val   Acc: 0.7867 | Precision: 0.4474\n",
      "  [RandomForest] Train Acc: 0.8167 | Precision: 0.6289\n",
      "  [RandomForest] Val   Acc: 0.7467 | Precision: 0.3684\n",
      "  [LightGBM] Train Acc: 0.7283 | Precision: 0.4940\n",
      "  [LightGBM] Val   Acc: 0.6733 | Precision: 0.3333\n",
      "  [XGBoost] Train Acc: 0.7367 | Precision: 1.0000\n",
      "  [XGBoost] Val   Acc: 0.8200 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 8/8 (final_holdout)\n",
      "  [CatBoost] Train Acc: 0.8433 | Precision: 0.6742\n",
      "  [CatBoost] Val   Acc: 0.6933 | Precision: 0.4000\n",
      "  [RandomForest] Train Acc: 0.7483 | Precision: 0.5413\n",
      "  [RandomForest] Val   Acc: 0.6333 | Precision: 0.3333\n",
      "  [LightGBM] Train Acc: 0.8383 | Precision: 0.6796\n",
      "  [LightGBM] Val   Acc: 0.6333 | Precision: 0.3485\n",
      "  [XGBoost] Train Acc: 0.7350 | Precision: 0.8333\n",
      "  [XGBoost] Val   Acc: 0.7667 | Precision: 0.5000\n",
      "\n",
      " === Trial Finished. Final Score: 0.3226R ===\n",
      "\n",
      "================================================================================\n",
      " Starting NEW trial_5_194451_L10_P1.6_S0.9\n",
      "\n",
      " Pipeline Started... (Train Start: 2020-01-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_256137/1210223439.py:54: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_ta['EMA_12'] = ta.ema(close, length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏùºÎ¥â Í∏∞Í∞Ñ: 2019-06-15 ~ 2025-11-20\n",
      "1ÏãúÍ∞ÑÎ¥â Í∏∞Í∞Ñ (KST Î≥ÄÌôò ÌõÑ): 2020-01-01 09:00:00 ~ 2025-11-23 08:00:00\n",
      "[Í≤ΩÍ≥†] 1ÏãúÍ∞ÑÎ¥â ÏãúÏûëÏùº(2020-01-01 09:00:00)Ïù¥ ÏùºÎ¥â ÏãúÏûëÏùº(2019-06-15 00:00:00) Ïù¥ÌõÑÏûÖÎãàÎã§. Ï¥àÎ∞ò ÌÉÄÍ≤ü ÏÜêÏã§ Î∞úÏÉù.\n",
      "Ïú†Ìö® ÏÉòÌîå: 2328/2341 (Ï†úÍ±∞: 13)\n",
      "Win: 751 | Lose: 1577 | Win Rate: 32.26%\n",
      "(2328, 85)\n",
      "\n",
      "================================================================================\n",
      "Reverse Rolling Walk-Forward + Final Holdout\n",
      "================================================================================\n",
      "Total period: 2020-01-01 ~ 2025-11-10 (2141 days)\n",
      "Rolling train: 800d | Val: 150d | Test: 150d | Gap: 10d\n",
      "Final holdout test: 2025-01-01 ~ 2025-11-10\n",
      "================================================================================\n",
      "\n",
      "Fold 1 (walk_forward_rolling)\n",
      "  Train:  800d  2020-03-02 ~ 2022-05-10\n",
      "  Val:    150d  2022-05-21 ~ 2022-10-17\n",
      "  Test:   150d  2022-10-28 ~ 2023-03-26\n",
      "\n",
      "Fold 2 (walk_forward_rolling)\n",
      "  Train:  800d  2020-08-09 ~ 2022-10-17\n",
      "  Val:    150d  2022-10-28 ~ 2023-03-26\n",
      "  Test:   150d  2023-04-06 ~ 2023-09-02\n",
      "\n",
      "Fold 3 (walk_forward_rolling)\n",
      "  Train:  800d  2021-01-16 ~ 2023-03-26\n",
      "  Val:    150d  2023-04-06 ~ 2023-09-02\n",
      "  Test:   150d  2023-09-13 ~ 2024-02-09\n",
      "\n",
      "Fold 4 (walk_forward_rolling)\n",
      "  Train:  800d  2021-06-25 ~ 2023-09-02\n",
      "  Val:    150d  2023-09-13 ~ 2024-02-09\n",
      "  Test:   150d  2024-02-20 ~ 2024-07-18\n",
      "\n",
      "Fold 5 (walk_forward_rolling)\n",
      "  Train:  800d  2021-12-02 ~ 2024-02-09\n",
      "  Val:    150d  2024-02-20 ~ 2024-07-18\n",
      "  Test:   150d  2024-07-29 ~ 2024-12-25\n",
      "\n",
      "Fold 6 (walk_forward_rolling)\n",
      "  Train:  800d  2022-05-11 ~ 2024-07-18\n",
      "  Val:    150d  2024-07-29 ~ 2024-12-25\n",
      "  Test:   150d  2025-01-05 ~ 2025-06-03\n",
      "\n",
      "Fold 7 (walk_forward_rolling)\n",
      "  Train:  800d  2022-10-18 ~ 2024-12-25\n",
      "  Val:    150d  2025-01-05 ~ 2025-06-03\n",
      "  Test:   150d  2025-06-14 ~ 2025-11-10\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Fold 8 (final_holdout - 2025 Ï†ÑÏ≤¥ Î≥ÑÎèÑ ÌèâÍ∞Ä)\n",
      "================================================================================\n",
      "  Train:  800d  2022-05-17 ~ 2024-07-24\n",
      "  Val:    150d  2024-08-04 ~ 2024-12-31\n",
      "  Test:   314d  2025-01-01 ~ 2025-11-10\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Created 8 folds total\n",
      "  - 7 walk-forward folds\n",
      "  - 1 final holdout fold (2025 Ï†ÑÏ≤¥)\n",
      "================================================================================\n",
      "\n",
      " Data Split Completed. Total 8 folds generated.\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 1 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-03-02 ~ 2022-05-10 (N=800)\n",
      " Val   Period: 2022-05-21 ~ 2022-10-17 (N=150)\n",
      " Test  Period: 2022-10-28 ~ 2023-03-26 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6216666666666667, 1: 0.37833333333333335}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, BREAKOUT_STR_5d, eth_return, usdt_totalMintedUSD_ma30_ratio, btc_return, PRICE_VS_LOW_5d, BB_WIDTH, MACD_12_26_9, EMA_12, MACDS_12_26_9, eth_log_return, OBV, BREAKOUT_STR_20d, PRICE_VS_HIGH_5d, UPPER_SHADOW, gold_GOLD_ma30_ratio, SMA_20, usdt_totalBridgedToUSD_ma30_ratio, fg_fear_greed\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 2 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-08-09 ~ 2022-10-17 (N=800)\n",
      " Val   Period: 2022-10-28 ~ 2023-03-26 (N=150)\n",
      " Test  Period: 2023-04-06 ~ 2023-09-02 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6966666666666667, 1: 0.30333333333333334}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, chain_eth_chain_tvl_ma30_ratio, eth_return, PRICE_VS_LOW_20d, BREAKOUT_STR_5d, PRICE_VS_LOW_60d, MACDS_12_26_9, eth_log_return, MACD_12_26_9, PRICE_VS_HIGH_5d, BREAKOUT_STR_20d, curve_curve-dex_eth_tvl_ma30_ratio, UPPER_SHADOW, usdt_totalUnreleased_ma30_ratio, dxy_DXY_ma30_ratio, BB_WIDTH, vix_VIX_pct_1d, usdt_totalBridgedToUSD_ma30_ratio, BREAKOUT_STR_60d\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 3 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-01-16 ~ 2023-03-26 (N=800)\n",
      " Val   Period: 2023-04-06 ~ 2023-09-02 (N=150)\n",
      " Test  Period: 2023-09-13 ~ 2024-02-09 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.71, 1: 0.29}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, eth_return, SMA_20, PRICE_VS_LOW_60d, eth_btc_spread, BREAKOUT_STR_5d, eth_log_return, usdt_totalBridgedToUSD_ma30_ratio, MACDS_12_26_9, l2_arbitrum_tvl_ma30_ratio, PRICE_VS_HIGH_5d, PRICE_VS_LOW_5d, BREAKOUT_STR_20d, btc_return, UPPER_SHADOW, eth_btc_corr_30d, usdt_totalCirculating_ma30_ratio, usdt_totalMintedUSD_ma30_ratio, curve_curve-dex_eth_tvl_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 4 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-06-25 ~ 2023-09-02 (N=800)\n",
      " Val   Period: 2023-09-13 ~ 2024-02-09 (N=150)\n",
      " Test  Period: 2024-02-20 ~ 2024-07-18 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7083333333333334, 1: 0.2916666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_20, btc_return, eth_return, usdt_totalCirculating_ma30_ratio, usdt_totalMintedUSD_ma30_ratio, BREAKOUT_STR_5d, SMA_50, MACDS_12_26_9, eth_log_return, BB_WIDTH, usdt_totalCirculatingUSD_ma30_ratio, MACDH_12_26_9, usdt_totalBridgedToUSD_ma30_ratio, eth_btc_spread, eth_btc_corr_7d, eth_btc_corr_30d, usdt_totalUnreleased_ma30_ratio, l2_optimism_tvl_ma30_ratio, MACD_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 5 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-12-02 ~ 2024-02-09 (N=800)\n",
      " Val   Period: 2024-02-20 ~ 2024-07-18 (N=150)\n",
      " Test  Period: 2024-07-29 ~ 2024-12-25 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6483333333333333, 1: 0.3516666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> btc_return, eth_return, gold_GOLD_ma30_ratio, dxy_DXY_ma30_ratio, BREAKOUT_STR_5d, l2_zksync era_tvl_ma30_ratio, eth_log_return, MACDS_12_26_9, MACDH_12_26_9, PRICE_VS_HIGH_5d, ATR_14, return_lag10, UPPER_SHADOW, LOWER_SHADOW, BREAKOUT_STR_20d, usdt_totalUnreleased_ma30_ratio, aave_aave_eth_tvl_ma30_ratio, l2_optimism_tvl_ma30_ratio, SMA_20, SMA_50\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 6 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-05-11 ~ 2024-07-18 (N=800)\n",
      " Val   Period: 2024-07-29 ~ 2024-12-25 (N=150)\n",
      " Test  Period: 2025-01-05 ~ 2025-06-03 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6366666666666667, 1: 0.36333333333333334}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, EMA_12, eth_return, btc_return, gold_GOLD_ma30_ratio, dxy_DXY_ma30_ratio, SMA_20, BB_WIDTH, eth_log_return, OBV, usdt_totalBridgedToUSD_ma30_ratio, BREAKOUT_STR_5d, l2_zksync era_tvl_ma30_ratio, PRICE_VS_HIGH_5d, PRICE_VS_LOW_60d, BREAKOUT_STR_20d, usdt_totalUnreleased_ma30_ratio, lido_lido_eth_tvl_ma30_ratio, dxy_DXY_pct_1d\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 7 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-10-18 ~ 2024-12-25 (N=800)\n",
      " Val   Period: 2025-01-05 ~ 2025-06-03 (N=150)\n",
      " Test  Period: 2025-06-14 ~ 2025-11-10 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6683333333333333, 1: 0.33166666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, EMA_12, MACDS_12_26_9, usdt_totalCirculating_ma30_ratio, eth_return, btc_return, l2_base_tvl_ma30_ratio, SMA_50, SMA_20, BB_WIDTH, eth_btc_corr_30d, usdt_totalCirculatingUSD_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, eth_log_return, PRICE_VS_HIGH_5d, BREAKOUT_STR_5d, usdt_totalUnreleased_ma30_ratio, gold_GOLD_ma30_ratio, usdt_totalMintedUSD_ma30_ratio, PRICE_VS_HIGH_60d\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 8 (final_holdout)\n",
      "================================================================================\n",
      " Train Period: 2022-05-17 ~ 2024-07-24 (N=800)\n",
      " Val   Period: 2024-08-04 ~ 2024-12-31 (N=150)\n",
      " Test  Period: 2025-01-01 ~ 2025-11-10 (N=314)\n",
      "[Class Balance] Train Set: {0: 0.64, 1: 0.36}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, EMA_12, eth_return, btc_return, gold_GOLD_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, PRICE_VS_HIGH_5d, dxy_DXY_ma30_ratio, SMA_20, BB_WIDTH, eth_log_return, OBV, l2_zksync era_tvl_ma30_ratio, BREAKOUT_STR_5d, l2_base_tvl_ma30_ratio, LOWER_SHADOW, BREAKOUT_STR_20d, price_rank_250d, eth_btc_corr_30d\n",
      "\n",
      "   >> Running Fold 1/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8033 | Precision: 0.6953\n",
      "  [CatBoost] Val   Acc: 0.6133 | Precision: 0.3380\n",
      "  [RandomForest] Train Acc: 0.7400 | Precision: 0.6320\n",
      "  [RandomForest] Val   Acc: 0.6333 | Precision: 0.3438\n",
      "  [LightGBM] Train Acc: 0.7417 | Precision: 0.6250\n",
      "  [LightGBM] Val   Acc: 0.6333 | Precision: 0.3611\n",
      "  [XGBoost] Train Acc: 0.7100 | Precision: 0.8118\n",
      "  [XGBoost] Val   Acc: 0.7933 | Precision: 0.6429\n",
      "\n",
      "   >> Running Fold 2/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8083 | Precision: 0.6476\n",
      "  [CatBoost] Val   Acc: 0.6467 | Precision: 0.4310\n",
      "  [RandomForest] Train Acc: 0.7900 | Precision: 0.6217\n",
      "  [RandomForest] Val   Acc: 0.6133 | Precision: 0.3968\n",
      "  [LightGBM] Train Acc: 0.7417 | Precision: 0.5506\n",
      "  [LightGBM] Val   Acc: 0.6667 | Precision: 0.4490\n",
      "  [XGBoost] Train Acc: 0.7183 | Precision: 1.0000\n",
      "  [XGBoost] Val   Acc: 0.7067 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 3/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8300 | Precision: 0.6651\n",
      "  [CatBoost] Val   Acc: 0.7400 | Precision: 0.5769\n",
      "  [RandomForest] Train Acc: 0.8067 | Precision: 0.6381\n",
      "  [RandomForest] Val   Acc: 0.7333 | Precision: 0.5484\n",
      "  [LightGBM] Train Acc: 0.8133 | Precision: 0.6435\n",
      "  [LightGBM] Val   Acc: 0.7667 | Precision: 0.7222\n",
      "  [XGBoost] Train Acc: 0.7583 | Precision: 0.9143\n",
      "  [XGBoost] Val   Acc: 0.7333 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 4/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8100 | Precision: 0.6309\n",
      "  [CatBoost] Val   Acc: 0.7133 | Precision: 0.7586\n",
      "  [RandomForest] Train Acc: 0.8850 | Precision: 0.7650\n",
      "  [RandomForest] Val   Acc: 0.6333 | Precision: 0.6957\n",
      "  [LightGBM] Train Acc: 0.6817 | Precision: 0.4704\n",
      "  [LightGBM] Val   Acc: 0.7000 | Precision: 0.7121\n",
      "  [XGBoost] Train Acc: 0.8150 | Precision: 0.8721\n",
      "  [XGBoost] Val   Acc: 0.5800 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 5/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9183 | Precision: 0.8462\n",
      "  [CatBoost] Val   Acc: 0.7133 | Precision: 0.4912\n",
      "  [RandomForest] Train Acc: 0.7767 | Precision: 0.6498\n",
      "  [RandomForest] Val   Acc: 0.6800 | Precision: 0.4545\n",
      "  [LightGBM] Train Acc: 0.9050 | Precision: 0.8319\n",
      "  [LightGBM] Val   Acc: 0.7200 | Precision: 0.5000\n",
      "  [XGBoost] Train Acc: 0.7283 | Precision: 0.9286\n",
      "  [XGBoost] Val   Acc: 0.7400 | Precision: 0.5652\n",
      "\n",
      "   >> Running Fold 6/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8300 | Precision: 0.7214\n",
      "  [CatBoost] Val   Acc: 0.6800 | Precision: 0.4706\n",
      "  [RandomForest] Train Acc: 0.7633 | Precision: 0.6473\n",
      "  [RandomForest] Val   Acc: 0.6733 | Precision: 0.4638\n",
      "  [LightGBM] Train Acc: 0.8100 | Precision: 0.7063\n",
      "  [LightGBM] Val   Acc: 0.6867 | Precision: 0.4776\n",
      "  [XGBoost] Train Acc: 0.7283 | Precision: 0.8873\n",
      "  [XGBoost] Val   Acc: 0.7333 | Precision: 0.6429\n",
      "\n",
      "   >> Running Fold 7/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8900 | Precision: 0.7782\n",
      "  [CatBoost] Val   Acc: 0.6733 | Precision: 0.3148\n",
      "  [RandomForest] Train Acc: 0.8167 | Precision: 0.6996\n",
      "  [RandomForest] Val   Acc: 0.6800 | Precision: 0.3137\n",
      "  [LightGBM] Train Acc: 0.7650 | Precision: 0.6250\n",
      "  [LightGBM] Val   Acc: 0.7267 | Precision: 0.3696\n",
      "  [XGBoost] Train Acc: 0.8367 | Precision: 0.8686\n",
      "  [XGBoost] Val   Acc: 0.8200 | Precision: 0.6667\n",
      "\n",
      "   >> Running Fold 8/8 (final_holdout)\n",
      "  [CatBoost] Train Acc: 0.7700 | Precision: 0.6434\n",
      "  [CatBoost] Val   Acc: 0.6600 | Precision: 0.4776\n",
      "  [RandomForest] Train Acc: 0.7833 | Precision: 0.6629\n",
      "  [RandomForest] Val   Acc: 0.6200 | Precision: 0.4348\n",
      "  [LightGBM] Train Acc: 0.8117 | Precision: 0.7068\n",
      "  [LightGBM] Val   Acc: 0.6533 | Precision: 0.4714\n",
      "  [XGBoost] Train Acc: 0.6583 | Precision: 0.8667\n",
      "  [XGBoost] Val   Acc: 0.6933 | Precision: 1.0000\n",
      "\n",
      " === Trial Finished. Final Score: 0.4669R ===\n",
      "\n",
      "================================================================================\n",
      " Starting NEW trial_6_195212_L7_P1.5_S1.0\n",
      "\n",
      " Pipeline Started... (Train Start: 2020-01-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_256137/1210223439.py:54: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_ta['EMA_12'] = ta.ema(close, length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏùºÎ¥â Í∏∞Í∞Ñ: 2019-06-15 ~ 2025-11-20\n",
      "1ÏãúÍ∞ÑÎ¥â Í∏∞Í∞Ñ (KST Î≥ÄÌôò ÌõÑ): 2020-01-01 09:00:00 ~ 2025-11-23 08:00:00\n",
      "[Í≤ΩÍ≥†] 1ÏãúÍ∞ÑÎ¥â ÏãúÏûëÏùº(2020-01-01 09:00:00)Ïù¥ ÏùºÎ¥â ÏãúÏûëÏùº(2019-06-15 00:00:00) Ïù¥ÌõÑÏûÖÎãàÎã§. Ï¥àÎ∞ò ÌÉÄÍ≤ü ÏÜêÏã§ Î∞úÏÉù.\n",
      "Ïú†Ìö® ÏÉòÌîå: 2331/2344 (Ï†úÍ±∞: 13)\n",
      "Win: 749 | Lose: 1582 | Win Rate: 32.13%\n",
      "(2331, 85)\n",
      "\n",
      "================================================================================\n",
      "Reverse Rolling Walk-Forward + Final Holdout\n",
      "================================================================================\n",
      "Total period: 2020-01-01 ~ 2025-11-13 (2144 days)\n",
      "Rolling train: 800d | Val: 150d | Test: 150d | Gap: 7d\n",
      "Final holdout test: 2025-01-01 ~ 2025-11-13\n",
      "================================================================================\n",
      "\n",
      "Fold 1 (walk_forward_rolling)\n",
      "  Train:  800d  2020-03-29 ~ 2022-06-06\n",
      "  Val:    150d  2022-06-14 ~ 2022-11-10\n",
      "  Test:   150d  2022-11-18 ~ 2023-04-16\n",
      "\n",
      "Fold 2 (walk_forward_rolling)\n",
      "  Train:  800d  2020-09-02 ~ 2022-11-10\n",
      "  Val:    150d  2022-11-18 ~ 2023-04-16\n",
      "  Test:   150d  2023-04-24 ~ 2023-09-20\n",
      "\n",
      "Fold 3 (walk_forward_rolling)\n",
      "  Train:  800d  2021-02-06 ~ 2023-04-16\n",
      "  Val:    150d  2023-04-24 ~ 2023-09-20\n",
      "  Test:   150d  2023-09-28 ~ 2024-02-24\n",
      "\n",
      "Fold 4 (walk_forward_rolling)\n",
      "  Train:  800d  2021-07-13 ~ 2023-09-20\n",
      "  Val:    150d  2023-09-28 ~ 2024-02-24\n",
      "  Test:   150d  2024-03-03 ~ 2024-07-30\n",
      "\n",
      "Fold 5 (walk_forward_rolling)\n",
      "  Train:  800d  2021-12-17 ~ 2024-02-24\n",
      "  Val:    150d  2024-03-03 ~ 2024-07-30\n",
      "  Test:   150d  2024-08-07 ~ 2025-01-03\n",
      "\n",
      "Fold 6 (walk_forward_rolling)\n",
      "  Train:  800d  2022-05-23 ~ 2024-07-30\n",
      "  Val:    150d  2024-08-07 ~ 2025-01-03\n",
      "  Test:   150d  2025-01-11 ~ 2025-06-09\n",
      "\n",
      "Fold 7 (walk_forward_rolling)\n",
      "  Train:  800d  2022-10-27 ~ 2025-01-03\n",
      "  Val:    150d  2025-01-11 ~ 2025-06-09\n",
      "  Test:   150d  2025-06-17 ~ 2025-11-13\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Fold 8 (final_holdout - 2025 Ï†ÑÏ≤¥ Î≥ÑÎèÑ ÌèâÍ∞Ä)\n",
      "================================================================================\n",
      "  Train:  800d  2022-05-20 ~ 2024-07-27\n",
      "  Val:    150d  2024-08-04 ~ 2024-12-31\n",
      "  Test:   317d  2025-01-01 ~ 2025-11-13\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Created 8 folds total\n",
      "  - 7 walk-forward folds\n",
      "  - 1 final holdout fold (2025 Ï†ÑÏ≤¥)\n",
      "================================================================================\n",
      "\n",
      " Data Split Completed. Total 8 folds generated.\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 1 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-03-29 ~ 2022-06-06 (N=800)\n",
      " Val   Period: 2022-06-14 ~ 2022-11-10 (N=150)\n",
      " Test  Period: 2022-11-18 ~ 2023-04-16 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6266666666666667, 1: 0.37333333333333335}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, eth_return, MACDS_12_26_9, btc_return, BB_WIDTH, MACD_12_26_9, eth_log_return, BREAKOUT_STR_5d, OBV, PRICE_VS_LOW_5d, EMA_12, PRICE_VS_LOW_20d, PRICE_VS_HIGH_20d, UPPER_SHADOW, PRICE_VS_HIGH_5d, usdt_totalUnreleased_ma30_ratio, gold_GOLD_ma30_ratio, SMA_20, return_lag2\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 2 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-09-02 ~ 2022-11-10 (N=800)\n",
      " Val   Period: 2022-11-18 ~ 2023-04-16 (N=150)\n",
      " Test  Period: 2023-04-24 ~ 2023-09-20 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6883333333333334, 1: 0.31166666666666665}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, eth_btc_spread, MACDS_12_26_9, eth_return, btc_return, MACD_12_26_9, PRICE_VS_LOW_20d, BREAKOUT_STR_20d, PRICE_VS_LOW_5d, eth_log_return, PRICE_VS_HIGH_5d, BREAKOUT_STR_5d, RSI_14, UPPER_SHADOW, PRICE_VS_LOW_60d, aave_aave_eth_tvl_ma30_ratio, uniswap_uniswap_eth_tvl_ma30_ratio, curve_curve-dex_eth_tvl_ma30_ratio, dxy_DXY_ma30_ratio, SMA_50\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 3 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-02-06 ~ 2023-04-16 (N=800)\n",
      " Val   Period: 2023-04-24 ~ 2023-09-20 (N=150)\n",
      " Test  Period: 2023-09-28 ~ 2024-02-24 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6966666666666667, 1: 0.30333333333333334}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, MACDS_12_26_9, eth_return, BREAKOUT_STR_5d, usdt_totalBridgedToUSD_ma30_ratio, eth_log_return, btc_return, eth_btc_spread, PRICE_VS_LOW_60d, l2_arbitrum_tvl_ma30_ratio, BREAKOUT_STR_20d, PRICE_VS_HIGH_5d, SMA_20, RSI_14, UPPER_SHADOW, eth_btc_corr_30d, aave_aave_eth_tvl_ma30_ratio, l2_optimism_tvl_ma30_ratio, vix_VIX_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 4 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-07-13 ~ 2023-09-20 (N=800)\n",
      " Val   Period: 2023-09-28 ~ 2024-02-24 (N=150)\n",
      " Test  Period: 2024-03-03 ~ 2024-07-30 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.72, 1: 0.28}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, btc_return, eth_return, usdt_totalMintedUSD_ma30_ratio, usdt_totalCirculating_ma30_ratio, BREAKOUT_STR_5d, SMA_50, SMA_20, MACDH_12_26_9, eth_log_return, usdt_totalCirculatingUSD_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, PRICE_VS_HIGH_5d, PRICE_VS_LOW_5d, eth_btc_spread, UPPER_SHADOW, eth_btc_corr_30d, usdt_totalUnreleased_ma30_ratio, l2_optimism_tvl_ma30_ratio, sp500_SP500_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 5 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-12-17 ~ 2024-02-24 (N=800)\n",
      " Val   Period: 2024-03-03 ~ 2024-07-30 (N=150)\n",
      " Test  Period: 2024-08-07 ~ 2025-01-03 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6366666666666667, 1: 0.36333333333333334}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, l2_zksync era_tvl_ma30_ratio, BREAKOUT_STR_5d, eth_return, btc_return, dxy_DXY_ma30_ratio, gold_GOLD_ma30_ratio, eth_log_return, PRICE_VS_HIGH_5d, MACD_12_26_9, PRICE_VS_HIGH_20d, UPPER_SHADOW, LOWER_SHADOW, BREAKOUT_STR_20d, usdt_totalCirculating_ma30_ratio, usdt_totalUnreleased_ma30_ratio, aave_aave_eth_tvl_ma30_ratio, l2_arbitrum_tvl_ma30_ratio, SMA_20\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 6 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-05-23 ~ 2024-07-30 (N=800)\n",
      " Val   Period: 2024-08-07 ~ 2025-01-03 (N=150)\n",
      " Test  Period: 2025-01-11 ~ 2025-06-09 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.635, 1: 0.365}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, EMA_12, btc_return, eth_return, gold_GOLD_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, BB_WIDTH, OBV, eth_log_return, l2_zksync era_tvl_ma30_ratio, PRICE_VS_HIGH_5d, PRICE_VS_HIGH_20d, UPPER_SHADOW, LOWER_SHADOW, BREAKOUT_STR_5d, BREAKOUT_STR_20d, usdt_totalUnreleased_ma30_ratio, lido_lido_eth_tvl_ma30_ratio, sp500_SP500_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 7 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-10-27 ~ 2025-01-03 (N=800)\n",
      " Val   Period: 2025-01-11 ~ 2025-06-09 (N=150)\n",
      " Test  Period: 2025-06-17 ~ 2025-11-13 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6516666666666666, 1: 0.34833333333333333}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, EMA_12, eth_btc_corr_30d, MACDS_12_26_9, usdt_totalCirculating_ma30_ratio, eth_return, PRICE_VS_HIGH_5d, btc_return, MFI_14, BB_WIDTH, SMA_20, usdt_totalBridgedToUSD_ma30_ratio, eth_log_return, l2_base_tvl_ma30_ratio, BREAKOUT_STR_5d, ATR_14, gold_GOLD_ma30_ratio, usdt_totalCirculatingUSD_ma30_ratio, usdt_totalMintedUSD_ma30_ratio, PRICE_VS_HIGH_60d\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 8 (final_holdout)\n",
      "================================================================================\n",
      " Train Period: 2022-05-20 ~ 2024-07-27 (N=800)\n",
      " Val   Period: 2024-08-04 ~ 2024-12-31 (N=150)\n",
      " Test  Period: 2025-01-01 ~ 2025-11-13 (N=317)\n",
      "[Class Balance] Train Set: {0: 0.6333333333333333, 1: 0.36666666666666664}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, EMA_12, gold_GOLD_ma30_ratio, btc_return, eth_return, usdt_totalBridgedToUSD_ma30_ratio, SMA_20, BB_WIDTH, OBV, eth_log_return, l2_zksync era_tvl_ma30_ratio, ATR_14, PRICE_VS_HIGH_5d, l2_base_tvl_ma30_ratio, UPPER_SHADOW, BREAKOUT_STR_5d, usdt_totalUnreleased_ma30_ratio, l2_optimism_tvl_ma30_ratio, sp500_SP500_ma30_ratio, eth_btc_corr_30d\n",
      "\n",
      "   >> Running Fold 1/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9350 | Precision: 0.8685\n",
      "  [CatBoost] Val   Acc: 0.6200 | Precision: 0.3766\n",
      "  [RandomForest] Train Acc: 0.7667 | Precision: 0.6533\n",
      "  [RandomForest] Val   Acc: 0.6067 | Precision: 0.3636\n",
      "  [LightGBM] Train Acc: 0.7317 | Precision: 0.6198\n",
      "  [LightGBM] Val   Acc: 0.6333 | Precision: 0.3836\n",
      "  [XGBoost] Train Acc: 0.7367 | Precision: 0.8056\n",
      "  [XGBoost] Val   Acc: 0.7667 | Precision: 0.5882\n",
      "\n",
      "   >> Running Fold 2/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8950 | Precision: 0.7719\n",
      "  [CatBoost] Val   Acc: 0.6533 | Precision: 0.5385\n",
      "  [RandomForest] Train Acc: 0.7517 | Precision: 0.5772\n",
      "  [RandomForest] Val   Acc: 0.6400 | Precision: 0.5270\n",
      "  [LightGBM] Train Acc: 0.7833 | Precision: 0.6256\n",
      "  [LightGBM] Val   Acc: 0.6733 | Precision: 0.5600\n",
      "  [XGBoost] Train Acc: 0.8383 | Precision: 0.8629\n",
      "  [XGBoost] Val   Acc: 0.6867 | Precision: 0.6897\n",
      "\n",
      "   >> Running Fold 3/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7817 | Precision: 0.6000\n",
      "  [CatBoost] Val   Acc: 0.6600 | Precision: 0.4000\n",
      "  [RandomForest] Train Acc: 0.7267 | Precision: 0.5360\n",
      "  [RandomForest] Val   Acc: 0.6800 | Precision: 0.4091\n",
      "  [LightGBM] Train Acc: 0.8117 | Precision: 0.6420\n",
      "  [LightGBM] Val   Acc: 0.6933 | Precision: 0.4167\n",
      "  [XGBoost] Train Acc: 0.7450 | Precision: 0.9394\n",
      "  [XGBoost] Val   Acc: 0.7600 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 4/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8050 | Precision: 0.6094\n",
      "  [CatBoost] Val   Acc: 0.6467 | Precision: 0.7419\n",
      "  [RandomForest] Train Acc: 0.7767 | Precision: 0.5752\n",
      "  [RandomForest] Val   Acc: 0.6267 | Precision: 0.7288\n",
      "  [LightGBM] Train Acc: 0.8183 | Precision: 0.6266\n",
      "  [LightGBM] Val   Acc: 0.6600 | Precision: 0.7424\n",
      "  [XGBoost] Train Acc: 0.7583 | Precision: 0.9600\n",
      "  [XGBoost] Val   Acc: 0.4667 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 5/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8650 | Precision: 0.7773\n",
      "  [CatBoost] Val   Acc: 0.6200 | Precision: 0.3194\n",
      "  [RandomForest] Train Acc: 0.7367 | Precision: 0.6111\n",
      "  [RandomForest] Val   Acc: 0.6200 | Precision: 0.3194\n",
      "  [LightGBM] Train Acc: 0.7567 | Precision: 0.6364\n",
      "  [LightGBM] Val   Acc: 0.6333 | Precision: 0.3286\n",
      "  [XGBoost] Train Acc: 0.6500 | Precision: 1.0000\n",
      "  [XGBoost] Val   Acc: 0.8067 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 6/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8067 | Precision: 0.7068\n",
      "  [CatBoost] Val   Acc: 0.6333 | Precision: 0.4545\n",
      "  [RandomForest] Train Acc: 0.7600 | Precision: 0.6596\n",
      "  [RandomForest] Val   Acc: 0.6733 | Precision: 0.5000\n",
      "  [LightGBM] Train Acc: 0.8250 | Precision: 0.7298\n",
      "  [LightGBM] Val   Acc: 0.6600 | Precision: 0.4828\n",
      "  [XGBoost] Train Acc: 0.7350 | Precision: 0.8846\n",
      "  [XGBoost] Val   Acc: 0.7200 | Precision: 0.7333\n",
      "\n",
      "   >> Running Fold 7/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8783 | Precision: 0.7906\n",
      "  [CatBoost] Val   Acc: 0.7200 | Precision: 0.4130\n",
      "  [RandomForest] Train Acc: 0.8417 | Precision: 0.7545\n",
      "  [RandomForest] Val   Acc: 0.7333 | Precision: 0.4250\n",
      "  [LightGBM] Train Acc: 0.7900 | Precision: 0.6844\n",
      "  [LightGBM] Val   Acc: 0.7133 | Precision: 0.4082\n",
      "  [XGBoost] Train Acc: 0.7583 | Precision: 0.8333\n",
      "  [XGBoost] Val   Acc: 0.7400 | Precision: 0.3913\n",
      "\n",
      "   >> Running Fold 8/8 (final_holdout)\n",
      "  [CatBoost] Train Acc: 0.9000 | Precision: 0.8252\n",
      "  [CatBoost] Val   Acc: 0.7000 | Precision: 0.5172\n",
      "  [RandomForest] Train Acc: 0.7617 | Precision: 0.6611\n",
      "  [RandomForest] Val   Acc: 0.6667 | Precision: 0.4754\n",
      "  [LightGBM] Train Acc: 0.8333 | Precision: 0.7439\n",
      "  [LightGBM] Val   Acc: 0.6667 | Precision: 0.4727\n",
      "  [XGBoost] Train Acc: 0.7217 | Precision: 0.8533\n",
      "  [XGBoost] Val   Acc: 0.7600 | Precision: 0.8667\n",
      "\n",
      " === Trial Finished. Final Score: 0.4390R ===\n",
      "\n",
      "================================================================================\n",
      " Starting NEW trial_7_200024_L9_P2.0_S0.8\n",
      "\n",
      " Pipeline Started... (Train Start: 2020-01-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_256137/1210223439.py:54: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_ta['EMA_12'] = ta.ema(close, length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏùºÎ¥â Í∏∞Í∞Ñ: 2019-06-15 ~ 2025-11-20\n",
      "1ÏãúÍ∞ÑÎ¥â Í∏∞Í∞Ñ (KST Î≥ÄÌôò ÌõÑ): 2020-01-01 09:00:00 ~ 2025-11-23 08:00:00\n",
      "[Í≤ΩÍ≥†] 1ÏãúÍ∞ÑÎ¥â ÏãúÏûëÏùº(2020-01-01 09:00:00)Ïù¥ ÏùºÎ¥â ÏãúÏûëÏùº(2019-06-15 00:00:00) Ïù¥ÌõÑÏûÖÎãàÎã§. Ï¥àÎ∞ò ÌÉÄÍ≤ü ÏÜêÏã§ Î∞úÏÉù.\n",
      "Ïú†Ìö® ÏÉòÌîå: 2329/2342 (Ï†úÍ±∞: 13)\n",
      "Win: 562 | Lose: 1767 | Win Rate: 24.13%\n",
      "(2329, 85)\n",
      "\n",
      "================================================================================\n",
      "Reverse Rolling Walk-Forward + Final Holdout\n",
      "================================================================================\n",
      "Total period: 2020-01-01 ~ 2025-11-11 (2142 days)\n",
      "Rolling train: 800d | Val: 150d | Test: 150d | Gap: 9d\n",
      "Final holdout test: 2025-01-01 ~ 2025-11-11\n",
      "================================================================================\n",
      "\n",
      "Fold 1 (walk_forward_rolling)\n",
      "  Train:  800d  2020-03-11 ~ 2022-05-19\n",
      "  Val:    150d  2022-05-29 ~ 2022-10-25\n",
      "  Test:   150d  2022-11-04 ~ 2023-04-02\n",
      "\n",
      "Fold 2 (walk_forward_rolling)\n",
      "  Train:  800d  2020-08-17 ~ 2022-10-25\n",
      "  Val:    150d  2022-11-04 ~ 2023-04-02\n",
      "  Test:   150d  2023-04-12 ~ 2023-09-08\n",
      "\n",
      "Fold 3 (walk_forward_rolling)\n",
      "  Train:  800d  2021-01-23 ~ 2023-04-02\n",
      "  Val:    150d  2023-04-12 ~ 2023-09-08\n",
      "  Test:   150d  2023-09-18 ~ 2024-02-14\n",
      "\n",
      "Fold 4 (walk_forward_rolling)\n",
      "  Train:  800d  2021-07-01 ~ 2023-09-08\n",
      "  Val:    150d  2023-09-18 ~ 2024-02-14\n",
      "  Test:   150d  2024-02-24 ~ 2024-07-22\n",
      "\n",
      "Fold 5 (walk_forward_rolling)\n",
      "  Train:  800d  2021-12-07 ~ 2024-02-14\n",
      "  Val:    150d  2024-02-24 ~ 2024-07-22\n",
      "  Test:   150d  2024-08-01 ~ 2024-12-28\n",
      "\n",
      "Fold 6 (walk_forward_rolling)\n",
      "  Train:  800d  2022-05-15 ~ 2024-07-22\n",
      "  Val:    150d  2024-08-01 ~ 2024-12-28\n",
      "  Test:   150d  2025-01-07 ~ 2025-06-05\n",
      "\n",
      "Fold 7 (walk_forward_rolling)\n",
      "  Train:  800d  2022-10-21 ~ 2024-12-28\n",
      "  Val:    150d  2025-01-07 ~ 2025-06-05\n",
      "  Test:   150d  2025-06-15 ~ 2025-11-11\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Fold 8 (final_holdout - 2025 Ï†ÑÏ≤¥ Î≥ÑÎèÑ ÌèâÍ∞Ä)\n",
      "================================================================================\n",
      "  Train:  800d  2022-05-18 ~ 2024-07-25\n",
      "  Val:    150d  2024-08-04 ~ 2024-12-31\n",
      "  Test:   315d  2025-01-01 ~ 2025-11-11\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Created 8 folds total\n",
      "  - 7 walk-forward folds\n",
      "  - 1 final holdout fold (2025 Ï†ÑÏ≤¥)\n",
      "================================================================================\n",
      "\n",
      " Data Split Completed. Total 8 folds generated.\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 1 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-03-11 ~ 2022-05-19 (N=800)\n",
      " Val   Period: 2022-05-29 ~ 2022-10-25 (N=150)\n",
      " Test  Period: 2022-11-04 ~ 2023-04-02 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.69, 1: 0.31}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, MACD_12_26_9, BREAKOUT_STR_5d, eth_return, usdt_totalMintedUSD_ma30_ratio, btc_return, BB_WIDTH, SMA_20, EMA_12, OBV, MACDS_12_26_9, eth_log_return, PRICE_VS_HIGH_5d, UPPER_SHADOW, PRICE_VS_LOW_5d, usdt_totalUnreleased_ma30_ratio, gold_GOLD_ma30_ratio, chain_eth_chain_tvl_ma30_ratio, curve_curve-dex_eth_tvl_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 2 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-08-17 ~ 2022-10-25 (N=800)\n",
      " Val   Period: 2022-11-04 ~ 2023-04-02 (N=150)\n",
      " Test  Period: 2023-04-12 ~ 2023-09-08 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7433333333333333, 1: 0.25666666666666665}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, PRICE_VS_LOW_20d, eth_return, BREAKOUT_STR_5d, BB_WIDTH, eth_log_return, MACD_12_26_9, SMA_20, MACDS_12_26_9, PRICE_VS_HIGH_5d, PRICE_VS_HIGH_20d, BREAKOUT_STR_20d, OBV, UPPER_SHADOW, PRICE_VS_LOW_60d, eth_btc_spread, usdt_totalUnreleased_ma30_ratio, chain_eth_chain_tvl_ma30_ratio, usdt_totalCirculatingUSD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 3 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-01-23 ~ 2023-04-02 (N=800)\n",
      " Val   Period: 2023-04-12 ~ 2023-09-08 (N=150)\n",
      " Test  Period: 2023-09-18 ~ 2024-02-14 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7833333333333333, 1: 0.21666666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, SMA_20, eth_return, curve_curve-dex_eth_tvl_ma30_ratio, usdt_totalCirculatingUSD_ma30_ratio, l2_arbitrum_tvl_ma30_ratio, eth_log_return, PRICE_VS_HIGH_5d, btc_return, usdt_totalCirculating_ma30_ratio, PRICE_VS_LOW_5d, BREAKOUT_STR_5d, eth_btc_spread, usdt_totalMintedUSD_ma30_ratio, BB_WIDTH, MACDS_12_26_9, usdt_totalBridgedToUSD_ma30_ratio, MACD_12_26_9, EMA_12\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 4 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-07-01 ~ 2023-09-08 (N=800)\n",
      " Val   Period: 2023-09-18 ~ 2024-02-14 (N=150)\n",
      " Test  Period: 2024-02-24 ~ 2024-07-22 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.795, 1: 0.205}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_20, eth_return, usdt_totalCirculating_ma30_ratio, MACDH_12_26_9, BREAKOUT_STR_5d, btc_return, SMA_50, eth_log_return, eth_btc_spread, usdt_totalCirculatingUSD_ma30_ratio, EMA_12, usdt_totalMintedUSD_ma30_ratio, price_rank_250d, PRICE_VS_HIGH_5d, usdt_totalBridgedToUSD_ma30_ratio, UPPER_SHADOW, LOWER_SHADOW, usdt_totalUnreleased_ma30_ratio, l2_optimism_tvl_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 5 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-12-07 ~ 2024-02-14 (N=800)\n",
      " Val   Period: 2024-02-24 ~ 2024-07-22 (N=150)\n",
      " Test  Period: 2024-08-01 ~ 2024-12-28 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7516666666666667, 1: 0.24833333333333332}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, eth_return, BREAKOUT_STR_5d, gold_GOLD_ma30_ratio, BREAKOUT_STR_20d, eth_log_return, usdt_totalCirculatingUSD_ma30_ratio, PRICE_VS_HIGH_5d, btc_return, EMA_12, MACDS_12_26_9, funding_fundingRate, UPPER_SHADOW, eth_btc_corr_7d, eth_btc_spread, l2_arbitrum_tvl_ma30_ratio, SMA_20, BB_WIDTH, PRICE_VS_HIGH_60d\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 6 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-05-15 ~ 2024-07-22 (N=800)\n",
      " Val   Period: 2024-08-01 ~ 2024-12-28 (N=150)\n",
      " Test  Period: 2025-01-07 ~ 2025-06-05 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7466666666666667, 1: 0.25333333333333335}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, EMA_12, BREAKOUT_STR_5d, eth_return, ATR_14, BREAKOUT_STR_20d, gold_GOLD_ma30_ratio, BB_WIDTH, OBV, btc_return, eth_log_return, PRICE_VS_HIGH_5d, l2_base_tvl_ma30_ratio, eth_btc_corr_30d, l2_zksync era_tvl_ma30_ratio, PRICE_VS_HIGH_20d, UPPER_SHADOW, usdt_totalCirculating_pct_1d, l2_arbitrum_tvl_ma30_ratio, sp500_SP500_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 7 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-10-21 ~ 2024-12-28 (N=800)\n",
      " Val   Period: 2025-01-07 ~ 2025-06-05 (N=150)\n",
      " Test  Period: 2025-06-15 ~ 2025-11-11 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7666666666666667, 1: 0.23333333333333334}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> EMA_12, MACDS_12_26_9, btc_return, PRICE_VS_HIGH_5d, sp500_SP500_ma30_ratio, usdt_totalCirculating_ma30_ratio, eth_btc_corr_30d, eth_return, SMA_50, BB_WIDTH, SMA_20, usdt_totalBridgedToUSD_ma30_ratio, ATR_14, fg_fear_greed, eth_log_return, eth_btc_corr_7d, UPPER_SHADOW, BREAKOUT_STR_20d, l2_base_tvl_ma30_ratio, gold_GOLD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 8 (final_holdout)\n",
      "================================================================================\n",
      " Train Period: 2022-05-18 ~ 2024-07-25 (N=800)\n",
      " Val   Period: 2024-08-04 ~ 2024-12-31 (N=150)\n",
      " Test  Period: 2025-01-01 ~ 2025-11-11 (N=315)\n",
      "[Class Balance] Train Set: {0: 0.7466666666666667, 1: 0.25333333333333335}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, EMA_12, eth_return, BREAKOUT_STR_5d, BREAKOUT_STR_20d, gold_GOLD_ma30_ratio, SMA_20, BB_WIDTH, OBV, btc_return, eth_log_return, PRICE_VS_HIGH_5d, ATR_14, eth_btc_corr_30d, l2_base_tvl_ma30_ratio, PRICE_VS_HIGH_20d, usdt_totalBridgedToUSD_ma30_ratio, UPPER_SHADOW, l2_arbitrum_tvl_ma30_ratio, sp500_SP500_ma30_ratio\n",
      "\n",
      "   >> Running Fold 1/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7933 | Precision: 0.6240\n",
      "  [CatBoost] Val   Acc: 0.5333 | Precision: 0.2935\n",
      "  [RandomForest] Train Acc: 0.7233 | Precision: 0.5407\n",
      "  [RandomForest] Val   Acc: 0.5067 | Precision: 0.2812\n",
      "  [LightGBM] Train Acc: 0.7217 | Precision: 0.5468\n",
      "  [LightGBM] Val   Acc: 0.6533 | Precision: 0.3571\n",
      "  [XGBoost] Train Acc: 0.6900 | Precision: 0.0000\n",
      "  [XGBoost] Val   Acc: 0.7933 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 2/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8200 | Precision: 0.6045\n",
      "  [CatBoost] Val   Acc: 0.5400 | Precision: 0.2955\n",
      "  [RandomForest] Train Acc: 0.7683 | Precision: 0.5328\n",
      "  [RandomForest] Val   Acc: 0.5400 | Precision: 0.2692\n",
      "  [LightGBM] Train Acc: 0.6750 | Precision: 0.4260\n",
      "  [LightGBM] Val   Acc: 0.5800 | Precision: 0.3125\n",
      "  [XGBoost] Train Acc: 0.7433 | Precision: 0.0000\n",
      "  [XGBoost] Val   Acc: 0.7800 | Precision: 0.0000\n",
      "\n",
      "   >> Running Fold 3/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9650 | Precision: 0.8707\n",
      "  [CatBoost] Val   Acc: 0.8133 | Precision: 0.4000\n",
      "  [RandomForest] Train Acc: 0.8867 | Precision: 0.7013\n",
      "  [RandomForest] Val   Acc: 0.8467 | Precision: 0.4783\n",
      "  [LightGBM] Train Acc: 0.7900 | Precision: 0.5093\n",
      "  [LightGBM] Val   Acc: 0.8000 | Precision: 0.3824\n",
      "  [XGBoost] Train Acc: 0.8567 | Precision: 0.9583\n",
      "  [XGBoost] Val   Acc: 0.8600 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 4/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8433 | Precision: 0.5801\n",
      "  [CatBoost] Val   Acc: 0.7067 | Precision: 0.6327\n",
      "  [RandomForest] Train Acc: 0.7350 | Precision: 0.4167\n",
      "  [RandomForest] Val   Acc: 0.6933 | Precision: 0.5965\n",
      "  [LightGBM] Train Acc: 0.9183 | Precision: 0.7284\n",
      "  [LightGBM] Val   Acc: 0.7000 | Precision: 0.6765\n",
      "  [XGBoost] Train Acc: 0.8483 | Precision: 1.0000\n",
      "  [XGBoost] Val   Acc: 0.6267 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 5/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9917 | Precision: 0.9675\n",
      "  [CatBoost] Val   Acc: 0.7467 | Precision: 0.4146\n",
      "  [RandomForest] Train Acc: 0.7800 | Precision: 0.5374\n",
      "  [RandomForest] Val   Acc: 0.6600 | Precision: 0.3387\n",
      "  [LightGBM] Train Acc: 0.7967 | Precision: 0.5600\n",
      "  [LightGBM] Val   Acc: 0.6800 | Precision: 0.3731\n",
      "  [XGBoost] Train Acc: 0.7900 | Precision: 1.0000\n",
      "  [XGBoost] Val   Acc: 0.8067 | Precision: 0.7500\n",
      "\n",
      "   >> Running Fold 6/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8583 | Precision: 0.6683\n",
      "  [CatBoost] Val   Acc: 0.6933 | Precision: 0.3500\n",
      "  [RandomForest] Train Acc: 0.7550 | Precision: 0.5104\n",
      "  [RandomForest] Val   Acc: 0.6533 | Precision: 0.3065\n",
      "  [LightGBM] Train Acc: 0.8667 | Precision: 0.6978\n",
      "  [LightGBM] Val   Acc: 0.6400 | Precision: 0.3143\n",
      "  [XGBoost] Train Acc: 0.7567 | Precision: 1.0000\n",
      "  [XGBoost] Val   Acc: 0.8133 | Precision: 0.5000\n",
      "\n",
      "   >> Running Fold 7/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9883 | Precision: 0.9524\n",
      "  [CatBoost] Val   Acc: 0.8800 | Precision: 0.3333\n",
      "  [RandomForest] Train Acc: 0.7733 | Precision: 0.5092\n",
      "  [RandomForest] Val   Acc: 0.6733 | Precision: 0.1667\n",
      "  [LightGBM] Train Acc: 0.7767 | Precision: 0.5143\n",
      "  [LightGBM] Val   Acc: 0.6733 | Precision: 0.1786\n",
      "  [XGBoost] Train Acc: 0.7800 | Precision: 1.0000\n",
      "  [XGBoost] Val   Acc: 0.9200 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 8/8 (final_holdout)\n",
      "  [CatBoost] Train Acc: 0.8283 | Precision: 0.6207\n",
      "  [CatBoost] Val   Acc: 0.6467 | Precision: 0.3182\n",
      "  [RandomForest] Train Acc: 0.8800 | Precision: 0.7299\n",
      "  [RandomForest] Val   Acc: 0.6467 | Precision: 0.3125\n",
      "  [LightGBM] Train Acc: 0.8300 | Precision: 0.6250\n",
      "  [LightGBM] Val   Acc: 0.6600 | Precision: 0.3281\n",
      "  [XGBoost] Train Acc: 0.7467 | Precision: 0.0000\n",
      "  [XGBoost] Val   Acc: 0.8067 | Precision: 0.0000\n",
      "\n",
      " === Trial Finished. Final Score: 0.4781R ===\n",
      "\n",
      "================================================================================\n",
      " Starting NEW trial_8_201038_L10_P1.9_S0.8\n",
      "\n",
      " Pipeline Started... (Train Start: 2020-01-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_256137/1210223439.py:54: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_ta['EMA_12'] = ta.ema(close, length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏùºÎ¥â Í∏∞Í∞Ñ: 2019-06-15 ~ 2025-11-20\n",
      "1ÏãúÍ∞ÑÎ¥â Í∏∞Í∞Ñ (KST Î≥ÄÌôò ÌõÑ): 2020-01-01 09:00:00 ~ 2025-11-23 08:00:00\n",
      "[Í≤ΩÍ≥†] 1ÏãúÍ∞ÑÎ¥â ÏãúÏûëÏùº(2020-01-01 09:00:00)Ïù¥ ÏùºÎ¥â ÏãúÏûëÏùº(2019-06-15 00:00:00) Ïù¥ÌõÑÏûÖÎãàÎã§. Ï¥àÎ∞ò ÌÉÄÍ≤ü ÏÜêÏã§ Î∞úÏÉù.\n",
      "Ïú†Ìö® ÏÉòÌîå: 2328/2341 (Ï†úÍ±∞: 13)\n",
      "Win: 609 | Lose: 1719 | Win Rate: 26.16%\n",
      "(2328, 85)\n",
      "\n",
      "================================================================================\n",
      "Reverse Rolling Walk-Forward + Final Holdout\n",
      "================================================================================\n",
      "Total period: 2020-01-01 ~ 2025-11-10 (2141 days)\n",
      "Rolling train: 800d | Val: 150d | Test: 150d | Gap: 10d\n",
      "Final holdout test: 2025-01-01 ~ 2025-11-10\n",
      "================================================================================\n",
      "\n",
      "Fold 1 (walk_forward_rolling)\n",
      "  Train:  800d  2020-03-02 ~ 2022-05-10\n",
      "  Val:    150d  2022-05-21 ~ 2022-10-17\n",
      "  Test:   150d  2022-10-28 ~ 2023-03-26\n",
      "\n",
      "Fold 2 (walk_forward_rolling)\n",
      "  Train:  800d  2020-08-09 ~ 2022-10-17\n",
      "  Val:    150d  2022-10-28 ~ 2023-03-26\n",
      "  Test:   150d  2023-04-06 ~ 2023-09-02\n",
      "\n",
      "Fold 3 (walk_forward_rolling)\n",
      "  Train:  800d  2021-01-16 ~ 2023-03-26\n",
      "  Val:    150d  2023-04-06 ~ 2023-09-02\n",
      "  Test:   150d  2023-09-13 ~ 2024-02-09\n",
      "\n",
      "Fold 4 (walk_forward_rolling)\n",
      "  Train:  800d  2021-06-25 ~ 2023-09-02\n",
      "  Val:    150d  2023-09-13 ~ 2024-02-09\n",
      "  Test:   150d  2024-02-20 ~ 2024-07-18\n",
      "\n",
      "Fold 5 (walk_forward_rolling)\n",
      "  Train:  800d  2021-12-02 ~ 2024-02-09\n",
      "  Val:    150d  2024-02-20 ~ 2024-07-18\n",
      "  Test:   150d  2024-07-29 ~ 2024-12-25\n",
      "\n",
      "Fold 6 (walk_forward_rolling)\n",
      "  Train:  800d  2022-05-11 ~ 2024-07-18\n",
      "  Val:    150d  2024-07-29 ~ 2024-12-25\n",
      "  Test:   150d  2025-01-05 ~ 2025-06-03\n",
      "\n",
      "Fold 7 (walk_forward_rolling)\n",
      "  Train:  800d  2022-10-18 ~ 2024-12-25\n",
      "  Val:    150d  2025-01-05 ~ 2025-06-03\n",
      "  Test:   150d  2025-06-14 ~ 2025-11-10\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Fold 8 (final_holdout - 2025 Ï†ÑÏ≤¥ Î≥ÑÎèÑ ÌèâÍ∞Ä)\n",
      "================================================================================\n",
      "  Train:  800d  2022-05-17 ~ 2024-07-24\n",
      "  Val:    150d  2024-08-04 ~ 2024-12-31\n",
      "  Test:   314d  2025-01-01 ~ 2025-11-10\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Created 8 folds total\n",
      "  - 7 walk-forward folds\n",
      "  - 1 final holdout fold (2025 Ï†ÑÏ≤¥)\n",
      "================================================================================\n",
      "\n",
      " Data Split Completed. Total 8 folds generated.\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 1 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-03-02 ~ 2022-05-10 (N=800)\n",
      " Val   Period: 2022-05-21 ~ 2022-10-17 (N=150)\n",
      " Test  Period: 2022-10-28 ~ 2023-03-26 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.675, 1: 0.325}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, BB_WIDTH, BREAKOUT_STR_5d, eth_return, btc_return, usdt_totalUnreleased_ma30_ratio, usdt_totalMintedUSD_ma30_ratio, SMA_20, EMA_12, MACD_12_26_9, MACDS_12_26_9, OBV, eth_log_return, curve_curve-dex_eth_tvl_ma30_ratio, UPPER_SHADOW, PRICE_VS_LOW_20d, uniswap_uniswap_eth_tvl_ma30_ratio, gold_GOLD_ma30_ratio, fg_fear_greed\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 2 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-08-09 ~ 2022-10-17 (N=800)\n",
      " Val   Period: 2022-10-28 ~ 2023-03-26 (N=150)\n",
      " Test  Period: 2023-04-06 ~ 2023-09-02 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7316666666666667, 1: 0.2683333333333333}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, BREAKOUT_STR_5d, eth_return, PRICE_VS_LOW_20d, BB_WIDTH, chain_eth_chain_tvl_ma30_ratio, MACD_12_26_9, eth_log_return, curve_curve-dex_eth_tvl_ma30_ratio, MACDS_12_26_9, btc_return, SMA_20, OBV, PRICE_VS_LOW_5d, PRICE_VS_LOW_60d, eth_btc_corr_7d, usdt_totalUnreleased_ma30_ratio, uniswap_uniswap_eth_tvl_ma30_ratio, vix_VIX_pct_1d\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 3 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-01-16 ~ 2023-03-26 (N=800)\n",
      " Val   Period: 2023-04-06 ~ 2023-09-02 (N=150)\n",
      " Test  Period: 2023-09-13 ~ 2024-02-09 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7566666666666667, 1: 0.24333333333333335}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, eth_return, SMA_20, PRICE_VS_LOW_20d, BREAKOUT_STR_5d, curve_curve-dex_eth_tvl_ma30_ratio, eth_btc_spread, usdt_totalCirculating_ma30_ratio, MACDS_12_26_9, eth_log_return, usdt_totalBridgedToUSD_ma30_ratio, l2_arbitrum_tvl_ma30_ratio, btc_return, EMA_12, PRICE_VS_HIGH_5d, PRICE_VS_LOW_5d, usdt_totalMintedUSD_ma30_ratio, usdt_totalUnreleased_ma30_ratio, BB_WIDTH\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 4 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-06-25 ~ 2023-09-02 (N=800)\n",
      " Val   Period: 2023-09-13 ~ 2024-02-09 (N=150)\n",
      " Test  Period: 2024-02-20 ~ 2024-07-18 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7616666666666667, 1: 0.23833333333333334}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_20, usdt_totalMintedUSD_ma30_ratio, eth_return, usdt_totalCirculating_ma30_ratio, BREAKOUT_STR_5d, usdt_totalBridgedToUSD_ma30_ratio, SMA_50, BB_WIDTH, btc_return, usdt_totalCirculatingUSD_ma30_ratio, eth_log_return, vix_VIX_pct_1d, PRICE_VS_LOW_5d, EMA_12, eth_btc_spread, eth_btc_corr_30d, usdt_totalUnreleased_ma30_ratio, curve_curve-dex_eth_tvl_ma30_ratio, MACDS_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 5 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-12-02 ~ 2024-02-09 (N=800)\n",
      " Val   Period: 2024-02-20 ~ 2024-07-18 (N=150)\n",
      " Test  Period: 2024-07-29 ~ 2024-12-25 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7266666666666667, 1: 0.2733333333333333}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_20, eth_return, BREAKOUT_STR_5d, gold_GOLD_ma30_ratio, usdt_totalUnreleased_ma30_ratio, SMA_50, btc_return, eth_log_return, PRICE_VS_HIGH_5d, funding_fundingRate, return_lag10, UPPER_SHADOW, BREAKOUT_STR_20d, eth_btc_corr_7d, usdt_totalCirculating_ma30_ratio, sp500_SP500_ma30_ratio, dxy_DXY_ma30_ratio, BB_WIDTH, usdt_totalCirculatingUSD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 6 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-05-11 ~ 2024-07-18 (N=800)\n",
      " Val   Period: 2024-07-29 ~ 2024-12-25 (N=150)\n",
      " Test  Period: 2025-01-05 ~ 2025-06-03 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.715, 1: 0.285}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, btc_return, eth_return, PRICE_VS_HIGH_5d, gold_GOLD_ma30_ratio, BREAKOUT_STR_20d, BB_WIDTH, EMA_12, OBV, BREAKOUT_STR_5d, eth_log_return, ATR_14, MACDS_12_26_9, UPPER_SHADOW, sp500_SP500_ma30_ratio, dxy_DXY_ma30_ratio, SMA_20, l2_zksync era_tvl_pct_1d, usdt_totalBridgedToUSD_ma30_ratio, eth_btc_corr_30d\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 7 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-10-18 ~ 2024-12-25 (N=800)\n",
      " Val   Period: 2025-01-05 ~ 2025-06-03 (N=150)\n",
      " Test  Period: 2025-06-14 ~ 2025-11-10 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7433333333333333, 1: 0.25666666666666665}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> EMA_12, MACDS_12_26_9, btc_return, ATR_14, MFI_14, eth_return, SMA_50, BB_WIDTH, SMA_20, usdt_totalBridgedToUSD_ma30_ratio, usdt_totalCirculating_ma30_ratio, eth_btc_corr_30d, eth_btc_corr_7d, l2_base_tvl_ma30_ratio, vix_VIX_ma30_ratio, eth_log_return, PRICE_VS_HIGH_5d, makerdao_makerdao_eth_tvl_ma30_ratio, gold_GOLD_ma30_ratio, PRICE_VS_LOW_60d\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 8 (final_holdout)\n",
      "================================================================================\n",
      " Train Period: 2022-05-17 ~ 2024-07-24 (N=800)\n",
      " Val   Period: 2024-08-04 ~ 2024-12-31 (N=150)\n",
      " Test  Period: 2025-01-01 ~ 2025-11-10 (N=314)\n",
      "[Class Balance] Train Set: {0: 0.7166666666666667, 1: 0.2833333333333333}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_20, btc_return, eth_return, gold_GOLD_ma30_ratio, PRICE_VS_HIGH_5d, ATR_14, BREAKOUT_STR_20d, SMA_50, BB_WIDTH, EMA_12, OBV, eth_log_return, eth_btc_corr_30d, BREAKOUT_STR_5d, MACDS_12_26_9, MFI_14, UPPER_SHADOW, sp500_SP500_ma30_ratio, dxy_DXY_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio\n",
      "\n",
      "   >> Running Fold 1/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7283 | Precision: 0.5548\n",
      "  [CatBoost] Val   Acc: 0.5667 | Precision: 0.2750\n",
      "  [RandomForest] Train Acc: 0.7250 | Precision: 0.5564\n",
      "  [RandomForest] Val   Acc: 0.5933 | Precision: 0.2895\n",
      "  [LightGBM] Train Acc: 0.6767 | Precision: 0.5017\n",
      "  [LightGBM] Val   Acc: 0.6133 | Precision: 0.3165\n",
      "  [XGBoost] Train Acc: 0.6817 | Precision: 1.0000\n",
      "  [XGBoost] Val   Acc: 0.8200 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 2/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7900 | Precision: 0.5709\n",
      "  [CatBoost] Val   Acc: 0.6333 | Precision: 0.3636\n",
      "  [RandomForest] Train Acc: 0.7833 | Precision: 0.5671\n",
      "  [RandomForest] Val   Acc: 0.6267 | Precision: 0.3443\n",
      "  [LightGBM] Train Acc: 0.7383 | Precision: 0.5081\n",
      "  [LightGBM] Val   Acc: 0.6933 | Precision: 0.4151\n",
      "  [XGBoost] Train Acc: 0.7317 | Precision: 0.0000\n",
      "  [XGBoost] Val   Acc: 0.7533 | Precision: 0.0000\n",
      "\n",
      "   >> Running Fold 3/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8567 | Precision: 0.6531\n",
      "  [CatBoost] Val   Acc: 0.7667 | Precision: 0.4062\n",
      "  [RandomForest] Train Acc: 0.8083 | Precision: 0.5787\n",
      "  [RandomForest] Val   Acc: 0.7733 | Precision: 0.4242\n",
      "  [LightGBM] Train Acc: 0.7800 | Precision: 0.5315\n",
      "  [LightGBM] Val   Acc: 0.7400 | Precision: 0.3529\n",
      "  [XGBoost] Train Acc: 0.8300 | Precision: 1.0000\n",
      "  [XGBoost] Val   Acc: 0.8200 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 4/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9267 | Precision: 0.7735\n",
      "  [CatBoost] Val   Acc: 0.7000 | Precision: 0.6471\n",
      "  [RandomForest] Train Acc: 0.8467 | Precision: 0.6364\n",
      "  [RandomForest] Val   Acc: 0.6933 | Precision: 0.6154\n",
      "  [LightGBM] Train Acc: 0.9033 | Precision: 0.7297\n",
      "  [LightGBM] Val   Acc: 0.6933 | Precision: 0.6552\n",
      "  [XGBoost] Train Acc: 0.8033 | Precision: 0.9310\n",
      "  [XGBoost] Val   Acc: 0.6467 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 5/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9150 | Precision: 0.7703\n",
      "  [CatBoost] Val   Acc: 0.7533 | Precision: 0.5000\n",
      "  [RandomForest] Train Acc: 0.8317 | Precision: 0.6507\n",
      "  [RandomForest] Val   Acc: 0.6733 | Precision: 0.3889\n",
      "  [LightGBM] Train Acc: 0.8083 | Precision: 0.6089\n",
      "  [LightGBM] Val   Acc: 0.6600 | Precision: 0.3906\n",
      "  [XGBoost] Train Acc: 0.8550 | Precision: 0.9753\n",
      "  [XGBoost] Val   Acc: 0.7667 | Precision: 0.6250\n",
      "\n",
      "   >> Running Fold 6/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8650 | Precision: 0.7027\n",
      "  [CatBoost] Val   Acc: 0.6600 | Precision: 0.3390\n",
      "  [RandomForest] Train Acc: 0.7917 | Precision: 0.6027\n",
      "  [RandomForest] Val   Acc: 0.6333 | Precision: 0.3284\n",
      "  [LightGBM] Train Acc: 0.8400 | Precision: 0.6812\n",
      "  [LightGBM] Val   Acc: 0.6400 | Precision: 0.3333\n",
      "  [XGBoost] Train Acc: 0.7233 | Precision: 0.7273\n",
      "  [XGBoost] Val   Acc: 0.7867 | Precision: 0.5000\n",
      "\n",
      "   >> Running Fold 7/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 1.0000 | Precision: 1.0000\n",
      "  [CatBoost] Val   Acc: 0.8200 | Precision: 0.2727\n",
      "  [RandomForest] Train Acc: 0.7383 | Precision: 0.4940\n",
      "  [RandomForest] Val   Acc: 0.6533 | Precision: 0.2034\n",
      "  [LightGBM] Train Acc: 0.7233 | Precision: 0.4758\n",
      "  [LightGBM] Val   Acc: 0.6467 | Precision: 0.2188\n",
      "  [XGBoost] Train Acc: 0.8150 | Precision: 0.9778\n",
      "  [XGBoost] Val   Acc: 0.8933 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 8/8 (final_holdout)\n",
      "  [CatBoost] Train Acc: 0.8300 | Precision: 0.6518\n",
      "  [CatBoost] Val   Acc: 0.6600 | Precision: 0.3548\n",
      "  [RandomForest] Train Acc: 0.8517 | Precision: 0.7015\n",
      "  [RandomForest] Val   Acc: 0.6467 | Precision: 0.3387\n",
      "  [LightGBM] Train Acc: 0.8383 | Precision: 0.6746\n",
      "  [LightGBM] Val   Acc: 0.6400 | Precision: 0.3521\n",
      "  [XGBoost] Train Acc: 0.7217 | Precision: 1.0000\n",
      "  [XGBoost] Val   Acc: 0.7800 | Precision: 0.5000\n",
      "\n",
      " === Trial Finished. Final Score: 0.2384R ===\n",
      "\n",
      "================================================================================\n",
      " Starting NEW trial_9_201906_L13_P1.6_S1.0\n",
      "\n",
      " Pipeline Started... (Train Start: 2020-01-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_256137/1210223439.py:54: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_ta['EMA_12'] = ta.ema(close, length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏùºÎ¥â Í∏∞Í∞Ñ: 2019-06-15 ~ 2025-11-20\n",
      "1ÏãúÍ∞ÑÎ¥â Í∏∞Í∞Ñ (KST Î≥ÄÌôò ÌõÑ): 2020-01-01 09:00:00 ~ 2025-11-23 08:00:00\n",
      "[Í≤ΩÍ≥†] 1ÏãúÍ∞ÑÎ¥â ÏãúÏûëÏùº(2020-01-01 09:00:00)Ïù¥ ÏùºÎ¥â ÏãúÏûëÏùº(2019-06-15 00:00:00) Ïù¥ÌõÑÏûÖÎãàÎã§. Ï¥àÎ∞ò ÌÉÄÍ≤ü ÏÜêÏã§ Î∞úÏÉù.\n",
      "Ïú†Ìö® ÏÉòÌîå: 2325/2338 (Ï†úÍ±∞: 13)\n",
      "Win: 848 | Lose: 1477 | Win Rate: 36.47%\n",
      "(2325, 85)\n",
      "\n",
      "================================================================================\n",
      "Reverse Rolling Walk-Forward + Final Holdout\n",
      "================================================================================\n",
      "Total period: 2020-01-01 ~ 2025-11-07 (2138 days)\n",
      "Rolling train: 800d | Val: 150d | Test: 150d | Gap: 13d\n",
      "Final holdout test: 2025-01-01 ~ 2025-11-07\n",
      "================================================================================\n",
      "\n",
      "Fold 1 (walk_forward_rolling)\n",
      "  Train:  800d  2020-02-04 ~ 2022-04-13\n",
      "  Val:    150d  2022-04-27 ~ 2022-09-23\n",
      "  Test:   150d  2022-10-07 ~ 2023-03-05\n",
      "\n",
      "Fold 2 (walk_forward_rolling)\n",
      "  Train:  800d  2020-07-16 ~ 2022-09-23\n",
      "  Val:    150d  2022-10-07 ~ 2023-03-05\n",
      "  Test:   150d  2023-03-19 ~ 2023-08-15\n",
      "\n",
      "Fold 3 (walk_forward_rolling)\n",
      "  Train:  800d  2020-12-26 ~ 2023-03-05\n",
      "  Val:    150d  2023-03-19 ~ 2023-08-15\n",
      "  Test:   150d  2023-08-29 ~ 2024-01-25\n",
      "\n",
      "Fold 4 (walk_forward_rolling)\n",
      "  Train:  800d  2021-06-07 ~ 2023-08-15\n",
      "  Val:    150d  2023-08-29 ~ 2024-01-25\n",
      "  Test:   150d  2024-02-08 ~ 2024-07-06\n",
      "\n",
      "Fold 5 (walk_forward_rolling)\n",
      "  Train:  800d  2021-11-17 ~ 2024-01-25\n",
      "  Val:    150d  2024-02-08 ~ 2024-07-06\n",
      "  Test:   150d  2024-07-20 ~ 2024-12-16\n",
      "\n",
      "Fold 6 (walk_forward_rolling)\n",
      "  Train:  800d  2022-04-29 ~ 2024-07-06\n",
      "  Val:    150d  2024-07-20 ~ 2024-12-16\n",
      "  Test:   150d  2024-12-30 ~ 2025-05-28\n",
      "\n",
      "Fold 7 (walk_forward_rolling)\n",
      "  Train:  800d  2022-10-09 ~ 2024-12-16\n",
      "  Val:    150d  2024-12-30 ~ 2025-05-28\n",
      "  Test:   150d  2025-06-11 ~ 2025-11-07\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Fold 8 (final_holdout - 2025 Ï†ÑÏ≤¥ Î≥ÑÎèÑ ÌèâÍ∞Ä)\n",
      "================================================================================\n",
      "  Train:  800d  2022-05-14 ~ 2024-07-21\n",
      "  Val:    150d  2024-08-04 ~ 2024-12-31\n",
      "  Test:   311d  2025-01-01 ~ 2025-11-07\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Created 8 folds total\n",
      "  - 7 walk-forward folds\n",
      "  - 1 final holdout fold (2025 Ï†ÑÏ≤¥)\n",
      "================================================================================\n",
      "\n",
      " Data Split Completed. Total 8 folds generated.\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 1 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-02-04 ~ 2022-04-13 (N=800)\n",
      " Val   Period: 2022-04-27 ~ 2022-09-23 (N=150)\n",
      " Test  Period: 2022-10-07 ~ 2023-03-05 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.5633333333333334, 1: 0.43666666666666665}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, BREAKOUT_STR_5d, eth_return, btc_return, SMA_20, BB_WIDTH, MACD_12_26_9, EMA_12, MACDS_12_26_9, OBV, eth_log_return, usdt_totalMintedUSD_ma30_ratio, PRICE_VS_HIGH_5d, ATR_14, usdt_totalUnreleased_ma30_ratio, dxy_DXY_ma30_ratio, l2_arbitrum_tvl_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, usdt_totalCirculatingUSD_ma30_ratio, usdt_totalCirculating_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 2 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-07-16 ~ 2022-09-23 (N=800)\n",
      " Val   Period: 2022-10-07 ~ 2023-03-05 (N=150)\n",
      " Test  Period: 2023-03-19 ~ 2023-08-15 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6433333333333333, 1: 0.3566666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, MACD_12_26_9, eth_return, PRICE_VS_LOW_60d, BB_WIDTH, eth_log_return, MACDS_12_26_9, PRICE_VS_LOW_20d, btc_return, usdt_totalCirculatingUSD_ma30_ratio, PRICE_VS_HIGH_5d, BREAKOUT_STR_20d, BREAKOUT_STR_5d, PRICE_VS_HIGH_20d, OBV, usdt_totalUnreleased_ma30_ratio, dxy_DXY_ma30_ratio, chain_eth_chain_tvl_ma30_ratio, SMA_20\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 3 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-12-26 ~ 2023-03-05 (N=800)\n",
      " Val   Period: 2023-03-19 ~ 2023-08-15 (N=150)\n",
      " Test  Period: 2023-08-29 ~ 2024-01-25 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6716666666666666, 1: 0.3283333333333333}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, SMA_20, eth_return, BREAKOUT_STR_5d, eth_btc_spread, PRICE_VS_LOW_60d, usdt_totalBridgedToUSD_ma30_ratio, l2_arbitrum_tvl_ma30_ratio, eth_log_return, MACDS_12_26_9, btc_return, PRICE_VS_HIGH_5d, UPPER_SHADOW, eth_btc_corr_7d, usdt_totalCirculatingUSD_ma30_ratio, usdt_totalMintedUSD_ma30_ratio, usdt_totalUnreleased_ma30_ratio, BB_WIDTH, MACD_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 4 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-06-07 ~ 2023-08-15 (N=800)\n",
      " Val   Period: 2023-08-29 ~ 2024-01-25 (N=150)\n",
      " Test  Period: 2024-02-08 ~ 2024-07-06 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6883333333333334, 1: 0.31166666666666665}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_20, btc_return, eth_return, usdt_totalCirculating_ma30_ratio, SMA_50, BB_WIDTH, usdt_totalBridgedToUSD_ma30_ratio, eth_log_return, EMA_12, usdt_totalCirculatingUSD_ma30_ratio, PRICE_VS_HIGH_5d, BREAKOUT_STR_5d, eth_btc_corr_30d, usdt_totalMintedUSD_ma30_ratio, usdt_totalUnreleased_ma30_ratio, l2_optimism_tvl_ma30_ratio, MACDS_12_26_9, MACD_12_26_9, eth_btc_spread\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 5 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-11-17 ~ 2024-01-25 (N=800)\n",
      " Val   Period: 2024-02-08 ~ 2024-07-06 (N=150)\n",
      " Test  Period: 2024-07-20 ~ 2024-12-16 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6266666666666667, 1: 0.37333333333333335}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, btc_return, gold_GOLD_ma30_ratio, usdt_totalUnreleased_ma30_ratio, eth_return, SMA_50, usdt_totalBridgedToUSD_ma30_ratio, l2_zksync era_tvl_ma30_ratio, MACDS_12_26_9, eth_btc_corr_30d, eth_log_return, return_lag10, UPPER_SHADOW, LOWER_SHADOW, BREAKOUT_STR_5d, BREAKOUT_STR_20d, eth_btc_corr_7d, usdt_totalCirculating_pct_1d, l2_optimism_tvl_ma30_ratio, SMA_20\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 6 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-04-29 ~ 2024-07-06 (N=800)\n",
      " Val   Period: 2024-07-20 ~ 2024-12-16 (N=150)\n",
      " Test  Period: 2024-12-30 ~ 2025-05-28 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6, 1: 0.4}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_20, l2_zksync era_tvl_ma30_ratio, eth_return, btc_return, gold_GOLD_ma30_ratio, PRICE_VS_HIGH_5d, EMA_12, BB_WIDTH, OBV, eth_log_return, MACD_12_26_9, BREAKOUT_STR_5d, dxy_DXY_ma30_ratio, MFI_14, BREAKOUT_STR_20d, usdt_totalUnreleased_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, lido_lido_eth_tvl_ma30_ratio, l2_base_tvl_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 7 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-10-09 ~ 2024-12-16 (N=800)\n",
      " Val   Period: 2024-12-30 ~ 2025-05-28 (N=150)\n",
      " Test  Period: 2025-06-11 ~ 2025-11-07 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.615, 1: 0.385}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, EMA_12, eth_btc_corr_30d, usdt_totalBridgedToUSD_ma30_ratio, l2_base_tvl_ma30_ratio, eth_return, btc_return, SMA_20, BB_WIDTH, MACDS_12_26_9, price_rank_250d, eth_log_return, usdt_totalMintedUSD_ma30_ratio, PRICE_VS_HIGH_5d, PRICE_VS_LOW_20d, l2_zksync era_tvl_ma30_ratio, gold_GOLD_ma30_ratio, usdt_totalCirculatingUSD_ma30_ratio, MFI_14\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 8 (final_holdout)\n",
      "================================================================================\n",
      " Train Period: 2022-05-14 ~ 2024-07-21 (N=800)\n",
      " Val   Period: 2024-08-04 ~ 2024-12-31 (N=150)\n",
      " Test  Period: 2025-01-01 ~ 2025-11-07 (N=311)\n",
      "[Class Balance] Train Set: {0: 0.5983333333333334, 1: 0.40166666666666667}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> EMA_12, btc_return, l2_base_tvl_ma30_ratio, eth_return, l2_zksync era_tvl_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, gold_GOLD_ma30_ratio, PRICE_VS_HIGH_5d, SMA_50, SMA_20, BB_WIDTH, OBV, eth_log_return, ATR_14, MFI_14, BREAKOUT_STR_20d, usdt_totalUnreleased_ma30_ratio, lido_lido_eth_tvl_ma30_ratio, eth_btc_corr_30d, MACD_12_26_9\n",
      "\n",
      "   >> Running Fold 1/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8383 | Precision: 0.7653\n",
      "  [CatBoost] Val   Acc: 0.6200 | Precision: 0.3684\n",
      "  [RandomForest] Train Acc: 0.7250 | Precision: 0.6667\n",
      "  [RandomForest] Val   Acc: 0.6467 | Precision: 0.3788\n",
      "  [LightGBM] Train Acc: 0.7267 | Precision: 0.6690\n",
      "  [LightGBM] Val   Acc: 0.6733 | Precision: 0.4062\n",
      "  [XGBoost] Train Acc: 0.8283 | Precision: 0.8142\n",
      "  [XGBoost] Val   Acc: 0.6667 | Precision: 0.3968\n",
      "\n",
      "   >> Running Fold 2/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8517 | Precision: 0.7413\n",
      "  [CatBoost] Val   Acc: 0.6267 | Precision: 0.4605\n",
      "  [RandomForest] Train Acc: 0.7567 | Precision: 0.6328\n",
      "  [RandomForest] Val   Acc: 0.6267 | Precision: 0.4615\n",
      "  [LightGBM] Train Acc: 0.7250 | Precision: 0.5984\n",
      "  [LightGBM] Val   Acc: 0.6400 | Precision: 0.4667\n",
      "  [XGBoost] Train Acc: 0.7250 | Precision: 0.7692\n",
      "  [XGBoost] Val   Acc: 0.7133 | Precision: 0.6667\n",
      "\n",
      "   >> Running Fold 3/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9350 | Precision: 0.8527\n",
      "  [CatBoost] Val   Acc: 0.6733 | Precision: 0.6000\n",
      "  [RandomForest] Train Acc: 0.7950 | Precision: 0.6609\n",
      "  [RandomForest] Val   Acc: 0.6600 | Precision: 0.5455\n",
      "  [LightGBM] Train Acc: 0.7800 | Precision: 0.6395\n",
      "  [LightGBM] Val   Acc: 0.6333 | Precision: 0.5000\n",
      "  [XGBoost] Train Acc: 0.7383 | Precision: 0.7381\n",
      "  [XGBoost] Val   Acc: 0.6733 | Precision: 0.8000\n",
      "\n",
      "   >> Running Fold 4/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7967 | Precision: 0.6444\n",
      "  [CatBoost] Val   Acc: 0.6933 | Precision: 0.7708\n",
      "  [RandomForest] Train Acc: 0.8000 | Precision: 0.6502\n",
      "  [RandomForest] Val   Acc: 0.6867 | Precision: 0.7358\n",
      "  [LightGBM] Train Acc: 0.8483 | Precision: 0.7069\n",
      "  [LightGBM] Val   Acc: 0.6667 | Precision: 0.7391\n",
      "  [XGBoost] Train Acc: 0.7700 | Precision: 0.8657\n",
      "  [XGBoost] Val   Acc: 0.5867 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 5/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9733 | Precision: 0.9370\n",
      "  [CatBoost] Val   Acc: 0.7000 | Precision: 0.5370\n",
      "  [RandomForest] Train Acc: 0.8633 | Precision: 0.8142\n",
      "  [RandomForest] Val   Acc: 0.7200 | Precision: 0.5636\n",
      "  [LightGBM] Train Acc: 0.9050 | Precision: 0.8553\n",
      "  [LightGBM] Val   Acc: 0.6733 | Precision: 0.5000\n",
      "  [XGBoost] Train Acc: 0.8100 | Precision: 0.8716\n",
      "  [XGBoost] Val   Acc: 0.7267 | Precision: 0.6000\n",
      "\n",
      "   >> Running Fold 6/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8167 | Precision: 0.7500\n",
      "  [CatBoost] Val   Acc: 0.6667 | Precision: 0.5238\n",
      "  [RandomForest] Train Acc: 0.7567 | Precision: 0.6836\n",
      "  [RandomForest] Val   Acc: 0.6600 | Precision: 0.5156\n",
      "  [LightGBM] Train Acc: 0.8217 | Precision: 0.7608\n",
      "  [LightGBM] Val   Acc: 0.6733 | Precision: 0.5312\n",
      "  [XGBoost] Train Acc: 0.7467 | Precision: 0.9314\n",
      "  [XGBoost] Val   Acc: 0.6800 | Precision: 0.6471\n",
      "\n",
      "   >> Running Fold 7/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8450 | Precision: 0.7717\n",
      "  [CatBoost] Val   Acc: 0.6867 | Precision: 0.4717\n",
      "  [RandomForest] Train Acc: 0.7817 | Precision: 0.7101\n",
      "  [RandomForest] Val   Acc: 0.6533 | Precision: 0.4231\n",
      "  [LightGBM] Train Acc: 0.7683 | Precision: 0.7110\n",
      "  [LightGBM] Val   Acc: 0.7267 | Precision: 0.5405\n",
      "  [XGBoost] Train Acc: 0.7550 | Precision: 0.7530\n",
      "  [XGBoost] Val   Acc: 0.7200 | Precision: 0.5333\n",
      "\n",
      "   >> Running Fold 8/8 (final_holdout)\n",
      "  [CatBoost] Train Acc: 0.7850 | Precision: 0.7014\n",
      "  [CatBoost] Val   Acc: 0.6933 | Precision: 0.5821\n",
      "  [RandomForest] Train Acc: 0.7783 | Precision: 0.7160\n",
      "  [RandomForest] Val   Acc: 0.6600 | Precision: 0.5484\n",
      "  [LightGBM] Train Acc: 0.7817 | Precision: 0.7218\n",
      "  [LightGBM] Val   Acc: 0.6733 | Precision: 0.5625\n",
      "  [XGBoost] Train Acc: 0.7617 | Precision: 0.9016\n",
      "  [XGBoost] Val   Acc: 0.6733 | Precision: 0.7000\n",
      "\n",
      " === Trial Finished. Final Score: 0.4367R ===\n",
      "\n",
      "================================================================================\n",
      " Starting NEW trial_10_202642_L15_P1.7_S1.0\n",
      "\n",
      " Pipeline Started... (Train Start: 2020-01-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_256137/1210223439.py:54: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_ta['EMA_12'] = ta.ema(close, length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏùºÎ¥â Í∏∞Í∞Ñ: 2019-06-15 ~ 2025-11-20\n",
      "1ÏãúÍ∞ÑÎ¥â Í∏∞Í∞Ñ (KST Î≥ÄÌôò ÌõÑ): 2020-01-01 09:00:00 ~ 2025-11-23 08:00:00\n",
      "[Í≤ΩÍ≥†] 1ÏãúÍ∞ÑÎ¥â ÏãúÏûëÏùº(2020-01-01 09:00:00)Ïù¥ ÏùºÎ¥â ÏãúÏûëÏùº(2019-06-15 00:00:00) Ïù¥ÌõÑÏûÖÎãàÎã§. Ï¥àÎ∞ò ÌÉÄÍ≤ü ÏÜêÏã§ Î∞úÏÉù.\n",
      "Ïú†Ìö® ÏÉòÌîå: 2323/2336 (Ï†úÍ±∞: 13)\n",
      "Win: 834 | Lose: 1489 | Win Rate: 35.90%\n",
      "(2323, 85)\n",
      "\n",
      "================================================================================\n",
      "Reverse Rolling Walk-Forward + Final Holdout\n",
      "================================================================================\n",
      "Total period: 2020-01-01 ~ 2025-11-05 (2136 days)\n",
      "Rolling train: 800d | Val: 150d | Test: 150d | Gap: 15d\n",
      "Final holdout test: 2025-01-01 ~ 2025-11-05\n",
      "================================================================================\n",
      "\n",
      "Fold 1 (walk_forward_rolling)\n",
      "  Train:  800d  2020-01-17 ~ 2022-03-26\n",
      "  Val:    150d  2022-04-11 ~ 2022-09-07\n",
      "  Test:   150d  2022-09-23 ~ 2023-02-19\n",
      "\n",
      "Fold 2 (walk_forward_rolling)\n",
      "  Train:  800d  2020-06-30 ~ 2022-09-07\n",
      "  Val:    150d  2022-09-23 ~ 2023-02-19\n",
      "  Test:   150d  2023-03-07 ~ 2023-08-03\n",
      "\n",
      "Fold 3 (walk_forward_rolling)\n",
      "  Train:  800d  2020-12-12 ~ 2023-02-19\n",
      "  Val:    150d  2023-03-07 ~ 2023-08-03\n",
      "  Test:   150d  2023-08-19 ~ 2024-01-15\n",
      "\n",
      "Fold 4 (walk_forward_rolling)\n",
      "  Train:  800d  2021-05-26 ~ 2023-08-03\n",
      "  Val:    150d  2023-08-19 ~ 2024-01-15\n",
      "  Test:   150d  2024-01-31 ~ 2024-06-28\n",
      "\n",
      "Fold 5 (walk_forward_rolling)\n",
      "  Train:  800d  2021-11-07 ~ 2024-01-15\n",
      "  Val:    150d  2024-01-31 ~ 2024-06-28\n",
      "  Test:   150d  2024-07-14 ~ 2024-12-10\n",
      "\n",
      "Fold 6 (walk_forward_rolling)\n",
      "  Train:  800d  2022-04-21 ~ 2024-06-28\n",
      "  Val:    150d  2024-07-14 ~ 2024-12-10\n",
      "  Test:   150d  2024-12-26 ~ 2025-05-24\n",
      "\n",
      "Fold 7 (walk_forward_rolling)\n",
      "  Train:  800d  2022-10-03 ~ 2024-12-10\n",
      "  Val:    150d  2024-12-26 ~ 2025-05-24\n",
      "  Test:   150d  2025-06-09 ~ 2025-11-05\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Fold 8 (final_holdout - 2025 Ï†ÑÏ≤¥ Î≥ÑÎèÑ ÌèâÍ∞Ä)\n",
      "================================================================================\n",
      "  Train:  800d  2022-05-12 ~ 2024-07-19\n",
      "  Val:    150d  2024-08-04 ~ 2024-12-31\n",
      "  Test:   309d  2025-01-01 ~ 2025-11-05\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Created 8 folds total\n",
      "  - 7 walk-forward folds\n",
      "  - 1 final holdout fold (2025 Ï†ÑÏ≤¥)\n",
      "================================================================================\n",
      "\n",
      " Data Split Completed. Total 8 folds generated.\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 1 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-01-17 ~ 2022-03-26 (N=800)\n",
      " Val   Period: 2022-04-11 ~ 2022-09-07 (N=150)\n",
      " Test  Period: 2022-09-23 ~ 2023-02-19 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.5616666666666666, 1: 0.43833333333333335}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, eth_return, btc_return, SMA_50, BB_WIDTH, SMA_20, MACD_12_26_9, MACDS_12_26_9, EMA_12, eth_log_return, usdt_totalMintedUSD_ma30_ratio, lido_lido_eth_tvl_ma30_ratio, PRICE_VS_HIGH_5d, PRICE_VS_LOW_60d, eth_btc_corr_30d, usdt_totalUnreleased_ma30_ratio, uniswap_uniswap_eth_tvl_ma30_ratio, dxy_DXY_ma30_ratio, funding_fundingRate, usdt_totalCirculatingUSD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 2 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-06-30 ~ 2022-09-07 (N=800)\n",
      " Val   Period: 2022-09-23 ~ 2023-02-19 (N=150)\n",
      " Test  Period: 2023-03-07 ~ 2023-08-03 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6266666666666667, 1: 0.37333333333333335}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, MACDS_12_26_9, eth_return, btc_return, PRICE_VS_LOW_60d, usdt_totalUnreleased_ma30_ratio, BB_WIDTH, MACD_12_26_9, eth_log_return, PRICE_VS_LOW_20d, PRICE_VS_LOW_5d, usdt_totalMintedUSD_ma30_ratio, ATR_14, EMA_12, dxy_DXY_ma30_ratio, SMA_20, chain_eth_chain_tvl_ma30_ratio, makerdao_makerdao_eth_tvl_ma30_ratio, funding_fundingRate, l2_arbitrum_tvl_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 3 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-12-12 ~ 2023-02-19 (N=800)\n",
      " Val   Period: 2023-03-07 ~ 2023-08-03 (N=150)\n",
      " Test  Period: 2023-08-19 ~ 2024-01-15 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6716666666666666, 1: 0.3283333333333333}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, eth_return, eth_btc_spread, btc_return, PRICE_VS_LOW_60d, SMA_20, eth_log_return, l2_arbitrum_tvl_ma30_ratio, PRICE_VS_LOW_5d, BREAKOUT_STR_5d, PRICE_VS_HIGH_5d, UPPER_SHADOW, eth_btc_corr_30d, usdt_totalCirculating_ma30_ratio, usdt_totalMintedUSD_ma30_ratio, BB_WIDTH, usdt_totalBridgedToUSD_ma30_ratio, makerdao_makerdao_eth_tvl_ma30_ratio, MACD_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 4 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-05-26 ~ 2023-08-03 (N=800)\n",
      " Val   Period: 2023-08-19 ~ 2024-01-15 (N=150)\n",
      " Test  Period: 2024-01-31 ~ 2024-06-28 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.695, 1: 0.305}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_20, usdt_totalBridgedToUSD_ma30_ratio, btc_return, eth_return, EMA_12, usdt_totalCirculating_ma30_ratio, usdt_totalUnreleased_ma30_ratio, SMA_50, MACDS_12_26_9, BB_WIDTH, eth_log_return, vix_VIX_pct_1d, LOWER_SHADOW, PRICE_VS_LOW_60d, eth_btc_corr_30d, usdt_totalMintedUSD_ma30_ratio, curve_curve-dex_eth_tvl_ma30_ratio, gold_GOLD_ma30_ratio, MACD_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 5 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-11-07 ~ 2024-01-15 (N=800)\n",
      " Val   Period: 2024-01-31 ~ 2024-06-28 (N=150)\n",
      " Test  Period: 2024-07-14 ~ 2024-12-10 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6383333333333333, 1: 0.3616666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, gold_GOLD_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, btc_return, usdt_totalUnreleased_ma30_ratio, BREAKOUT_STR_5d, SMA_50, BB_WIDTH, MACD_12_26_9, MACDS_12_26_9, return_lag5, UPPER_SHADOW, BREAKOUT_STR_20d, eth_return, eth_btc_corr_7d, l2_optimism_tvl_ma30_ratio, dxy_DXY_ma30_ratio, SMA_20, l2_zksync era_tvl_ma30_ratio, l2_base_tvl_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 6 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-04-21 ~ 2024-06-28 (N=800)\n",
      " Val   Period: 2024-07-14 ~ 2024-12-10 (N=150)\n",
      " Test  Period: 2024-12-26 ~ 2025-05-24 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6216666666666667, 1: 0.37833333333333335}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_20, eth_btc_corr_30d, ATR_14, btc_return, gold_GOLD_ma30_ratio, dxy_DXY_ma30_ratio, PRICE_VS_HIGH_5d, eth_return, BB_WIDTH, EMA_12, OBV, l2_base_tvl_ma30_ratio, l2_zksync era_tvl_ma30_ratio, dxy_DXY_pct_1d, BREAKOUT_STR_5d, eth_log_return, BREAKOUT_STR_20d, usdt_totalUnreleased_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, SMA_50\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 7 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-10-03 ~ 2024-12-10 (N=800)\n",
      " Val   Period: 2024-12-26 ~ 2025-05-24 (N=150)\n",
      " Test  Period: 2025-06-09 ~ 2025-11-05 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.63, 1: 0.37}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, EMA_12, eth_btc_corr_30d, l2_base_tvl_ma30_ratio, price_rank_250d, usdt_totalBridgedToUSD_ma30_ratio, btc_return, BB_WIDTH, SMA_20, MACDS_12_26_9, usdt_totalCirculating_ma30_ratio, makerdao_makerdao_eth_tvl_ma30_ratio, vix_VIX_ma30_ratio, OBV, sp500_SP500_ma30_ratio, eth_return, curve_curve-dex_eth_tvl_ma30_ratio, gold_GOLD_ma30_ratio, MACD_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 8 (final_holdout)\n",
      "================================================================================\n",
      " Train Period: 2022-05-12 ~ 2024-07-19 (N=800)\n",
      " Val   Period: 2024-08-04 ~ 2024-12-31 (N=150)\n",
      " Test  Period: 2025-01-01 ~ 2025-11-05 (N=309)\n",
      "[Class Balance] Train Set: {0: 0.6133333333333333, 1: 0.38666666666666666}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> EMA_12, ATR_14, btc_return, l2_base_tvl_ma30_ratio, gold_GOLD_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, PRICE_VS_HIGH_5d, SMA_50, BB_WIDTH, OBV, l2_zksync era_tvl_ma30_ratio, dxy_DXY_ma30_ratio, MACDH_12_26_9, BREAKOUT_STR_20d, eth_return, usdt_totalUnreleased_ma30_ratio, l2_optimism_tvl_ma30_ratio, SMA_20, MACD_12_26_9, eth_btc_corr_30d\n",
      "\n",
      "   >> Running Fold 1/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7683 | Precision: 0.6975\n",
      "  [CatBoost] Val   Acc: 0.6200 | Precision: 0.3766\n",
      "  [RandomForest] Train Acc: 0.7417 | Precision: 0.6776\n",
      "  [RandomForest] Val   Acc: 0.6667 | Precision: 0.4091\n",
      "  [LightGBM] Train Acc: 0.7383 | Precision: 0.6853\n",
      "  [LightGBM] Val   Acc: 0.7467 | Precision: 0.5000\n",
      "  [XGBoost] Train Acc: 0.7400 | Precision: 0.7536\n",
      "  [XGBoost] Val   Acc: 0.7600 | Precision: 0.5250\n",
      "\n",
      "   >> Running Fold 2/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8100 | Precision: 0.7037\n",
      "  [CatBoost] Val   Acc: 0.6400 | Precision: 0.4583\n",
      "  [RandomForest] Train Acc: 0.7550 | Precision: 0.6475\n",
      "  [RandomForest] Val   Acc: 0.6533 | Precision: 0.4688\n",
      "  [LightGBM] Train Acc: 0.7250 | Precision: 0.6528\n",
      "  [LightGBM] Val   Acc: 0.6667 | Precision: 0.4750\n",
      "  [XGBoost] Train Acc: 0.6817 | Precision: 0.9714\n",
      "  [XGBoost] Val   Acc: 0.7067 | Precision: 0.7000\n",
      "\n",
      "   >> Running Fold 3/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9183 | Precision: 0.8246\n",
      "  [CatBoost] Val   Acc: 0.6867 | Precision: 0.6585\n",
      "  [RandomForest] Train Acc: 0.7750 | Precision: 0.6292\n",
      "  [RandomForest] Val   Acc: 0.6733 | Precision: 0.6122\n",
      "  [LightGBM] Train Acc: 0.8283 | Precision: 0.7009\n",
      "  [LightGBM] Val   Acc: 0.6800 | Precision: 0.6765\n",
      "  [XGBoost] Train Acc: 0.7367 | Precision: 0.8545\n",
      "  [XGBoost] Val   Acc: 0.6067 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 4/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9233 | Precision: 0.8128\n",
      "  [CatBoost] Val   Acc: 0.6933 | Precision: 0.7708\n",
      "  [RandomForest] Train Acc: 0.9067 | Precision: 0.8098\n",
      "  [RandomForest] Val   Acc: 0.6800 | Precision: 0.7222\n",
      "  [LightGBM] Train Acc: 0.7667 | Precision: 0.5837\n",
      "  [LightGBM] Val   Acc: 0.6867 | Precision: 0.8049\n",
      "  [XGBoost] Train Acc: 0.9283 | Precision: 0.9795\n",
      "  [XGBoost] Val   Acc: 0.6000 | Precision: 0.8333\n",
      "\n",
      "   >> Running Fold 5/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9683 | Precision: 0.9231\n",
      "  [CatBoost] Val   Acc: 0.7133 | Precision: 0.5957\n",
      "  [RandomForest] Train Acc: 0.8383 | Precision: 0.7655\n",
      "  [RandomForest] Val   Acc: 0.7067 | Precision: 0.5714\n",
      "  [LightGBM] Train Acc: 0.7900 | Precision: 0.6904\n",
      "  [LightGBM] Val   Acc: 0.6800 | Precision: 0.5294\n",
      "  [XGBoost] Train Acc: 0.8467 | Precision: 0.9032\n",
      "  [XGBoost] Val   Acc: 0.7467 | Precision: 0.7333\n",
      "\n",
      "   >> Running Fold 6/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8217 | Precision: 0.7308\n",
      "  [CatBoost] Val   Acc: 0.6733 | Precision: 0.5135\n",
      "  [RandomForest] Train Acc: 0.8533 | Precision: 0.7957\n",
      "  [RandomForest] Val   Acc: 0.6800 | Precision: 0.5224\n",
      "  [LightGBM] Train Acc: 0.7800 | Precision: 0.6908\n",
      "  [LightGBM] Val   Acc: 0.6533 | Precision: 0.4915\n",
      "  [XGBoost] Train Acc: 0.6767 | Precision: 0.9459\n",
      "  [XGBoost] Val   Acc: 0.6933 | Precision: 0.7778\n",
      "\n",
      "   >> Running Fold 7/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8267 | Precision: 0.7341\n",
      "  [CatBoost] Val   Acc: 0.6800 | Precision: 0.4528\n",
      "  [RandomForest] Train Acc: 0.8400 | Precision: 0.7540\n",
      "  [RandomForest] Val   Acc: 0.6867 | Precision: 0.4615\n",
      "  [LightGBM] Train Acc: 0.8017 | Precision: 0.7036\n",
      "  [LightGBM] Val   Acc: 0.7133 | Precision: 0.5000\n",
      "  [XGBoost] Train Acc: 0.7783 | Precision: 0.8870\n",
      "  [XGBoost] Val   Acc: 0.7400 | Precision: 0.6250\n",
      "\n",
      "   >> Running Fold 8/8 (final_holdout)\n",
      "  [CatBoost] Train Acc: 0.8333 | Precision: 0.7578\n",
      "  [CatBoost] Val   Acc: 0.6267 | Precision: 0.4839\n",
      "  [RandomForest] Train Acc: 0.7833 | Precision: 0.7024\n",
      "  [RandomForest] Val   Acc: 0.6333 | Precision: 0.4915\n",
      "  [LightGBM] Train Acc: 0.8000 | Precision: 0.7205\n",
      "  [LightGBM] Val   Acc: 0.6133 | Precision: 0.4677\n",
      "  [XGBoost] Train Acc: 0.7450 | Precision: 0.9341\n",
      "  [XGBoost] Val   Acc: 0.6733 | Precision: 0.7778\n",
      "\n",
      " === Trial Finished. Final Score: 0.5245R ===\n",
      "\n",
      "[Skip] Found existing result for L=15, P=1.7, S=1.0. Score: 0.5245\n",
      "\n",
      "================================================================================\n",
      " Starting NEW trial_12_203416_L15_P1.6_S1.0\n",
      "\n",
      " Pipeline Started... (Train Start: 2020-01-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_256137/1210223439.py:54: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_ta['EMA_12'] = ta.ema(close, length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏùºÎ¥â Í∏∞Í∞Ñ: 2019-06-15 ~ 2025-11-20\n",
      "1ÏãúÍ∞ÑÎ¥â Í∏∞Í∞Ñ (KST Î≥ÄÌôò ÌõÑ): 2020-01-01 09:00:00 ~ 2025-11-23 08:00:00\n",
      "[Í≤ΩÍ≥†] 1ÏãúÍ∞ÑÎ¥â ÏãúÏûëÏùº(2020-01-01 09:00:00)Ïù¥ ÏùºÎ¥â ÏãúÏûëÏùº(2019-06-15 00:00:00) Ïù¥ÌõÑÏûÖÎãàÎã§. Ï¥àÎ∞ò ÌÉÄÍ≤ü ÏÜêÏã§ Î∞úÏÉù.\n",
      "Ïú†Ìö® ÏÉòÌîå: 2323/2336 (Ï†úÍ±∞: 13)\n",
      "Win: 866 | Lose: 1457 | Win Rate: 37.28%\n",
      "(2323, 85)\n",
      "\n",
      "================================================================================\n",
      "Reverse Rolling Walk-Forward + Final Holdout\n",
      "================================================================================\n",
      "Total period: 2020-01-01 ~ 2025-11-05 (2136 days)\n",
      "Rolling train: 800d | Val: 150d | Test: 150d | Gap: 15d\n",
      "Final holdout test: 2025-01-01 ~ 2025-11-05\n",
      "================================================================================\n",
      "\n",
      "Fold 1 (walk_forward_rolling)\n",
      "  Train:  800d  2020-01-17 ~ 2022-03-26\n",
      "  Val:    150d  2022-04-11 ~ 2022-09-07\n",
      "  Test:   150d  2022-09-23 ~ 2023-02-19\n",
      "\n",
      "Fold 2 (walk_forward_rolling)\n",
      "  Train:  800d  2020-06-30 ~ 2022-09-07\n",
      "  Val:    150d  2022-09-23 ~ 2023-02-19\n",
      "  Test:   150d  2023-03-07 ~ 2023-08-03\n",
      "\n",
      "Fold 3 (walk_forward_rolling)\n",
      "  Train:  800d  2020-12-12 ~ 2023-02-19\n",
      "  Val:    150d  2023-03-07 ~ 2023-08-03\n",
      "  Test:   150d  2023-08-19 ~ 2024-01-15\n",
      "\n",
      "Fold 4 (walk_forward_rolling)\n",
      "  Train:  800d  2021-05-26 ~ 2023-08-03\n",
      "  Val:    150d  2023-08-19 ~ 2024-01-15\n",
      "  Test:   150d  2024-01-31 ~ 2024-06-28\n",
      "\n",
      "Fold 5 (walk_forward_rolling)\n",
      "  Train:  800d  2021-11-07 ~ 2024-01-15\n",
      "  Val:    150d  2024-01-31 ~ 2024-06-28\n",
      "  Test:   150d  2024-07-14 ~ 2024-12-10\n",
      "\n",
      "Fold 6 (walk_forward_rolling)\n",
      "  Train:  800d  2022-04-21 ~ 2024-06-28\n",
      "  Val:    150d  2024-07-14 ~ 2024-12-10\n",
      "  Test:   150d  2024-12-26 ~ 2025-05-24\n",
      "\n",
      "Fold 7 (walk_forward_rolling)\n",
      "  Train:  800d  2022-10-03 ~ 2024-12-10\n",
      "  Val:    150d  2024-12-26 ~ 2025-05-24\n",
      "  Test:   150d  2025-06-09 ~ 2025-11-05\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Fold 8 (final_holdout - 2025 Ï†ÑÏ≤¥ Î≥ÑÎèÑ ÌèâÍ∞Ä)\n",
      "================================================================================\n",
      "  Train:  800d  2022-05-12 ~ 2024-07-19\n",
      "  Val:    150d  2024-08-04 ~ 2024-12-31\n",
      "  Test:   309d  2025-01-01 ~ 2025-11-05\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Created 8 folds total\n",
      "  - 7 walk-forward folds\n",
      "  - 1 final holdout fold (2025 Ï†ÑÏ≤¥)\n",
      "================================================================================\n",
      "\n",
      " Data Split Completed. Total 8 folds generated.\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 1 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-01-17 ~ 2022-03-26 (N=800)\n",
      " Val   Period: 2022-04-11 ~ 2022-09-07 (N=150)\n",
      " Test  Period: 2022-09-23 ~ 2023-02-19 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.555, 1: 0.445}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, BB_WIDTH, MACDS_12_26_9, eth_return, ATR_14, PRICE_VS_LOW_60d, btc_return, MACD_12_26_9, EMA_12, eth_log_return, usdt_totalMintedUSD_ma30_ratio, PRICE_VS_HIGH_5d, eth_btc_corr_30d, usdt_totalUnreleased_ma30_ratio, gold_GOLD_ma30_ratio, SMA_20, funding_fundingRate, usdt_totalCirculating_ma30_ratio, usdt_totalCirculatingUSD_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 2 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-06-30 ~ 2022-09-07 (N=800)\n",
      " Val   Period: 2022-09-23 ~ 2023-02-19 (N=150)\n",
      " Test  Period: 2023-03-07 ~ 2023-08-03 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.62, 1: 0.38}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, BB_WIDTH, MACDS_12_26_9, eth_return, MACD_12_26_9, eth_log_return, l2_arbitrum_tvl_ma30_ratio, PRICE_VS_LOW_60d, PRICE_VS_LOW_20d, btc_return, PRICE_VS_LOW_5d, BREAKOUT_STR_20d, BREAKOUT_STR_60d, EMA_12, OBV, dxy_DXY_ma30_ratio, SMA_20, chain_eth_chain_tvl_ma30_ratio, makerdao_makerdao_eth_tvl_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 3 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-12-12 ~ 2023-02-19 (N=800)\n",
      " Val   Period: 2023-03-07 ~ 2023-08-03 (N=150)\n",
      " Test  Period: 2023-08-19 ~ 2024-01-15 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.665, 1: 0.335}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, eth_return, MACD_12_26_9, eth_btc_spread, BREAKOUT_STR_5d, btc_return, SMA_50, usdt_totalBridgedToUSD_ma30_ratio, SMA_20, eth_log_return, l2_arbitrum_tvl_ma30_ratio, PRICE_VS_HIGH_5d, UPPER_SHADOW, LOWER_SHADOW, PRICE_VS_LOW_60d, eth_btc_corr_7d, eth_btc_corr_30d, usdt_totalCirculatingUSD_ma30_ratio, BB_WIDTH, MACDS_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 4 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-05-26 ~ 2023-08-03 (N=800)\n",
      " Val   Period: 2023-08-19 ~ 2024-01-15 (N=150)\n",
      " Test  Period: 2024-01-31 ~ 2024-06-28 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6816666666666666, 1: 0.31833333333333336}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_20, usdt_totalBridgedToUSD_ma30_ratio, eth_return, btc_return, usdt_totalCirculating_ma30_ratio, SMA_50, BB_WIDTH, eth_log_return, MACD_12_26_9, EMA_12, eth_btc_corr_7d, eth_btc_corr_30d, usdt_totalMintedUSD_ma30_ratio, usdt_totalUnreleased_ma30_ratio, l2_optimism_tvl_ma30_ratio, sp500_SP500_ma30_ratio, MACDS_12_26_9, l2_zksync era_tvl_ma30_ratio, MACDH_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 5 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-11-07 ~ 2024-01-15 (N=800)\n",
      " Val   Period: 2024-01-31 ~ 2024-06-28 (N=150)\n",
      " Test  Period: 2024-07-14 ~ 2024-12-10 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6183333333333333, 1: 0.38166666666666665}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, l2_zksync era_tvl_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, gold_GOLD_ma30_ratio, btc_return, eth_return, BREAKOUT_STR_5d, usdt_totalUnreleased_ma30_ratio, SMA_50, eth_btc_corr_30d, eth_log_return, return_lag5, UPPER_SHADOW, LOWER_SHADOW, BREAKOUT_STR_20d, eth_btc_corr_7d, dxy_DXY_ma30_ratio, SMA_20, MACDS_12_26_9, l2_base_tvl_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 6 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-04-21 ~ 2024-06-28 (N=800)\n",
      " Val   Period: 2024-07-14 ~ 2024-12-10 (N=150)\n",
      " Test  Period: 2024-12-26 ~ 2025-05-24 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.5983333333333334, 1: 0.40166666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_20, l2_zksync era_tvl_ma30_ratio, eth_return, btc_return, gold_GOLD_ma30_ratio, dxy_DXY_ma30_ratio, SMA_50, EMA_12, BB_WIDTH, OBV, eth_btc_corr_30d, eth_log_return, ATR_14, l2_base_tvl_ma30_ratio, BREAKOUT_STR_20d, usdt_totalUnreleased_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, lido_lido_eth_tvl_ma30_ratio, price_rank_250d, MACD_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 7 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-10-03 ~ 2024-12-10 (N=800)\n",
      " Val   Period: 2024-12-26 ~ 2025-05-24 (N=150)\n",
      " Test  Period: 2025-06-09 ~ 2025-11-05 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6083333333333333, 1: 0.39166666666666666}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, EMA_12, l2_base_tvl_ma30_ratio, price_rank_250d, usdt_totalBridgedToUSD_ma30_ratio, eth_return, btc_return, PRICE_VS_LOW_20d, SMA_50, SMA_20, BB_WIDTH, eth_btc_corr_30d, usdt_totalCirculating_ma30_ratio, eth_log_return, BREAKOUT_STR_5d, lido_lido_eth_tvl_ma30_ratio, MACDS_12_26_9, usdt_totalCirculatingUSD_ma30_ratio, MFI_14, MACD_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 8 (final_holdout)\n",
      "================================================================================\n",
      " Train Period: 2022-05-12 ~ 2024-07-19 (N=800)\n",
      " Val   Period: 2024-08-04 ~ 2024-12-31 (N=150)\n",
      " Test  Period: 2025-01-01 ~ 2025-11-05 (N=309)\n",
      "[Class Balance] Train Set: {0: 0.59, 1: 0.41}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, EMA_12, btc_return, eth_return, gold_GOLD_ma30_ratio, l2_zksync era_tvl_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, SMA_20, BB_WIDTH, OBV, eth_log_return, l2_base_tvl_ma30_ratio, BREAKOUT_STR_5d, BREAKOUT_STR_20d, usdt_totalUnreleased_ma30_ratio, lido_lido_eth_tvl_ma30_ratio, dxy_DXY_ma30_ratio, SMA_50, eth_btc_corr_30d, price_rank_250d\n",
      "\n",
      "   >> Running Fold 1/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7733 | Precision: 0.7093\n",
      "  [CatBoost] Val   Acc: 0.6200 | Precision: 0.3875\n",
      "  [RandomForest] Train Acc: 0.7417 | Precision: 0.6867\n",
      "  [RandomForest] Val   Acc: 0.6667 | Precision: 0.4179\n",
      "  [LightGBM] Train Acc: 0.7133 | Precision: 0.6557\n",
      "  [LightGBM] Val   Acc: 0.6867 | Precision: 0.4412\n",
      "  [XGBoost] Train Acc: 0.7417 | Precision: 0.7917\n",
      "  [XGBoost] Val   Acc: 0.7400 | Precision: 0.5000\n",
      "\n",
      "   >> Running Fold 2/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7967 | Precision: 0.6978\n",
      "  [CatBoost] Val   Acc: 0.6000 | Precision: 0.4432\n",
      "  [RandomForest] Train Acc: 0.7883 | Precision: 0.6935\n",
      "  [RandomForest] Val   Acc: 0.6067 | Precision: 0.4430\n",
      "  [LightGBM] Train Acc: 0.7417 | Precision: 0.6367\n",
      "  [LightGBM] Val   Acc: 0.6267 | Precision: 0.4643\n",
      "  [XGBoost] Train Acc: 0.7117 | Precision: 0.8235\n",
      "  [XGBoost] Val   Acc: 0.7200 | Precision: 0.7000\n",
      "\n",
      "   >> Running Fold 3/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8833 | Precision: 0.7718\n",
      "  [CatBoost] Val   Acc: 0.7000 | Precision: 0.6852\n",
      "  [RandomForest] Train Acc: 0.7217 | Precision: 0.5630\n",
      "  [RandomForest] Val   Acc: 0.6867 | Precision: 0.6552\n",
      "  [LightGBM] Train Acc: 0.7900 | Precision: 0.6518\n",
      "  [LightGBM] Val   Acc: 0.7467 | Precision: 0.7872\n",
      "  [XGBoost] Train Acc: 0.7083 | Precision: 0.7826\n",
      "  [XGBoost] Val   Acc: 0.6267 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 4/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8583 | Precision: 0.7208\n",
      "  [CatBoost] Val   Acc: 0.7200 | Precision: 0.7361\n",
      "  [RandomForest] Train Acc: 0.8100 | Precision: 0.6652\n",
      "  [RandomForest] Val   Acc: 0.7133 | Precision: 0.7538\n",
      "  [LightGBM] Train Acc: 0.8233 | Precision: 0.6693\n",
      "  [LightGBM] Val   Acc: 0.7133 | Precision: 0.7391\n",
      "  [XGBoost] Train Acc: 0.8300 | Precision: 0.8618\n",
      "  [XGBoost] Val   Acc: 0.5867 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 5/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9133 | Precision: 0.8766\n",
      "  [CatBoost] Val   Acc: 0.7067 | Precision: 0.5932\n",
      "  [RandomForest] Train Acc: 0.8450 | Precision: 0.7833\n",
      "  [RandomForest] Val   Acc: 0.6867 | Precision: 0.5645\n",
      "  [LightGBM] Train Acc: 0.9050 | Precision: 0.8554\n",
      "  [LightGBM] Val   Acc: 0.7000 | Precision: 0.5862\n",
      "  [XGBoost] Train Acc: 0.9333 | Precision: 0.9610\n",
      "  [XGBoost] Val   Acc: 0.7133 | Precision: 0.6579\n",
      "\n",
      "   >> Running Fold 6/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8433 | Precision: 0.7795\n",
      "  [CatBoost] Val   Acc: 0.6733 | Precision: 0.5286\n",
      "  [RandomForest] Train Acc: 0.7583 | Precision: 0.6920\n",
      "  [RandomForest] Val   Acc: 0.7000 | Precision: 0.5667\n",
      "  [LightGBM] Train Acc: 0.8433 | Precision: 0.7882\n",
      "  [LightGBM] Val   Acc: 0.6867 | Precision: 0.5469\n",
      "  [XGBoost] Train Acc: 0.7500 | Precision: 0.8273\n",
      "  [XGBoost] Val   Acc: 0.7267 | Precision: 0.6765\n",
      "\n",
      "   >> Running Fold 7/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8083 | Precision: 0.7400\n",
      "  [CatBoost] Val   Acc: 0.6600 | Precision: 0.4490\n",
      "  [RandomForest] Train Acc: 0.7700 | Precision: 0.6964\n",
      "  [RandomForest] Val   Acc: 0.6533 | Precision: 0.4348\n",
      "  [LightGBM] Train Acc: 0.7667 | Precision: 0.7149\n",
      "  [LightGBM] Val   Acc: 0.7200 | Precision: 0.5556\n",
      "  [XGBoost] Train Acc: 0.7567 | Precision: 0.7764\n",
      "  [XGBoost] Val   Acc: 0.7267 | Precision: 0.5926\n",
      "\n",
      "   >> Running Fold 8/8 (final_holdout)\n",
      "  [CatBoost] Train Acc: 0.7967 | Precision: 0.7403\n",
      "  [CatBoost] Val   Acc: 0.6333 | Precision: 0.5161\n",
      "  [RandomForest] Train Acc: 0.8000 | Precision: 0.7520\n",
      "  [RandomForest] Val   Acc: 0.6400 | Precision: 0.5246\n",
      "  [LightGBM] Train Acc: 0.7900 | Precision: 0.7362\n",
      "  [LightGBM] Val   Acc: 0.6533 | Precision: 0.5424\n",
      "  [XGBoost] Train Acc: 0.7967 | Precision: 0.8827\n",
      "  [XGBoost] Val   Acc: 0.6800 | Precision: 0.6098\n",
      "\n",
      " === Trial Finished. Final Score: 0.7212R ===\n",
      "\n",
      "================================================================================\n",
      " Starting NEW trial_13_204138_L13_P1.5_S1.0\n",
      "\n",
      " Pipeline Started... (Train Start: 2020-01-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_256137/1210223439.py:54: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_ta['EMA_12'] = ta.ema(close, length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏùºÎ¥â Í∏∞Í∞Ñ: 2019-06-15 ~ 2025-11-20\n",
      "1ÏãúÍ∞ÑÎ¥â Í∏∞Í∞Ñ (KST Î≥ÄÌôò ÌõÑ): 2020-01-01 09:00:00 ~ 2025-11-23 08:00:00\n",
      "[Í≤ΩÍ≥†] 1ÏãúÍ∞ÑÎ¥â ÏãúÏûëÏùº(2020-01-01 09:00:00)Ïù¥ ÏùºÎ¥â ÏãúÏûëÏùº(2019-06-15 00:00:00) Ïù¥ÌõÑÏûÖÎãàÎã§. Ï¥àÎ∞ò ÌÉÄÍ≤ü ÏÜêÏã§ Î∞úÏÉù.\n",
      "Ïú†Ìö® ÏÉòÌîå: 2325/2338 (Ï†úÍ±∞: 13)\n",
      "Win: 886 | Lose: 1439 | Win Rate: 38.11%\n",
      "(2325, 85)\n",
      "\n",
      "================================================================================\n",
      "Reverse Rolling Walk-Forward + Final Holdout\n",
      "================================================================================\n",
      "Total period: 2020-01-01 ~ 2025-11-07 (2138 days)\n",
      "Rolling train: 800d | Val: 150d | Test: 150d | Gap: 13d\n",
      "Final holdout test: 2025-01-01 ~ 2025-11-07\n",
      "================================================================================\n",
      "\n",
      "Fold 1 (walk_forward_rolling)\n",
      "  Train:  800d  2020-02-04 ~ 2022-04-13\n",
      "  Val:    150d  2022-04-27 ~ 2022-09-23\n",
      "  Test:   150d  2022-10-07 ~ 2023-03-05\n",
      "\n",
      "Fold 2 (walk_forward_rolling)\n",
      "  Train:  800d  2020-07-16 ~ 2022-09-23\n",
      "  Val:    150d  2022-10-07 ~ 2023-03-05\n",
      "  Test:   150d  2023-03-19 ~ 2023-08-15\n",
      "\n",
      "Fold 3 (walk_forward_rolling)\n",
      "  Train:  800d  2020-12-26 ~ 2023-03-05\n",
      "  Val:    150d  2023-03-19 ~ 2023-08-15\n",
      "  Test:   150d  2023-08-29 ~ 2024-01-25\n",
      "\n",
      "Fold 4 (walk_forward_rolling)\n",
      "  Train:  800d  2021-06-07 ~ 2023-08-15\n",
      "  Val:    150d  2023-08-29 ~ 2024-01-25\n",
      "  Test:   150d  2024-02-08 ~ 2024-07-06\n",
      "\n",
      "Fold 5 (walk_forward_rolling)\n",
      "  Train:  800d  2021-11-17 ~ 2024-01-25\n",
      "  Val:    150d  2024-02-08 ~ 2024-07-06\n",
      "  Test:   150d  2024-07-20 ~ 2024-12-16\n",
      "\n",
      "Fold 6 (walk_forward_rolling)\n",
      "  Train:  800d  2022-04-29 ~ 2024-07-06\n",
      "  Val:    150d  2024-07-20 ~ 2024-12-16\n",
      "  Test:   150d  2024-12-30 ~ 2025-05-28\n",
      "\n",
      "Fold 7 (walk_forward_rolling)\n",
      "  Train:  800d  2022-10-09 ~ 2024-12-16\n",
      "  Val:    150d  2024-12-30 ~ 2025-05-28\n",
      "  Test:   150d  2025-06-11 ~ 2025-11-07\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Fold 8 (final_holdout - 2025 Ï†ÑÏ≤¥ Î≥ÑÎèÑ ÌèâÍ∞Ä)\n",
      "================================================================================\n",
      "  Train:  800d  2022-05-14 ~ 2024-07-21\n",
      "  Val:    150d  2024-08-04 ~ 2024-12-31\n",
      "  Test:   311d  2025-01-01 ~ 2025-11-07\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Created 8 folds total\n",
      "  - 7 walk-forward folds\n",
      "  - 1 final holdout fold (2025 Ï†ÑÏ≤¥)\n",
      "================================================================================\n",
      "\n",
      " Data Split Completed. Total 8 folds generated.\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 1 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-02-04 ~ 2022-04-13 (N=800)\n",
      " Val   Period: 2022-04-27 ~ 2022-09-23 (N=150)\n",
      " Test  Period: 2022-10-07 ~ 2023-03-05 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.55, 1: 0.45}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, eth_return, btc_return, BREAKOUT_STR_5d, SMA_20, BB_WIDTH, MACD_12_26_9, EMA_12, MACDS_12_26_9, eth_log_return, usdt_totalMintedUSD_ma30_ratio, PRICE_VS_HIGH_5d, ATR_14, makerdao_makerdao_eth_tvl_ma30_ratio, eth_btc_corr_30d, usdt_totalUnreleased_ma30_ratio, gold_GOLD_ma30_ratio, dxy_DXY_ma30_ratio, l2_arbitrum_tvl_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 2 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-07-16 ~ 2022-09-23 (N=800)\n",
      " Val   Period: 2022-10-07 ~ 2023-03-05 (N=150)\n",
      " Test  Period: 2023-03-19 ~ 2023-08-15 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.63, 1: 0.37}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, BB_WIDTH, eth_return, MACDS_12_26_9, PRICE_VS_LOW_60d, PRICE_VS_HIGH_5d, btc_return, eth_log_return, MACD_12_26_9, BREAKOUT_STR_20d, eth_btc_spread, PRICE_VS_LOW_20d, BREAKOUT_STR_60d, PRICE_VS_LOW_5d, BREAKOUT_STR_5d, eth_btc_corr_7d, usdt_totalUnreleased_ma30_ratio, dxy_DXY_ma30_ratio, SMA_20\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 3 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-12-26 ~ 2023-03-05 (N=800)\n",
      " Val   Period: 2023-03-19 ~ 2023-08-15 (N=150)\n",
      " Test  Period: 2023-08-29 ~ 2024-01-25 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6616666666666666, 1: 0.3383333333333333}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, eth_return, MACDS_12_26_9, BREAKOUT_STR_5d, PRICE_VS_LOW_60d, usdt_totalBridgedToUSD_ma30_ratio, SMA_20, eth_log_return, l2_arbitrum_tvl_ma30_ratio, eth_btc_spread, btc_return, PRICE_VS_HIGH_5d, BREAKOUT_STR_20d, PRICE_VS_LOW_5d, UPPER_SHADOW, eth_btc_corr_7d, eth_btc_corr_30d, usdt_totalUnreleased_ma30_ratio, BB_WIDTH\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 4 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-06-07 ~ 2023-08-15 (N=800)\n",
      " Val   Period: 2023-08-29 ~ 2024-01-25 (N=150)\n",
      " Test  Period: 2024-02-08 ~ 2024-07-06 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6783333333333333, 1: 0.32166666666666666}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_20, btc_return, eth_return, usdt_totalCirculating_ma30_ratio, SMA_50, MACDS_12_26_9, usdt_totalBridgedToUSD_ma30_ratio, BB_WIDTH, eth_log_return, EMA_12, usdt_totalCirculatingUSD_ma30_ratio, PRICE_VS_HIGH_5d, OBV, UPPER_SHADOW, BREAKOUT_STR_5d, eth_btc_corr_30d, usdt_totalMintedUSD_ma30_ratio, usdt_totalUnreleased_ma30_ratio, MACD_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 5 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-11-17 ~ 2024-01-25 (N=800)\n",
      " Val   Period: 2024-02-08 ~ 2024-07-06 (N=150)\n",
      " Test  Period: 2024-07-20 ~ 2024-12-16 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6116666666666667, 1: 0.3883333333333333}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, gold_GOLD_ma30_ratio, eth_btc_corr_30d, btc_return, eth_return, usdt_totalUnreleased_ma30_ratio, BREAKOUT_STR_5d, usdt_totalBridgedToUSD_ma30_ratio, ATR_14, eth_log_return, MACD_12_26_9, UPPER_SHADOW, LOWER_SHADOW, dxy_DXY_ma30_ratio, SMA_20, l2_zksync era_tvl_ma30_ratio, BB_WIDTH, EMA_12, MACDS_12_26_9, price_rank_250d\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 6 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-04-29 ~ 2024-07-06 (N=800)\n",
      " Val   Period: 2024-07-20 ~ 2024-12-16 (N=150)\n",
      " Test  Period: 2024-12-30 ~ 2025-05-28 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.585, 1: 0.415}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_20, l2_zksync era_tvl_ma30_ratio, eth_return, btc_return, gold_GOLD_ma30_ratio, dxy_DXY_ma30_ratio, SMA_50, BB_WIDTH, EMA_12, OBV, eth_log_return, MFI_14, PRICE_VS_HIGH_5d, UPPER_SHADOW, LOWER_SHADOW, BREAKOUT_STR_20d, usdt_totalUnreleased_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, lido_lido_eth_tvl_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 7 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-10-09 ~ 2024-12-16 (N=800)\n",
      " Val   Period: 2024-12-30 ~ 2025-05-28 (N=150)\n",
      " Test  Period: 2025-06-11 ~ 2025-11-07 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.5916666666666667, 1: 0.4083333333333333}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, EMA_12, eth_btc_corr_30d, usdt_totalBridgedToUSD_ma30_ratio, eth_return, MFI_14, btc_return, BREAKOUT_STR_5d, l2_base_tvl_ma30_ratio, BB_WIDTH, SMA_20, eth_log_return, usdt_totalCirculating_ma30_ratio, PRICE_VS_HIGH_5d, PRICE_VS_LOW_20d, BREAKOUT_STR_20d, MACDS_12_26_9, price_rank_250d, usdt_totalCirculatingUSD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 8 (final_holdout)\n",
      "================================================================================\n",
      " Train Period: 2022-05-14 ~ 2024-07-21 (N=800)\n",
      " Val   Period: 2024-08-04 ~ 2024-12-31 (N=150)\n",
      " Test  Period: 2025-01-01 ~ 2025-11-07 (N=311)\n",
      "[Class Balance] Train Set: {0: 0.5833333333333334, 1: 0.4166666666666667}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, EMA_12, btc_return, eth_return, l2_zksync era_tvl_ma30_ratio, gold_GOLD_ma30_ratio, SMA_50, SMA_20, BB_WIDTH, eth_btc_corr_30d, OBV, eth_log_return, MACD_12_26_9, usdt_totalBridgedToUSD_ma30_ratio, l2_base_tvl_ma30_ratio, LOWER_SHADOW, BREAKOUT_STR_5d, BREAKOUT_STR_20d, lido_lido_eth_tvl_ma30_ratio, l2_zksync era_tvl_pct_1d\n",
      "\n",
      "   >> Running Fold 1/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7733 | Precision: 0.7175\n",
      "  [CatBoost] Val   Acc: 0.6267 | Precision: 0.3784\n",
      "  [RandomForest] Train Acc: 0.7467 | Precision: 0.7034\n",
      "  [RandomForest] Val   Acc: 0.7000 | Precision: 0.4386\n",
      "  [LightGBM] Train Acc: 0.7583 | Precision: 0.7076\n",
      "  [LightGBM] Val   Acc: 0.7133 | Precision: 0.4510\n",
      "  [XGBoost] Train Acc: 0.7667 | Precision: 0.7754\n",
      "  [XGBoost] Val   Acc: 0.7600 | Precision: 0.5238\n",
      "\n",
      "   >> Running Fold 2/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8717 | Precision: 0.7821\n",
      "  [CatBoost] Val   Acc: 0.6200 | Precision: 0.4605\n",
      "  [RandomForest] Train Acc: 0.7667 | Precision: 0.6565\n",
      "  [RandomForest] Val   Acc: 0.6333 | Precision: 0.4714\n",
      "  [LightGBM] Train Acc: 0.7800 | Precision: 0.6718\n",
      "  [LightGBM] Val   Acc: 0.6600 | Precision: 0.5000\n",
      "  [XGBoost] Train Acc: 0.8083 | Precision: 0.9421\n",
      "  [XGBoost] Val   Acc: 0.6600 | Precision: 0.5000\n",
      "\n",
      "   >> Running Fold 3/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7850 | Precision: 0.6504\n",
      "  [CatBoost] Val   Acc: 0.6800 | Precision: 0.6410\n",
      "  [RandomForest] Train Acc: 0.7650 | Precision: 0.6303\n",
      "  [RandomForest] Val   Acc: 0.6467 | Precision: 0.5682\n",
      "  [LightGBM] Train Acc: 0.8050 | Precision: 0.6886\n",
      "  [LightGBM] Val   Acc: 0.6933 | Precision: 0.6757\n",
      "  [XGBoost] Train Acc: 0.7917 | Precision: 0.7910\n",
      "  [XGBoost] Val   Acc: 0.6733 | Precision: 0.8571\n",
      "\n",
      "   >> Running Fold 4/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9033 | Precision: 0.7922\n",
      "  [CatBoost] Val   Acc: 0.6800 | Precision: 0.8611\n",
      "  [RandomForest] Train Acc: 0.7950 | Precision: 0.6562\n",
      "  [RandomForest] Val   Acc: 0.6800 | Precision: 0.7321\n",
      "  [LightGBM] Train Acc: 0.8517 | Precision: 0.7261\n",
      "  [LightGBM] Val   Acc: 0.6867 | Precision: 0.8857\n",
      "  [XGBoost] Train Acc: 0.8683 | Precision: 0.9191\n",
      "  [XGBoost] Val   Acc: 0.5867 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 5/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8767 | Precision: 0.8219\n",
      "  [CatBoost] Val   Acc: 0.7400 | Precision: 0.6250\n",
      "  [RandomForest] Train Acc: 0.8067 | Precision: 0.7368\n",
      "  [RandomForest] Val   Acc: 0.7267 | Precision: 0.5962\n",
      "  [LightGBM] Train Acc: 0.9033 | Precision: 0.8514\n",
      "  [LightGBM] Val   Acc: 0.6800 | Precision: 0.5273\n",
      "  [XGBoost] Train Acc: 0.8900 | Precision: 0.9465\n",
      "  [XGBoost] Val   Acc: 0.7200 | Precision: 0.6364\n",
      "\n",
      "   >> Running Fold 6/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7900 | Precision: 0.7253\n",
      "  [CatBoost] Val   Acc: 0.6800 | Precision: 0.5676\n",
      "  [RandomForest] Train Acc: 0.7567 | Precision: 0.6958\n",
      "  [RandomForest] Val   Acc: 0.7133 | Precision: 0.6056\n",
      "  [LightGBM] Train Acc: 0.7883 | Precision: 0.7243\n",
      "  [LightGBM] Val   Acc: 0.7000 | Precision: 0.5890\n",
      "  [XGBoost] Train Acc: 0.7900 | Precision: 0.8361\n",
      "  [XGBoost] Val   Acc: 0.7267 | Precision: 0.6735\n",
      "\n",
      "   >> Running Fold 7/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9267 | Precision: 0.8851\n",
      "  [CatBoost] Val   Acc: 0.6533 | Precision: 0.4655\n",
      "  [RandomForest] Train Acc: 0.7867 | Precision: 0.7427\n",
      "  [RandomForest] Val   Acc: 0.6600 | Precision: 0.4706\n",
      "  [LightGBM] Train Acc: 0.7617 | Precision: 0.7318\n",
      "  [LightGBM] Val   Acc: 0.6933 | Precision: 0.5263\n",
      "  [XGBoost] Train Acc: 0.7533 | Precision: 0.7740\n",
      "  [XGBoost] Val   Acc: 0.7000 | Precision: 0.5455\n",
      "\n",
      "   >> Running Fold 8/8 (final_holdout)\n",
      "  [CatBoost] Train Acc: 0.7683 | Precision: 0.7048\n",
      "  [CatBoost] Val   Acc: 0.6667 | Precision: 0.5833\n",
      "  [RandomForest] Train Acc: 0.7883 | Precision: 0.7356\n",
      "  [RandomForest] Val   Acc: 0.6733 | Precision: 0.5942\n",
      "  [LightGBM] Train Acc: 0.7700 | Precision: 0.7105\n",
      "  [LightGBM] Val   Acc: 0.6800 | Precision: 0.6000\n",
      "  [XGBoost] Train Acc: 0.7667 | Precision: 0.8395\n",
      "  [XGBoost] Val   Acc: 0.6800 | Precision: 0.6591\n",
      "\n",
      " === Trial Finished. Final Score: 0.4481R ===\n",
      "\n",
      "================================================================================\n",
      " Starting NEW trial_14_204947_L12_P1.6_S1.0\n",
      "\n",
      " Pipeline Started... (Train Start: 2020-01-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_256137/1210223439.py:54: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_ta['EMA_12'] = ta.ema(close, length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏùºÎ¥â Í∏∞Í∞Ñ: 2019-06-15 ~ 2025-11-20\n",
      "1ÏãúÍ∞ÑÎ¥â Í∏∞Í∞Ñ (KST Î≥ÄÌôò ÌõÑ): 2020-01-01 09:00:00 ~ 2025-11-23 08:00:00\n",
      "[Í≤ΩÍ≥†] 1ÏãúÍ∞ÑÎ¥â ÏãúÏûëÏùº(2020-01-01 09:00:00)Ïù¥ ÏùºÎ¥â ÏãúÏûëÏùº(2019-06-15 00:00:00) Ïù¥ÌõÑÏûÖÎãàÎã§. Ï¥àÎ∞ò ÌÉÄÍ≤ü ÏÜêÏã§ Î∞úÏÉù.\n",
      "Ïú†Ìö® ÏÉòÌîå: 2326/2339 (Ï†úÍ±∞: 13)\n",
      "Win: 833 | Lose: 1493 | Win Rate: 35.81%\n",
      "(2326, 85)\n",
      "\n",
      "================================================================================\n",
      "Reverse Rolling Walk-Forward + Final Holdout\n",
      "================================================================================\n",
      "Total period: 2020-01-01 ~ 2025-11-08 (2139 days)\n",
      "Rolling train: 800d | Val: 150d | Test: 150d | Gap: 12d\n",
      "Final holdout test: 2025-01-01 ~ 2025-11-08\n",
      "================================================================================\n",
      "\n",
      "Fold 1 (walk_forward_rolling)\n",
      "  Train:  800d  2020-02-13 ~ 2022-04-22\n",
      "  Val:    150d  2022-05-05 ~ 2022-10-01\n",
      "  Test:   150d  2022-10-14 ~ 2023-03-12\n",
      "\n",
      "Fold 2 (walk_forward_rolling)\n",
      "  Train:  800d  2020-07-24 ~ 2022-10-01\n",
      "  Val:    150d  2022-10-14 ~ 2023-03-12\n",
      "  Test:   150d  2023-03-25 ~ 2023-08-21\n",
      "\n",
      "Fold 3 (walk_forward_rolling)\n",
      "  Train:  800d  2021-01-02 ~ 2023-03-12\n",
      "  Val:    150d  2023-03-25 ~ 2023-08-21\n",
      "  Test:   150d  2023-09-03 ~ 2024-01-30\n",
      "\n",
      "Fold 4 (walk_forward_rolling)\n",
      "  Train:  800d  2021-06-13 ~ 2023-08-21\n",
      "  Val:    150d  2023-09-03 ~ 2024-01-30\n",
      "  Test:   150d  2024-02-12 ~ 2024-07-10\n",
      "\n",
      "Fold 5 (walk_forward_rolling)\n",
      "  Train:  800d  2021-11-22 ~ 2024-01-30\n",
      "  Val:    150d  2024-02-12 ~ 2024-07-10\n",
      "  Test:   150d  2024-07-23 ~ 2024-12-19\n",
      "\n",
      "Fold 6 (walk_forward_rolling)\n",
      "  Train:  800d  2022-05-03 ~ 2024-07-10\n",
      "  Val:    150d  2024-07-23 ~ 2024-12-19\n",
      "  Test:   150d  2025-01-01 ~ 2025-05-30\n",
      "\n",
      "Fold 7 (walk_forward_rolling)\n",
      "  Train:  800d  2022-10-12 ~ 2024-12-19\n",
      "  Val:    150d  2025-01-01 ~ 2025-05-30\n",
      "  Test:   150d  2025-06-12 ~ 2025-11-08\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Fold 8 (final_holdout - 2025 Ï†ÑÏ≤¥ Î≥ÑÎèÑ ÌèâÍ∞Ä)\n",
      "================================================================================\n",
      "  Train:  800d  2022-05-15 ~ 2024-07-22\n",
      "  Val:    150d  2024-08-04 ~ 2024-12-31\n",
      "  Test:   312d  2025-01-01 ~ 2025-11-08\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Created 8 folds total\n",
      "  - 7 walk-forward folds\n",
      "  - 1 final holdout fold (2025 Ï†ÑÏ≤¥)\n",
      "================================================================================\n",
      "\n",
      " Data Split Completed. Total 8 folds generated.\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 1 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-02-13 ~ 2022-04-22 (N=800)\n",
      " Val   Period: 2022-05-05 ~ 2022-10-01 (N=150)\n",
      " Test  Period: 2022-10-14 ~ 2023-03-12 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.5766666666666667, 1: 0.42333333333333334}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, SMA_20, MACD_12_26_9, BREAKOUT_STR_5d, eth_return, btc_return, BB_WIDTH, EMA_12, MACDS_12_26_9, usdt_totalMintedUSD_ma30_ratio, eth_log_return, BREAKOUT_STR_20d, PRICE_VS_HIGH_5d, eth_btc_corr_30d, usdt_totalUnreleased_ma30_ratio, gold_GOLD_ma30_ratio, dxy_DXY_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, fg_fear_greed\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 2 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-07-24 ~ 2022-10-01 (N=800)\n",
      " Val   Period: 2022-10-14 ~ 2023-03-12 (N=150)\n",
      " Test  Period: 2023-03-25 ~ 2023-08-21 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.655, 1: 0.345}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, MACD_12_26_9, chain_eth_chain_tvl_ma30_ratio, eth_return, PRICE_VS_LOW_60d, SMA_50, eth_log_return, PRICE_VS_LOW_20d, MACDS_12_26_9, btc_return, BREAKOUT_STR_20d, PRICE_VS_HIGH_5d, EMA_12, OBV, usdt_totalUnreleased_ma30_ratio, curve_curve-dex_eth_tvl_ma30_ratio, dxy_DXY_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, BB_WIDTH, sp500_SP500_pct_1d\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 3 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-01-02 ~ 2023-03-12 (N=800)\n",
      " Val   Period: 2023-03-25 ~ 2023-08-21 (N=150)\n",
      " Test  Period: 2023-09-03 ~ 2024-01-30 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6683333333333333, 1: 0.33166666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, eth_return, SMA_20, BREAKOUT_STR_5d, eth_btc_spread, btc_return, PRICE_VS_LOW_60d, BB_WIDTH, eth_log_return, l2_arbitrum_tvl_ma30_ratio, MACD_12_26_9, MACDS_12_26_9, PRICE_VS_LOW_5d, UPPER_SHADOW, LOWER_SHADOW, usdt_totalMintedUSD_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, TREND_SCORE, lido_lido_eth_tvl_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 4 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-06-13 ~ 2023-08-21 (N=800)\n",
      " Val   Period: 2023-09-03 ~ 2024-01-30 (N=150)\n",
      " Test  Period: 2024-02-12 ~ 2024-07-10 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6916666666666667, 1: 0.30833333333333335}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_20, btc_return, BB_WIDTH, usdt_totalBridgedToUSD_ma30_ratio, eth_return, SMA_50, EMA_12, usdt_totalCirculating_ma30_ratio, eth_log_return, usdt_totalCirculatingUSD_ma30_ratio, PRICE_VS_HIGH_5d, PRICE_VS_LOW_60d, LOWER_SHADOW, BREAKOUT_STR_5d, usdt_totalMintedUSD_ma30_ratio, usdt_totalUnreleased_ma30_ratio, l2_optimism_tvl_ma30_ratio, sp500_SP500_ma30_ratio, MACDS_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 5 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-11-22 ~ 2024-01-30 (N=800)\n",
      " Val   Period: 2024-02-12 ~ 2024-07-10 (N=150)\n",
      " Test  Period: 2024-07-23 ~ 2024-12-19 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6233333333333333, 1: 0.37666666666666665}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> btc_return, gold_GOLD_ma30_ratio, l2_zksync era_tvl_ma30_ratio, eth_return, dxy_DXY_ma30_ratio, usdt_totalUnreleased_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, eth_btc_corr_30d, eth_log_return, PRICE_VS_LOW_5d, ATR_14, return_lag10, UPPER_SHADOW, LOWER_SHADOW, BREAKOUT_STR_5d, lido_lido_eth_tvl_ma30_ratio, SMA_20, SMA_50, l2_base_tvl_ma30_ratio, EMA_12\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 6 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-05-03 ~ 2024-07-10 (N=800)\n",
      " Val   Period: 2024-07-23 ~ 2024-12-19 (N=150)\n",
      " Test  Period: 2025-01-01 ~ 2025-05-30 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6, 1: 0.4}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_20, EMA_12, l2_zksync era_tvl_ma30_ratio, btc_return, eth_return, gold_GOLD_ma30_ratio, l2_base_tvl_ma30_ratio, BB_WIDTH, OBV, eth_log_return, PRICE_VS_LOW_60d, UPPER_SHADOW, BREAKOUT_STR_5d, BREAKOUT_STR_20d, dxy_DXY_ma30_ratio, SMA_50, eth_btc_corr_30d, price_rank_250d, PRICE_VS_HIGH_60d, ATR_14\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 7 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-10-12 ~ 2024-12-19 (N=800)\n",
      " Val   Period: 2025-01-01 ~ 2025-05-30 (N=150)\n",
      " Test  Period: 2025-06-12 ~ 2025-11-08 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6216666666666667, 1: 0.37833333333333335}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, EMA_12, l2_base_tvl_ma30_ratio, eth_return, usdt_totalBridgedToUSD_ma30_ratio, btc_return, SMA_20, BB_WIDTH, eth_btc_corr_30d, eth_log_return, usdt_totalCirculating_ma30_ratio, BREAKOUT_STR_5d, PRICE_VS_LOW_20d, BREAKOUT_STR_20d, lido_lido_eth_tvl_ma30_ratio, MACDS_12_26_9, usdt_totalCirculatingUSD_ma30_ratio, PRICE_VS_HIGH_60d, MACD_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 8 (final_holdout)\n",
      "================================================================================\n",
      " Train Period: 2022-05-15 ~ 2024-07-22 (N=800)\n",
      " Val   Period: 2024-08-04 ~ 2024-12-31 (N=150)\n",
      " Test  Period: 2025-01-01 ~ 2025-11-08 (N=312)\n",
      "[Class Balance] Train Set: {0: 0.6033333333333334, 1: 0.39666666666666667}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_20, EMA_12, btc_return, eth_return, gold_GOLD_ma30_ratio, l2_base_tvl_ma30_ratio, SMA_50, BB_WIDTH, OBV, eth_log_return, l2_zksync era_tvl_ma30_ratio, BREAKOUT_STR_5d, LOWER_SHADOW, PRICE_VS_HIGH_5d, BREAKOUT_STR_20d, usdt_totalBridgedToUSD_ma30_ratio, lido_lido_eth_tvl_ma30_ratio, l2_arbitrum_tvl_ma30_ratio, eth_btc_corr_30d\n",
      "\n",
      "   >> Running Fold 1/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7767 | Precision: 0.7000\n",
      "  [CatBoost] Val   Acc: 0.6333 | Precision: 0.3594\n",
      "  [RandomForest] Train Acc: 0.7350 | Precision: 0.6667\n",
      "  [RandomForest] Val   Acc: 0.6733 | Precision: 0.4000\n",
      "  [LightGBM] Train Acc: 0.7367 | Precision: 0.6690\n",
      "  [LightGBM] Val   Acc: 0.6800 | Precision: 0.4035\n",
      "  [XGBoost] Train Acc: 0.7567 | Precision: 0.7647\n",
      "  [XGBoost] Val   Acc: 0.7600 | Precision: 0.5128\n",
      "\n",
      "   >> Running Fold 2/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8417 | Precision: 0.7276\n",
      "  [CatBoost] Val   Acc: 0.6267 | Precision: 0.4667\n",
      "  [RandomForest] Train Acc: 0.7567 | Precision: 0.6187\n",
      "  [RandomForest] Val   Acc: 0.6333 | Precision: 0.4861\n",
      "  [LightGBM] Train Acc: 0.7200 | Precision: 0.5783\n",
      "  [LightGBM] Val   Acc: 0.6400 | Precision: 0.4928\n",
      "  [XGBoost] Train Acc: 0.6883 | Precision: 0.8846\n",
      "  [XGBoost] Val   Acc: 0.6667 | Precision: 0.8000\n",
      "\n",
      "   >> Running Fold 3/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8583 | Precision: 0.7436\n",
      "  [CatBoost] Val   Acc: 0.6867 | Precision: 0.5789\n",
      "  [RandomForest] Train Acc: 0.7717 | Precision: 0.6303\n",
      "  [RandomForest] Val   Acc: 0.7000 | Precision: 0.6000\n",
      "  [LightGBM] Train Acc: 0.7967 | Precision: 0.6611\n",
      "  [LightGBM] Val   Acc: 0.6867 | Precision: 0.6071\n",
      "  [XGBoost] Train Acc: 0.7267 | Precision: 0.8182\n",
      "  [XGBoost] Val   Acc: 0.6867 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 4/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8183 | Precision: 0.6681\n",
      "  [CatBoost] Val   Acc: 0.6533 | Precision: 0.7091\n",
      "  [RandomForest] Train Acc: 0.7250 | Precision: 0.5400\n",
      "  [RandomForest] Val   Acc: 0.6867 | Precision: 0.7258\n",
      "  [LightGBM] Train Acc: 0.7483 | Precision: 0.5664\n",
      "  [LightGBM] Val   Acc: 0.6533 | Precision: 0.6825\n",
      "  [XGBoost] Train Acc: 0.7200 | Precision: 0.8696\n",
      "  [XGBoost] Val   Acc: 0.5133 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 5/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8183 | Precision: 0.7294\n",
      "  [CatBoost] Val   Acc: 0.7200 | Precision: 0.5517\n",
      "  [RandomForest] Train Acc: 0.8383 | Precision: 0.7590\n",
      "  [RandomForest] Val   Acc: 0.7267 | Precision: 0.5593\n",
      "  [LightGBM] Train Acc: 0.8500 | Precision: 0.7787\n",
      "  [LightGBM] Val   Acc: 0.7000 | Precision: 0.5205\n",
      "  [XGBoost] Train Acc: 0.7650 | Precision: 0.9126\n",
      "  [XGBoost] Val   Acc: 0.7200 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 6/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7833 | Precision: 0.7115\n",
      "  [CatBoost] Val   Acc: 0.6467 | Precision: 0.4861\n",
      "  [RandomForest] Train Acc: 0.7983 | Precision: 0.7390\n",
      "  [RandomForest] Val   Acc: 0.6400 | Precision: 0.4769\n",
      "  [LightGBM] Train Acc: 0.7783 | Precision: 0.7050\n",
      "  [LightGBM] Val   Acc: 0.6200 | Precision: 0.4516\n",
      "  [XGBoost] Train Acc: 0.7700 | Precision: 0.8148\n",
      "  [XGBoost] Val   Acc: 0.7133 | Precision: 0.6250\n",
      "\n",
      "   >> Running Fold 7/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8667 | Precision: 0.8000\n",
      "  [CatBoost] Val   Acc: 0.7000 | Precision: 0.4286\n",
      "  [RandomForest] Train Acc: 0.7767 | Precision: 0.6946\n",
      "  [RandomForest] Val   Acc: 0.6533 | Precision: 0.3600\n",
      "  [LightGBM] Train Acc: 0.7683 | Precision: 0.6964\n",
      "  [LightGBM] Val   Acc: 0.7400 | Precision: 0.4872\n",
      "  [XGBoost] Train Acc: 0.7917 | Precision: 0.9322\n",
      "  [XGBoost] Val   Acc: 0.7400 | Precision: 0.4667\n",
      "\n",
      "   >> Running Fold 8/8 (final_holdout)\n",
      "  [CatBoost] Train Acc: 0.8300 | Precision: 0.7576\n",
      "  [CatBoost] Val   Acc: 0.6600 | Precision: 0.5303\n",
      "  [RandomForest] Train Acc: 0.7650 | Precision: 0.6902\n",
      "  [RandomForest] Val   Acc: 0.6600 | Precision: 0.5303\n",
      "  [LightGBM] Train Acc: 0.7833 | Precision: 0.7160\n",
      "  [LightGBM] Val   Acc: 0.6533 | Precision: 0.5263\n",
      "  [XGBoost] Train Acc: 0.7533 | Precision: 0.9091\n",
      "  [XGBoost] Val   Acc: 0.6800 | Precision: 0.6522\n",
      "\n",
      " === Trial Finished. Final Score: 0.3970R ===\n",
      "\n",
      "================================================================================\n",
      " Starting NEW trial_15_205649_L15_P1.6_S0.9\n",
      "\n",
      " Pipeline Started... (Train Start: 2020-01-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_256137/1210223439.py:54: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_ta['EMA_12'] = ta.ema(close, length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏùºÎ¥â Í∏∞Í∞Ñ: 2019-06-15 ~ 2025-11-20\n",
      "1ÏãúÍ∞ÑÎ¥â Í∏∞Í∞Ñ (KST Î≥ÄÌôò ÌõÑ): 2020-01-01 09:00:00 ~ 2025-11-23 08:00:00\n",
      "[Í≤ΩÍ≥†] 1ÏãúÍ∞ÑÎ¥â ÏãúÏûëÏùº(2020-01-01 09:00:00)Ïù¥ ÏùºÎ¥â ÏãúÏûëÏùº(2019-06-15 00:00:00) Ïù¥ÌõÑÏûÖÎãàÎã§. Ï¥àÎ∞ò ÌÉÄÍ≤ü ÏÜêÏã§ Î∞úÏÉù.\n",
      "Ïú†Ìö® ÏÉòÌîå: 2323/2336 (Ï†úÍ±∞: 13)\n",
      "Win: 819 | Lose: 1504 | Win Rate: 35.26%\n",
      "(2323, 85)\n",
      "\n",
      "================================================================================\n",
      "Reverse Rolling Walk-Forward + Final Holdout\n",
      "================================================================================\n",
      "Total period: 2020-01-01 ~ 2025-11-05 (2136 days)\n",
      "Rolling train: 800d | Val: 150d | Test: 150d | Gap: 15d\n",
      "Final holdout test: 2025-01-01 ~ 2025-11-05\n",
      "================================================================================\n",
      "\n",
      "Fold 1 (walk_forward_rolling)\n",
      "  Train:  800d  2020-01-17 ~ 2022-03-26\n",
      "  Val:    150d  2022-04-11 ~ 2022-09-07\n",
      "  Test:   150d  2022-09-23 ~ 2023-02-19\n",
      "\n",
      "Fold 2 (walk_forward_rolling)\n",
      "  Train:  800d  2020-06-30 ~ 2022-09-07\n",
      "  Val:    150d  2022-09-23 ~ 2023-02-19\n",
      "  Test:   150d  2023-03-07 ~ 2023-08-03\n",
      "\n",
      "Fold 3 (walk_forward_rolling)\n",
      "  Train:  800d  2020-12-12 ~ 2023-02-19\n",
      "  Val:    150d  2023-03-07 ~ 2023-08-03\n",
      "  Test:   150d  2023-08-19 ~ 2024-01-15\n",
      "\n",
      "Fold 4 (walk_forward_rolling)\n",
      "  Train:  800d  2021-05-26 ~ 2023-08-03\n",
      "  Val:    150d  2023-08-19 ~ 2024-01-15\n",
      "  Test:   150d  2024-01-31 ~ 2024-06-28\n",
      "\n",
      "Fold 5 (walk_forward_rolling)\n",
      "  Train:  800d  2021-11-07 ~ 2024-01-15\n",
      "  Val:    150d  2024-01-31 ~ 2024-06-28\n",
      "  Test:   150d  2024-07-14 ~ 2024-12-10\n",
      "\n",
      "Fold 6 (walk_forward_rolling)\n",
      "  Train:  800d  2022-04-21 ~ 2024-06-28\n",
      "  Val:    150d  2024-07-14 ~ 2024-12-10\n",
      "  Test:   150d  2024-12-26 ~ 2025-05-24\n",
      "\n",
      "Fold 7 (walk_forward_rolling)\n",
      "  Train:  800d  2022-10-03 ~ 2024-12-10\n",
      "  Val:    150d  2024-12-26 ~ 2025-05-24\n",
      "  Test:   150d  2025-06-09 ~ 2025-11-05\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Fold 8 (final_holdout - 2025 Ï†ÑÏ≤¥ Î≥ÑÎèÑ ÌèâÍ∞Ä)\n",
      "================================================================================\n",
      "  Train:  800d  2022-05-12 ~ 2024-07-19\n",
      "  Val:    150d  2024-08-04 ~ 2024-12-31\n",
      "  Test:   309d  2025-01-01 ~ 2025-11-05\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Created 8 folds total\n",
      "  - 7 walk-forward folds\n",
      "  - 1 final holdout fold (2025 Ï†ÑÏ≤¥)\n",
      "================================================================================\n",
      "\n",
      " Data Split Completed. Total 8 folds generated.\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 1 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-01-17 ~ 2022-03-26 (N=800)\n",
      " Val   Period: 2022-04-11 ~ 2022-09-07 (N=150)\n",
      " Test  Period: 2022-09-23 ~ 2023-02-19 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.5833333333333334, 1: 0.4166666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, MACDS_12_26_9, eth_return, BREAKOUT_STR_5d, btc_return, usdt_totalUnreleased_ma30_ratio, BB_WIDTH, MACD_12_26_9, eth_log_return, ATR_14, PRICE_VS_HIGH_5d, usdt_totalMintedUSD_ma30_ratio, eth_btc_corr_30d, uniswap_uniswap_eth_tvl_ma30_ratio, gold_GOLD_ma30_ratio, dxy_DXY_ma30_ratio, SMA_20, EMA_12, usdt_totalBridgedToUSD_ma30_ratio, funding_fundingRate\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 2 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-06-30 ~ 2022-09-07 (N=800)\n",
      " Val   Period: 2022-09-23 ~ 2023-02-19 (N=150)\n",
      " Test  Period: 2023-03-07 ~ 2023-08-03 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.64, 1: 0.36}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, BB_WIDTH, eth_return, MACDS_12_26_9, usdt_totalUnreleased_ma30_ratio, BREAKOUT_STR_5d, btc_return, MACD_12_26_9, eth_log_return, PRICE_VS_LOW_20d, usdt_totalCirculatingUSD_ma30_ratio, BREAKOUT_STR_60d, PRICE_VS_LOW_60d, PRICE_VS_LOW_5d, OBV, SMA_20, chain_eth_chain_tvl_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, l2_arbitrum_tvl_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 3 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-12-12 ~ 2023-02-19 (N=800)\n",
      " Val   Period: 2023-03-07 ~ 2023-08-03 (N=150)\n",
      " Test  Period: 2023-08-19 ~ 2024-01-15 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6833333333333333, 1: 0.31666666666666665}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, eth_return, eth_btc_spread, l2_optimism_tvl_ma30_ratio, BREAKOUT_STR_5d, eth_btc_corr_30d, BB_WIDTH, SMA_20, usdt_totalBridgedToUSD_ma30_ratio, eth_log_return, l2_arbitrum_tvl_ma30_ratio, MACD_12_26_9, PRICE_VS_HIGH_5d, PRICE_VS_LOW_5d, ATR_14, UPPER_SHADOW, PRICE_VS_LOW_60d, btc_return, eth_btc_corr_7d, MFI_14\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 4 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-05-26 ~ 2023-08-03 (N=800)\n",
      " Val   Period: 2023-08-19 ~ 2024-01-15 (N=150)\n",
      " Test  Period: 2024-01-31 ~ 2024-06-28 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.695, 1: 0.305}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_20, usdt_totalBridgedToUSD_ma30_ratio, eth_return, usdt_totalCirculating_ma30_ratio, usdt_totalUnreleased_ma30_ratio, usdt_totalMintedUSD_ma30_ratio, SMA_50, BB_WIDTH, eth_log_return, btc_return, EMA_12, PRICE_VS_LOW_60d, usdt_totalCirculatingUSD_ma30_ratio, OBV, BREAKOUT_STR_5d, eth_btc_corr_7d, eth_btc_corr_30d, l2_arbitrum_tvl_ma30_ratio, l2_optimism_tvl_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 5 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-11-07 ~ 2024-01-15 (N=800)\n",
      " Val   Period: 2024-01-31 ~ 2024-06-28 (N=150)\n",
      " Test  Period: 2024-07-14 ~ 2024-12-10 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6383333333333333, 1: 0.3616666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, gold_GOLD_ma30_ratio, btc_return, eth_return, BREAKOUT_STR_5d, usdt_totalUnreleased_ma30_ratio, SMA_20, usdt_totalBridgedToUSD_ma30_ratio, eth_log_return, l2_zksync era_tvl_ma30_ratio, return_lag5, return_lag10, BREAKOUT_STR_20d, eth_btc_corr_7d, usdt_totalCirculating_ma30_ratio, dxy_DXY_ma30_ratio, MACDS_12_26_9, BB_WIDTH, eth_btc_corr_30d\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 6 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-04-21 ~ 2024-06-28 (N=800)\n",
      " Val   Period: 2024-07-14 ~ 2024-12-10 (N=150)\n",
      " Test  Period: 2024-12-26 ~ 2025-05-24 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.62, 1: 0.38}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_20, eth_return, btc_return, gold_GOLD_ma30_ratio, dxy_DXY_ma30_ratio, SMA_50, BB_WIDTH, EMA_12, OBV, eth_btc_corr_30d, eth_log_return, l2_zksync era_tvl_ma30_ratio, BREAKOUT_STR_5d, l2_base_tvl_ma30_ratio, PRICE_VS_HIGH_5d, BREAKOUT_STR_20d, PRICE_VS_LOW_60d, usdt_totalUnreleased_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 7 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-10-03 ~ 2024-12-10 (N=800)\n",
      " Val   Period: 2024-12-26 ~ 2025-05-24 (N=150)\n",
      " Test  Period: 2025-06-09 ~ 2025-11-05 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6316666666666667, 1: 0.36833333333333335}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, EMA_12, l2_base_tvl_ma30_ratio, eth_return, btc_return, SMA_20, MACDS_12_26_9, BB_WIDTH, eth_btc_corr_30d, usdt_totalCirculating_ma30_ratio, eth_log_return, usdt_totalBridgedToUSD_ma30_ratio, PRICE_VS_LOW_20d, BREAKOUT_STR_5d, PRICE_VS_HIGH_5d, BREAKOUT_STR_20d, usdt_totalCirculatingUSD_ma30_ratio, PRICE_VS_HIGH_60d, RSI_14\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 8 (final_holdout)\n",
      "================================================================================\n",
      " Train Period: 2022-05-12 ~ 2024-07-19 (N=800)\n",
      " Val   Period: 2024-08-04 ~ 2024-12-31 (N=150)\n",
      " Test  Period: 2025-01-01 ~ 2025-11-05 (N=309)\n",
      "[Class Balance] Train Set: {0: 0.6133333333333333, 1: 0.38666666666666666}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> EMA_12, eth_return, btc_return, gold_GOLD_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, SMA_50, SMA_20, BB_WIDTH, OBV, eth_log_return, BREAKOUT_STR_5d, PRICE_VS_HIGH_5d, usdt_totalUnreleased_ma30_ratio, lido_lido_eth_tvl_ma30_ratio, l2_zksync era_tvl_ma30_ratio, dxy_DXY_ma30_ratio, eth_btc_corr_30d, price_rank_250d, ATR_14, fg_fear_greed\n",
      "\n",
      "   >> Running Fold 1/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7767 | Precision: 0.6921\n",
      "  [CatBoost] Val   Acc: 0.6267 | Precision: 0.3846\n",
      "  [RandomForest] Train Acc: 0.7317 | Precision: 0.6519\n",
      "  [RandomForest] Val   Acc: 0.6533 | Precision: 0.3971\n",
      "  [LightGBM] Train Acc: 0.7183 | Precision: 0.6311\n",
      "  [LightGBM] Val   Acc: 0.6667 | Precision: 0.4143\n",
      "  [XGBoost] Train Acc: 0.7733 | Precision: 0.8065\n",
      "  [XGBoost] Val   Acc: 0.7600 | Precision: 0.5357\n",
      "\n",
      "   >> Running Fold 2/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8067 | Precision: 0.6894\n",
      "  [CatBoost] Val   Acc: 0.6133 | Precision: 0.4231\n",
      "  [RandomForest] Train Acc: 0.7433 | Precision: 0.6183\n",
      "  [RandomForest] Val   Acc: 0.6267 | Precision: 0.4306\n",
      "  [LightGBM] Train Acc: 0.7417 | Precision: 0.6368\n",
      "  [LightGBM] Val   Acc: 0.6800 | Precision: 0.4737\n",
      "  [XGBoost] Train Acc: 0.7183 | Precision: 0.8507\n",
      "  [XGBoost] Val   Acc: 0.7400 | Precision: 0.7059\n",
      "\n",
      "   >> Running Fold 3/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9050 | Precision: 0.8009\n",
      "  [CatBoost] Val   Acc: 0.7333 | Precision: 0.7500\n",
      "  [RandomForest] Train Acc: 0.8017 | Precision: 0.6592\n",
      "  [RandomForest] Val   Acc: 0.7133 | Precision: 0.7111\n",
      "  [LightGBM] Train Acc: 0.7867 | Precision: 0.6240\n",
      "  [LightGBM] Val   Acc: 0.7733 | Precision: 0.7692\n",
      "  [XGBoost] Train Acc: 0.7867 | Precision: 0.8523\n",
      "  [XGBoost] Val   Acc: 0.6400 | Precision: 0.8333\n",
      "\n",
      "   >> Running Fold 4/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7650 | Precision: 0.5840\n",
      "  [CatBoost] Val   Acc: 0.7267 | Precision: 0.7313\n",
      "  [RandomForest] Train Acc: 0.7383 | Precision: 0.5537\n",
      "  [RandomForest] Val   Acc: 0.7200 | Precision: 0.7344\n",
      "  [LightGBM] Train Acc: 0.8167 | Precision: 0.6466\n",
      "  [LightGBM] Val   Acc: 0.7467 | Precision: 0.7833\n",
      "  [XGBoost] Train Acc: 0.8417 | Precision: 0.9074\n",
      "  [XGBoost] Val   Acc: 0.5667 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 5/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8850 | Precision: 0.8162\n",
      "  [CatBoost] Val   Acc: 0.6800 | Precision: 0.5345\n",
      "  [RandomForest] Train Acc: 0.8467 | Precision: 0.7706\n",
      "  [RandomForest] Val   Acc: 0.6733 | Precision: 0.5273\n",
      "  [LightGBM] Train Acc: 0.8417 | Precision: 0.7585\n",
      "  [LightGBM] Val   Acc: 0.6800 | Precision: 0.5385\n",
      "  [XGBoost] Train Acc: 0.7983 | Precision: 0.8871\n",
      "  [XGBoost] Val   Acc: 0.6533 | Precision: 0.5000\n",
      "\n",
      "   >> Running Fold 6/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7800 | Precision: 0.6860\n",
      "  [CatBoost] Val   Acc: 0.6933 | Precision: 0.5231\n",
      "  [RandomForest] Train Acc: 0.7900 | Precision: 0.6992\n",
      "  [RandomForest] Val   Acc: 0.6733 | Precision: 0.5000\n",
      "  [LightGBM] Train Acc: 0.7900 | Precision: 0.6903\n",
      "  [LightGBM] Val   Acc: 0.7067 | Precision: 0.5362\n",
      "  [XGBoost] Train Acc: 0.7783 | Precision: 0.8146\n",
      "  [XGBoost] Val   Acc: 0.7333 | Precision: 0.6154\n",
      "\n",
      "   >> Running Fold 7/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8417 | Precision: 0.7520\n",
      "  [CatBoost] Val   Acc: 0.6867 | Precision: 0.4750\n",
      "  [RandomForest] Train Acc: 0.7683 | Precision: 0.6614\n",
      "  [RandomForest] Val   Acc: 0.6600 | Precision: 0.4348\n",
      "  [LightGBM] Train Acc: 0.7967 | Precision: 0.7054\n",
      "  [LightGBM] Val   Acc: 0.7200 | Precision: 0.5385\n",
      "  [XGBoost] Train Acc: 0.7300 | Precision: 0.7921\n",
      "  [XGBoost] Val   Acc: 0.7267 | Precision: 0.6429\n",
      "\n",
      "   >> Running Fold 8/8 (final_holdout)\n",
      "  [CatBoost] Train Acc: 0.7717 | Precision: 0.6834\n",
      "  [CatBoost] Val   Acc: 0.6733 | Precision: 0.5286\n",
      "  [RandomForest] Train Acc: 0.7450 | Precision: 0.6502\n",
      "  [RandomForest] Val   Acc: 0.6800 | Precision: 0.5362\n",
      "  [LightGBM] Train Acc: 0.8050 | Precision: 0.7186\n",
      "  [LightGBM] Val   Acc: 0.6733 | Precision: 0.5286\n",
      "  [XGBoost] Train Acc: 0.7650 | Precision: 0.8421\n",
      "  [XGBoost] Val   Acc: 0.7133 | Precision: 0.6786\n",
      "\n",
      " === Trial Finished. Final Score: 0.6439R ===\n",
      "\n",
      "================================================================================\n",
      " Starting NEW trial_16_210423_L12_P1.5_S0.9\n",
      "\n",
      " Pipeline Started... (Train Start: 2020-01-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_256137/1210223439.py:54: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_ta['EMA_12'] = ta.ema(close, length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏùºÎ¥â Í∏∞Í∞Ñ: 2019-06-15 ~ 2025-11-20\n",
      "1ÏãúÍ∞ÑÎ¥â Í∏∞Í∞Ñ (KST Î≥ÄÌôò ÌõÑ): 2020-01-01 09:00:00 ~ 2025-11-23 08:00:00\n",
      "[Í≤ΩÍ≥†] 1ÏãúÍ∞ÑÎ¥â ÏãúÏûëÏùº(2020-01-01 09:00:00)Ïù¥ ÏùºÎ¥â ÏãúÏûëÏùº(2019-06-15 00:00:00) Ïù¥ÌõÑÏûÖÎãàÎã§. Ï¥àÎ∞ò ÌÉÄÍ≤ü ÏÜêÏã§ Î∞úÏÉù.\n",
      "Ïú†Ìö® ÏÉòÌîå: 2326/2339 (Ï†úÍ±∞: 13)\n",
      "Win: 826 | Lose: 1500 | Win Rate: 35.51%\n",
      "(2326, 85)\n",
      "\n",
      "================================================================================\n",
      "Reverse Rolling Walk-Forward + Final Holdout\n",
      "================================================================================\n",
      "Total period: 2020-01-01 ~ 2025-11-08 (2139 days)\n",
      "Rolling train: 800d | Val: 150d | Test: 150d | Gap: 12d\n",
      "Final holdout test: 2025-01-01 ~ 2025-11-08\n",
      "================================================================================\n",
      "\n",
      "Fold 1 (walk_forward_rolling)\n",
      "  Train:  800d  2020-02-13 ~ 2022-04-22\n",
      "  Val:    150d  2022-05-05 ~ 2022-10-01\n",
      "  Test:   150d  2022-10-14 ~ 2023-03-12\n",
      "\n",
      "Fold 2 (walk_forward_rolling)\n",
      "  Train:  800d  2020-07-24 ~ 2022-10-01\n",
      "  Val:    150d  2022-10-14 ~ 2023-03-12\n",
      "  Test:   150d  2023-03-25 ~ 2023-08-21\n",
      "\n",
      "Fold 3 (walk_forward_rolling)\n",
      "  Train:  800d  2021-01-02 ~ 2023-03-12\n",
      "  Val:    150d  2023-03-25 ~ 2023-08-21\n",
      "  Test:   150d  2023-09-03 ~ 2024-01-30\n",
      "\n",
      "Fold 4 (walk_forward_rolling)\n",
      "  Train:  800d  2021-06-13 ~ 2023-08-21\n",
      "  Val:    150d  2023-09-03 ~ 2024-01-30\n",
      "  Test:   150d  2024-02-12 ~ 2024-07-10\n",
      "\n",
      "Fold 5 (walk_forward_rolling)\n",
      "  Train:  800d  2021-11-22 ~ 2024-01-30\n",
      "  Val:    150d  2024-02-12 ~ 2024-07-10\n",
      "  Test:   150d  2024-07-23 ~ 2024-12-19\n",
      "\n",
      "Fold 6 (walk_forward_rolling)\n",
      "  Train:  800d  2022-05-03 ~ 2024-07-10\n",
      "  Val:    150d  2024-07-23 ~ 2024-12-19\n",
      "  Test:   150d  2025-01-01 ~ 2025-05-30\n",
      "\n",
      "Fold 7 (walk_forward_rolling)\n",
      "  Train:  800d  2022-10-12 ~ 2024-12-19\n",
      "  Val:    150d  2025-01-01 ~ 2025-05-30\n",
      "  Test:   150d  2025-06-12 ~ 2025-11-08\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Fold 8 (final_holdout - 2025 Ï†ÑÏ≤¥ Î≥ÑÎèÑ ÌèâÍ∞Ä)\n",
      "================================================================================\n",
      "  Train:  800d  2022-05-15 ~ 2024-07-22\n",
      "  Val:    150d  2024-08-04 ~ 2024-12-31\n",
      "  Test:   312d  2025-01-01 ~ 2025-11-08\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Created 8 folds total\n",
      "  - 7 walk-forward folds\n",
      "  - 1 final holdout fold (2025 Ï†ÑÏ≤¥)\n",
      "================================================================================\n",
      "\n",
      " Data Split Completed. Total 8 folds generated.\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 1 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-02-13 ~ 2022-04-22 (N=800)\n",
      " Val   Period: 2022-05-05 ~ 2022-10-01 (N=150)\n",
      " Test  Period: 2022-10-14 ~ 2023-03-12 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.5883333333333334, 1: 0.4116666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, eth_return, MACDS_12_26_9, btc_return, ATR_14, SMA_20, BB_WIDTH, MACD_12_26_9, eth_log_return, BREAKOUT_STR_5d, PRICE_VS_HIGH_5d, BREAKOUT_STR_20d, usdt_totalMintedUSD_ma30_ratio, UPPER_SHADOW, usdt_totalUnreleased_ma30_ratio, gold_GOLD_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, EMA_12, usdt_totalCirculatingUSD_ma30_ratio, return_lag10\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 2 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-07-24 ~ 2022-10-01 (N=800)\n",
      " Val   Period: 2022-10-14 ~ 2023-03-12 (N=150)\n",
      " Test  Period: 2023-03-25 ~ 2023-08-21 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.66, 1: 0.34}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, eth_return, MACD_12_26_9, BREAKOUT_STR_5d, PRICE_VS_LOW_60d, SMA_50, BB_WIDTH, eth_log_return, MACDS_12_26_9, PRICE_VS_HIGH_5d, chain_eth_chain_tvl_ma30_ratio, BREAKOUT_STR_20d, PRICE_VS_LOW_20d, BREAKOUT_STR_60d, eth_btc_spread, btc_return, UPPER_SHADOW, usdt_totalUnreleased_ma30_ratio, dxy_DXY_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 3 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-01-02 ~ 2023-03-12 (N=800)\n",
      " Val   Period: 2023-03-25 ~ 2023-08-21 (N=150)\n",
      " Test  Period: 2023-09-03 ~ 2024-01-30 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6783333333333333, 1: 0.32166666666666666}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, eth_return, eth_btc_spread, BREAKOUT_STR_5d, BB_WIDTH, usdt_totalBridgedToUSD_ma30_ratio, eth_log_return, l2_arbitrum_tvl_ma30_ratio, MACDS_12_26_9, PRICE_VS_LOW_60d, PRICE_VS_LOW_5d, BREAKOUT_STR_20d, EMA_12, UPPER_SHADOW, btc_return, eth_btc_corr_30d, usdt_totalCirculating_ma30_ratio, usdt_totalMintedUSD_ma30_ratio, usdt_totalUnreleased_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 4 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-06-13 ~ 2023-08-21 (N=800)\n",
      " Val   Period: 2023-09-03 ~ 2024-01-30 (N=150)\n",
      " Test  Period: 2024-02-12 ~ 2024-07-10 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6983333333333334, 1: 0.3016666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_20, usdt_totalCirculating_ma30_ratio, btc_return, eth_return, usdt_totalMintedUSD_ma30_ratio, SMA_50, BB_WIDTH, usdt_totalBridgedToUSD_ma30_ratio, usdt_totalCirculatingUSD_ma30_ratio, EMA_12, eth_log_return, eth_btc_spread, PRICE_VS_HIGH_5d, PRICE_VS_LOW_60d, BREAKOUT_STR_5d, usdt_totalUnreleased_ma30_ratio, l2_optimism_tvl_ma30_ratio, MACDS_12_26_9, MACD_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 5 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-11-22 ~ 2024-01-30 (N=800)\n",
      " Val   Period: 2024-02-12 ~ 2024-07-10 (N=150)\n",
      " Test  Period: 2024-07-23 ~ 2024-12-19 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6333333333333333, 1: 0.36666666666666664}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> btc_return, gold_GOLD_ma30_ratio, eth_return, ATR_14, BREAKOUT_STR_5d, dxy_DXY_ma30_ratio, return_lag10, SMA_50, usdt_totalBridgedToUSD_ma30_ratio, BB_WIDTH, eth_log_return, eth_btc_corr_30d, MACDS_12_26_9, UPPER_SHADOW, LOWER_SHADOW, BREAKOUT_STR_20d, eth_btc_corr_7d, SMA_20, l2_zksync era_tvl_ma30_ratio, EMA_12\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 6 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-05-03 ~ 2024-07-10 (N=800)\n",
      " Val   Period: 2024-07-23 ~ 2024-12-19 (N=150)\n",
      " Test  Period: 2025-01-01 ~ 2025-05-30 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6116666666666667, 1: 0.3883333333333333}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> EMA_12, eth_return, btc_return, gold_GOLD_ma30_ratio, l2_zksync era_tvl_ma30_ratio, dxy_DXY_ma30_ratio, BREAKOUT_STR_5d, SMA_50, SMA_20, BB_WIDTH, OBV, eth_log_return, l2_arbitrum_tvl_ma30_ratio, PRICE_VS_HIGH_20d, UPPER_SHADOW, BREAKOUT_STR_20d, usdt_totalUnreleased_ma30_ratio, eth_btc_corr_30d, ATR_14, price_rank_250d\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 7 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-10-12 ~ 2024-12-19 (N=800)\n",
      " Val   Period: 2025-01-01 ~ 2025-05-30 (N=150)\n",
      " Test  Period: 2025-06-12 ~ 2025-11-08 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6266666666666667, 1: 0.37333333333333335}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, EMA_12, eth_return, BREAKOUT_STR_5d, usdt_totalBridgedToUSD_ma30_ratio, l2_base_tvl_ma30_ratio, btc_return, PRICE_VS_LOW_20d, BB_WIDTH, SMA_20, MACDS_12_26_9, eth_btc_corr_30d, eth_log_return, PRICE_VS_HIGH_5d, MFI_14, BREAKOUT_STR_20d, lido_lido_eth_tvl_ma30_ratio, usdt_totalCirculating_ma30_ratio, usdt_totalMintedUSD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 8 (final_holdout)\n",
      "================================================================================\n",
      " Train Period: 2022-05-15 ~ 2024-07-22 (N=800)\n",
      " Val   Period: 2024-08-04 ~ 2024-12-31 (N=150)\n",
      " Test  Period: 2025-01-01 ~ 2025-11-08 (N=312)\n",
      "[Class Balance] Train Set: {0: 0.615, 1: 0.385}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, EMA_12, eth_return, btc_return, gold_GOLD_ma30_ratio, l2_arbitrum_tvl_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, l2_zksync era_tvl_ma30_ratio, SMA_50, SMA_20, BB_WIDTH, eth_log_return, OBV, BREAKOUT_STR_5d, MACD_12_26_9, PRICE_VS_HIGH_5d, BREAKOUT_STR_20d, usdt_totalUnreleased_ma30_ratio, dxy_DXY_ma30_ratio, eth_btc_corr_30d\n",
      "\n",
      "   >> Running Fold 1/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7633 | Precision: 0.6895\n",
      "  [CatBoost] Val   Acc: 0.6667 | Precision: 0.3968\n",
      "  [RandomForest] Train Acc: 0.7483 | Precision: 0.6752\n",
      "  [RandomForest] Val   Acc: 0.6933 | Precision: 0.4237\n",
      "  [LightGBM] Train Acc: 0.7433 | Precision: 0.6655\n",
      "  [LightGBM] Val   Acc: 0.6933 | Precision: 0.4182\n",
      "  [XGBoost] Train Acc: 0.7583 | Precision: 0.7684\n",
      "  [XGBoost] Val   Acc: 0.7600 | Precision: 0.5152\n",
      "\n",
      "   >> Running Fold 2/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7717 | Precision: 0.6304\n",
      "  [CatBoost] Val   Acc: 0.6400 | Precision: 0.4576\n",
      "  [RandomForest] Train Acc: 0.7433 | Precision: 0.5954\n",
      "  [RandomForest] Val   Acc: 0.6400 | Precision: 0.4648\n",
      "  [LightGBM] Train Acc: 0.7383 | Precision: 0.5861\n",
      "  [LightGBM] Val   Acc: 0.6467 | Precision: 0.4706\n",
      "  [XGBoost] Train Acc: 0.7100 | Precision: 0.8750\n",
      "  [XGBoost] Val   Acc: 0.6800 | Precision: 0.6667\n",
      "\n",
      "   >> Running Fold 3/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8150 | Precision: 0.6814\n",
      "  [CatBoost] Val   Acc: 0.7467 | Precision: 0.6923\n",
      "  [RandomForest] Train Acc: 0.8000 | Precision: 0.6637\n",
      "  [RandomForest] Val   Acc: 0.7200 | Precision: 0.6897\n",
      "  [LightGBM] Train Acc: 0.7867 | Precision: 0.6407\n",
      "  [LightGBM] Val   Acc: 0.7600 | Precision: 0.7931\n",
      "  [XGBoost] Train Acc: 0.8000 | Precision: 0.8230\n",
      "  [XGBoost] Val   Acc: 0.6933 | Precision: 0.8889\n",
      "\n",
      "   >> Running Fold 4/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8517 | Precision: 0.7035\n",
      "  [CatBoost] Val   Acc: 0.6533 | Precision: 0.7333\n",
      "  [RandomForest] Train Acc: 0.7350 | Precision: 0.5440\n",
      "  [RandomForest] Val   Acc: 0.6600 | Precision: 0.6774\n",
      "  [LightGBM] Train Acc: 0.7950 | Precision: 0.6208\n",
      "  [LightGBM] Val   Acc: 0.6600 | Precision: 0.7200\n",
      "  [XGBoost] Train Acc: 0.8017 | Precision: 0.9697\n",
      "  [XGBoost] Val   Acc: 0.5467 | Precision: 0.7778\n",
      "\n",
      "   >> Running Fold 5/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8750 | Precision: 0.7984\n",
      "  [CatBoost] Val   Acc: 0.6867 | Precision: 0.5000\n",
      "  [RandomForest] Train Acc: 0.8100 | Precision: 0.7137\n",
      "  [RandomForest] Val   Acc: 0.7133 | Precision: 0.5333\n",
      "  [LightGBM] Train Acc: 0.9533 | Precision: 0.9103\n",
      "  [LightGBM] Val   Acc: 0.7333 | Precision: 0.5897\n",
      "  [XGBoost] Train Acc: 0.7317 | Precision: 0.7252\n",
      "  [XGBoost] Val   Acc: 0.7333 | Precision: 0.5854\n",
      "\n",
      "   >> Running Fold 6/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7733 | Precision: 0.6777\n",
      "  [CatBoost] Val   Acc: 0.7067 | Precision: 0.5522\n",
      "  [RandomForest] Train Acc: 0.7600 | Precision: 0.6679\n",
      "  [RandomForest] Val   Acc: 0.7000 | Precision: 0.5429\n",
      "  [LightGBM] Train Acc: 0.8133 | Precision: 0.7336\n",
      "  [LightGBM] Val   Acc: 0.7267 | Precision: 0.5758\n",
      "  [XGBoost] Train Acc: 0.7383 | Precision: 0.8065\n",
      "  [XGBoost] Val   Acc: 0.7400 | Precision: 0.6875\n",
      "\n",
      "   >> Running Fold 7/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8367 | Precision: 0.7582\n",
      "  [CatBoost] Val   Acc: 0.7133 | Precision: 0.5000\n",
      "  [RandomForest] Train Acc: 0.8217 | Precision: 0.7532\n",
      "  [RandomForest] Val   Acc: 0.7067 | Precision: 0.4889\n",
      "  [LightGBM] Train Acc: 0.7700 | Precision: 0.6870\n",
      "  [LightGBM] Val   Acc: 0.7133 | Precision: 0.5000\n",
      "  [XGBoost] Train Acc: 0.8250 | Precision: 0.8940\n",
      "  [XGBoost] Val   Acc: 0.7267 | Precision: 0.5385\n",
      "\n",
      "   >> Running Fold 8/8 (final_holdout)\n",
      "  [CatBoost] Train Acc: 0.7750 | Precision: 0.6778\n",
      "  [CatBoost] Val   Acc: 0.6867 | Precision: 0.5606\n",
      "  [RandomForest] Train Acc: 0.7433 | Precision: 0.6410\n",
      "  [RandomForest] Val   Acc: 0.6800 | Precision: 0.5493\n",
      "  [LightGBM] Train Acc: 0.7783 | Precision: 0.6801\n",
      "  [LightGBM] Val   Acc: 0.6933 | Precision: 0.5692\n",
      "  [XGBoost] Train Acc: 0.7400 | Precision: 0.8440\n",
      "  [XGBoost] Val   Acc: 0.7267 | Precision: 0.7059\n",
      "\n",
      " === Trial Finished. Final Score: 0.4908R ===\n",
      "\n",
      "[Skip] Found existing result for L=15, P=1.6, S=0.9. Score: 0.6439\n",
      "\n",
      "================================================================================\n",
      " Starting NEW trial_18_211150_L11_P1.6_S0.9\n",
      "\n",
      " Pipeline Started... (Train Start: 2020-01-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_256137/1210223439.py:54: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_ta['EMA_12'] = ta.ema(close, length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏùºÎ¥â Í∏∞Í∞Ñ: 2019-06-15 ~ 2025-11-20\n",
      "1ÏãúÍ∞ÑÎ¥â Í∏∞Í∞Ñ (KST Î≥ÄÌôò ÌõÑ): 2020-01-01 09:00:00 ~ 2025-11-23 08:00:00\n",
      "[Í≤ΩÍ≥†] 1ÏãúÍ∞ÑÎ¥â ÏãúÏûëÏùº(2020-01-01 09:00:00)Ïù¥ ÏùºÎ¥â ÏãúÏûëÏùº(2019-06-15 00:00:00) Ïù¥ÌõÑÏûÖÎãàÎã§. Ï¥àÎ∞ò ÌÉÄÍ≤ü ÏÜêÏã§ Î∞úÏÉù.\n",
      "Ïú†Ìö® ÏÉòÌîå: 2327/2340 (Ï†úÍ±∞: 13)\n",
      "Win: 769 | Lose: 1558 | Win Rate: 33.05%\n",
      "(2327, 85)\n",
      "\n",
      "================================================================================\n",
      "Reverse Rolling Walk-Forward + Final Holdout\n",
      "================================================================================\n",
      "Total period: 2020-01-01 ~ 2025-11-09 (2140 days)\n",
      "Rolling train: 800d | Val: 150d | Test: 150d | Gap: 11d\n",
      "Final holdout test: 2025-01-01 ~ 2025-11-09\n",
      "================================================================================\n",
      "\n",
      "Fold 1 (walk_forward_rolling)\n",
      "  Train:  800d  2020-02-22 ~ 2022-05-01\n",
      "  Val:    150d  2022-05-13 ~ 2022-10-09\n",
      "  Test:   150d  2022-10-21 ~ 2023-03-19\n",
      "\n",
      "Fold 2 (walk_forward_rolling)\n",
      "  Train:  800d  2020-08-01 ~ 2022-10-09\n",
      "  Val:    150d  2022-10-21 ~ 2023-03-19\n",
      "  Test:   150d  2023-03-31 ~ 2023-08-27\n",
      "\n",
      "Fold 3 (walk_forward_rolling)\n",
      "  Train:  800d  2021-01-09 ~ 2023-03-19\n",
      "  Val:    150d  2023-03-31 ~ 2023-08-27\n",
      "  Test:   150d  2023-09-08 ~ 2024-02-04\n",
      "\n",
      "Fold 4 (walk_forward_rolling)\n",
      "  Train:  800d  2021-06-19 ~ 2023-08-27\n",
      "  Val:    150d  2023-09-08 ~ 2024-02-04\n",
      "  Test:   150d  2024-02-16 ~ 2024-07-14\n",
      "\n",
      "Fold 5 (walk_forward_rolling)\n",
      "  Train:  800d  2021-11-27 ~ 2024-02-04\n",
      "  Val:    150d  2024-02-16 ~ 2024-07-14\n",
      "  Test:   150d  2024-07-26 ~ 2024-12-22\n",
      "\n",
      "Fold 6 (walk_forward_rolling)\n",
      "  Train:  800d  2022-05-07 ~ 2024-07-14\n",
      "  Val:    150d  2024-07-26 ~ 2024-12-22\n",
      "  Test:   150d  2025-01-03 ~ 2025-06-01\n",
      "\n",
      "Fold 7 (walk_forward_rolling)\n",
      "  Train:  800d  2022-10-15 ~ 2024-12-22\n",
      "  Val:    150d  2025-01-03 ~ 2025-06-01\n",
      "  Test:   150d  2025-06-13 ~ 2025-11-09\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Fold 8 (final_holdout - 2025 Ï†ÑÏ≤¥ Î≥ÑÎèÑ ÌèâÍ∞Ä)\n",
      "================================================================================\n",
      "  Train:  800d  2022-05-16 ~ 2024-07-23\n",
      "  Val:    150d  2024-08-04 ~ 2024-12-31\n",
      "  Test:   313d  2025-01-01 ~ 2025-11-09\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Created 8 folds total\n",
      "  - 7 walk-forward folds\n",
      "  - 1 final holdout fold (2025 Ï†ÑÏ≤¥)\n",
      "================================================================================\n",
      "\n",
      " Data Split Completed. Total 8 folds generated.\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 1 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-02-22 ~ 2022-05-01 (N=800)\n",
      " Val   Period: 2022-05-13 ~ 2022-10-09 (N=150)\n",
      " Test  Period: 2022-10-21 ~ 2023-03-19 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6116666666666667, 1: 0.3883333333333333}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, MACD_12_26_9, BREAKOUT_STR_5d, eth_return, usdt_totalMintedUSD_ma30_ratio, btc_return, BB_WIDTH, EMA_12, MACDS_12_26_9, eth_log_return, BREAKOUT_STR_20d, PRICE_VS_HIGH_5d, PRICE_VS_LOW_5d, ATR_14, eth_btc_corr_30d, usdt_totalUnreleased_ma30_ratio, gold_GOLD_ma30_ratio, SMA_20, usdt_totalBridgedToUSD_ma30_ratio, TREND_SCORE\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 2 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-08-01 ~ 2022-10-09 (N=800)\n",
      " Val   Period: 2022-10-21 ~ 2023-03-19 (N=150)\n",
      " Test  Period: 2023-03-31 ~ 2023-08-27 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6866666666666666, 1: 0.31333333333333335}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, eth_return, PRICE_VS_LOW_20d, BREAKOUT_STR_5d, PRICE_VS_LOW_60d, BB_WIDTH, eth_log_return, MACD_12_26_9, MACDS_12_26_9, chain_eth_chain_tvl_ma30_ratio, PRICE_VS_HIGH_5d, BREAKOUT_STR_60d, BREAKOUT_STR_20d, PRICE_VS_HIGH_20d, btc_return, usdt_totalUnreleased_ma30_ratio, dxy_DXY_ma30_ratio, TREND_SCORE, SMA_20\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 3 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-01-09 ~ 2023-03-19 (N=800)\n",
      " Val   Period: 2023-03-31 ~ 2023-08-27 (N=150)\n",
      " Test  Period: 2023-09-08 ~ 2024-02-04 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6933333333333334, 1: 0.30666666666666664}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, eth_return, MACDS_12_26_9, BREAKOUT_STR_5d, PRICE_VS_LOW_60d, eth_btc_spread, BB_WIDTH, eth_log_return, l2_arbitrum_tvl_ma30_ratio, PRICE_VS_LOW_5d, BREAKOUT_STR_20d, btc_return, UPPER_SHADOW, eth_btc_corr_30d, usdt_totalCirculating_ma30_ratio, l2_optimism_tvl_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, vix_VIX_pct_1d, SMA_20\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 4 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-06-19 ~ 2023-08-27 (N=800)\n",
      " Val   Period: 2023-09-08 ~ 2024-02-04 (N=150)\n",
      " Test  Period: 2024-02-16 ~ 2024-07-14 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7033333333333334, 1: 0.2966666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_20, btc_return, eth_return, usdt_totalCirculating_ma30_ratio, SMA_50, BB_WIDTH, eth_log_return, usdt_totalBridgedToUSD_ma30_ratio, usdt_totalCirculatingUSD_ma30_ratio, EMA_12, VOLUME_RATIO, BREAKOUT_STR_5d, eth_btc_corr_30d, usdt_totalUnreleased_ma30_ratio, l2_optimism_tvl_ma30_ratio, dxy_DXY_ma30_ratio, MACDS_12_26_9, l2_base_tvl_ma30_ratio, MACD_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 5 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-11-27 ~ 2024-02-04 (N=800)\n",
      " Val   Period: 2024-02-16 ~ 2024-07-14 (N=150)\n",
      " Test  Period: 2024-07-26 ~ 2024-12-22 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.645, 1: 0.355}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, gold_GOLD_ma30_ratio, eth_return, lido_lido_eth_tvl_ma30_ratio, BREAKOUT_STR_5d, btc_return, usdt_totalBridgedToUSD_ma30_ratio, eth_log_return, eth_btc_corr_30d, MACDS_12_26_9, ATR_14, dxy_DXY_ma30_ratio, PRICE_VS_HIGH_5d, return_lag10, LOWER_SHADOW, BREAKOUT_STR_20d, eth_btc_corr_7d, usdt_totalUnreleased_ma30_ratio, l2_optimism_tvl_ma30_ratio, SMA_20\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 6 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-05-07 ~ 2024-07-14 (N=800)\n",
      " Val   Period: 2024-07-26 ~ 2024-12-22 (N=150)\n",
      " Test  Period: 2025-01-03 ~ 2025-06-01 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6266666666666667, 1: 0.37333333333333335}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, EMA_12, eth_return, btc_return, gold_GOLD_ma30_ratio, dxy_DXY_ma30_ratio, SMA_50, SMA_20, BB_WIDTH, eth_log_return, OBV, eth_btc_corr_30d, BREAKOUT_STR_5d, l2_base_tvl_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, dxy_DXY_pct_1d, UPPER_SHADOW, LOWER_SHADOW, PRICE_VS_HIGH_5d, BREAKOUT_STR_20d\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 7 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-10-15 ~ 2024-12-22 (N=800)\n",
      " Val   Period: 2025-01-03 ~ 2025-06-01 (N=150)\n",
      " Test  Period: 2025-06-13 ~ 2025-11-09 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.655, 1: 0.345}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, EMA_12, eth_return, usdt_totalBridgedToUSD_ma30_ratio, btc_return, l2_base_tvl_ma30_ratio, SMA_20, BB_WIDTH, MACDS_12_26_9, usdt_totalCirculating_ma30_ratio, eth_log_return, usdt_totalMintedUSD_ma30_ratio, vix_VIX_ma30_ratio, PRICE_VS_HIGH_5d, BREAKOUT_STR_5d, PRICE_VS_LOW_20d, usdt_totalUnreleased_ma30_ratio, l2_zksync era_tvl_ma30_ratio, gold_GOLD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 8 (final_holdout)\n",
      "================================================================================\n",
      " Train Period: 2022-05-16 ~ 2024-07-23 (N=800)\n",
      " Val   Period: 2024-08-04 ~ 2024-12-31 (N=150)\n",
      " Test  Period: 2025-01-01 ~ 2025-11-09 (N=313)\n",
      "[Class Balance] Train Set: {0: 0.6333333333333333, 1: 0.36666666666666664}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_20, EMA_12, eth_return, btc_return, gold_GOLD_ma30_ratio, l2_zksync era_tvl_ma30_ratio, PRICE_VS_HIGH_5d, usdt_totalBridgedToUSD_ma30_ratio, SMA_50, BB_WIDTH, eth_log_return, OBV, l2_base_tvl_ma30_ratio, BREAKOUT_STR_5d, dxy_DXY_pct_1d, LOWER_SHADOW, BREAKOUT_STR_20d, dxy_DXY_ma30_ratio, eth_btc_corr_30d\n",
      "\n",
      "   >> Running Fold 1/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8667 | Precision: 0.7823\n",
      "  [CatBoost] Val   Acc: 0.6533 | Precision: 0.3651\n",
      "  [RandomForest] Train Acc: 0.7317 | Precision: 0.6343\n",
      "  [RandomForest] Val   Acc: 0.6533 | Precision: 0.3607\n",
      "  [LightGBM] Train Acc: 0.7217 | Precision: 0.6170\n",
      "  [LightGBM] Val   Acc: 0.6800 | Precision: 0.3860\n",
      "  [XGBoost] Train Acc: 0.6950 | Precision: 0.8788\n",
      "  [XGBoost] Val   Acc: 0.7800 | Precision: 0.6667\n",
      "\n",
      "   >> Running Fold 2/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8100 | Precision: 0.6529\n",
      "  [CatBoost] Val   Acc: 0.6200 | Precision: 0.4407\n",
      "  [RandomForest] Train Acc: 0.7933 | Precision: 0.6368\n",
      "  [RandomForest] Val   Acc: 0.6133 | Precision: 0.4375\n",
      "  [LightGBM] Train Acc: 0.7467 | Precision: 0.5756\n",
      "  [LightGBM] Val   Acc: 0.6467 | Precision: 0.4727\n",
      "  [XGBoost] Train Acc: 0.7517 | Precision: 0.7910\n",
      "  [XGBoost] Val   Acc: 0.6867 | Precision: 0.6000\n",
      "\n",
      "   >> Running Fold 3/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8033 | Precision: 0.6473\n",
      "  [CatBoost] Val   Acc: 0.7400 | Precision: 0.6333\n",
      "  [RandomForest] Train Acc: 0.7900 | Precision: 0.6330\n",
      "  [RandomForest] Val   Acc: 0.7733 | Precision: 0.7241\n",
      "  [LightGBM] Train Acc: 0.8917 | Precision: 0.7742\n",
      "  [LightGBM] Val   Acc: 0.7533 | Precision: 0.7273\n",
      "  [XGBoost] Train Acc: 0.7900 | Precision: 0.7900\n",
      "  [XGBoost] Val   Acc: 0.7333 | Precision: 0.8182\n",
      "\n",
      "   >> Running Fold 4/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8850 | Precision: 0.7608\n",
      "  [CatBoost] Val   Acc: 0.6600 | Precision: 0.7273\n",
      "  [RandomForest] Train Acc: 0.7650 | Precision: 0.5755\n",
      "  [RandomForest] Val   Acc: 0.6467 | Precision: 0.6667\n",
      "  [LightGBM] Train Acc: 0.7117 | Precision: 0.5099\n",
      "  [LightGBM] Val   Acc: 0.6867 | Precision: 0.7000\n",
      "  [XGBoost] Train Acc: 0.7800 | Precision: 0.9107\n",
      "  [XGBoost] Val   Acc: 0.5733 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 5/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8167 | Precision: 0.7004\n",
      "  [CatBoost] Val   Acc: 0.7267 | Precision: 0.5417\n",
      "  [RandomForest] Train Acc: 0.7833 | Precision: 0.6627\n",
      "  [RandomForest] Val   Acc: 0.7067 | Precision: 0.5079\n",
      "  [LightGBM] Train Acc: 0.9133 | Precision: 0.8485\n",
      "  [LightGBM] Val   Acc: 0.7133 | Precision: 0.5312\n",
      "  [XGBoost] Train Acc: 0.9333 | Precision: 0.9482\n",
      "  [XGBoost] Val   Acc: 0.7400 | Precision: 0.7500\n",
      "\n",
      "   >> Running Fold 6/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7783 | Precision: 0.6667\n",
      "  [CatBoost] Val   Acc: 0.6533 | Precision: 0.4531\n",
      "  [RandomForest] Train Acc: 0.8017 | Precision: 0.7075\n",
      "  [RandomForest] Val   Acc: 0.6600 | Precision: 0.4615\n",
      "  [LightGBM] Train Acc: 0.8250 | Precision: 0.7449\n",
      "  [LightGBM] Val   Acc: 0.6800 | Precision: 0.4861\n",
      "  [XGBoost] Train Acc: 0.7683 | Precision: 0.8829\n",
      "  [XGBoost] Val   Acc: 0.6600 | Precision: 0.3913\n",
      "\n",
      "   >> Running Fold 7/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9800 | Precision: 0.9493\n",
      "  [CatBoost] Val   Acc: 0.7200 | Precision: 0.3830\n",
      "  [RandomForest] Train Acc: 0.8017 | Precision: 0.6864\n",
      "  [RandomForest] Val   Acc: 0.6933 | Precision: 0.3404\n",
      "  [LightGBM] Train Acc: 0.7717 | Precision: 0.6522\n",
      "  [LightGBM] Val   Acc: 0.7533 | Precision: 0.4250\n",
      "  [XGBoost] Train Acc: 0.8367 | Precision: 0.9098\n",
      "  [XGBoost] Val   Acc: 0.7933 | Precision: 0.5000\n",
      "\n",
      "   >> Running Fold 8/8 (final_holdout)\n",
      "  [CatBoost] Train Acc: 0.7850 | Precision: 0.6704\n",
      "  [CatBoost] Val   Acc: 0.6800 | Precision: 0.5147\n",
      "  [RandomForest] Train Acc: 0.7867 | Precision: 0.6797\n",
      "  [RandomForest] Val   Acc: 0.6333 | Precision: 0.4627\n",
      "  [LightGBM] Train Acc: 0.8233 | Precision: 0.7298\n",
      "  [LightGBM] Val   Acc: 0.6667 | Precision: 0.5000\n",
      "  [XGBoost] Train Acc: 0.6883 | Precision: 0.8667\n",
      "  [XGBoost] Val   Acc: 0.6733 | Precision: 1.0000\n",
      "\n",
      " === Trial Finished. Final Score: 0.4801R ===\n",
      "\n",
      "================================================================================\n",
      " Starting NEW trial_19_212011_L14_P1.5_S0.9\n",
      "\n",
      " Pipeline Started... (Train Start: 2020-01-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_256137/1210223439.py:54: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_ta['EMA_12'] = ta.ema(close, length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏùºÎ¥â Í∏∞Í∞Ñ: 2019-06-15 ~ 2025-11-20\n",
      "1ÏãúÍ∞ÑÎ¥â Í∏∞Í∞Ñ (KST Î≥ÄÌôò ÌõÑ): 2020-01-01 09:00:00 ~ 2025-11-23 08:00:00\n",
      "[Í≤ΩÍ≥†] 1ÏãúÍ∞ÑÎ¥â ÏãúÏûëÏùº(2020-01-01 09:00:00)Ïù¥ ÏùºÎ¥â ÏãúÏûëÏùº(2019-06-15 00:00:00) Ïù¥ÌõÑÏûÖÎãàÎã§. Ï¥àÎ∞ò ÌÉÄÍ≤ü ÏÜêÏã§ Î∞úÏÉù.\n",
      "Ïú†Ìö® ÏÉòÌîå: 2324/2337 (Ï†úÍ±∞: 13)\n",
      "Win: 849 | Lose: 1475 | Win Rate: 36.53%\n",
      "(2324, 85)\n",
      "\n",
      "================================================================================\n",
      "Reverse Rolling Walk-Forward + Final Holdout\n",
      "================================================================================\n",
      "Total period: 2020-01-01 ~ 2025-11-06 (2137 days)\n",
      "Rolling train: 800d | Val: 150d | Test: 150d | Gap: 14d\n",
      "Final holdout test: 2025-01-01 ~ 2025-11-06\n",
      "================================================================================\n",
      "\n",
      "Fold 1 (walk_forward_rolling)\n",
      "  Train:  800d  2020-01-26 ~ 2022-04-04\n",
      "  Val:    150d  2022-04-19 ~ 2022-09-15\n",
      "  Test:   150d  2022-09-30 ~ 2023-02-26\n",
      "\n",
      "Fold 2 (walk_forward_rolling)\n",
      "  Train:  800d  2020-07-08 ~ 2022-09-15\n",
      "  Val:    150d  2022-09-30 ~ 2023-02-26\n",
      "  Test:   150d  2023-03-13 ~ 2023-08-09\n",
      "\n",
      "Fold 3 (walk_forward_rolling)\n",
      "  Train:  800d  2020-12-19 ~ 2023-02-26\n",
      "  Val:    150d  2023-03-13 ~ 2023-08-09\n",
      "  Test:   150d  2023-08-24 ~ 2024-01-20\n",
      "\n",
      "Fold 4 (walk_forward_rolling)\n",
      "  Train:  800d  2021-06-01 ~ 2023-08-09\n",
      "  Val:    150d  2023-08-24 ~ 2024-01-20\n",
      "  Test:   150d  2024-02-04 ~ 2024-07-02\n",
      "\n",
      "Fold 5 (walk_forward_rolling)\n",
      "  Train:  800d  2021-11-12 ~ 2024-01-20\n",
      "  Val:    150d  2024-02-04 ~ 2024-07-02\n",
      "  Test:   150d  2024-07-17 ~ 2024-12-13\n",
      "\n",
      "Fold 6 (walk_forward_rolling)\n",
      "  Train:  800d  2022-04-25 ~ 2024-07-02\n",
      "  Val:    150d  2024-07-17 ~ 2024-12-13\n",
      "  Test:   150d  2024-12-28 ~ 2025-05-26\n",
      "\n",
      "Fold 7 (walk_forward_rolling)\n",
      "  Train:  800d  2022-10-06 ~ 2024-12-13\n",
      "  Val:    150d  2024-12-28 ~ 2025-05-26\n",
      "  Test:   150d  2025-06-10 ~ 2025-11-06\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Fold 8 (final_holdout - 2025 Ï†ÑÏ≤¥ Î≥ÑÎèÑ ÌèâÍ∞Ä)\n",
      "================================================================================\n",
      "  Train:  800d  2022-05-13 ~ 2024-07-20\n",
      "  Val:    150d  2024-08-04 ~ 2024-12-31\n",
      "  Test:   310d  2025-01-01 ~ 2025-11-06\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Created 8 folds total\n",
      "  - 7 walk-forward folds\n",
      "  - 1 final holdout fold (2025 Ï†ÑÏ≤¥)\n",
      "================================================================================\n",
      "\n",
      " Data Split Completed. Total 8 folds generated.\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 1 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-01-26 ~ 2022-04-04 (N=800)\n",
      " Val   Period: 2022-04-19 ~ 2022-09-15 (N=150)\n",
      " Test  Period: 2022-09-30 ~ 2023-02-26 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.57, 1: 0.43}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, MACD_12_26_9, eth_return, btc_return, SMA_20, BB_WIDTH, MACDS_12_26_9, eth_log_return, ATR_14, BREAKOUT_STR_5d, usdt_totalMintedUSD_ma30_ratio, BREAKOUT_STR_20d, UPPER_SHADOW, eth_btc_corr_30d, eth_btc_spread, usdt_totalUnreleased_ma30_ratio, gold_GOLD_ma30_ratio, dxy_DXY_ma30_ratio, EMA_12, funding_fundingRate\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 2 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-07-08 ~ 2022-09-15 (N=800)\n",
      " Val   Period: 2022-09-30 ~ 2023-02-26 (N=150)\n",
      " Test  Period: 2023-03-13 ~ 2023-08-09 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6333333333333333, 1: 0.36666666666666664}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, BB_WIDTH, eth_return, MACDS_12_26_9, BREAKOUT_STR_5d, btc_return, eth_log_return, PRICE_VS_HIGH_5d, BREAKOUT_STR_20d, PRICE_VS_LOW_60d, BREAKOUT_STR_60d, eth_btc_spread, PRICE_VS_LOW_20d, PRICE_VS_LOW_5d, OBV, UPPER_SHADOW, LOWER_SHADOW, usdt_totalUnreleased_ma30_ratio, aave_aave_eth_tvl_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 3 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-12-19 ~ 2023-02-26 (N=800)\n",
      " Val   Period: 2023-03-13 ~ 2023-08-09 (N=150)\n",
      " Test  Period: 2023-08-24 ~ 2024-01-20 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6766666666666666, 1: 0.3233333333333333}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, eth_return, eth_btc_spread, PRICE_VS_LOW_60d, BREAKOUT_STR_5d, usdt_totalBridgedToUSD_ma30_ratio, SMA_20, eth_log_return, l2_arbitrum_tvl_ma30_ratio, PRICE_VS_LOW_5d, l2_optimism_tvl_ma30_ratio, MACDS_12_26_9, VOLUME_RATIO, UPPER_SHADOW, LOWER_SHADOW, btc_return, eth_btc_corr_7d, eth_btc_corr_30d, usdt_totalMintedUSD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 4 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-06-01 ~ 2023-08-09 (N=800)\n",
      " Val   Period: 2023-08-24 ~ 2024-01-20 (N=150)\n",
      " Test  Period: 2024-02-04 ~ 2024-07-02 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6883333333333334, 1: 0.31166666666666665}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, SMA_20, usdt_totalBridgedToUSD_ma30_ratio, eth_return, btc_return, usdt_totalCirculating_ma30_ratio, usdt_totalMintedUSD_ma30_ratio, usdt_totalUnreleased_ma30_ratio, eth_log_return, EMA_12, usdt_totalCirculatingUSD_ma30_ratio, PRICE_VS_HIGH_5d, PRICE_VS_LOW_60d, UPPER_SHADOW, BREAKOUT_STR_5d, eth_btc_corr_7d, eth_btc_corr_30d, l2_optimism_tvl_ma30_ratio, MACDS_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 5 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-11-12 ~ 2024-01-20 (N=800)\n",
      " Val   Period: 2024-02-04 ~ 2024-07-02 (N=150)\n",
      " Test  Period: 2024-07-17 ~ 2024-12-13 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6333333333333333, 1: 0.36666666666666664}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_20, usdt_totalBridgedToUSD_ma30_ratio, gold_GOLD_ma30_ratio, btc_return, eth_return, BREAKOUT_STR_5d, l2_zksync era_tvl_ma30_ratio, SMA_50, eth_log_return, BB_WIDTH, eth_btc_corr_30d, ATR_14, MACDS_12_26_9, usdt_totalUnreleased_ma30_ratio, return_lag10, LOWER_SHADOW, BREAKOUT_STR_20d, eth_btc_corr_7d, dxy_DXY_ma30_ratio, BREAKOUT_STR_60d\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 6 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-04-25 ~ 2024-07-02 (N=800)\n",
      " Val   Period: 2024-07-17 ~ 2024-12-13 (N=150)\n",
      " Test  Period: 2024-12-28 ~ 2025-05-26 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.61, 1: 0.39}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_20, eth_return, l2_zksync era_tvl_ma30_ratio, btc_return, gold_GOLD_ma30_ratio, dxy_DXY_ma30_ratio, BB_WIDTH, EMA_12, eth_log_return, eth_btc_corr_30d, OBV, ATR_14, BREAKOUT_STR_5d, PRICE_VS_HIGH_20d, UPPER_SHADOW, PRICE_VS_HIGH_5d, BREAKOUT_STR_20d, usdt_totalUnreleased_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, l2_zksync era_tvl_pct_1d\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 7 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-10-06 ~ 2024-12-13 (N=800)\n",
      " Val   Period: 2024-12-28 ~ 2025-05-26 (N=150)\n",
      " Test  Period: 2025-06-10 ~ 2025-11-06 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6116666666666667, 1: 0.3883333333333333}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, EMA_12, usdt_totalBridgedToUSD_ma30_ratio, BREAKOUT_STR_5d, eth_return, btc_return, l2_base_tvl_ma30_ratio, PRICE_VS_LOW_20d, SMA_20, BB_WIDTH, MACDS_12_26_9, eth_btc_corr_30d, usdt_totalCirculating_ma30_ratio, PRICE_VS_HIGH_5d, eth_log_return, MFI_14, BREAKOUT_STR_20d, lido_lido_eth_tvl_ma30_ratio, gold_GOLD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 8 (final_holdout)\n",
      "================================================================================\n",
      " Train Period: 2022-05-13 ~ 2024-07-20 (N=800)\n",
      " Val   Period: 2024-08-04 ~ 2024-12-31 (N=150)\n",
      " Test  Period: 2025-01-01 ~ 2025-11-06 (N=310)\n",
      "[Class Balance] Train Set: {0: 0.605, 1: 0.395}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> EMA_12, eth_return, btc_return, gold_GOLD_ma30_ratio, l2_zksync era_tvl_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, SMA_50, SMA_20, BB_WIDTH, eth_log_return, OBV, MACD_12_26_9, LOWER_SHADOW, PRICE_VS_HIGH_5d, BREAKOUT_STR_20d, usdt_totalUnreleased_ma30_ratio, dxy_DXY_ma30_ratio, price_rank_250d, eth_btc_corr_30d, ATR_14\n",
      "\n",
      "   >> Running Fold 1/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9133 | Precision: 0.8456\n",
      "  [CatBoost] Val   Acc: 0.6333 | Precision: 0.3951\n",
      "  [RandomForest] Train Acc: 0.7500 | Precision: 0.6875\n",
      "  [RandomForest] Val   Acc: 0.6800 | Precision: 0.4167\n",
      "  [LightGBM] Train Acc: 0.7383 | Precision: 0.6603\n",
      "  [LightGBM] Val   Acc: 0.6733 | Precision: 0.4127\n",
      "  [XGBoost] Train Acc: 0.8717 | Precision: 0.9132\n",
      "  [XGBoost] Val   Acc: 0.7267 | Precision: 0.4737\n",
      "\n",
      "   >> Running Fold 2/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7783 | Precision: 0.6761\n",
      "  [CatBoost] Val   Acc: 0.6467 | Precision: 0.4533\n",
      "  [RandomForest] Train Acc: 0.7433 | Precision: 0.6260\n",
      "  [RandomForest] Val   Acc: 0.6600 | Precision: 0.4638\n",
      "  [LightGBM] Train Acc: 0.7083 | Precision: 0.5743\n",
      "  [LightGBM] Val   Acc: 0.6067 | Precision: 0.4253\n",
      "  [XGBoost] Train Acc: 0.6933 | Precision: 0.9091\n",
      "  [XGBoost] Val   Acc: 0.7133 | Precision: 0.6667\n",
      "\n",
      "   >> Running Fold 3/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8750 | Precision: 0.7644\n",
      "  [CatBoost] Val   Acc: 0.6933 | Precision: 0.7667\n",
      "  [RandomForest] Train Acc: 0.8350 | Precision: 0.7230\n",
      "  [RandomForest] Val   Acc: 0.6867 | Precision: 0.7586\n",
      "  [LightGBM] Train Acc: 0.8467 | Precision: 0.7161\n",
      "  [LightGBM] Val   Acc: 0.6867 | Precision: 0.8000\n",
      "  [XGBoost] Train Acc: 0.7300 | Precision: 0.7105\n",
      "  [XGBoost] Val   Acc: 0.6400 | Precision: 0.8333\n",
      "\n",
      "   >> Running Fold 4/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8483 | Precision: 0.7087\n",
      "  [CatBoost] Val   Acc: 0.7133 | Precision: 0.7344\n",
      "  [RandomForest] Train Acc: 0.7500 | Precision: 0.5755\n",
      "  [RandomForest] Val   Acc: 0.7200 | Precision: 0.7183\n",
      "  [LightGBM] Train Acc: 0.7283 | Precision: 0.5448\n",
      "  [LightGBM] Val   Acc: 0.7000 | Precision: 0.7121\n",
      "  [XGBoost] Train Acc: 0.8683 | Precision: 0.9286\n",
      "  [XGBoost] Val   Acc: 0.6000 | Precision: 0.9333\n",
      "\n",
      "   >> Running Fold 5/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8517 | Precision: 0.7764\n",
      "  [CatBoost] Val   Acc: 0.7133 | Precision: 0.5690\n",
      "  [RandomForest] Train Acc: 0.8300 | Precision: 0.7521\n",
      "  [RandomForest] Val   Acc: 0.7133 | Precision: 0.5769\n",
      "  [LightGBM] Train Acc: 0.8517 | Precision: 0.7695\n",
      "  [LightGBM] Val   Acc: 0.7000 | Precision: 0.5577\n",
      "  [XGBoost] Train Acc: 0.7550 | Precision: 0.8288\n",
      "  [XGBoost] Val   Acc: 0.7200 | Precision: 0.6452\n",
      "\n",
      "   >> Running Fold 6/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8317 | Precision: 0.7568\n",
      "  [CatBoost] Val   Acc: 0.7067 | Precision: 0.5735\n",
      "  [RandomForest] Train Acc: 0.7517 | Precision: 0.6557\n",
      "  [RandomForest] Val   Acc: 0.7067 | Precision: 0.5735\n",
      "  [LightGBM] Train Acc: 0.8033 | Precision: 0.7248\n",
      "  [LightGBM] Val   Acc: 0.7133 | Precision: 0.5846\n",
      "  [XGBoost] Train Acc: 0.7917 | Precision: 0.8471\n",
      "  [XGBoost] Val   Acc: 0.7533 | Precision: 0.7073\n",
      "\n",
      "   >> Running Fold 7/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8167 | Precision: 0.7490\n",
      "  [CatBoost] Val   Acc: 0.7067 | Precision: 0.5652\n",
      "  [RandomForest] Train Acc: 0.7733 | Precision: 0.6948\n",
      "  [RandomForest] Val   Acc: 0.6867 | Precision: 0.5333\n",
      "  [LightGBM] Train Acc: 0.7550 | Precision: 0.6870\n",
      "  [LightGBM] Val   Acc: 0.7200 | Precision: 0.6053\n",
      "  [XGBoost] Train Acc: 0.7617 | Precision: 0.7557\n",
      "  [XGBoost] Val   Acc: 0.7200 | Precision: 0.6333\n",
      "\n",
      "   >> Running Fold 8/8 (final_holdout)\n",
      "  [CatBoost] Train Acc: 0.7733 | Precision: 0.6850\n",
      "  [CatBoost] Val   Acc: 0.7000 | Precision: 0.5915\n",
      "  [RandomForest] Train Acc: 0.7417 | Precision: 0.6486\n",
      "  [RandomForest] Val   Acc: 0.7000 | Precision: 0.5942\n",
      "  [LightGBM] Train Acc: 0.8083 | Precision: 0.7311\n",
      "  [LightGBM] Val   Acc: 0.7000 | Precision: 0.6032\n",
      "  [XGBoost] Train Acc: 0.7700 | Precision: 0.8462\n",
      "  [XGBoost] Val   Acc: 0.7067 | Precision: 0.6750\n",
      "\n",
      " === Trial Finished. Final Score: 0.6101R ===\n",
      "\n",
      "================================================================================\n",
      " Starting NEW trial_20_212801_L14_P1.8_S0.9\n",
      "\n",
      " Pipeline Started... (Train Start: 2020-01-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_256137/1210223439.py:54: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_ta['EMA_12'] = ta.ema(close, length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏùºÎ¥â Í∏∞Í∞Ñ: 2019-06-15 ~ 2025-11-20\n",
      "1ÏãúÍ∞ÑÎ¥â Í∏∞Í∞Ñ (KST Î≥ÄÌôò ÌõÑ): 2020-01-01 09:00:00 ~ 2025-11-23 08:00:00\n",
      "[Í≤ΩÍ≥†] 1ÏãúÍ∞ÑÎ¥â ÏãúÏûëÏùº(2020-01-01 09:00:00)Ïù¥ ÏùºÎ¥â ÏãúÏûëÏùº(2019-06-15 00:00:00) Ïù¥ÌõÑÏûÖÎãàÎã§. Ï¥àÎ∞ò ÌÉÄÍ≤ü ÏÜêÏã§ Î∞úÏÉù.\n",
      "Ïú†Ìö® ÏÉòÌîå: 2324/2337 (Ï†úÍ±∞: 13)\n",
      "Win: 740 | Lose: 1584 | Win Rate: 31.84%\n",
      "(2324, 85)\n",
      "\n",
      "================================================================================\n",
      "Reverse Rolling Walk-Forward + Final Holdout\n",
      "================================================================================\n",
      "Total period: 2020-01-01 ~ 2025-11-06 (2137 days)\n",
      "Rolling train: 800d | Val: 150d | Test: 150d | Gap: 14d\n",
      "Final holdout test: 2025-01-01 ~ 2025-11-06\n",
      "================================================================================\n",
      "\n",
      "Fold 1 (walk_forward_rolling)\n",
      "  Train:  800d  2020-01-26 ~ 2022-04-04\n",
      "  Val:    150d  2022-04-19 ~ 2022-09-15\n",
      "  Test:   150d  2022-09-30 ~ 2023-02-26\n",
      "\n",
      "Fold 2 (walk_forward_rolling)\n",
      "  Train:  800d  2020-07-08 ~ 2022-09-15\n",
      "  Val:    150d  2022-09-30 ~ 2023-02-26\n",
      "  Test:   150d  2023-03-13 ~ 2023-08-09\n",
      "\n",
      "Fold 3 (walk_forward_rolling)\n",
      "  Train:  800d  2020-12-19 ~ 2023-02-26\n",
      "  Val:    150d  2023-03-13 ~ 2023-08-09\n",
      "  Test:   150d  2023-08-24 ~ 2024-01-20\n",
      "\n",
      "Fold 4 (walk_forward_rolling)\n",
      "  Train:  800d  2021-06-01 ~ 2023-08-09\n",
      "  Val:    150d  2023-08-24 ~ 2024-01-20\n",
      "  Test:   150d  2024-02-04 ~ 2024-07-02\n",
      "\n",
      "Fold 5 (walk_forward_rolling)\n",
      "  Train:  800d  2021-11-12 ~ 2024-01-20\n",
      "  Val:    150d  2024-02-04 ~ 2024-07-02\n",
      "  Test:   150d  2024-07-17 ~ 2024-12-13\n",
      "\n",
      "Fold 6 (walk_forward_rolling)\n",
      "  Train:  800d  2022-04-25 ~ 2024-07-02\n",
      "  Val:    150d  2024-07-17 ~ 2024-12-13\n",
      "  Test:   150d  2024-12-28 ~ 2025-05-26\n",
      "\n",
      "Fold 7 (walk_forward_rolling)\n",
      "  Train:  800d  2022-10-06 ~ 2024-12-13\n",
      "  Val:    150d  2024-12-28 ~ 2025-05-26\n",
      "  Test:   150d  2025-06-10 ~ 2025-11-06\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Fold 8 (final_holdout - 2025 Ï†ÑÏ≤¥ Î≥ÑÎèÑ ÌèâÍ∞Ä)\n",
      "================================================================================\n",
      "  Train:  800d  2022-05-13 ~ 2024-07-20\n",
      "  Val:    150d  2024-08-04 ~ 2024-12-31\n",
      "  Test:   310d  2025-01-01 ~ 2025-11-06\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Created 8 folds total\n",
      "  - 7 walk-forward folds\n",
      "  - 1 final holdout fold (2025 Ï†ÑÏ≤¥)\n",
      "================================================================================\n",
      "\n",
      " Data Split Completed. Total 8 folds generated.\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 1 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-01-26 ~ 2022-04-04 (N=800)\n",
      " Val   Period: 2022-04-19 ~ 2022-09-15 (N=150)\n",
      " Test  Period: 2022-09-30 ~ 2023-02-26 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6033333333333334, 1: 0.39666666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, SMA_20, eth_return, btc_return, BB_WIDTH, MACD_12_26_9, MACDS_12_26_9, EMA_12, ATR_14, usdt_totalMintedUSD_ma30_ratio, BREAKOUT_STR_5d, eth_log_return, BREAKOUT_STR_20d, PRICE_VS_HIGH_60d, eth_btc_spread, uniswap_uniswap_eth_tvl_ma30_ratio, dxy_DXY_ma30_ratio, usdt_totalCirculatingUSD_ma30_ratio, usdt_totalCirculating_ma30_ratio, usdt_totalUnreleased_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 2 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-07-08 ~ 2022-09-15 (N=800)\n",
      " Val   Period: 2022-09-30 ~ 2023-02-26 (N=150)\n",
      " Test  Period: 2023-03-13 ~ 2023-08-09 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.665, 1: 0.335}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, MACDS_12_26_9, eth_return, btc_return, SMA_50, BB_WIDTH, MACD_12_26_9, eth_log_return, PRICE_VS_HIGH_5d, PRICE_VS_HIGH_20d, BREAKOUT_STR_5d, BREAKOUT_STR_60d, curve_curve-dex_eth_tvl_ma30_ratio, OBV, LOWER_SHADOW, usdt_totalUnreleased_ma30_ratio, dxy_DXY_ma30_ratio, SMA_20, chain_eth_chain_tvl_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 3 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-12-19 ~ 2023-02-26 (N=800)\n",
      " Val   Period: 2023-03-13 ~ 2023-08-09 (N=150)\n",
      " Test  Period: 2023-08-24 ~ 2024-01-20 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.705, 1: 0.295}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, usdt_totalBridgedToUSD_ma30_ratio, eth_return, BREAKOUT_STR_5d, eth_btc_spread, usdt_totalMintedUSD_ma30_ratio, PRICE_VS_LOW_60d, SMA_20, l2_arbitrum_tvl_ma30_ratio, eth_log_return, MACD_12_26_9, PRICE_VS_LOW_5d, l2_optimism_tvl_ma30_ratio, VOLUME_RATIO, btc_return, UPPER_SHADOW, LOWER_SHADOW, eth_btc_corr_7d, BB_WIDTH\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 4 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-06-01 ~ 2023-08-09 (N=800)\n",
      " Val   Period: 2023-08-24 ~ 2024-01-20 (N=150)\n",
      " Test  Period: 2024-02-04 ~ 2024-07-02 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7266666666666667, 1: 0.2733333333333333}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_20, btc_return, usdt_totalBridgedToUSD_ma30_ratio, usdt_totalCirculating_ma30_ratio, usdt_totalMintedUSD_ma30_ratio, eth_return, usdt_totalUnreleased_ma30_ratio, SMA_50, MACDS_12_26_9, usdt_totalCirculatingUSD_ma30_ratio, EMA_12, eth_log_return, vix_VIX_pct_1d, PRICE_VS_LOW_60d, OBV, BREAKOUT_STR_5d, eth_btc_corr_7d, eth_btc_corr_30d, l2_optimism_tvl_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 5 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-11-12 ~ 2024-01-20 (N=800)\n",
      " Val   Period: 2024-02-04 ~ 2024-07-02 (N=150)\n",
      " Test  Period: 2024-07-17 ~ 2024-12-13 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6816666666666666, 1: 0.31833333333333336}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, btc_return, MACDS_12_26_9, gold_GOLD_ma30_ratio, usdt_totalUnreleased_ma30_ratio, BREAKOUT_STR_5d, eth_return, SMA_20, usdt_totalBridgedToUSD_ma30_ratio, MACD_12_26_9, usdt_totalCirculatingUSD_ma30_ratio, eth_log_return, ATR_14, UPPER_SHADOW, BREAKOUT_STR_20d, eth_btc_corr_7d, usdt_totalCirculating_ma30_ratio, uniswap_uniswap_eth_tvl_ma30_ratio, dxy_DXY_ma30_ratio, l2_zksync era_tvl_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 6 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-04-25 ~ 2024-07-02 (N=800)\n",
      " Val   Period: 2024-07-17 ~ 2024-12-13 (N=150)\n",
      " Test  Period: 2024-12-28 ~ 2025-05-26 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6633333333333333, 1: 0.33666666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, SMA_20, BB_WIDTH, btc_return, ATR_14, eth_return, gold_GOLD_ma30_ratio, PRICE_VS_HIGH_5d, EMA_12, eth_btc_corr_30d, OBV, eth_log_return, l2_zksync era_tvl_ma30_ratio, dxy_DXY_ma30_ratio, BREAKOUT_STR_5d, l2_base_tvl_ma30_ratio, UPPER_SHADOW, BREAKOUT_STR_20d, usdt_totalUnreleased_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 7 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-10-06 ~ 2024-12-13 (N=800)\n",
      " Val   Period: 2024-12-28 ~ 2025-05-26 (N=150)\n",
      " Test  Period: 2025-06-10 ~ 2025-11-06 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6716666666666666, 1: 0.3283333333333333}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, EMA_12, eth_btc_corr_30d, usdt_totalBridgedToUSD_ma30_ratio, l2_base_tvl_ma30_ratio, btc_return, eth_return, SMA_50, SMA_20, BB_WIDTH, price_rank_250d, makerdao_makerdao_eth_tvl_ma30_ratio, PRICE_VS_HIGH_5d, eth_log_return, BREAKOUT_STR_20d, curve_curve-dex_eth_tvl_ma30_ratio, MACDS_12_26_9, usdt_totalCirculating_ma30_ratio, RSI_14, MACD_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 8 (final_holdout)\n",
      "================================================================================\n",
      " Train Period: 2022-05-13 ~ 2024-07-20 (N=800)\n",
      " Val   Period: 2024-08-04 ~ 2024-12-31 (N=150)\n",
      " Test  Period: 2025-01-01 ~ 2025-11-06 (N=310)\n",
      "[Class Balance] Train Set: {0: 0.655, 1: 0.345}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> EMA_12, eth_btc_corr_30d, btc_return, eth_return, gold_GOLD_ma30_ratio, SMA_50, SMA_20, BB_WIDTH, OBV, ATR_14, eth_log_return, l2_base_tvl_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, dxy_DXY_ma30_ratio, UPPER_SHADOW, PRICE_VS_HIGH_5d, BREAKOUT_STR_20d, usdt_totalUnreleased_ma30_ratio, price_rank_250d, MACD_12_26_9\n",
      "\n",
      "   >> Running Fold 1/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8383 | Precision: 0.7456\n",
      "  [CatBoost] Val   Acc: 0.6200 | Precision: 0.3571\n",
      "  [RandomForest] Train Acc: 0.7500 | Precision: 0.6594\n",
      "  [RandomForest] Val   Acc: 0.6800 | Precision: 0.3729\n",
      "  [LightGBM] Train Acc: 0.7033 | Precision: 0.6071\n",
      "  [LightGBM] Val   Acc: 0.6933 | Precision: 0.3898\n",
      "  [XGBoost] Train Acc: 0.7117 | Precision: 0.8155\n",
      "  [XGBoost] Val   Acc: 0.7867 | Precision: 0.5238\n",
      "\n",
      "   >> Running Fold 2/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9333 | Precision: 0.8578\n",
      "  [CatBoost] Val   Acc: 0.6067 | Precision: 0.4000\n",
      "  [RandomForest] Train Acc: 0.7683 | Precision: 0.6260\n",
      "  [RandomForest] Val   Acc: 0.5333 | Precision: 0.3571\n",
      "  [LightGBM] Train Acc: 0.7267 | Precision: 0.5781\n",
      "  [LightGBM] Val   Acc: 0.6800 | Precision: 0.4400\n",
      "  [XGBoost] Train Acc: 0.8917 | Precision: 0.9595\n",
      "  [XGBoost] Val   Acc: 0.7467 | Precision: 0.5909\n",
      "\n",
      "   >> Running Fold 3/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8900 | Precision: 0.7656\n",
      "  [CatBoost] Val   Acc: 0.7067 | Precision: 0.5758\n",
      "  [RandomForest] Train Acc: 0.7150 | Precision: 0.5126\n",
      "  [RandomForest] Val   Acc: 0.7000 | Precision: 0.5417\n",
      "  [LightGBM] Train Acc: 0.7567 | Precision: 0.5683\n",
      "  [LightGBM] Val   Acc: 0.7133 | Precision: 0.5682\n",
      "  [XGBoost] Train Acc: 0.7383 | Precision: 0.9545\n",
      "  [XGBoost] Val   Acc: 0.6800 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 4/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7850 | Precision: 0.5799\n",
      "  [CatBoost] Val   Acc: 0.6867 | Precision: 0.6441\n",
      "  [RandomForest] Train Acc: 0.8667 | Precision: 0.7121\n",
      "  [RandomForest] Val   Acc: 0.6400 | Precision: 0.6250\n",
      "  [LightGBM] Train Acc: 0.8317 | Precision: 0.6479\n",
      "  [LightGBM] Val   Acc: 0.6600 | Precision: 0.6757\n",
      "  [XGBoost] Train Acc: 0.7683 | Precision: 0.8788\n",
      "  [XGBoost] Val   Acc: 0.5733 | Precision: 0.5000\n",
      "\n",
      "   >> Running Fold 5/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8933 | Precision: 0.7953\n",
      "  [CatBoost] Val   Acc: 0.7267 | Precision: 0.5385\n",
      "  [RandomForest] Train Acc: 0.7967 | Precision: 0.6533\n",
      "  [RandomForest] Val   Acc: 0.6933 | Precision: 0.4915\n",
      "  [LightGBM] Train Acc: 0.9317 | Precision: 0.8505\n",
      "  [LightGBM] Val   Acc: 0.7200 | Precision: 0.5319\n",
      "  [XGBoost] Train Acc: 0.7867 | Precision: 0.8795\n",
      "  [XGBoost] Val   Acc: 0.7067 | Precision: 0.5333\n",
      "\n",
      "   >> Running Fold 6/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7933 | Precision: 0.6512\n",
      "  [CatBoost] Val   Acc: 0.6867 | Precision: 0.4853\n",
      "  [RandomForest] Train Acc: 0.7467 | Precision: 0.5954\n",
      "  [RandomForest] Val   Acc: 0.7067 | Precision: 0.5079\n",
      "  [LightGBM] Train Acc: 0.8150 | Precision: 0.6920\n",
      "  [LightGBM] Val   Acc: 0.7067 | Precision: 0.5072\n",
      "  [XGBoost] Train Acc: 0.7317 | Precision: 0.8727\n",
      "  [XGBoost] Val   Acc: 0.7133 | Precision: 0.5833\n",
      "\n",
      "   >> Running Fold 7/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8400 | Precision: 0.7113\n",
      "  [CatBoost] Val   Acc: 0.7133 | Precision: 0.3500\n",
      "  [RandomForest] Train Acc: 0.8200 | Precision: 0.6910\n",
      "  [RandomForest] Val   Acc: 0.6533 | Precision: 0.2941\n",
      "  [LightGBM] Train Acc: 0.7700 | Precision: 0.6204\n",
      "  [LightGBM] Val   Acc: 0.7067 | Precision: 0.3725\n",
      "  [XGBoost] Train Acc: 0.7650 | Precision: 0.8333\n",
      "  [XGBoost] Val   Acc: 0.8133 | Precision: 0.7143\n",
      "\n",
      "   >> Running Fold 8/8 (final_holdout)\n",
      "  [CatBoost] Train Acc: 0.8950 | Precision: 0.7951\n",
      "  [CatBoost] Val   Acc: 0.6333 | Precision: 0.4429\n",
      "  [RandomForest] Train Acc: 0.8167 | Precision: 0.7029\n",
      "  [RandomForest] Val   Acc: 0.6667 | Precision: 0.4776\n",
      "  [LightGBM] Train Acc: 0.8467 | Precision: 0.7578\n",
      "  [LightGBM] Val   Acc: 0.6867 | Precision: 0.5000\n",
      "  [XGBoost] Train Acc: 0.7733 | Precision: 0.8737\n",
      "  [XGBoost] Val   Acc: 0.6933 | Precision: 0.5238\n",
      "\n",
      " === Trial Finished. Final Score: 0.4547R ===\n",
      "\n",
      "[Skip] Found existing result for L=15, P=1.6, S=0.9. Score: 0.6439\n",
      "\n",
      "[Skip] Found existing result for L=15, P=1.6, S=0.9. Score: 0.6439\n",
      "\n",
      "================================================================================\n",
      " Starting NEW trial_23_213637_L14_P1.7_S0.9\n",
      "\n",
      " Pipeline Started... (Train Start: 2020-01-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_256137/1210223439.py:54: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_ta['EMA_12'] = ta.ema(close, length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏùºÎ¥â Í∏∞Í∞Ñ: 2019-06-15 ~ 2025-11-20\n",
      "1ÏãúÍ∞ÑÎ¥â Í∏∞Í∞Ñ (KST Î≥ÄÌôò ÌõÑ): 2020-01-01 09:00:00 ~ 2025-11-23 08:00:00\n",
      "[Í≤ΩÍ≥†] 1ÏãúÍ∞ÑÎ¥â ÏãúÏûëÏùº(2020-01-01 09:00:00)Ïù¥ ÏùºÎ¥â ÏãúÏûëÏùº(2019-06-15 00:00:00) Ïù¥ÌõÑÏûÖÎãàÎã§. Ï¥àÎ∞ò ÌÉÄÍ≤ü ÏÜêÏã§ Î∞úÏÉù.\n",
      "Ïú†Ìö® ÏÉòÌîå: 2324/2337 (Ï†úÍ±∞: 13)\n",
      "Win: 780 | Lose: 1544 | Win Rate: 33.56%\n",
      "(2324, 85)\n",
      "\n",
      "================================================================================\n",
      "Reverse Rolling Walk-Forward + Final Holdout\n",
      "================================================================================\n",
      "Total period: 2020-01-01 ~ 2025-11-06 (2137 days)\n",
      "Rolling train: 800d | Val: 150d | Test: 150d | Gap: 14d\n",
      "Final holdout test: 2025-01-01 ~ 2025-11-06\n",
      "================================================================================\n",
      "\n",
      "Fold 1 (walk_forward_rolling)\n",
      "  Train:  800d  2020-01-26 ~ 2022-04-04\n",
      "  Val:    150d  2022-04-19 ~ 2022-09-15\n",
      "  Test:   150d  2022-09-30 ~ 2023-02-26\n",
      "\n",
      "Fold 2 (walk_forward_rolling)\n",
      "  Train:  800d  2020-07-08 ~ 2022-09-15\n",
      "  Val:    150d  2022-09-30 ~ 2023-02-26\n",
      "  Test:   150d  2023-03-13 ~ 2023-08-09\n",
      "\n",
      "Fold 3 (walk_forward_rolling)\n",
      "  Train:  800d  2020-12-19 ~ 2023-02-26\n",
      "  Val:    150d  2023-03-13 ~ 2023-08-09\n",
      "  Test:   150d  2023-08-24 ~ 2024-01-20\n",
      "\n",
      "Fold 4 (walk_forward_rolling)\n",
      "  Train:  800d  2021-06-01 ~ 2023-08-09\n",
      "  Val:    150d  2023-08-24 ~ 2024-01-20\n",
      "  Test:   150d  2024-02-04 ~ 2024-07-02\n",
      "\n",
      "Fold 5 (walk_forward_rolling)\n",
      "  Train:  800d  2021-11-12 ~ 2024-01-20\n",
      "  Val:    150d  2024-02-04 ~ 2024-07-02\n",
      "  Test:   150d  2024-07-17 ~ 2024-12-13\n",
      "\n",
      "Fold 6 (walk_forward_rolling)\n",
      "  Train:  800d  2022-04-25 ~ 2024-07-02\n",
      "  Val:    150d  2024-07-17 ~ 2024-12-13\n",
      "  Test:   150d  2024-12-28 ~ 2025-05-26\n",
      "\n",
      "Fold 7 (walk_forward_rolling)\n",
      "  Train:  800d  2022-10-06 ~ 2024-12-13\n",
      "  Val:    150d  2024-12-28 ~ 2025-05-26\n",
      "  Test:   150d  2025-06-10 ~ 2025-11-06\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Fold 8 (final_holdout - 2025 Ï†ÑÏ≤¥ Î≥ÑÎèÑ ÌèâÍ∞Ä)\n",
      "================================================================================\n",
      "  Train:  800d  2022-05-13 ~ 2024-07-20\n",
      "  Val:    150d  2024-08-04 ~ 2024-12-31\n",
      "  Test:   310d  2025-01-01 ~ 2025-11-06\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Created 8 folds total\n",
      "  - 7 walk-forward folds\n",
      "  - 1 final holdout fold (2025 Ï†ÑÏ≤¥)\n",
      "================================================================================\n",
      "\n",
      " Data Split Completed. Total 8 folds generated.\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 1 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-01-26 ~ 2022-04-04 (N=800)\n",
      " Val   Period: 2022-04-19 ~ 2022-09-15 (N=150)\n",
      " Test  Period: 2022-09-30 ~ 2023-02-26 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.59, 1: 0.41}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, MACD_12_26_9, eth_return, ATR_14, usdt_totalUnreleased_ma30_ratio, btc_return, SMA_20, BB_WIDTH, MACDS_12_26_9, EMA_12, eth_log_return, usdt_totalMintedUSD_ma30_ratio, BREAKOUT_STR_5d, PRICE_VS_HIGH_5d, eth_btc_corr_30d, eth_btc_spread, uniswap_uniswap_eth_tvl_ma30_ratio, gold_GOLD_ma30_ratio, dxy_DXY_ma30_ratio, funding_fundingRate\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 2 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-07-08 ~ 2022-09-15 (N=800)\n",
      " Val   Period: 2022-09-30 ~ 2023-02-26 (N=150)\n",
      " Test  Period: 2023-03-13 ~ 2023-08-09 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6533333333333333, 1: 0.3466666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, MACDS_12_26_9, eth_return, btc_return, BREAKOUT_STR_5d, BB_WIDTH, MACD_12_26_9, chain_eth_chain_tvl_ma30_ratio, eth_log_return, usdt_totalUnreleased_ma30_ratio, PRICE_VS_HIGH_20d, PRICE_VS_HIGH_5d, PRICE_VS_LOW_60d, OBV, UPPER_SHADOW, eth_btc_spread, aave_aave_eth_tvl_ma30_ratio, uniswap_uniswap_eth_tvl_ma30_ratio, SMA_20\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 3 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-12-19 ~ 2023-02-26 (N=800)\n",
      " Val   Period: 2023-03-13 ~ 2023-08-09 (N=150)\n",
      " Test  Period: 2023-08-24 ~ 2024-01-20 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.69, 1: 0.31}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, eth_return, eth_btc_spread, BREAKOUT_STR_5d, PRICE_VS_LOW_60d, usdt_totalBridgedToUSD_ma30_ratio, SMA_20, eth_log_return, l2_arbitrum_tvl_ma30_ratio, l2_optimism_tvl_ma30_ratio, PRICE_VS_LOW_5d, PRICE_VS_HIGH_5d, ATR_14, VOLUME_RATIO, UPPER_SHADOW, LOWER_SHADOW, eth_btc_corr_7d, eth_btc_corr_30d, usdt_totalCirculating_ma30_ratio, usdt_totalMintedUSD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 4 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-06-01 ~ 2023-08-09 (N=800)\n",
      " Val   Period: 2023-08-24 ~ 2024-01-20 (N=150)\n",
      " Test  Period: 2024-02-04 ~ 2024-07-02 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7083333333333334, 1: 0.2916666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_20, usdt_totalCirculating_ma30_ratio, btc_return, usdt_totalBridgedToUSD_ma30_ratio, eth_return, usdt_totalMintedUSD_ma30_ratio, usdt_totalUnreleased_ma30_ratio, SMA_50, BB_WIDTH, EMA_12, eth_log_return, usdt_totalCirculatingUSD_ma30_ratio, OBV, UPPER_SHADOW, BREAKOUT_STR_5d, eth_btc_corr_30d, l2_optimism_tvl_ma30_ratio, gold_GOLD_ma30_ratio, MACDS_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 5 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-11-12 ~ 2024-01-20 (N=800)\n",
      " Val   Period: 2024-02-04 ~ 2024-07-02 (N=150)\n",
      " Test  Period: 2024-07-17 ~ 2024-12-13 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6616666666666666, 1: 0.3383333333333333}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_20, SMA_50, gold_GOLD_ma30_ratio, btc_return, usdt_totalUnreleased_ma30_ratio, eth_return, BREAKOUT_STR_5d, l2_zksync era_tvl_ma30_ratio, MACDS_12_26_9, EMA_12, ATR_14, eth_log_return, lido_lido_eth_tvl_ma30_ratio, usdt_totalCirculating_ma30_ratio, uniswap_uniswap_eth_tvl_ma30_ratio, dxy_DXY_ma30_ratio, BB_WIDTH, usdt_totalBridgedToUSD_ma30_ratio, eth_btc_corr_30d, MACD_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 6 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-04-25 ~ 2024-07-02 (N=800)\n",
      " Val   Period: 2024-07-17 ~ 2024-12-13 (N=150)\n",
      " Test  Period: 2024-12-28 ~ 2025-05-26 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.645, 1: 0.355}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_20, l2_zksync era_tvl_ma30_ratio, eth_return, btc_return, gold_GOLD_ma30_ratio, dxy_DXY_ma30_ratio, BB_WIDTH, EMA_12, eth_btc_corr_30d, OBV, ATR_14, eth_log_return, PRICE_VS_HIGH_5d, BREAKOUT_STR_5d, l2_arbitrum_tvl_ma30_ratio, BREAKOUT_STR_20d, usdt_totalUnreleased_ma30_ratio, curve_curve-dex_eth_tvl_ma30_ratio, SMA_50, MACD_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 7 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-10-06 ~ 2024-12-13 (N=800)\n",
      " Val   Period: 2024-12-28 ~ 2025-05-26 (N=150)\n",
      " Test  Period: 2025-06-10 ~ 2025-11-06 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.655, 1: 0.345}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, EMA_12, eth_btc_corr_30d, usdt_totalBridgedToUSD_ma30_ratio, l2_base_tvl_ma30_ratio, btc_return, makerdao_makerdao_eth_tvl_ma30_ratio, eth_return, SMA_20, BB_WIDTH, MFI_14, eth_log_return, PRICE_VS_LOW_20d, BREAKOUT_STR_20d, gold_GOLD_ma30_ratio, MACDS_12_26_9, usdt_totalCirculating_ma30_ratio, RSI_14, usdt_totalCirculatingUSD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 8 (final_holdout)\n",
      "================================================================================\n",
      " Train Period: 2022-05-13 ~ 2024-07-20 (N=800)\n",
      " Val   Period: 2024-08-04 ~ 2024-12-31 (N=150)\n",
      " Test  Period: 2025-01-01 ~ 2025-11-06 (N=310)\n",
      "[Class Balance] Train Set: {0: 0.64, 1: 0.36}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_20, btc_return, eth_return, gold_GOLD_ma30_ratio, SMA_50, BB_WIDTH, EMA_12, OBV, ATR_14, eth_log_return, l2_base_tvl_ma30_ratio, BREAKOUT_STR_5d, usdt_totalBridgedToUSD_ma30_ratio, BREAKOUT_STR_20d, usdt_totalUnreleased_ma30_ratio, l2_optimism_tvl_ma30_ratio, l2_zksync era_tvl_ma30_ratio, dxy_DXY_ma30_ratio, price_rank_250d, eth_btc_corr_30d\n",
      "\n",
      "   >> Running Fold 1/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7833 | Precision: 0.6895\n",
      "  [CatBoost] Val   Acc: 0.6133 | Precision: 0.3590\n",
      "  [RandomForest] Train Acc: 0.7367 | Precision: 0.6517\n",
      "  [RandomForest] Val   Acc: 0.6333 | Precision: 0.3623\n",
      "  [LightGBM] Train Acc: 0.7000 | Precision: 0.6071\n",
      "  [LightGBM] Val   Acc: 0.6600 | Precision: 0.3913\n",
      "  [XGBoost] Train Acc: 0.8283 | Precision: 0.8522\n",
      "  [XGBoost] Val   Acc: 0.6933 | Precision: 0.4194\n",
      "\n",
      "   >> Running Fold 2/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8817 | Precision: 0.7729\n",
      "  [CatBoost] Val   Acc: 0.6267 | Precision: 0.4321\n",
      "  [RandomForest] Train Acc: 0.7717 | Precision: 0.6437\n",
      "  [RandomForest] Val   Acc: 0.6000 | Precision: 0.4000\n",
      "  [LightGBM] Train Acc: 0.7083 | Precision: 0.5613\n",
      "  [LightGBM] Val   Acc: 0.6000 | Precision: 0.4074\n",
      "  [XGBoost] Train Acc: 0.7233 | Precision: 0.8889\n",
      "  [XGBoost] Val   Acc: 0.7200 | Precision: 0.7143\n",
      "\n",
      "   >> Running Fold 3/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8833 | Precision: 0.7613\n",
      "  [CatBoost] Val   Acc: 0.6933 | Precision: 0.5897\n",
      "  [RandomForest] Train Acc: 0.7667 | Precision: 0.6009\n",
      "  [RandomForest] Val   Acc: 0.6800 | Precision: 0.5610\n",
      "  [LightGBM] Train Acc: 0.8250 | Precision: 0.6753\n",
      "  [LightGBM] Val   Acc: 0.7400 | Precision: 0.7059\n",
      "  [XGBoost] Train Acc: 0.7983 | Precision: 1.0000\n",
      "  [XGBoost] Val   Acc: 0.6600 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 4/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8333 | Precision: 0.6638\n",
      "  [CatBoost] Val   Acc: 0.7267 | Precision: 0.7321\n",
      "  [RandomForest] Train Acc: 0.7883 | Precision: 0.6071\n",
      "  [RandomForest] Val   Acc: 0.6933 | Precision: 0.6909\n",
      "  [LightGBM] Train Acc: 0.7283 | Precision: 0.5233\n",
      "  [LightGBM] Val   Acc: 0.7067 | Precision: 0.7018\n",
      "  [XGBoost] Train Acc: 0.7650 | Precision: 0.8864\n",
      "  [XGBoost] Val   Acc: 0.5600 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 5/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8167 | Precision: 0.7031\n",
      "  [CatBoost] Val   Acc: 0.7467 | Precision: 0.6000\n",
      "  [RandomForest] Train Acc: 0.7783 | Precision: 0.6458\n",
      "  [RandomForest] Val   Acc: 0.7133 | Precision: 0.5283\n",
      "  [LightGBM] Train Acc: 0.8300 | Precision: 0.7131\n",
      "  [LightGBM] Val   Acc: 0.6733 | Precision: 0.4706\n",
      "  [XGBoost] Train Acc: 0.7833 | Precision: 0.9011\n",
      "  [XGBoost] Val   Acc: 0.7133 | Precision: 0.8000\n",
      "\n",
      "   >> Running Fold 6/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7450 | Precision: 0.6056\n",
      "  [CatBoost] Val   Acc: 0.7067 | Precision: 0.5231\n",
      "  [RandomForest] Train Acc: 0.7483 | Precision: 0.6192\n",
      "  [RandomForest] Val   Acc: 0.7267 | Precision: 0.5455\n",
      "  [LightGBM] Train Acc: 0.8233 | Precision: 0.7131\n",
      "  [LightGBM] Val   Acc: 0.7200 | Precision: 0.5397\n",
      "  [XGBoost] Train Acc: 0.7583 | Precision: 0.8696\n",
      "  [XGBoost] Val   Acc: 0.7400 | Precision: 0.6429\n",
      "\n",
      "   >> Running Fold 7/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8750 | Precision: 0.7797\n",
      "  [CatBoost] Val   Acc: 0.6800 | Precision: 0.4500\n",
      "  [RandomForest] Train Acc: 0.8183 | Precision: 0.7112\n",
      "  [RandomForest] Val   Acc: 0.6600 | Precision: 0.4118\n",
      "  [LightGBM] Train Acc: 0.7583 | Precision: 0.6240\n",
      "  [LightGBM] Val   Acc: 0.7200 | Precision: 0.5000\n",
      "  [XGBoost] Train Acc: 0.7783 | Precision: 0.9111\n",
      "  [XGBoost] Val   Acc: 0.7400 | Precision: 0.6667\n",
      "\n",
      "   >> Running Fold 8/8 (final_holdout)\n",
      "  [CatBoost] Train Acc: 0.8867 | Precision: 0.7846\n",
      "  [CatBoost] Val   Acc: 0.6933 | Precision: 0.5263\n",
      "  [RandomForest] Train Acc: 0.7633 | Precision: 0.6381\n",
      "  [RandomForest] Val   Acc: 0.6600 | Precision: 0.4923\n",
      "  [LightGBM] Train Acc: 0.8250 | Precision: 0.7284\n",
      "  [LightGBM] Val   Acc: 0.6867 | Precision: 0.5217\n",
      "  [XGBoost] Train Acc: 0.6833 | Precision: 1.0000\n",
      "  [XGBoost] Val   Acc: 0.6800 | Precision: 0.6667\n",
      "\n",
      " === Trial Finished. Final Score: 0.5152R ===\n",
      "\n",
      "[Skip] Found existing result for L=12, P=1.5, S=0.9. Score: 0.4908\n",
      "\n",
      "================================================================================\n",
      " Starting NEW trial_25_214446_L15_P1.6_S0.8\n",
      "\n",
      " Pipeline Started... (Train Start: 2020-01-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_256137/1210223439.py:54: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_ta['EMA_12'] = ta.ema(close, length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏùºÎ¥â Í∏∞Í∞Ñ: 2019-06-15 ~ 2025-11-20\n",
      "1ÏãúÍ∞ÑÎ¥â Í∏∞Í∞Ñ (KST Î≥ÄÌôò ÌõÑ): 2020-01-01 09:00:00 ~ 2025-11-23 08:00:00\n",
      "[Í≤ΩÍ≥†] 1ÏãúÍ∞ÑÎ¥â ÏãúÏûëÏùº(2020-01-01 09:00:00)Ïù¥ ÏùºÎ¥â ÏãúÏûëÏùº(2019-06-15 00:00:00) Ïù¥ÌõÑÏûÖÎãàÎã§. Ï¥àÎ∞ò ÌÉÄÍ≤ü ÏÜêÏã§ Î∞úÏÉù.\n",
      "Ïú†Ìö® ÏÉòÌîå: 2323/2336 (Ï†úÍ±∞: 13)\n",
      "Win: 766 | Lose: 1557 | Win Rate: 32.97%\n",
      "(2323, 85)\n",
      "\n",
      "================================================================================\n",
      "Reverse Rolling Walk-Forward + Final Holdout\n",
      "================================================================================\n",
      "Total period: 2020-01-01 ~ 2025-11-05 (2136 days)\n",
      "Rolling train: 800d | Val: 150d | Test: 150d | Gap: 15d\n",
      "Final holdout test: 2025-01-01 ~ 2025-11-05\n",
      "================================================================================\n",
      "\n",
      "Fold 1 (walk_forward_rolling)\n",
      "  Train:  800d  2020-01-17 ~ 2022-03-26\n",
      "  Val:    150d  2022-04-11 ~ 2022-09-07\n",
      "  Test:   150d  2022-09-23 ~ 2023-02-19\n",
      "\n",
      "Fold 2 (walk_forward_rolling)\n",
      "  Train:  800d  2020-06-30 ~ 2022-09-07\n",
      "  Val:    150d  2022-09-23 ~ 2023-02-19\n",
      "  Test:   150d  2023-03-07 ~ 2023-08-03\n",
      "\n",
      "Fold 3 (walk_forward_rolling)\n",
      "  Train:  800d  2020-12-12 ~ 2023-02-19\n",
      "  Val:    150d  2023-03-07 ~ 2023-08-03\n",
      "  Test:   150d  2023-08-19 ~ 2024-01-15\n",
      "\n",
      "Fold 4 (walk_forward_rolling)\n",
      "  Train:  800d  2021-05-26 ~ 2023-08-03\n",
      "  Val:    150d  2023-08-19 ~ 2024-01-15\n",
      "  Test:   150d  2024-01-31 ~ 2024-06-28\n",
      "\n",
      "Fold 5 (walk_forward_rolling)\n",
      "  Train:  800d  2021-11-07 ~ 2024-01-15\n",
      "  Val:    150d  2024-01-31 ~ 2024-06-28\n",
      "  Test:   150d  2024-07-14 ~ 2024-12-10\n",
      "\n",
      "Fold 6 (walk_forward_rolling)\n",
      "  Train:  800d  2022-04-21 ~ 2024-06-28\n",
      "  Val:    150d  2024-07-14 ~ 2024-12-10\n",
      "  Test:   150d  2024-12-26 ~ 2025-05-24\n",
      "\n",
      "Fold 7 (walk_forward_rolling)\n",
      "  Train:  800d  2022-10-03 ~ 2024-12-10\n",
      "  Val:    150d  2024-12-26 ~ 2025-05-24\n",
      "  Test:   150d  2025-06-09 ~ 2025-11-05\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Fold 8 (final_holdout - 2025 Ï†ÑÏ≤¥ Î≥ÑÎèÑ ÌèâÍ∞Ä)\n",
      "================================================================================\n",
      "  Train:  800d  2022-05-12 ~ 2024-07-19\n",
      "  Val:    150d  2024-08-04 ~ 2024-12-31\n",
      "  Test:   309d  2025-01-01 ~ 2025-11-05\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Created 8 folds total\n",
      "  - 7 walk-forward folds\n",
      "  - 1 final holdout fold (2025 Ï†ÑÏ≤¥)\n",
      "================================================================================\n",
      "\n",
      " Data Split Completed. Total 8 folds generated.\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 1 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-01-17 ~ 2022-03-26 (N=800)\n",
      " Val   Period: 2022-04-11 ~ 2022-09-07 (N=150)\n",
      " Test  Period: 2022-09-23 ~ 2023-02-19 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6066666666666667, 1: 0.3933333333333333}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, MACDS_12_26_9, eth_return, usdt_totalMintedUSD_ma30_ratio, BB_WIDTH, SMA_20, MACD_12_26_9, EMA_12, BREAKOUT_STR_5d, lido_lido_eth_tvl_ma30_ratio, ATR_14, eth_log_return, BREAKOUT_STR_20d, RSI_14, UPPER_SHADOW, PRICE_VS_HIGH_60d, usdt_totalUnreleased_ma30_ratio, gold_GOLD_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, usdt_totalCirculating_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 2 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-06-30 ~ 2022-09-07 (N=800)\n",
      " Val   Period: 2022-09-23 ~ 2023-02-19 (N=150)\n",
      " Test  Period: 2023-03-07 ~ 2023-08-03 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6516666666666666, 1: 0.34833333333333333}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, BB_WIDTH, eth_return, MACDS_12_26_9, btc_return, BREAKOUT_STR_5d, MACD_12_26_9, eth_log_return, usdt_totalCirculatingUSD_ma30_ratio, PRICE_VS_LOW_20d, PRICE_VS_LOW_5d, PRICE_VS_LOW_60d, EMA_12, BREAKOUT_STR_20d, ATR_14, OBV, usdt_totalUnreleased_ma30_ratio, dxy_DXY_ma30_ratio, SMA_20, chain_eth_chain_tvl_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 3 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-12-12 ~ 2023-02-19 (N=800)\n",
      " Val   Period: 2023-03-07 ~ 2023-08-03 (N=150)\n",
      " Test  Period: 2023-08-19 ~ 2024-01-15 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6966666666666667, 1: 0.30333333333333334}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, eth_return, BREAKOUT_STR_5d, usdt_totalBridgedToUSD_ma30_ratio, SMA_20, eth_log_return, l2_arbitrum_tvl_ma30_ratio, eth_btc_spread, l2_optimism_tvl_ma30_ratio, ATR_14, PRICE_VS_HIGH_5d, PRICE_VS_LOW_5d, UPPER_SHADOW, PRICE_VS_LOW_60d, eth_btc_corr_7d, eth_btc_corr_30d, curve_curve-dex_eth_tvl_ma30_ratio, BB_WIDTH, MFI_14, MACD_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 4 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-05-26 ~ 2023-08-03 (N=800)\n",
      " Val   Period: 2023-08-19 ~ 2024-01-15 (N=150)\n",
      " Test  Period: 2024-01-31 ~ 2024-06-28 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7166666666666667, 1: 0.2833333333333333}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_20, eth_return, usdt_totalUnreleased_ma30_ratio, usdt_totalCirculating_ma30_ratio, SMA_50, BB_WIDTH, eth_log_return, EMA_12, btc_return, PRICE_VS_HIGH_5d, MACDH_12_26_9, OBV, BREAKOUT_STR_5d, eth_btc_corr_30d, curve_curve-dex_eth_tvl_ma30_ratio, l2_optimism_tvl_ma30_ratio, MACDS_12_26_9, usdt_totalBridgedToUSD_ma30_ratio, MACD_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 5 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-11-07 ~ 2024-01-15 (N=800)\n",
      " Val   Period: 2024-01-31 ~ 2024-06-28 (N=150)\n",
      " Test  Period: 2024-07-14 ~ 2024-12-10 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6716666666666666, 1: 0.3283333333333333}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, eth_return, BREAKOUT_STR_5d, gold_GOLD_ma30_ratio, dxy_DXY_ma30_ratio, btc_return, SMA_20, eth_log_return, SMA_50, MACDS_12_26_9, eth_btc_corr_30d, lido_lido_eth_tvl_ma30_ratio, usdt_totalMintedUSD_ma30_ratio, BREAKOUT_STR_60d, return_lag5, return_lag10, VOLUME_RATIO, UPPER_SHADOW, LOWER_SHADOW, BREAKOUT_STR_20d\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 6 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-04-21 ~ 2024-06-28 (N=800)\n",
      " Val   Period: 2024-07-14 ~ 2024-12-10 (N=150)\n",
      " Test  Period: 2024-12-26 ~ 2025-05-24 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6516666666666666, 1: 0.34833333333333333}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_20, eth_return, btc_return, l2_zksync era_tvl_ma30_ratio, gold_GOLD_ma30_ratio, dxy_DXY_ma30_ratio, SMA_50, BB_WIDTH, EMA_12, eth_log_return, eth_btc_corr_30d, BREAKOUT_STR_5d, PRICE_VS_HIGH_20d, l2_base_tvl_ma30_ratio, ATR_14, UPPER_SHADOW, PRICE_VS_HIGH_5d, BREAKOUT_STR_20d, usdt_totalUnreleased_ma30_ratio, uniswap_uniswap_eth_tvl_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 7 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-10-03 ~ 2024-12-10 (N=800)\n",
      " Val   Period: 2024-12-26 ~ 2025-05-24 (N=150)\n",
      " Test  Period: 2025-06-09 ~ 2025-11-05 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.66, 1: 0.34}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, EMA_12, MACDS_12_26_9, l2_base_tvl_ma30_ratio, eth_return, btc_return, MFI_14, SMA_50, SMA_20, BB_WIDTH, eth_btc_corr_30d, eth_log_return, usdt_totalCirculating_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, eth_btc_corr_7d, vix_VIX_ma30_ratio, PRICE_VS_LOW_20d, BREAKOUT_STR_20d, usdt_totalUnreleased_ma30_ratio, usdt_totalCirculatingUSD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 8 (final_holdout)\n",
      "================================================================================\n",
      " Train Period: 2022-05-12 ~ 2024-07-19 (N=800)\n",
      " Val   Period: 2024-08-04 ~ 2024-12-31 (N=150)\n",
      " Test  Period: 2025-01-01 ~ 2025-11-05 (N=309)\n",
      "[Class Balance] Train Set: {0: 0.645, 1: 0.355}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, EMA_12, eth_return, eth_btc_corr_30d, btc_return, PRICE_VS_HIGH_20d, BREAKOUT_STR_20d, gold_GOLD_ma30_ratio, SMA_50, SMA_20, BB_WIDTH, eth_log_return, OBV, BREAKOUT_STR_5d, dxy_DXY_ma30_ratio, UPPER_SHADOW, PRICE_VS_HIGH_5d, usdt_totalUnreleased_ma30_ratio, price_rank_250d, RSI_14\n",
      "\n",
      "   >> Running Fold 1/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9000 | Precision: 0.8165\n",
      "  [CatBoost] Val   Acc: 0.6400 | Precision: 0.4000\n",
      "  [RandomForest] Train Acc: 0.7433 | Precision: 0.6589\n",
      "  [RandomForest] Val   Acc: 0.7333 | Precision: 0.4717\n",
      "  [LightGBM] Train Acc: 0.7150 | Precision: 0.6173\n",
      "  [LightGBM] Val   Acc: 0.7533 | Precision: 0.5000\n",
      "  [XGBoost] Train Acc: 0.6933 | Precision: 0.7281\n",
      "  [XGBoost] Val   Acc: 0.7733 | Precision: 0.5882\n",
      "\n",
      "   >> Running Fold 2/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7850 | Precision: 0.6575\n",
      "  [CatBoost] Val   Acc: 0.6333 | Precision: 0.4203\n",
      "  [RandomForest] Train Acc: 0.7500 | Precision: 0.6148\n",
      "  [RandomForest] Val   Acc: 0.5867 | Precision: 0.3929\n",
      "  [LightGBM] Train Acc: 0.7283 | Precision: 0.5852\n",
      "  [LightGBM] Val   Acc: 0.6000 | Precision: 0.4091\n",
      "  [XGBoost] Train Acc: 0.7333 | Precision: 0.8889\n",
      "  [XGBoost] Val   Acc: 0.7533 | Precision: 0.7059\n",
      "\n",
      "   >> Running Fold 3/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8600 | Precision: 0.7269\n",
      "  [CatBoost] Val   Acc: 0.7400 | Precision: 0.6944\n",
      "  [RandomForest] Train Acc: 0.7950 | Precision: 0.6335\n",
      "  [RandomForest] Val   Acc: 0.7400 | Precision: 0.6522\n",
      "  [LightGBM] Train Acc: 0.8083 | Precision: 0.6450\n",
      "  [LightGBM] Val   Acc: 0.7667 | Precision: 0.6800\n",
      "  [XGBoost] Train Acc: 0.7783 | Precision: 0.7579\n",
      "  [XGBoost] Val   Acc: 0.7067 | Precision: 0.8000\n",
      "\n",
      "   >> Running Fold 4/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8667 | Precision: 0.6991\n",
      "  [CatBoost] Val   Acc: 0.7000 | Precision: 0.7209\n",
      "  [RandomForest] Train Acc: 0.8000 | Precision: 0.6126\n",
      "  [RandomForest] Val   Acc: 0.7000 | Precision: 0.6667\n",
      "  [LightGBM] Train Acc: 0.7833 | Precision: 0.5847\n",
      "  [LightGBM] Val   Acc: 0.7000 | Precision: 0.6863\n",
      "  [XGBoost] Train Acc: 0.7300 | Precision: 1.0000\n",
      "  [XGBoost] Val   Acc: 0.5800 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 5/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9133 | Precision: 0.8281\n",
      "  [CatBoost] Val   Acc: 0.7267 | Precision: 0.6000\n",
      "  [RandomForest] Train Acc: 0.8183 | Precision: 0.6930\n",
      "  [RandomForest] Val   Acc: 0.7067 | Precision: 0.5636\n",
      "  [LightGBM] Train Acc: 0.8167 | Precision: 0.6851\n",
      "  [LightGBM] Val   Acc: 0.6933 | Precision: 0.5410\n",
      "  [XGBoost] Train Acc: 0.8567 | Precision: 0.9111\n",
      "  [XGBoost] Val   Acc: 0.7333 | Precision: 0.8667\n",
      "\n",
      "   >> Running Fold 6/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9167 | Precision: 0.8442\n",
      "  [CatBoost] Val   Acc: 0.6733 | Precision: 0.4706\n",
      "  [RandomForest] Train Acc: 0.8167 | Precision: 0.7106\n",
      "  [RandomForest] Val   Acc: 0.6733 | Precision: 0.4655\n",
      "  [LightGBM] Train Acc: 0.8733 | Precision: 0.7830\n",
      "  [LightGBM] Val   Acc: 0.6667 | Precision: 0.4576\n",
      "  [XGBoost] Train Acc: 0.7583 | Precision: 0.8902\n",
      "  [XGBoost] Val   Acc: 0.7133 | Precision: 0.5625\n",
      "\n",
      "   >> Running Fold 7/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9317 | Precision: 0.8498\n",
      "  [CatBoost] Val   Acc: 0.6867 | Precision: 0.4222\n",
      "  [RandomForest] Train Acc: 0.8567 | Precision: 0.7634\n",
      "  [RandomForest] Val   Acc: 0.6800 | Precision: 0.4130\n",
      "  [LightGBM] Train Acc: 0.7950 | Precision: 0.6667\n",
      "  [LightGBM] Val   Acc: 0.7267 | Precision: 0.4906\n",
      "  [XGBoost] Train Acc: 0.7867 | Precision: 0.9872\n",
      "  [XGBoost] Val   Acc: 0.7400 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 8/8 (final_holdout)\n",
      "  [CatBoost] Train Acc: 0.8717 | Precision: 0.7742\n",
      "  [CatBoost] Val   Acc: 0.6800 | Precision: 0.5072\n",
      "  [RandomForest] Train Acc: 0.7800 | Precision: 0.6667\n",
      "  [RandomForest] Val   Acc: 0.6400 | Precision: 0.4627\n",
      "  [LightGBM] Train Acc: 0.7050 | Precision: 0.5687\n",
      "  [LightGBM] Val   Acc: 0.6533 | Precision: 0.4789\n",
      "  [XGBoost] Train Acc: 0.7767 | Precision: 0.8911\n",
      "  [XGBoost] Val   Acc: 0.6667 | Precision: 0.4857\n",
      "\n",
      " === Trial Finished. Final Score: 0.6572R ===\n",
      "\n",
      "[Skip] Found existing result for L=13, P=1.6, S=0.8. Score: 0.5631\n",
      "\n",
      "================================================================================\n",
      " Starting NEW trial_27_215310_L11_P1.7_S0.8\n",
      "\n",
      " Pipeline Started... (Train Start: 2020-01-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_256137/1210223439.py:54: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_ta['EMA_12'] = ta.ema(close, length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏùºÎ¥â Í∏∞Í∞Ñ: 2019-06-15 ~ 2025-11-20\n",
      "1ÏãúÍ∞ÑÎ¥â Í∏∞Í∞Ñ (KST Î≥ÄÌôò ÌõÑ): 2020-01-01 09:00:00 ~ 2025-11-23 08:00:00\n",
      "[Í≤ΩÍ≥†] 1ÏãúÍ∞ÑÎ¥â ÏãúÏûëÏùº(2020-01-01 09:00:00)Ïù¥ ÏùºÎ¥â ÏãúÏûëÏùº(2019-06-15 00:00:00) Ïù¥ÌõÑÏûÖÎãàÎã§. Ï¥àÎ∞ò ÌÉÄÍ≤ü ÏÜêÏã§ Î∞úÏÉù.\n",
      "Ïú†Ìö® ÏÉòÌîå: 2327/2340 (Ï†úÍ±∞: 13)\n",
      "Win: 693 | Lose: 1634 | Win Rate: 29.78%\n",
      "(2327, 85)\n",
      "\n",
      "================================================================================\n",
      "Reverse Rolling Walk-Forward + Final Holdout\n",
      "================================================================================\n",
      "Total period: 2020-01-01 ~ 2025-11-09 (2140 days)\n",
      "Rolling train: 800d | Val: 150d | Test: 150d | Gap: 11d\n",
      "Final holdout test: 2025-01-01 ~ 2025-11-09\n",
      "================================================================================\n",
      "\n",
      "Fold 1 (walk_forward_rolling)\n",
      "  Train:  800d  2020-02-22 ~ 2022-05-01\n",
      "  Val:    150d  2022-05-13 ~ 2022-10-09\n",
      "  Test:   150d  2022-10-21 ~ 2023-03-19\n",
      "\n",
      "Fold 2 (walk_forward_rolling)\n",
      "  Train:  800d  2020-08-01 ~ 2022-10-09\n",
      "  Val:    150d  2022-10-21 ~ 2023-03-19\n",
      "  Test:   150d  2023-03-31 ~ 2023-08-27\n",
      "\n",
      "Fold 3 (walk_forward_rolling)\n",
      "  Train:  800d  2021-01-09 ~ 2023-03-19\n",
      "  Val:    150d  2023-03-31 ~ 2023-08-27\n",
      "  Test:   150d  2023-09-08 ~ 2024-02-04\n",
      "\n",
      "Fold 4 (walk_forward_rolling)\n",
      "  Train:  800d  2021-06-19 ~ 2023-08-27\n",
      "  Val:    150d  2023-09-08 ~ 2024-02-04\n",
      "  Test:   150d  2024-02-16 ~ 2024-07-14\n",
      "\n",
      "Fold 5 (walk_forward_rolling)\n",
      "  Train:  800d  2021-11-27 ~ 2024-02-04\n",
      "  Val:    150d  2024-02-16 ~ 2024-07-14\n",
      "  Test:   150d  2024-07-26 ~ 2024-12-22\n",
      "\n",
      "Fold 6 (walk_forward_rolling)\n",
      "  Train:  800d  2022-05-07 ~ 2024-07-14\n",
      "  Val:    150d  2024-07-26 ~ 2024-12-22\n",
      "  Test:   150d  2025-01-03 ~ 2025-06-01\n",
      "\n",
      "Fold 7 (walk_forward_rolling)\n",
      "  Train:  800d  2022-10-15 ~ 2024-12-22\n",
      "  Val:    150d  2025-01-03 ~ 2025-06-01\n",
      "  Test:   150d  2025-06-13 ~ 2025-11-09\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Fold 8 (final_holdout - 2025 Ï†ÑÏ≤¥ Î≥ÑÎèÑ ÌèâÍ∞Ä)\n",
      "================================================================================\n",
      "  Train:  800d  2022-05-16 ~ 2024-07-23\n",
      "  Val:    150d  2024-08-04 ~ 2024-12-31\n",
      "  Test:   313d  2025-01-01 ~ 2025-11-09\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Created 8 folds total\n",
      "  - 7 walk-forward folds\n",
      "  - 1 final holdout fold (2025 Ï†ÑÏ≤¥)\n",
      "================================================================================\n",
      "\n",
      " Data Split Completed. Total 8 folds generated.\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 1 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-02-22 ~ 2022-05-01 (N=800)\n",
      " Val   Period: 2022-05-13 ~ 2022-10-09 (N=150)\n",
      " Test  Period: 2022-10-21 ~ 2023-03-19 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6383333333333333, 1: 0.3616666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, SMA_20, MACD_12_26_9, BREAKOUT_STR_5d, usdt_totalMintedUSD_ma30_ratio, btc_return, eth_return, BB_WIDTH, EMA_12, MACDS_12_26_9, eth_log_return, BREAKOUT_STR_20d, PRICE_VS_HIGH_5d, usdt_totalUnreleased_ma30_ratio, l2_arbitrum_tvl_ma30_ratio, OBV, usdt_totalBridgedToUSD_ma30_ratio, usdt_totalCirculatingUSD_ma30_ratio, usdt_totalCirculating_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 2 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-08-01 ~ 2022-10-09 (N=800)\n",
      " Val   Period: 2022-10-21 ~ 2023-03-19 (N=150)\n",
      " Test  Period: 2023-03-31 ~ 2023-08-27 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7016666666666667, 1: 0.29833333333333334}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, eth_return, chain_eth_chain_tvl_ma30_ratio, PRICE_VS_LOW_20d, eth_log_return, MACD_12_26_9, SMA_20, MACDS_12_26_9, btc_return, BREAKOUT_STR_5d, PRICE_VS_HIGH_20d, PRICE_VS_HIGH_5d, PRICE_VS_LOW_5d, OBV, PRICE_VS_HIGH_60d, PRICE_VS_LOW_60d, usdt_totalMintedUSD_ma30_ratio, usdt_totalUnreleased_ma30_ratio, BB_WIDTH\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 3 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-01-09 ~ 2023-03-19 (N=800)\n",
      " Val   Period: 2023-03-31 ~ 2023-08-27 (N=150)\n",
      " Test  Period: 2023-09-08 ~ 2024-02-04 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7133333333333334, 1: 0.2866666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, eth_return, MACDS_12_26_9, BREAKOUT_STR_5d, BREAKOUT_STR_20d, usdt_totalBridgedToUSD_ma30_ratio, eth_log_return, l2_arbitrum_tvl_ma30_ratio, SMA_20, PRICE_VS_LOW_5d, btc_return, eth_btc_spread, PRICE_VS_HIGH_5d, UPPER_SHADOW, PRICE_VS_LOW_60d, usdt_totalCirculating_ma30_ratio, usdt_totalMintedUSD_ma30_ratio, curve_curve-dex_eth_tvl_ma30_ratio, l2_optimism_tvl_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 4 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-06-19 ~ 2023-08-27 (N=800)\n",
      " Val   Period: 2023-09-08 ~ 2024-02-04 (N=150)\n",
      " Test  Period: 2024-02-16 ~ 2024-07-14 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.7316666666666667, 1: 0.2683333333333333}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, SMA_50, SMA_20, usdt_totalCirculating_ma30_ratio, btc_return, eth_return, usdt_totalCirculatingUSD_ma30_ratio, EMA_12, eth_log_return, vix_VIX_pct_1d, usdt_totalBridgedToUSD_ma30_ratio, usdt_totalMintedUSD_ma30_ratio, UPPER_SHADOW, LOWER_SHADOW, BREAKOUT_STR_5d, eth_btc_corr_7d, usdt_totalUnreleased_ma30_ratio, curve_curve-dex_eth_tvl_ma30_ratio, l2_optimism_tvl_ma30_ratio, MACDS_12_26_9\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 5 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-11-27 ~ 2024-02-04 (N=800)\n",
      " Val   Period: 2024-02-16 ~ 2024-07-14 (N=150)\n",
      " Test  Period: 2024-07-26 ~ 2024-12-22 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6883333333333334, 1: 0.31166666666666665}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, gold_GOLD_ma30_ratio, dxy_DXY_ma30_ratio, eth_return, usdt_totalUnreleased_ma30_ratio, BREAKOUT_STR_5d, SMA_50, SMA_20, BB_WIDTH, btc_return, lido_lido_eth_tvl_ma30_ratio, PRICE_VS_HIGH_5d, eth_log_return, l2_arbitrum_tvl_ma30_ratio, return_lag10, RSI_14, UPPER_SHADOW, LOWER_SHADOW, eth_btc_corr_30d, aave_aave_eth_tvl_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 6 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-05-07 ~ 2024-07-14 (N=800)\n",
      " Val   Period: 2024-07-26 ~ 2024-12-22 (N=150)\n",
      " Test  Period: 2025-01-03 ~ 2025-06-01 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.675, 1: 0.325}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, btc_return, eth_return, eth_btc_corr_30d, gold_GOLD_ma30_ratio, dxy_DXY_ma30_ratio, SMA_50, EMA_12, BB_WIDTH, OBV, eth_log_return, BREAKOUT_STR_5d, PRICE_VS_HIGH_20d, l2_arbitrum_tvl_ma30_ratio, UPPER_SHADOW, LOWER_SHADOW, PRICE_VS_HIGH_5d, BREAKOUT_STR_20d, usdt_totalUnreleased_ma30_ratio, l2_base_tvl_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 7 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-10-15 ~ 2024-12-22 (N=800)\n",
      " Val   Period: 2025-01-03 ~ 2025-06-01 (N=150)\n",
      " Test  Period: 2025-06-13 ~ 2025-11-09 (N=150)\n",
      "[Class Balance] Train Set: {0: 0.6983333333333334, 1: 0.3016666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, EMA_12, btc_return, eth_return, eth_btc_corr_30d, makerdao_makerdao_eth_tvl_ma30_ratio, SMA_50, BB_WIDTH, SMA_20, MACDS_12_26_9, usdt_totalBridgedToUSD_ma30_ratio, usdt_totalCirculating_ma30_ratio, eth_log_return, l2_base_tvl_ma30_ratio, vix_VIX_ma30_ratio, PRICE_VS_HIGH_60d, usdt_totalUnreleased_ma30_ratio, l2_zksync era_tvl_ma30_ratio, sp500_SP500_ma30_ratio, gold_GOLD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 8 (final_holdout)\n",
      "================================================================================\n",
      " Train Period: 2022-05-16 ~ 2024-07-23 (N=800)\n",
      " Val   Period: 2024-08-04 ~ 2024-12-31 (N=150)\n",
      " Test  Period: 2025-01-01 ~ 2025-11-09 (N=313)\n",
      "[Class Balance] Train Set: {0: 0.68, 1: 0.32}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_20, btc_return, eth_return, gold_GOLD_ma30_ratio, BREAKOUT_STR_5d, dxy_DXY_ma30_ratio, l2_zksync era_tvl_ma30_ratio, EMA_12, BB_WIDTH, OBV, eth_log_return, eth_btc_corr_30d, l2_base_tvl_ma30_ratio, PRICE_VS_HIGH_20d, ATR_14, BREAKOUT_STR_20d, usdt_totalUnreleased_ma30_ratio, sp500_SP500_ma30_ratio, SMA_50, RSI_14\n",
      "\n",
      "   >> Running Fold 1/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7717 | Precision: 0.6471\n",
      "  [CatBoost] Val   Acc: 0.6533 | Precision: 0.3500\n",
      "  [RandomForest] Train Acc: 0.7283 | Precision: 0.6023\n",
      "  [RandomForest] Val   Acc: 0.6467 | Precision: 0.3443\n",
      "  [LightGBM] Train Acc: 0.7167 | Precision: 0.5808\n",
      "  [LightGBM] Val   Acc: 0.6467 | Precision: 0.3582\n",
      "  [XGBoost] Train Acc: 0.6383 | Precision: 0.0000\n",
      "  [XGBoost] Val   Acc: 0.7867 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 2/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7217 | Precision: 0.5238\n",
      "  [CatBoost] Val   Acc: 0.6533 | Precision: 0.4483\n",
      "  [RandomForest] Train Acc: 0.7517 | Precision: 0.5615\n",
      "  [RandomForest] Val   Acc: 0.6267 | Precision: 0.4194\n",
      "  [LightGBM] Train Acc: 0.7200 | Precision: 0.5223\n",
      "  [LightGBM] Val   Acc: 0.6867 | Precision: 0.4889\n",
      "  [XGBoost] Train Acc: 0.7350 | Precision: 0.8333\n",
      "  [XGBoost] Val   Acc: 0.7000 | Precision: 0.5455\n",
      "\n",
      "   >> Running Fold 3/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.9167 | Precision: 0.7933\n",
      "  [CatBoost] Val   Acc: 0.7533 | Precision: 0.5000\n",
      "  [RandomForest] Train Acc: 0.8183 | Precision: 0.6567\n",
      "  [RandomForest] Val   Acc: 0.7400 | Precision: 0.4750\n",
      "  [LightGBM] Train Acc: 0.7950 | Precision: 0.6129\n",
      "  [LightGBM] Val   Acc: 0.7667 | Precision: 0.5312\n",
      "  [XGBoost] Train Acc: 0.7583 | Precision: 0.9655\n",
      "  [XGBoost] Val   Acc: 0.7600 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 4/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7617 | Precision: 0.5433\n",
      "  [CatBoost] Val   Acc: 0.6867 | Precision: 0.6230\n",
      "  [RandomForest] Train Acc: 0.6983 | Precision: 0.4587\n",
      "  [RandomForest] Val   Acc: 0.6600 | Precision: 0.6000\n",
      "  [LightGBM] Train Acc: 0.8233 | Precision: 0.6151\n",
      "  [LightGBM] Val   Acc: 0.6667 | Precision: 0.6500\n",
      "  [XGBoost] Train Acc: 0.7583 | Precision: 0.9444\n",
      "  [XGBoost] Val   Acc: 0.6200 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 5/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7900 | Precision: 0.6287\n",
      "  [CatBoost] Val   Acc: 0.7267 | Precision: 0.5000\n",
      "  [RandomForest] Train Acc: 0.7567 | Precision: 0.5858\n",
      "  [RandomForest] Val   Acc: 0.6867 | Precision: 0.4559\n",
      "  [LightGBM] Train Acc: 0.7733 | Precision: 0.6032\n",
      "  [LightGBM] Val   Acc: 0.6800 | Precision: 0.4507\n",
      "  [XGBoost] Train Acc: 0.7283 | Precision: 0.8333\n",
      "  [XGBoost] Val   Acc: 0.7467 | Precision: 0.8000\n",
      "\n",
      "   >> Running Fold 6/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.7617 | Precision: 0.6008\n",
      "  [CatBoost] Val   Acc: 0.6533 | Precision: 0.4030\n",
      "  [RandomForest] Train Acc: 0.8267 | Precision: 0.7116\n",
      "  [RandomForest] Val   Acc: 0.6200 | Precision: 0.3448\n",
      "  [LightGBM] Train Acc: 0.8317 | Precision: 0.7260\n",
      "  [LightGBM] Val   Acc: 0.6667 | Precision: 0.4225\n",
      "  [XGBoost] Train Acc: 0.7983 | Precision: 1.0000\n",
      "  [XGBoost] Val   Acc: 0.7267 | Precision: 0.4444\n",
      "\n",
      "   >> Running Fold 7/8 (walk_forward_rolling_reverse)\n",
      "  [CatBoost] Train Acc: 0.8550 | Precision: 0.7061\n",
      "  [CatBoost] Val   Acc: 0.7400 | Precision: 0.3243\n",
      "  [RandomForest] Train Acc: 0.7617 | Precision: 0.5766\n",
      "  [RandomForest] Val   Acc: 0.6933 | Precision: 0.3214\n",
      "  [LightGBM] Train Acc: 0.9517 | Precision: 0.8689\n",
      "  [LightGBM] Val   Acc: 0.8200 | Precision: 0.4762\n",
      "  [XGBoost] Train Acc: 0.7550 | Precision: 0.8542\n",
      "  [XGBoost] Val   Acc: 0.8333 | Precision: 1.0000\n",
      "\n",
      "   >> Running Fold 8/8 (final_holdout)\n",
      "  [CatBoost] Train Acc: 0.8417 | Precision: 0.6948\n",
      "  [CatBoost] Val   Acc: 0.6600 | Precision: 0.4384\n",
      "  [RandomForest] Train Acc: 0.7833 | Precision: 0.6281\n",
      "  [RandomForest] Val   Acc: 0.6133 | Precision: 0.3667\n",
      "  [LightGBM] Train Acc: 0.8333 | Precision: 0.6983\n",
      "  [LightGBM] Val   Acc: 0.6533 | Precision: 0.4286\n",
      "  [XGBoost] Train Acc: 0.6867 | Precision: 1.0000\n",
      "  [XGBoost] Val   Acc: 0.7267 | Precision: 1.0000\n",
      "\n",
      " === Trial Finished. Final Score: 0.4583R ===\n",
      "\n",
      "[Skip] Found existing result for L=14, P=1.9, S=0.8. Score: 0.5580\n",
      "\n",
      "[Skip] Found existing result for L=13, P=1.8, S=0.8. Score: 0.4286\n",
      "\n",
      "[Optuna] Optimization Completed!\n",
      "Best Params: {'lookahead': 15, 'profit_mult': 1.6, 'stop_mult': 1.0}\n",
      "\n",
      "==================================================\n",
      " Best Trial Value (Avg Buy Precision): 0.7212\n",
      " Best Parameters: {'lookahead': 15, 'profit_mult': 1.6, 'stop_mult': 1.0}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if tf.config.list_physical_devices('GPU'):\n",
    "        try:\n",
    "            for gpu in tf.config.list_physical_devices('GPU'):\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(\" GPU Detected & Memory Growth Set!\")\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "    df_merged=pd.read_csv(\"merge_data.csv\")\n",
    "    df_hour=pd.read_csv(\"eth_hour.csv\")\n",
    "    if 'df_merged' in locals() and not df_merged.empty:\n",
    "        df_merged['date'] = pd.to_datetime(df_merged['date'])\n",
    "        df_merged = df_merged.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "        print(f\"Loaded Data: {len(df_merged)} rows ({df_merged['date'].min().date()} ~ {df_merged['date'].max().date()})\")\n",
    "\n",
    "        study = run_optuna_optimization(df_merged,df_hour, n_trials=30)\n",
    "        \n",
    "        print(\"\\n==================================================\")\n",
    "        print(f\" Best Trial Value (Avg Buy Precision): {study.best_value:.4f}\")\n",
    "        print(f\" Best Parameters: {study.best_params}\")\n",
    "        print(\"==================================================\")\n",
    "    else:\n",
    "        print(\"[Error] 'df_merged' variable is not defined or empty. Please load data first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "549d025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ÏàòÎèôÏúºÎ°ú ÌÉÄÍ≤ü ÏÉùÏÑ± ÌÖåÏä§Ìä∏\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# df_test = df_merged.copy()\n",
    "# df_test['date'] = pd.to_datetime(df_test['date'])\n",
    "# df_merged=pd.read_csv(\"merge_data.csv\")\n",
    "# eth_hourly=pd.read_csv(\"eth_hour.csv\")\n",
    "# eth_hourly['datetime'] = pd.to_datetime(eth_hourly['datetime'])\n",
    "# eth_hourly['datetime'] = eth_hourly['datetime'] + pd.Timedelta(hours=9)  # UTC‚ÜíKST\n",
    "\n",
    "# # ÌäπÏ†ï ÎÇ†Ïßú ÌïòÎÇòÎßå ÌÖåÏä§Ìä∏\n",
    "# test_date = pd.to_datetime('2024-01-15')\n",
    "# test_row = df_test[df_test['date'] == test_date].iloc[0]\n",
    "\n",
    "# atr = test_row['ATR_14'] if 'ATR_14' in df_test.columns else 100  # ÏûÑÏãúÍ∞í\n",
    "# print(f\"Test Date: {test_date}\")\n",
    "# print(f\"ATR: {atr}\")\n",
    "\n",
    "# # Îã§ÏùåÎÇ† 1ÏãúÍ∞ÑÎ¥â Ï∞æÍ∏∞\n",
    "# entry_start = test_date + pd.Timedelta(days=1)\n",
    "# entry_end = entry_start + pd.Timedelta(days=5)\n",
    "\n",
    "# mask = (eth_hourly['datetime'] >= entry_start) & (eth_hourly['datetime'] < entry_end)\n",
    "# period = eth_hourly[mask].sort_values('datetime')\n",
    "\n",
    "# print(f\"\\nÎã§ÏùåÎÇ† ÏãúÏûë: {entry_start}\")\n",
    "# print(f\"1ÏãúÍ∞ÑÎ¥â Ï≤´ Ï∫îÎì§: {period['datetime'].iloc[0] if len(period) > 0 else 'None'}\")\n",
    "# print(f\"1ÏãúÍ∞ÑÎ¥â Í∞úÏàò: {len(period)}\")\n",
    "\n",
    "# if len(period) > 0:\n",
    "#     entry_price = period.iloc[0]['open']\n",
    "#     tp = entry_price + (atr * 1.0)  # profit_mult=1.0\n",
    "#     sl = entry_price - (atr * 1.0)  # stop_mult=1.0\n",
    "    \n",
    "#     print(f\"\\nEntry: {entry_price}\")\n",
    "#     print(f\"TP: {tp}\")\n",
    "#     print(f\"SL: {sl}\")\n",
    "#     print(f\"Period High Max: {period['high'].max()}\")\n",
    "#     print(f\"Period Low Min: {period['low'].min()}\")\n",
    "    \n",
    "#     if period['high'].max() >= tp:\n",
    "#         print(\"‚Üí TP ÎèÑÎã¨ Í∞ÄÎä•!\")\n",
    "#     if period['low'].min() <= sl:\n",
    "#         print(\"‚Üí SL ÎèÑÎã¨ Í∞ÄÎä•!\")\n",
    "        \n",
    "        \n",
    "# print(f\"ÏùºÎ¥â ETH_Close: {df_test['ETH_Close'].iloc[-10:].values}\")\n",
    "# print(f\"1ÏãúÍ∞ÑÎ¥â close: {eth_hourly['close'].iloc[-10:].values}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

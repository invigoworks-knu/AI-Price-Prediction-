{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21fb3116",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! pip install pycoingecko ccxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "354b91d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Ethereum Price Prediction - Data Collection Module\n",
    "# 수집 데이터:\n",
    "# - Cryptocurrency OHLCV (yfinance + CCXT)\n",
    "# - Macro indicators (SP500, VIX, Gold, DXY)\n",
    "# - Fear & Greed Index\n",
    "# - DeFi TVL (Protocols, L2 chains)\n",
    "# - ETH Funding Rate\n",
    "# \"\"\"\n",
    "\n",
    "# import os\n",
    "# import time\n",
    "# import warnings\n",
    "# from datetime import datetime, timedelta\n",
    "\n",
    "# import pandas as pd\n",
    "# import requests\n",
    "# import yfinance as yf\n",
    "# import ccxt\n",
    "# from binance.client import Client\n",
    "# from defillama2 import DefiLlama\n",
    "\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# pyupbit_url = \"https://api.upbit.com/v1/candles/days\"\n",
    "# # ============================================================================\n",
    "# # Configuration\n",
    "# # ============================================================================\n",
    "# START_DATE = \"2017-01-01\"\n",
    "# END_DATE = datetime.today().strftime('%Y-%m-%d')\n",
    "# OUTPUT_DIR = \"./macro_data\"\n",
    "# os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# CRYPTO_TICKERS = {\n",
    "#     'BTC-USD': ('BTC', 'BTC/USDT'),\n",
    "#     'ETH-USD': ('ETH', 'ETH/USDT'),\n",
    "#     'BNB-USD': ('BNB', 'BNB/USDT'),\n",
    "#     'XRP-USD': ('XRP', 'XRP/USDT'),\n",
    "#     'SOL-USD': ('SOL', 'SOL/USDT'),\n",
    "#     'ADA-USD': ('ADA', 'ADA/USDT'),\n",
    "#     'DOGE-USD': ('DOGE', 'DOGE/USDT'),\n",
    "#     'AVAX-USD': ('AVAX', 'AVAX/USDT'),\n",
    "#     'DOT-USD': ('DOT', 'DOT/USDT')\n",
    "# }\n",
    "\n",
    "# MACRO_TICKERS = {\n",
    "#     'DX-Y.NYB': 'DXY',\n",
    "#     'GC=F': 'GOLD',\n",
    "#     '^VIX': 'VIX',\n",
    "#     '^GSPC': 'SP500'\n",
    "# }\n",
    "\n",
    "# DEFI_PROTOCOLS = ['makerdao', 'lido', 'aave', 'uniswap', 'curve-dex']\n",
    "# L2_CHAINS = ['Arbitrum', 'Optimism', 'Base', 'zkSync Era']\n",
    "\n",
    "\n",
    "# # ============================================================================\n",
    "# # 1. Cryptocurrency Price Data (yfinance + CCXT)\n",
    "# # ============================================================================\n",
    "# def collect_crypto_prices():\n",
    "#     \"\"\"암호화폐 가격 데이터 수집 (yfinance 우선, CCXT 보완)\"\"\"\n",
    "#     print(f\"\\n[1/6] Collecting cryptocurrency prices...\")\n",
    "    \n",
    "#     start_dt = pd.to_datetime(START_DATE)\n",
    "#     end_dt = pd.Timestamp.today()\n",
    "#     date_range = pd.date_range(start=start_dt, end=end_dt, freq='D')\n",
    "#     merged_df = pd.DataFrame(date_range, columns=['date'])\n",
    "    \n",
    "#     for ticker, (symbol, ccxt_symbol) in CRYPTO_TICKERS.items():\n",
    "#         try:\n",
    "#             df = yf.Ticker(ticker).history(start=START_DATE)\n",
    "#             if df.empty:\n",
    "#                 print(f\"  - {symbol}: No data\")\n",
    "#                 continue\n",
    "                \n",
    "#             df = df[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "#             df.columns = [f\"{symbol}_{col}\" for col in df.columns]\n",
    "#             df = df.reset_index()\n",
    "#             df['date'] = df['Date'].dt.tz_localize(None)\n",
    "#             df = df.drop(columns=['Date'])\n",
    "            \n",
    "#             merged_df = pd.merge(merged_df, df, on='date', how='outer')\n",
    "#             print(f\"  - {symbol}: {len(df)} days\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"  - {symbol}: Failed ({str(e)[:50]})\")\n",
    "    \n",
    "#     merged_df = merged_df.sort_values('date')\n",
    "#     output_path = os.path.join(OUTPUT_DIR, \"macro_crypto_data.csv\")\n",
    "#     merged_df.to_csv(output_path, index=False)\n",
    "#     print(f\"  Saved: {output_path}\")\n",
    "#     return merged_df\n",
    "\n",
    "\n",
    "# # ============================================================================\n",
    "# # 2. Macro Indicators (SP500, VIX, Gold, DXY)\n",
    "# # ============================================================================\n",
    "# def collect_macro_indicators():\n",
    "#     \"\"\"거시경제 지표 수집\"\"\"\n",
    "#     print(f\"\\n[2/6] Collecting macro indicators...\")\n",
    "    \n",
    "#     for ticker, name in MACRO_TICKERS.items():\n",
    "#         try:\n",
    "#             df = yf.download(ticker, start=START_DATE, end=END_DATE, \n",
    "#                            progress=False, group_by='column')\n",
    "#             df = df[['Close']].copy()\n",
    "#             df.columns = [name]\n",
    "#             df.index.name = 'date'\n",
    "            \n",
    "#             output_path = os.path.join(OUTPUT_DIR, f\"{name}.csv\")\n",
    "#             df.to_csv(output_path)\n",
    "#             print(f\"  - {name}: {len(df)} days\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"  - {name}: Failed ({str(e)[:50]})\")\n",
    "\n",
    "\n",
    "# # ============================================================================\n",
    "# # 3. Fear & Greed Index\n",
    "# # ============================================================================\n",
    "# def collect_fear_greed():\n",
    "#     \"\"\"Fear & Greed Index 수집\"\"\"\n",
    "#     print(f\"\\n[3/6] Collecting Fear & Greed Index...\")\n",
    "    \n",
    "#     try:\n",
    "#         url = \"https://api.alternative.me/fng/?limit=4000&format=json\"\n",
    "#         response = requests.get(url)\n",
    "#         data = response.json()['data']\n",
    "        \n",
    "#         df = pd.DataFrame(data)\n",
    "#         df['date'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "#         df = df[['date', 'value']].rename(columns={'value': 'fear_greed'})\n",
    "#         df = df.sort_values('date').reset_index(drop=True)\n",
    "        \n",
    "#         output_path = os.path.join(OUTPUT_DIR, \"fear_greed.csv\")\n",
    "#         df.to_csv(output_path, index=False)\n",
    "#         print(f\"  - Fear & Greed: {len(df)} days\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"  - Fear & Greed: Failed ({str(e)[:50]})\")\n",
    "\n",
    "\n",
    "# # ============================================================================\n",
    "# # 4. ETH Funding Rate\n",
    "# # ============================================================================\n",
    "# def collect_funding_rate():\n",
    "#     \"\"\"이더리움 펀딩비 수집\"\"\"\n",
    "#     print(f\"\\n[4/6] Collecting ETH funding rate...\")\n",
    "    \n",
    "#     try:\n",
    "#         client = Client(\"\", \"\")\n",
    "#         funding_rates = []\n",
    "        \n",
    "#         start_time = int(datetime.strptime(START_DATE, \"%Y-%m-%d\").timestamp() * 1000)\n",
    "#         end_time = int(datetime.strptime(END_DATE, \"%Y-%m-%d\").timestamp() * 1000)\n",
    "#         current_ts = start_time\n",
    "        \n",
    "#         while current_ts < end_time:\n",
    "#             rates = client.futures_funding_rate(\n",
    "#                 symbol='ETHUSDT',\n",
    "#                 startTime=current_ts,\n",
    "#                 limit=1000\n",
    "#             )\n",
    "#             if not rates:\n",
    "#                 break\n",
    "#             funding_rates.extend(rates)\n",
    "#             current_ts = rates[-1]['fundingTime'] + 1\n",
    "        \n",
    "#         df = pd.DataFrame(funding_rates)\n",
    "#         df['date'] = pd.to_datetime(df['fundingTime'], unit='ms').dt.date\n",
    "#         df['fundingRate'] = df['fundingRate'].astype(float)\n",
    "#         df = df.groupby('date')['fundingRate'].mean().reset_index()\n",
    "        \n",
    "#         output_path = os.path.join(OUTPUT_DIR, \"eth_funding_rate.csv\")\n",
    "#         df.to_csv(output_path, index=False)\n",
    "#         print(f\"  - Funding Rate: {len(df)} days\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"  - Funding Rate: Failed ({str(e)[:50]})\")\n",
    "\n",
    "\n",
    "# # ============================================================================\n",
    "# # 5. DeFi Protocol TVL\n",
    "# # ============================================================================\n",
    "# def collect_defi_tvl():\n",
    "#     \"\"\"DeFi 프로토콜 TVL 수집\"\"\"\n",
    "#     print(f\"\\n[5/6] Collecting DeFi protocol TVL...\")\n",
    "    \n",
    "#     obj = DefiLlama()\n",
    "    \n",
    "#     # Ethereum Chain TVL\n",
    "#     try:\n",
    "#         df = obj.get_chain_hist_tvl('Ethereum')\n",
    "#         df = df.reset_index().rename(columns={'tvl': 'eth_chain_tvl'})\n",
    "#         output_path = os.path.join(OUTPUT_DIR, 'eth_chain_tvl.csv')\n",
    "#         df.to_csv(output_path, index=False)\n",
    "#         print(f\"  - ETH Chain TVL: {len(df)} days\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"  - ETH Chain TVL: Failed ({str(e)[:50]})\")\n",
    "    \n",
    "#     # Protocol TVL (Ethereum only)\n",
    "#     for protocol in DEFI_PROTOCOLS:\n",
    "#         try:\n",
    "#             tvl_dict = obj.get_protocol_hist_tvl_by_chain(protocol)\n",
    "#             if 'Ethereum' in tvl_dict:\n",
    "#                 df = tvl_dict['Ethereum'].reset_index()\n",
    "#                 df = df.rename(columns={'tvl': f'{protocol}_eth_tvl'})\n",
    "#                 output_path = os.path.join(OUTPUT_DIR, f'{protocol}_eth_tvl.csv')\n",
    "#                 df.to_csv(output_path, index=False)\n",
    "#                 print(f\"  - {protocol}: {len(df)} days\")\n",
    "#             else:\n",
    "#                 print(f\"  - {protocol}: No Ethereum data\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"  - {protocol}: Failed ({str(e)[:50]})\")\n",
    "    \n",
    "#     # USDT Market Cap\n",
    "#     try:\n",
    "#         df = obj.get_stablecoin_hist_mcap_on_a_chain(1, 'ethereum')\n",
    "#         df = df.reset_index().rename(columns={'mcap': 'usdt_eth_mcap'})\n",
    "#         output_path = os.path.join(OUTPUT_DIR, 'usdt_eth_mcap.csv')\n",
    "#         df.to_csv(output_path, index=False)\n",
    "#         print(f\"  - USDT ETH Mcap: {len(df)} days\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"  - USDT ETH Mcap: Failed ({str(e)[:50]})\")\n",
    "\n",
    "\n",
    "# # ============================================================================\n",
    "# # 6. Layer 2 TVL\n",
    "# # ============================================================================\n",
    "# def collect_l2_tvl():\n",
    "#     \"\"\"Layer 2 TVL 수집\"\"\"\n",
    "#     print(f\"\\n[6/6] Collecting Layer 2 TVL...\")\n",
    "    \n",
    "#     all_data = []\n",
    "    \n",
    "#     for chain in L2_CHAINS:\n",
    "#         try:\n",
    "#             url = f\"https://api.llama.fi/v2/historicalChainTvl/{chain}\"\n",
    "#             response = requests.get(url)\n",
    "            \n",
    "#             if response.status_code == 200:\n",
    "#                 data = response.json()\n",
    "#                 df = pd.DataFrame(data)\n",
    "#                 df['date'] = pd.to_datetime(df['date'], unit='s')\n",
    "#                 df = df.rename(columns={'tvl': f'{chain.lower()}_tvl'})\n",
    "#                 all_data.append(df[['date', f'{chain.lower()}_tvl']])\n",
    "#                 print(f\"  - {chain}: {len(df)} days\")\n",
    "#             else:\n",
    "#                 print(f\"  - {chain}: API error\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"  - {chain}: Failed ({str(e)[:50]})\")\n",
    "    \n",
    "#     if all_data:\n",
    "#         result = all_data[0]\n",
    "#         for df in all_data[1:]:\n",
    "#             result = pd.merge(result, df, on='date', how='outer')\n",
    "        \n",
    "#         result = result.sort_values('date').reset_index(drop=True)\n",
    "#         output_path = os.path.join(OUTPUT_DIR, 'layer2_tvl.csv')\n",
    "#         result.to_csv(output_path, index=False)\n",
    "#         print(f\"  Saved: {output_path}\")\n",
    "\n",
    "\n",
    "# # ============================================================================\n",
    "# # Main Execution\n",
    "# # ============================================================================\n",
    "# if __name__ == \"__main__\":\n",
    "#     print(\"=\" * 80)\n",
    "#     print(\"ETH Price Prediction - Data Collection Pipeline\")\n",
    "#     print(\"=\" * 80)\n",
    "    \n",
    "#     collect_crypto_prices()\n",
    "#     collect_macro_indicators()\n",
    "#     collect_fear_greed()\n",
    "#     collect_funding_rate()\n",
    "#     collect_defi_tvl()\n",
    "#     collect_l2_tvl()\n",
    "    \n",
    "#     print(\"\\n\" + \"=\" * 80)\n",
    "#     print(\"Data collection completed!\")\n",
    "#     print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "#     print(\"=\" * 80)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5f8a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "import yfinance as yf\n",
    "import ccxt\n",
    "from binance.client import Client\n",
    "from defillama2 import DefiLlama\n",
    "NEWS_DIR = '../news_data'\n",
    "\n",
    "####################################################\n",
    "# 1. 데이터 로드 함수\n",
    "####################################################\n",
    "\n",
    "def parse_date_from_filename(filename):\n",
    "    \"\"\"파일명에서 날짜 추출\"\"\"\n",
    "    patterns = [\n",
    "        r'(\\d{4})-(\\d{2})-(\\d{2})',\n",
    "        r'(\\d{4})(\\d{2})(\\d{2})',\n",
    "        r'(\\d{2})-(\\d{2})-(\\d{4})',\n",
    "        r'(\\d{2})(\\d{2})(\\d{4})'\n",
    "    ]\n",
    "    basename = os.path.basename(filename)\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, basename)\n",
    "        if match:\n",
    "            try:\n",
    "                if len(match.group(1)) == 4:\n",
    "                    year, month, day = match.groups()\n",
    "                else:\n",
    "                    day, month, year = match.groups()\n",
    "                return pd.to_datetime(f\"{year}-{month}-{day}\")\n",
    "            except:\n",
    "                continue\n",
    "    return None\n",
    "\n",
    "def load_all_news_data(root_dir):\n",
    "    \"\"\"뉴스 데이터 로드 및 일간 집계\"\"\"\n",
    "    print(\"\\n=== 뉴스 데이터 로드 ===\")\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    if not os.path.exists(root_dir):\n",
    "        print(f\"경고: {root_dir} 디렉토리가 존재하지 않습니다. 더미 데이터를 생성합니다.\")\n",
    "        dates = pd.date_range(START_TIME, END_TIME, freq='D')\n",
    "        return pd.DataFrame({\n",
    "            'date': dates,\n",
    "            'news': ['test news'] * len(dates),\n",
    "            'label': np.random.choice([1, 0, -1], len(dates))\n",
    "        })\n",
    "    \n",
    "    csv_files = sorted([f for f in os.listdir(root_dir) if f.endswith('.csv')])\n",
    "    print(f\"발견된 뉴스 파일: {len(csv_files)}개\")\n",
    "    \n",
    "    for filename in csv_files:\n",
    "        filepath = os.path.join(root_dir, filename)\n",
    "        file_date = parse_date_from_filename(filename)\n",
    "        \n",
    "        # 여러 인코딩 시도\n",
    "        for enc in ['utf-8', 'cp949', 'latin1']:\n",
    "            try:\n",
    "                df = pd.read_csv(filepath, encoding=enc)\n",
    "                break\n",
    "            except Exception:\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"  건너뜀: {filename} (인코딩 실패)\")\n",
    "            continue\n",
    "        \n",
    "        # 날짜 컬럼 처리\n",
    "        if 'date' not in df.columns:\n",
    "            df['date'] = file_date\n",
    "        else:\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            if file_date is not None:\n",
    "                df['date'] = df['date'].fillna(file_date)\n",
    "        \n",
    "        # label 컬럼 확인\n",
    "        if 'label' not in df.columns:\n",
    "            print(f\"  경고: {filename}에 'label' 컬럼이 없습니다. 0으로 채웁니다.\")\n",
    "            df['label'] = 0\n",
    "        \n",
    "        # 필요한 컬럼만 선택\n",
    "        if 'news' in df.columns:\n",
    "            df = df[['date', 'news', 'label']]\n",
    "        else:\n",
    "            df = df[['date', 'label']]\n",
    "        \n",
    "        all_data.append(df)\n",
    "    \n",
    "    if len(all_data) == 0:\n",
    "        print(\"경고: 유효한 뉴스 파일을 찾을 수 없습니다. 더미 데이터를 생성합니다.\")\n",
    "        dates = pd.date_range(START_TIME, END_TIME, freq='D')\n",
    "        return pd.DataFrame({\n",
    "            'date': dates,\n",
    "            'news': ['test news'] * len(dates),\n",
    "            'label': np.random.choice([1, 0, -1], len(dates))\n",
    "        })\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a962d4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 뉴스 데이터 로드 ===\n",
      "발견된 뉴스 파일: 2135개\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>news</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26341</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>익명 고래 트레이더가 자오창펑(CZ) 관련 발언 직후 알트코인 공매도 포지션으로 대...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26342</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>마치 빅 브라더(Machi Big Brother)로 알려진 유명 트레이더 제프리 황...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26343</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>리플(Ripple)의 스테이블코인 RLUSD가 출시 1년 만에 시가총액 10억달러를...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26344</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>시바이누(Shiba Inu, SHIB)가 미국에서 현물 상장지수펀드(ETF) 출시 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26345</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>엑스알피(XRP)와 리플의 스테이블코인 RLUSD가 글로벌 결제 혁신에 속도를 내며...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                               news label\n",
       "26341 2025-11-05  익명 고래 트레이더가 자오창펑(CZ) 관련 발언 직후 알트코인 공매도 포지션으로 대...     0\n",
       "26342 2025-11-05  마치 빅 브라더(Machi Big Brother)로 알려진 유명 트레이더 제프리 황...    -1\n",
       "26343 2025-11-05  리플(Ripple)의 스테이블코인 RLUSD가 출시 1년 만에 시가총액 10억달러를...     1\n",
       "26344 2025-11-05  시바이누(Shiba Inu, SHIB)가 미국에서 현물 상장지수펀드(ETF) 출시 ...     1\n",
       "26345 2025-11-05  엑스알피(XRP)와 리플의 스테이블코인 RLUSD가 글로벌 결제 혁신에 속도를 내며...     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=load_all_news_data(NEWS_DIR)\n",
    "df.to_csv(\"news_data.csv\",index=False)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b68131da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ETH Price Prediction - Data Collection Pipeline\n",
      "================================================================================\n",
      "\n",
      "[1/6] Collecting cryptocurrency prices from Upbit...\n",
      "  - BTC: 2968 days\n",
      "  - ETH: 2965 days\n",
      "  - XRP: 2965 days\n",
      "  - SOL: 1487 days\n",
      "  - ADA: 2954 days\n",
      "  - DOGE: 1720 days\n",
      "  - AVAX: 1371 days\n",
      "  - DOT: 1862 days\n",
      "  Saved: ./macro_data/macro_crypto_data.csv\n",
      "\n",
      "[2/6] Collecting macro indicators...\n",
      "  - DXY: 2228 days\n",
      "  - GOLD: 2227 days\n",
      "  - VIX: 2226 days\n",
      "  - SP500: 2226 days\n",
      "\n",
      "[3/6] Collecting Fear & Greed Index...\n",
      "  - Fear & Greed: 2835 days\n",
      "\n",
      "[4/6] Collecting ETH funding rate...\n",
      "  - Funding Rate: 2175 days\n",
      "\n",
      "[5/6] Collecting DeFi protocol TVL...\n",
      "  - ETH Chain TVL: 2966 days\n",
      "  - makerdao: 2503 days\n",
      "  - lido: 1787 days\n",
      "  - aave: 2001 days\n",
      "  - uniswap: 2565 days\n",
      "  - curve-dex: 2095 days\n",
      "  - USDT ETH Mcap: 2903 days\n",
      "\n",
      "[6/6] Collecting Layer 2 TVL...\n",
      "  - Arbitrum: 1559 days\n",
      "  - Optimism: 1580 days\n",
      "  - Base: 879 days\n",
      "  - zkSync Era: 1278 days\n",
      "  Saved: ./macro_data/layer2_tvl.csv\n",
      "\n",
      "================================================================================\n",
      "Data collection completed!\n",
      "Output directory: ./macro_data\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import yfinance as yf\n",
    "import ccxt\n",
    "from binance.client import Client\n",
    "from defillama2 import DefiLlama\n",
    "import pandas as pd\n",
    "import requests\n",
    "import yfinance as yf\n",
    "from defillama2 import DefiLlama\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "START_DATE = \"2017-01-01\"\n",
    "END_DATE = datetime.today().strftime('%Y-%m-%d')\n",
    "OUTPUT_DIR = \"./macro_data\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "UPBIT_CRYPTO_TICKERS = {\n",
    "    'KRW-BTC': ('BTC', 'BTC'),\n",
    "    'KRW-ETH': ('ETH', 'ETH'),\n",
    "    #'KRW-BNB': ('BNB', 'BNB'),\n",
    "    'KRW-XRP': ('XRP', 'XRP'),\n",
    "    'KRW-SOL': ('SOL', 'SOL'),\n",
    "    'KRW-ADA': ('ADA', 'ADA'),\n",
    "    'KRW-DOGE': ('DOGE', 'DOGE'),\n",
    "    'KRW-AVAX': ('AVAX', 'AVAX'),\n",
    "    'KRW-DOT': ('DOT', 'DOT')\n",
    "}\n",
    "\n",
    "MACRO_TICKERS = {\n",
    "    'DX-Y.NYB': 'DXY',\n",
    "    'GC=F': 'GOLD',\n",
    "    '^VIX': 'VIX',\n",
    "    '^GSPC': 'SP500'\n",
    "}\n",
    "\n",
    "DEFI_PROTOCOLS = ['makerdao', 'lido', 'aave', 'uniswap', 'curve-dex']\n",
    "L2_CHAINS = ['Arbitrum', 'Optimism', 'Base', 'zkSync Era']\n",
    "\n",
    "\n",
    "def collect_upbit_crypto_prices():\n",
    "    print(f\"\\n[1/6] Collecting cryptocurrency prices from Upbit...\")\n",
    "    \n",
    "    start_dt = pd.to_datetime(START_DATE)\n",
    "    merged_df = None\n",
    "    \n",
    "    for market, (symbol, _) in UPBIT_CRYPTO_TICKERS.items():\n",
    "        try:\n",
    "            all_candles = []\n",
    "            to_date = None\n",
    "            \n",
    "            while True:\n",
    "                url = f\"https://api.upbit.com/v1/candles/days\"\n",
    "                params = {\n",
    "                    'market': market,\n",
    "                    'count': 200\n",
    "                }\n",
    "                if to_date:\n",
    "                    params['to'] = to_date\n",
    "                \n",
    "                response = requests.get(url, params=params)\n",
    "                response.raise_for_status()\n",
    "                candles = response.json()\n",
    "                \n",
    "                if not candles:\n",
    "                    break\n",
    "                \n",
    "                all_candles.extend(candles)\n",
    "                oldest_date = pd.to_datetime(candles[-1]['candle_date_time_kst'])\n",
    "                \n",
    "                if oldest_date <= start_dt:\n",
    "                    break\n",
    "                \n",
    "                to_date = candles[-1]['candle_date_time_utc']\n",
    "                time.sleep(0.1)\n",
    "            \n",
    "            if not all_candles:\n",
    "                print(f\"  - {symbol}: No data\")\n",
    "                continue\n",
    "            \n",
    "            df = pd.DataFrame(all_candles)\n",
    "            df['date'] = pd.to_datetime(df['candle_date_time_kst']).dt.normalize()\n",
    "            \n",
    "            df = df.rename(columns={\n",
    "                'opening_price': f'{symbol}_Open',\n",
    "                'high_price': f'{symbol}_High',\n",
    "                'low_price': f'{symbol}_Low',\n",
    "                'trade_price': f'{symbol}_Close',\n",
    "                'candle_acc_trade_volume': f'{symbol}_Volume'\n",
    "            })\n",
    "            \n",
    "            df = df[['date', f'{symbol}_Open', f'{symbol}_High', \n",
    "                    f'{symbol}_Low', f'{symbol}_Close', f'{symbol}_Volume']]\n",
    "            df = df.sort_values('date')\n",
    "            df = df[df['date'] >= start_dt]\n",
    "            \n",
    "            if merged_df is None:\n",
    "                merged_df = df\n",
    "            else:\n",
    "                merged_df = pd.merge(merged_df, df, on='date', how='outer')\n",
    "            \n",
    "            print(f\"  - {symbol}: {len(df)} days\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  - {symbol}: Failed ({str(e)[:50]})\")\n",
    "    \n",
    "    if merged_df is not None:\n",
    "        merged_df = merged_df.sort_values('date')\n",
    "        output_path = os.path.join(OUTPUT_DIR, \"macro_crypto_data.csv\")\n",
    "        merged_df.to_csv(output_path, index=False)\n",
    "        print(f\"  Saved: {output_path}\")\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# ============================================================================\n",
    "# 2. Macro Indicators (SP500, VIX, Gold, DXY)\n",
    "# ============================================================================\n",
    "def collect_macro_indicators():\n",
    "    \"\"\"거시경제 지표 수집\"\"\"\n",
    "    print(f\"\\n[2/6] Collecting macro indicators...\")\n",
    "    \n",
    "    for ticker, name in MACRO_TICKERS.items():\n",
    "        try:\n",
    "            df = yf.download(ticker, start=START_DATE, end=END_DATE, \n",
    "                           progress=False, group_by='column')\n",
    "            df = df[['Close']].copy()\n",
    "            df.columns = [name]\n",
    "            df.index.name = 'date'\n",
    "            \n",
    "            output_path = os.path.join(OUTPUT_DIR, f\"{name}.csv\")\n",
    "            df.to_csv(output_path)\n",
    "            print(f\"  - {name}: {len(df)} days\")\n",
    "        except Exception as e:\n",
    "            print(f\"  - {name}: Failed ({str(e)[:50]})\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 3. Fear & Greed Index\n",
    "# ============================================================================\n",
    "def collect_fear_greed():\n",
    "    \"\"\"Fear & Greed Index 수집\"\"\"\n",
    "    print(f\"\\n[3/6] Collecting Fear & Greed Index...\")\n",
    "    \n",
    "    try:\n",
    "        url = \"https://api.alternative.me/fng/?limit=4000&format=json\"\n",
    "        response = requests.get(url)\n",
    "        data = response.json()['data']\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        df['date'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "        df = df[['date', 'value']].rename(columns={'value': 'fear_greed'})\n",
    "        df = df.sort_values('date').reset_index(drop=True)\n",
    "        \n",
    "        output_path = os.path.join(OUTPUT_DIR, \"fear_greed.csv\")\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"  - Fear & Greed: {len(df)} days\")\n",
    "    except Exception as e:\n",
    "        print(f\"  - Fear & Greed: Failed ({str(e)[:50]})\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 4. ETH Funding Rate\n",
    "# ============================================================================\n",
    "def collect_funding_rate():\n",
    "    \"\"\"이더리움 펀딩비 수집\"\"\"\n",
    "    print(f\"\\n[4/6] Collecting ETH funding rate...\")\n",
    "    \n",
    "    try:\n",
    "        client = Client(\"\", \"\")\n",
    "        funding_rates = []\n",
    "        \n",
    "        start_time = int(datetime.strptime(START_DATE, \"%Y-%m-%d\").timestamp() * 1000)\n",
    "        end_time = int(datetime.strptime(END_DATE, \"%Y-%m-%d\").timestamp() * 1000)\n",
    "        current_ts = start_time\n",
    "        \n",
    "        while current_ts < end_time:\n",
    "            rates = client.futures_funding_rate(\n",
    "                symbol='ETHUSDT',\n",
    "                startTime=current_ts,\n",
    "                limit=1000\n",
    "            )\n",
    "            if not rates:\n",
    "                break\n",
    "            funding_rates.extend(rates)\n",
    "            current_ts = rates[-1]['fundingTime'] + 1\n",
    "        \n",
    "        df = pd.DataFrame(funding_rates)\n",
    "        df['date'] = pd.to_datetime(df['fundingTime'], unit='ms').dt.date\n",
    "        df['fundingRate'] = df['fundingRate'].astype(float)\n",
    "        df = df.groupby('date')['fundingRate'].mean().reset_index()\n",
    "        \n",
    "        output_path = os.path.join(OUTPUT_DIR, \"eth_funding_rate.csv\")\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"  - Funding Rate: {len(df)} days\")\n",
    "    except Exception as e:\n",
    "        print(f\"  - Funding Rate: Failed ({str(e)[:50]})\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 5. DeFi Protocol TVL\n",
    "# ============================================================================\n",
    "def collect_defi_tvl():\n",
    "    \"\"\"DeFi 프로토콜 TVL 수집\"\"\"\n",
    "    print(f\"\\n[5/6] Collecting DeFi protocol TVL...\")\n",
    "    \n",
    "    obj = DefiLlama()\n",
    "    \n",
    "    # Ethereum Chain TVL\n",
    "    try:\n",
    "        df = obj.get_chain_hist_tvl('Ethereum')\n",
    "        df = df.reset_index().rename(columns={'tvl': 'eth_chain_tvl'})\n",
    "        output_path = os.path.join(OUTPUT_DIR, 'eth_chain_tvl.csv')\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"  - ETH Chain TVL: {len(df)} days\")\n",
    "    except Exception as e:\n",
    "        print(f\"  - ETH Chain TVL: Failed ({str(e)[:50]})\")\n",
    "    \n",
    "    # Protocol TVL (Ethereum only)\n",
    "    for protocol in DEFI_PROTOCOLS:\n",
    "        try:\n",
    "            tvl_dict = obj.get_protocol_hist_tvl_by_chain(protocol)\n",
    "            if 'Ethereum' in tvl_dict:\n",
    "                df = tvl_dict['Ethereum'].reset_index()\n",
    "                df = df.rename(columns={'tvl': f'{protocol}_eth_tvl'})\n",
    "                output_path = os.path.join(OUTPUT_DIR, f'{protocol}_eth_tvl.csv')\n",
    "                df.to_csv(output_path, index=False)\n",
    "                print(f\"  - {protocol}: {len(df)} days\")\n",
    "            else:\n",
    "                print(f\"  - {protocol}: No Ethereum data\")\n",
    "        except Exception as e:\n",
    "            print(f\"  - {protocol}: Failed ({str(e)[:50]})\")\n",
    "    \n",
    "    # USDT Market Cap\n",
    "    try:\n",
    "        df = obj.get_stablecoin_hist_mcap_on_a_chain(1, 'ethereum')\n",
    "        df = df.reset_index().rename(columns={'mcap': 'usdt_eth_mcap'})\n",
    "        output_path = os.path.join(OUTPUT_DIR, 'usdt_eth_mcap.csv')\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"  - USDT ETH Mcap: {len(df)} days\")\n",
    "    except Exception as e:\n",
    "        print(f\"  - USDT ETH Mcap: Failed ({str(e)[:50]})\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 6. Layer 2 TVL\n",
    "# ============================================================================\n",
    "def collect_l2_tvl():\n",
    "    \"\"\"Layer 2 TVL 수집\"\"\"\n",
    "    print(f\"\\n[6/6] Collecting Layer 2 TVL...\")\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    for chain in L2_CHAINS:\n",
    "        try:\n",
    "            url = f\"https://api.llama.fi/v2/historicalChainTvl/{chain}\"\n",
    "            response = requests.get(url)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                df = pd.DataFrame(data)\n",
    "                df['date'] = pd.to_datetime(df['date'], unit='s')\n",
    "                df = df.rename(columns={'tvl': f'{chain.lower()}_tvl'})\n",
    "                all_data.append(df[['date', f'{chain.lower()}_tvl']])\n",
    "                print(f\"  - {chain}: {len(df)} days\")\n",
    "            else:\n",
    "                print(f\"  - {chain}: API error\")\n",
    "        except Exception as e:\n",
    "            print(f\"  - {chain}: Failed ({str(e)[:50]})\")\n",
    "    \n",
    "    if all_data:\n",
    "        result = all_data[0]\n",
    "        for df in all_data[1:]:\n",
    "            result = pd.merge(result, df, on='date', how='outer')\n",
    "        \n",
    "        result = result.sort_values('date').reset_index(drop=True)\n",
    "        output_path = os.path.join(OUTPUT_DIR, 'layer2_tvl.csv')\n",
    "        result.to_csv(output_path, index=False)\n",
    "        print(f\"  Saved: {output_path}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Main Execution\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ETH Price Prediction - Data Collection Pipeline\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    collect_upbit_crypto_prices()\n",
    "    collect_macro_indicators()\n",
    "    collect_fear_greed()\n",
    "    collect_funding_rate()\n",
    "    collect_defi_tvl()\n",
    "    collect_l2_tvl()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Data collection completed!\")\n",
    "    print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

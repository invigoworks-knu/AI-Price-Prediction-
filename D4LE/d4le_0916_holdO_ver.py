import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Concatenate

# ====================================
# 1. ÏÑ§Ï†ï (Hyperparameters)
# ====================================
MARKETS = ["KRW-ETH", "USDT-ETH", "BTC-ETH"]
# ÎÖºÎ¨∏Ïóê Î™ÖÏãúÎêú ÏµúÏ†ÅÏùò ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞
LOOK_BACK = 7           # Window Size
EPOCHS = 50             # Epochs
LSTM_UNITS = 32         # Number of LSTM Neurons
BATCH_SIZE = 32
TRAIN_RATIO = 0.8

# Î∞©Ìñ•ÏÑ± Í≤∞Ï†ï ÏûÑÍ≥ÑÍ∞í (%)
LONG_THRESHOLD = 1.0
SHORT_THRESHOLD = -1.0

# ====================================
# 2. Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è ÌÜµÌï©
# ====================================
def load_and_prepare_data(markets):
    """3Í∞ú ÎßàÏºì OHLCV Îç∞Ïù¥ÌÑ∞Î•º Î°úÎìúÌïòÍ≥† ÌÜµÌï©Ìï©ÎãàÎã§."""
    dfs = {}
    for market in markets:
        try:
            df = pd.read_csv(f"{market}_ohlcv.csv", index_col=0, parse_dates=True)
            df = df[['open', 'high', 'low', 'close', 'volume']]
            prefix = f"{market.split('-')[0].lower()}_"
            df = df.add_prefix(prefix)
            dfs[market] = df
        except FileNotFoundError:
            print(f"Ïò§Î•ò: {market}_ohlcv.csv ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")
            return None

    main_df = dfs["USDT-ETH"]
    main_df = main_df.join(dfs["KRW-ETH"], how='inner')
    main_df = main_df.join(dfs["BTC-ETH"], how='inner')
    
    print(f"Îç∞Ïù¥ÌÑ∞ ÌÜµÌï© ÏôÑÎ£å. Ï¥ù {len(main_df.columns)}Í∞úÏùò ÌäπÏÑ±(Feature) ÏÉùÏÑ±.")
    return main_df

# ====================================
# 3. LSTMÏö© Îç∞Ïù¥ÌÑ∞ÏÖã Íµ¨Ï∂ï
# ====================================
def create_lstm_dataset(df):
    """LSTM ÌïôÏäµÏùÑ ÏúÑÌïú ÏãúÌÄÄÏä§ Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§."""
    df = df.copy().dropna()
    
    y = df['usdt_close'].shift(-1)
    X = df
    
    X = X.iloc[:-1]
    y = y.iloc[:-1]
    
    scaler_X = MinMaxScaler()
    X_scaled = scaler_X.fit_transform(X)
    
    scaler_y = MinMaxScaler()
    y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))

    X_seq, y_seq = [], []
    for i in range(len(X_scaled) - LOOK_BACK):
        X_seq.append(X_scaled[i:i + LOOK_BACK])
        y_seq.append(y_scaled[i + LOOK_BACK])
        
    return np.array(X_seq), np.array(y_seq), scaler_X, scaler_y, X.index[LOOK_BACK:]

# ====================================
# 4. D4LE Î™®Îç∏ Íµ¨Ï∂ï (ÎÖºÎ¨∏ Í∏∞Î∞ò)
# ====================================
def build_d4le_model(input_shape, lstm_units):
    """ÎÖºÎ¨∏Ïóê Í∏∞Ïà†Îêú 4Í∞úÏùò LSTMÏùÑ ÏïôÏÉÅÎ∏îÌïòÎäî D4LE Î™®Îç∏ÏùÑ Íµ¨Ï∂ïÌï©ÎãàÎã§."""
    input_layer = Input(shape=input_shape)

    lstm1 = LSTM(units=lstm_units, activation='tanh', return_sequences=False)(input_layer)
    lstm2 = LSTM(units=lstm_units, activation='tanh', return_sequences=False)(input_layer)
    lstm3 = LSTM(units=lstm_units, activation='tanh', return_sequences=False)(input_layer)
    lstm4 = LSTM(units=lstm_units, activation='tanh', return_sequences=False)(input_layer)

    merged = Concatenate()([lstm1, lstm2, lstm3, lstm4])
    dense_layer = Dense(64, activation='relu')(merged)
    output_layer = Dense(1)(dense_layer)

    model = Model(inputs=input_layer, outputs=output_layer)
    model.compile(optimizer='adam', loss='mean_squared_error')
    
    print("D4LE Î™®Îç∏ Íµ¨Ï∂ï ÏôÑÎ£å.")
    model.summary()
    return model

# ====================================
# 5. Î™®Îç∏ ÏÑ±Îä• ÌèâÍ∞Ä Ìï®Ïàò (Ï∂îÍ∞ÄÎêú Î∂ÄÎ∂Ñ)
# ====================================
def evaluate_model_performance(y_true_price, y_pred_price, y_true_labels, y_pred_labels):
    """RMSEÏôÄ ÏÉÅÏÑ∏ Î∂ÑÎ•ò ÏßÄÌëúÎ•º Í≥ÑÏÇ∞ÌïòÍ≥† Ï∂úÎ†•Ìï©ÎãàÎã§."""
    
    print("\n" + "="*50)
    print("Î™®Îç∏ Ï¢ÖÌï© ÏÑ±Îä• ÌèâÍ∞Ä")
    print("="*50)

    # 1. RMSE Í≥ÑÏÇ∞ (ÌöåÍ∑Ä ÏÑ±Îä•)
    rmse = np.sqrt(mean_squared_error(y_true_price, y_pred_price))
    nrmse = rmse / np.mean(y_true_price) * 100
    print(f"Í∞ÄÍ≤© ÏòàÏ∏° ÏÑ±Îä• (RMSE): {rmse:,.2f} USDT")
    print(f"Ï†ïÍ∑úÌôîÎêú RMSE: {nrmse:.2f}% (Í∞íÏù¥ ÎÇÆÏùÑÏàòÎ°ù Ï¢ãÏùå)")
    print("-" * 50)
    
    # 2. Î∂ÑÎ•ò ÏÑ±Îä• ÌèâÍ∞Ä
    print("Î∞©Ìñ•ÏÑ± ÏòàÏ∏° ÏÑ±Îä• (Classification Metrics)\n")
    
    report = classification_report(y_true_labels, y_pred_labels, 
                                   target_names=['SHORT', 'HOLD', 'LONG'], output_dict=True, zero_division=0)
    accuracy = report['accuracy']
    
    cm = confusion_matrix(y_true_labels, y_pred_labels)
    
    results = {}
    for i, label in enumerate(['SHORT', 'HOLD', 'LONG']):
        TP = cm[i, i]
        FP = cm[:, i].sum() - TP
        FN = cm[i, :].sum() - TP
        TN = cm.sum() - (TP + FP + FN)
        
        sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0 # Recall
        specificity = TN / (TN + FP) if (TN + FP) > 0 else 0
        precision = TP / (TP + FP) if (TP + FP) > 0 else 0
        
        results[label] = {
            'Sensitivity': sensitivity,
            'Specificity': specificity,
            'Precision': precision
        }
    
    print(f"{'Metric':<12} | {'SHORT':<10} | {'HOLD':<10} | {'LONG':<10} | {'Average':<10}")
    print("-" * 60)
    
    metrics_to_print = ['Sensitivity', 'Specificity', 'Precision']
    for metric in metrics_to_print:
        short_val = results['SHORT'][metric]
        hold_val = results['HOLD'][metric]
        long_val = results['LONG'][metric]
        avg_val = np.mean([short_val, hold_val, long_val])
        print(f"{metric:<12} | {short_val:<10.4f} | {hold_val:<10.4f} | {long_val:<10.4f} | {avg_val:<10.4f}")

    f1_avg = report['macro avg']['f1-score']
    print(f"{'F1 Score':<12} | {'-':<10} | {'-':<10} | {'-':<10} | {f1_avg:<10.4f}")
    print(f"{'Accuracy':<12} | {'-':<10} | {'-':<10} | {'-':<10} | {accuracy*100:<9.2f}%")
    print("="*50)
    
    return cm

# ====================================
# 6. Î©îÏù∏ Ïã§Ìñâ Î°úÏßÅ
# ====================================
unified_df = load_and_prepare_data(MARKETS)
if unified_df is not None:
    X_seq, y_seq, scaler_X, scaler_y, dates = create_lstm_dataset(unified_df)

    split_idx = int(len(X_seq) * TRAIN_RATIO)
    X_train, X_test = X_seq[:split_idx], X_seq[split_idx:]
    y_train, y_test = y_seq[:split_idx], y_seq[split_idx:]
    dates_test = dates[split_idx:]

    input_shape = (X_train.shape[1], X_train.shape[2])
    d4le_model = build_d4le_model(input_shape, LSTM_UNITS)
    
    print("\nÎ™®Îç∏ ÌõàÎ†® ÏãúÏûë...")
    history = d4le_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, 
                             validation_split=0.1, verbose=1)
    print("Î™®Îç∏ ÌõàÎ†® ÏôÑÎ£å.")

    # ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ ÏòàÏ∏°
    predicted_scaled = d4le_model.predict(X_test)
    predicted_prices = scaler_y.inverse_transform(predicted_scaled)
    actual_prices = scaler_y.inverse_transform(y_test)

    # --- ÌèâÍ∞ÄÎ•º ÏúÑÌïú Î∞©Ìñ•ÏÑ± ÎùºÎ≤® ÏÉùÏÑ± ---
    # ÌÖåÏä§Ìä∏ Í∏∞Í∞ÑÏùò 'Ïñ¥Ï†ú' Ï¢ÖÍ∞Ä Îç∞Ïù¥ÌÑ∞ Ï∂îÏ∂ú
    test_start_date_loc = unified_df.index.get_loc(dates_test[0])
    last_actual_prices_test = unified_df['usdt_close'].iloc[test_start_date_loc - 1 : test_start_date_loc - 1 + len(dates_test)].values
    
    predicted_returns = (predicted_prices.flatten() - last_actual_prices_test) / last_actual_prices_test * 100
    actual_returns = (actual_prices.flatten() - last_actual_prices_test) / last_actual_prices_test * 100

    def get_label(returns):
        labels = np.ones_like(returns, dtype=int) # HOLD
        labels[returns > LONG_THRESHOLD] = 2    # LONG
        labels[returns < SHORT_THRESHOLD] = 0   # SHORT
        return labels

    y_pred_labels = get_label(predicted_returns)
    y_true_labels = get_label(actual_returns)

    # --- ÏÉàÎ°úÏö¥ ÌèâÍ∞Ä Ìï®Ïàò Ìò∏Ï∂ú ---
    cm = evaluate_model_performance(actual_prices, predicted_prices, y_true_labels, y_pred_labels)
    
    # --- ÏãúÍ∞ÅÌôî ---
    plt.style.use('seaborn-v0_8-darkgrid')
    plt.figure(figsize=(15, 7))
    plt.plot(dates_test, actual_prices, color='cyan', label='Original Price')
    plt.plot(dates_test, predicted_prices, color='gray', label='Predicted Price')
    plt.title('D4LE Model: Actual vs. Predicted Price')
    plt.xlabel('Date')
    plt.ylabel('Price (USDT)')
    plt.legend()
    plt.show()

    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=['SHORT', 'HOLD', 'LONG'], yticklabels=['SHORT', 'HOLD', 'LONG'])
    plt.title('Confusion Matrix')
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.show()

    # --- ÎÇ¥Ïùº Î∞©Ìñ•ÏÑ± ÏòàÏ∏° ---
    print("\n" + "="*50)
    print("ÎÇ¥Ïùº ETH Í∞ÄÍ≤© Î∞©Ìñ•ÏÑ± ÏòàÏ∏°")
    print("="*50)
    
    last_sequence_scaled = X_seq[-1].reshape(1, LOOK_BACK, X_seq.shape[2])
    tomorrow_pred_scaled = d4le_model.predict(last_sequence_scaled)
    tomorrow_pred_price = scaler_y.inverse_transform(tomorrow_pred_scaled)[0][0]
    
    last_actual_price = unified_df['usdt_close'].iloc[-1]
    predicted_return = (tomorrow_pred_price - last_actual_price) / last_actual_price * 100
    
    direction = "HOLD (Ïú†ÏßÄ)"
    if predicted_return > LONG_THRESHOLD:
        direction = "LONG (ÏÉÅÏäπ)"
    elif predicted_return < SHORT_THRESHOLD:
        direction = "SHORT (ÌïòÎùΩ)"
        
    print(f"Ïò§Îäò Ï¢ÖÍ∞Ä (USDT): {last_actual_price:,.2f}")
    print(f"ÎÇ¥Ïùº ÏòàÏ∏° Ï¢ÖÍ∞Ä (USDT): {tomorrow_pred_price:,.2f}")
    print(f"ÏòàÏÉÅ ÏàòÏùµÎ•†: {predicted_return:.2f}%")
    print("-" * 50)
    print(f"üí° ÏµúÏ¢Ö ÏòàÏ∏° Î∞©Ìñ•: {direction}")
    print("="*50)
    print("\n*Ïã†Î¢∞ÎèÑÎäî Î™®Îç∏Ïùò ÏòàÏ∏° ÏàòÏùµÎ•† ÌÅ¨Í∏∞Ïóê ÎπÑÎ°ÄÌï©ÎãàÎã§. Ï†àÎåÄÏ†ÅÏù∏ ÌôïÎ•†Ïù¥ ÏïÑÎãôÎãàÎã§.")

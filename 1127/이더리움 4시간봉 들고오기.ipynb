{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dfa697c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETH Price Prediction - 4H Data Collection Pipeline (Robust)\n",
      "================================================================================\n",
      "\n",
      "[1/6] Collecting 4H cryptocurrency prices from Upbit...\n",
      "  - BTC: 17901 4H candles\n",
      "  - ETH: 17878 4H candles\n",
      "  - XRP: 17877 4H candles\n",
      "  - SOL: 9024 4H candles\n",
      "  - ADA: 17817 4H candles\n",
      "  - DOGE: 10422 4H candles\n",
      "  - AVAX: 8327 4H candles\n",
      "  - DOT: 11274 4H candles\n",
      "  Saved: crypto_4h_kst.csv\n",
      "\n",
      "[2/6] Collecting macro indicators (resampled to 4H)...\n",
      "  - DXY: 19495 rows\n",
      "  - GOLD: 19495 rows\n",
      "  - VIX: 19495 rows\n",
      "  - SP500: 19495 rows\n",
      "\n",
      "[3/6] Collecting Fear & Greed Index (resampled to 4H)...\n",
      "  - Fear & Greed: 17137 rows\n",
      "\n",
      "[4/6] Collecting ETH funding rate (resampled to 4H)...\n",
      "  - Funding Rate: 13151 rows\n",
      "\n",
      "[5/6] Collecting DeFi TVL (interpolated to 4H)...\n",
      "  - ETH Chain TVL: 17899 rows\n",
      "  - makerdao: 15116 rows\n",
      "  - lido: 10821 rows\n",
      "  - aave: 12104 rows\n",
      "    Error: HTTPSConnectionPool(host='api.... Retrying in 5s\n",
      "  - uniswap: 15488 rows\n",
      "  - curve-dex: 12710 rows\n",
      "  - USDT Mcap: 17521 rows\n",
      "\n",
      "[6/6] Collecting Layer 2 TVL (interpolated to 4H)...\n",
      "  - Arbitrum: 9823 rows\n",
      "  - Optimism: 9583 rows\n",
      "  - Base: 5377 rows\n",
      "  - zkSync Era: 7771 rows\n",
      "\n",
      "================================================================================\n",
      "4H Data collection completed!\n",
      "Output directory: ./macro_data_4h\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import requests\n",
    "import yfinance as yf\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "from binance.client import Client\n",
    "from defillama2 import DefiLlama # 라이브러리 사용 유지\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 설정 ---\n",
    "START_DATE = \"2017-01-01\"\n",
    "END_DATE = (datetime.today() + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "OUTPUT_DIR = \"./macro_data_4h\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "UPBIT_CRYPTO_TICKERS = {\n",
    "    'KRW-BTC': ('BTC', 'BTC'), 'KRW-ETH': ('ETH', 'ETH'), 'KRW-XRP': ('XRP', 'XRP'),\n",
    "    'KRW-SOL': ('SOL', 'SOL'), 'KRW-ADA': ('ADA', 'ADA'), 'KRW-DOGE': ('DOGE', 'DOGE'),\n",
    "    'KRW-AVAX': ('AVAX', 'AVAX'), 'KRW-DOT': ('DOT', 'DOT')\n",
    "}\n",
    "\n",
    "MACRO_TICKERS = {\n",
    "    'DX-Y.NYB': 'DXY', 'GC=F': 'GOLD', '^VIX': 'VIX', '^GSPC': 'SP500'\n",
    "}\n",
    "\n",
    "DEFI_PROTOCOLS = ['makerdao', 'lido', 'aave', 'uniswap', 'curve-dex']\n",
    "L2_CHAINS = ['Arbitrum', 'Optimism', 'Base', 'zkSync Era']\n",
    "\n",
    "# --- 안전한 요청을 위한 세션 설정 (443 에러 방지 핵심) ---\n",
    "def get_session():\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "        \"Accept\": \"application/json\"\n",
    "    })\n",
    "    # 재시도 횟수 5회, 간격 증가(Backoff)\n",
    "    retry = Retry(total=5, backoff_factor=2, status_forcelist=[429, 500, 502, 503, 504])\n",
    "    session.mount('https://', HTTPAdapter(max_retries=retry))\n",
    "    return session\n",
    "\n",
    "# ============================================================================\n",
    "# 1. Upbit (진짜 4시간봉 수집)\n",
    "# ============================================================================\n",
    "def collect_upbit_crypto_prices_4h():\n",
    "    print(f\"\\n[1/6] Collecting 4H cryptocurrency prices from Upbit...\")\n",
    "    session = get_session()\n",
    "    start_dt = pd.to_datetime(START_DATE)\n",
    "    merged_df = None\n",
    "    \n",
    "    for market, (symbol, _) in UPBIT_CRYPTO_TICKERS.items():\n",
    "        try:\n",
    "            all_candles = []\n",
    "            to_date = None\n",
    "            while True:\n",
    "                # minutes/240 = 4시간봉\n",
    "                url = \"https://api.upbit.com/v1/candles/minutes/240\"\n",
    "                params = {'market': market, 'count': 200}\n",
    "                if to_date: params['to'] = to_date\n",
    "                \n",
    "                # 타임아웃 10초 설정\n",
    "                resp = session.get(url, params=params, timeout=10)\n",
    "                resp.raise_for_status()\n",
    "                candles = resp.json()\n",
    "                if not candles: break\n",
    "                \n",
    "                all_candles.extend(candles)\n",
    "                \n",
    "                # 날짜 확인\n",
    "                last_date = pd.to_datetime(candles[-1]['candle_date_time_kst'])\n",
    "                if last_date <= start_dt: break\n",
    "                \n",
    "                to_date = candles[-1]['candle_date_time_utc']\n",
    "                time.sleep(0.2) # 요청 간격 0.1 -> 0.2초로 완화\n",
    "            \n",
    "            if not all_candles:\n",
    "                print(f\"  - {symbol}: No data\")\n",
    "                continue\n",
    "            \n",
    "            df = pd.DataFrame(all_candles)\n",
    "            df['timestamp'] = pd.to_datetime(df['candle_date_time_kst']) # KST 기준\n",
    "            \n",
    "            df = df.rename(columns={\n",
    "                'opening_price': f'{symbol}_Open',\n",
    "                'high_price': f'{symbol}_High',\n",
    "                'low_price': f'{symbol}_Low',\n",
    "                'trade_price': f'{symbol}_Close',\n",
    "                'candle_acc_trade_volume': f'{symbol}_Volume'\n",
    "            })\n",
    "            \n",
    "            df = df[['timestamp', f'{symbol}_Open', f'{symbol}_High', \n",
    "                    f'{symbol}_Low', f'{symbol}_Close', f'{symbol}_Volume']]\n",
    "            df = df.sort_values('timestamp')\n",
    "            df = df[df['timestamp'] >= start_dt]\n",
    "            \n",
    "            merged_df = df if merged_df is None else pd.merge(merged_df, df, on='timestamp', how='outer')\n",
    "            print(f\"  - {symbol}: {len(df)} 4H candles\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  - {symbol}: Failed ({str(e)[:50]})\")\n",
    "    \n",
    "    if merged_df is not None:\n",
    "        merged_df = merged_df.sort_values('timestamp')\n",
    "        merged_df.to_csv(os.path.join(OUTPUT_DIR, \"crypto_4h_kst.csv\"), index=False)\n",
    "        print(f\"  Saved: crypto_4h_kst.csv\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. Macro Indicators (일봉 -> 4시간봉 변환)\n",
    "# ============================================================================\n",
    "def collect_macro_indicators_4h():\n",
    "    print(f\"\\n[2/6] Collecting macro indicators (resampled to 4H)...\")\n",
    "    for ticker, name in MACRO_TICKERS.items():\n",
    "        try:\n",
    "            df = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False, interval='1d')\n",
    "            if isinstance(df.columns, pd.MultiIndex):\n",
    "                df = df.xs('Close', level=0, axis=1)\n",
    "            else:\n",
    "                df = df[['Close']]\n",
    "            \n",
    "            # 인덱스 정리\n",
    "            df.index = pd.to_datetime(df.index).tz_localize(None)\n",
    "            \n",
    "            # 4시간봉으로 리샘플링 (직전 값 채우기 - Forward Fill)\n",
    "            df_4h = df.resample('4H').ffill()\n",
    "            df_4h.columns = [name]\n",
    "            df_4h.index.name = 'timestamp'\n",
    "            \n",
    "            # 2017년부터 필터링\n",
    "            df_4h = df_4h[df_4h.index >= pd.to_datetime(START_DATE)]\n",
    "            \n",
    "            df_4h.to_csv(os.path.join(OUTPUT_DIR, f\"{name}_4h.csv\"))\n",
    "            print(f\"  - {name}: {len(df_4h)} rows\")\n",
    "        except Exception as e:\n",
    "            print(f\"  - {name}: Failed ({str(e)[:50]})\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. Fear & Greed (일봉 -> 4시간봉 변환)\n",
    "# ============================================================================\n",
    "def collect_fear_greed_4h():\n",
    "    print(f\"\\n[3/6] Collecting Fear & Greed Index (resampled to 4H)...\")\n",
    "    try:\n",
    "        session = get_session()\n",
    "        url = \"https://api.alternative.me/fng/?limit=4000&format=json\"\n",
    "        resp = session.get(url, timeout=10)\n",
    "        data = resp.json()['data']\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "        df = df[['timestamp', 'value']].rename(columns={'value': 'fear_greed'})\n",
    "        df['fear_greed'] = df['fear_greed'].astype(float)\n",
    "        df = df.set_index('timestamp').sort_index()\n",
    "        \n",
    "        # 4시간봉 리샘플링\n",
    "        df_4h = df.resample('4H').ffill().reset_index()\n",
    "        \n",
    "        df_4h.to_csv(os.path.join(OUTPUT_DIR, \"fear_greed_4h.csv\"), index=False)\n",
    "        print(f\"  - Fear & Greed: {len(df_4h)} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"  - Fear & Greed: Failed ({str(e)[:50]})\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. ETH Funding Rate (8시간봉 -> 4시간봉 변환)\n",
    "# ============================================================================\n",
    "def collect_funding_rate_4h():\n",
    "    print(f\"\\n[4/6] Collecting ETH funding rate (resampled to 4H)...\")\n",
    "    try:\n",
    "        client = Client(\"\", \"\")\n",
    "        funding_rates = []\n",
    "        start_ts = int(datetime.strptime(START_DATE, \"%Y-%m-%d\").timestamp() * 1000)\n",
    "        end_ts = int(datetime.strptime(END_DATE, \"%Y-%m-%d\").timestamp() * 1000)\n",
    "        \n",
    "        while start_ts < end_ts:\n",
    "            rates = client.futures_funding_rate(symbol='ETHUSDT', startTime=start_ts, limit=1000)\n",
    "            if not rates: break\n",
    "            funding_rates.extend(rates)\n",
    "            start_ts = rates[-1]['fundingTime'] + 1\n",
    "            time.sleep(0.2) # 0.1 -> 0.2 안전하게\n",
    "        \n",
    "        df = pd.DataFrame(funding_rates)\n",
    "        df['timestamp'] = pd.to_datetime(df['fundingTime'], unit='ms')\n",
    "        df['fundingRate'] = df['fundingRate'].astype(float)\n",
    "        df = df[['timestamp', 'fundingRate']].sort_values('timestamp').set_index('timestamp')\n",
    "        \n",
    "        # 8시간 -> 4시간 리샘플링\n",
    "        df_4h = df.resample('4H').ffill().reset_index()\n",
    "        \n",
    "        df_4h.to_csv(os.path.join(OUTPUT_DIR, \"eth_funding_rate_4h.csv\"), index=False)\n",
    "        print(f\"  - Funding Rate: {len(df_4h)} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"  - Funding Rate: Failed ({str(e)[:50]})\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. DeFi TVL (일봉 -> 4시간봉 보간)\n",
    "# ============================================================================\n",
    "def collect_defi_tvl_4h():\n",
    "    print(f\"\\n[5/6] Collecting DeFi TVL (interpolated to 4H)...\")\n",
    "    \n",
    "    # DefiLlama 라이브러리 사용하되, 안전장치 추가\n",
    "    obj = DefiLlama()\n",
    "    \n",
    "    def safe_run(func, *args):\n",
    "        try:\n",
    "            time.sleep(2) # 요청 전 2초 대기 (강력한 Rate Limit 방지)\n",
    "            return func(*args)\n",
    "        except Exception as e:\n",
    "            print(f\"    Error: {str(e)[:30]}... Retrying in 5s\")\n",
    "            time.sleep(5)\n",
    "            return func(*args) # 한번 더 시도\n",
    "\n",
    "    # 1. Chain TVL\n",
    "    try:\n",
    "        df = safe_run(obj.get_chain_hist_tvl, 'Ethereum')\n",
    "        df = df.reset_index().rename(columns={'date': 'timestamp', 'tvl': 'eth_chain_tvl'})\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        df = df.set_index('timestamp').resample('4H').interpolate().reset_index()\n",
    "        df.to_csv(os.path.join(OUTPUT_DIR, 'eth_chain_tvl_4h.csv'), index=False)\n",
    "        print(f\"  - ETH Chain TVL: {len(df)} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"  - ETH Chain TVL Failed: {e}\")\n",
    "\n",
    "    # 2. Protocol TVL\n",
    "    for protocol in DEFI_PROTOCOLS:\n",
    "        try:\n",
    "            tvl_dict = safe_run(obj.get_protocol_hist_tvl_by_chain, protocol)\n",
    "            if 'Ethereum' in tvl_dict:\n",
    "                df = tvl_dict['Ethereum'].reset_index().rename(columns={'date': 'timestamp', 'tvl': f'{protocol}_eth_tvl'})\n",
    "                df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "                # 4시간으로 부드럽게 보간 (Interpolate)\n",
    "                df_4h = df.set_index('timestamp').resample('4H').interpolate().reset_index()\n",
    "                df_4h.to_csv(os.path.join(OUTPUT_DIR, f'{protocol}_eth_tvl_4h.csv'), index=False)\n",
    "                print(f\"  - {protocol}: {len(df_4h)} rows\")\n",
    "        except Exception as e:\n",
    "            print(f\"  - {protocol}: Failed ({str(e)[:30]})\")\n",
    "\n",
    "    # 3. USDT Mcap\n",
    "    try:\n",
    "        df = safe_run(obj.get_stablecoin_hist_mcap_on_a_chain, 1, 'ethereum')\n",
    "        df = df.reset_index().rename(columns={'date': 'timestamp', 'mcap': 'usdt_eth_mcap'})\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        df_4h = df.set_index('timestamp').resample('4H').interpolate().reset_index()\n",
    "        df_4h.to_csv(os.path.join(OUTPUT_DIR, 'usdt_eth_mcap_4h.csv'), index=False)\n",
    "        print(f\"  - USDT Mcap: {len(df_4h)} rows\")\n",
    "    except: pass\n",
    "\n",
    "# ============================================================================\n",
    "# 6. Layer 2 TVL (일봉 -> 4시간봉 보간)\n",
    "# ============================================================================\n",
    "def collect_l2_tvl_4h():\n",
    "    print(f\"\\n[6/6] Collecting Layer 2 TVL (interpolated to 4H)...\")\n",
    "    session = get_session()\n",
    "    \n",
    "    for chain in L2_CHAINS:\n",
    "        try:\n",
    "            time.sleep(2) # 2초 대기\n",
    "            url = f\"https://api.llama.fi/v2/historicalChainTvl/{chain}\"\n",
    "            resp = session.get(url, timeout=20)\n",
    "            \n",
    "            if resp.status_code == 200:\n",
    "                df = pd.DataFrame(resp.json())\n",
    "                df['timestamp'] = pd.to_datetime(df['date'], unit='s')\n",
    "                df = df.set_index('timestamp').rename(columns={'tvl': f'{chain.lower()}_tvl'})\n",
    "                \n",
    "                # 4시간 보간\n",
    "                df_4h = df[f'{chain.lower()}_tvl'].resample('4H').interpolate().reset_index()\n",
    "                df_4h.to_csv(os.path.join(OUTPUT_DIR, f'{chain.lower()}_tvl_4h.csv'), index=False)\n",
    "                print(f\"  - {chain}: {len(df_4h)} rows\")\n",
    "            else:\n",
    "                print(f\"  - {chain}: API Status {resp.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  - {chain}: Failed ({str(e)[:30]})\")\n",
    "\n",
    "# ============================================================================\n",
    "# Main\n",
    "# ============================================================================\n",
    "\n",
    "print(\"ETH Price Prediction - 4H Data Collection Pipeline (Robust)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "collect_upbit_crypto_prices_4h()\n",
    "collect_macro_indicators_4h()\n",
    "collect_fear_greed_4h()\n",
    "collect_funding_rate_4h()\n",
    "collect_defi_tvl_4h()\n",
    "collect_l2_tvl_4h()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"4H Data collection completed!\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(\"=\" * 80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc36941e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Smart Merge: 0 for Pre-history, ffill for Missing\n",
      "============================================================\n",
      "Master Range: 2017-09-26 17:00:00 ~ 2025-11-27 13:00:00\n",
      "  + Merged usdt_eth_mcap_4h.csv\n",
      "  + Merged base_tvl_4h.csv\n",
      "  + Merged lido_eth_tvl_4h.csv\n",
      "  + Merged eth_chain_tvl_4h.csv\n",
      "  + Merged zksync era_tvl_4h.csv\n",
      "  + Merged aave_eth_tvl_4h.csv\n",
      "  + Merged DXY_4h.csv\n",
      "  + Merged VIX_4h.csv\n",
      "  + Merged curve-dex_eth_tvl_4h.csv\n",
      "  + Merged makerdao_eth_tvl_4h.csv\n",
      "  + Merged fear_greed_4h.csv\n",
      "  + Merged SP500_4h.csv\n",
      "  + Merged binance_4h_kst.csv\n",
      "  + Merged arbitrum_tvl_4h.csv\n",
      "  + Merged uniswap_eth_tvl_4h.csv\n",
      "  + Merged optimism_tvl_4h.csv\n",
      "  + Merged eth_funding_rate_4h.csv\n",
      "  + Merged GOLD_4h.csv\n",
      "\n",
      "Applying Smart Fill Logic...\n",
      "============================================================\n",
      "Completed! Saved to ./macro_data_4h/final_dataset_4h.csv\n",
      "Shape: (17901, 102)\n",
      "\n",
      "[Verify Logic with 'base_tvl']\n",
      "--- Head (Should be 0) ---\n",
      "            timestamp  base_tvl\n",
      "0 2017-09-26 17:00:00       0.0\n",
      "1 2017-09-26 21:00:00       0.0\n",
      "2 2017-09-27 01:00:00       0.0\n",
      "--- Tail (Should have value) ---\n",
      "                timestamp      base_tvl\n",
      "17898 2025-11-27 05:00:00  4.304308e+09\n",
      "17899 2025-11-27 09:00:00  4.304308e+09\n",
      "17900 2025-11-27 13:00:00  4.304308e+09\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "OUTPUT_DIR = \"./macro_data_4h\"\n",
    "FINAL_FILE = \"final_dataset_4h.csv\"\n",
    "\n",
    "def robust_load_csv(path):\n",
    "    # (기존과 동일: 날짜 파싱 및 정렬)\n",
    "    df = pd.read_csv(path)\n",
    "    date_col = None\n",
    "    for col in df.columns:\n",
    "        if col.lower() in ['timestamp', 'date', 'datetime', 'time', 'index']:\n",
    "            date_col = col\n",
    "            break\n",
    "    if not date_col:\n",
    "        try:\n",
    "            pd.to_datetime(df.iloc[:, 0])\n",
    "            date_col = df.columns[0]\n",
    "        except: return None\n",
    "            \n",
    "    df = df.rename(columns={date_col: 'timestamp'})\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "    df = df.dropna(subset=['timestamp'])\n",
    "    \n",
    "    if df['timestamp'].dt.tz is not None:\n",
    "        df['timestamp'] = df['timestamp'].dt.tz_localize(None)\n",
    "        \n",
    "    df['timestamp'] = df['timestamp'].dt.floor('min')\n",
    "    return df.sort_values('timestamp')\n",
    "\n",
    "def smart_merge_and_fill():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Smart Merge: 0 for Pre-history, ffill for Missing\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 1. Master (Upbit) 로드\n",
    "    upbit_path = os.path.join(OUTPUT_DIR, \"crypto_4h_kst.csv\")\n",
    "    if not os.path.exists(upbit_path):\n",
    "        print(\"Error: Master file not found.\")\n",
    "        return\n",
    "\n",
    "    df_master = robust_load_csv(upbit_path)\n",
    "    df_master = df_master.drop_duplicates('timestamp').reset_index(drop=True)\n",
    "    print(f\"Master Range: {df_master['timestamp'].min()} ~ {df_master['timestamp'].max()}\")\n",
    "\n",
    "    # 2. 모든 파일 병합 (일단 NaN 상태로)\n",
    "    all_files = glob.glob(os.path.join(OUTPUT_DIR, \"*.csv\"))\n",
    "    target_files = [f for f in all_files if \"crypto_4h_kst.csv\" not in f and \"final_dataset\" not in f]\n",
    "\n",
    "    for file_path in target_files:\n",
    "        try:\n",
    "            filename = os.path.basename(file_path)\n",
    "            df_temp = robust_load_csv(file_path)\n",
    "            if df_temp is None or df_temp.empty: continue\n",
    "            \n",
    "            df_temp = df_temp.drop_duplicates('timestamp')\n",
    "            \n",
    "            # merge_asof로 병합 (매칭 안되면 NaN 들어감)\n",
    "            df_master = pd.merge_asof(\n",
    "                df_master, \n",
    "                df_temp, \n",
    "                on='timestamp', \n",
    "                direction='backward',\n",
    "                tolerance=pd.Timedelta('24h') \n",
    "            )\n",
    "            print(f\"  + Merged {filename}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  - Error merging {filename}: {e}\")\n",
    "\n",
    "    # 3. [핵심 로직] 스마트 결측치 처리\n",
    "    print(\"\\nApplying Smart Fill Logic...\")\n",
    "    \n",
    "    # 타임스탬프를 제외한 모든 컬럼에 대해 반복\n",
    "    feature_cols = [c for c in df_master.columns if c != 'timestamp']\n",
    "    \n",
    "    for col in feature_cols:\n",
    "        # 1) 첫 유효 값(First Valid Index) 찾기\n",
    "        first_idx = df_master[col].first_valid_index()\n",
    "        \n",
    "        if first_idx is None:\n",
    "            # 데이터가 아예 하나도 없으면 전체 0\n",
    "            df_master[col] = 0\n",
    "            print(f\"  - {col}: No data (Filled 0)\")\n",
    "            continue\n",
    "            \n",
    "        # 2) 유효 구간(First Index 이후)은 ffill 적용\n",
    "        # (데이터 시작 후 발생한 결측은 '누락'이므로 직전 값 유지)\n",
    "        df_master.loc[first_idx:, col] = df_master.loc[first_idx:, col].ffill()\n",
    "        \n",
    "        # 3) 비유효 구간(First Index 이전)은 0으로 채움\n",
    "        # (데이터 시작 전이므로 '존재하지 않음' = 0)\n",
    "        df_master.loc[:first_idx, col] = df_master.loc[:first_idx, col].fillna(0)\n",
    "        \n",
    "        # 혹시 남은 NaN(맨 끝부분 등)이 있다면 0 처리 (안전장치)\n",
    "        df_master[col] = df_master[col].fillna(0)\n",
    "\n",
    "    # 4. 저장\n",
    "    save_path = os.path.join(OUTPUT_DIR, FINAL_FILE)\n",
    "    df_master.to_csv(save_path, index=False)\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Completed! Saved to {save_path}\")\n",
    "    print(f\"Shape: {df_master.shape}\")\n",
    "    \n",
    "    # 검증: 앞부분(0이어야 함)과 뒷부분(값 있어야 함) 확인\n",
    "    sample_col = [c for c in df_master.columns if 'tvl' in c.lower()][0] # TVL 컬럼 하나 골라서 확인\n",
    "    print(f\"\\n[Verify Logic with '{sample_col}']\")\n",
    "    print(\"--- Head (Should be 0) ---\")\n",
    "    print(df_master[['timestamp', sample_col]].head(3))\n",
    "    print(\"--- Tail (Should have value) ---\")\n",
    "    print(df_master[['timestamp', sample_col]].tail(3))\n",
    "    return df_master\n",
    "\n",
    "\n",
    "df= smart_merge_and_fill()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e4492ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"eth_4hour.csv\",index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23843c8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATA LOADING\n",
      "================================================================================\n",
      "(2980, 41) macro_crypto_data.csv\n",
      "(2235, 2) SP500.csv\n",
      "(2236, 2) VIX.csv\n",
      "(2237, 2) GOLD.csv\n",
      "(2238, 2) DXY.csv\n",
      "(2847, 2) fear_greed.csv\n",
      "(2187, 2) eth_funding_rate.csv\n",
      "(2915, 6) usdt_eth_mcap.csv\n",
      "(2013, 2) aave_eth_tvl.csv\n",
      "(1799, 2) lido_eth_tvl.csv\n",
      "(2515, 2) makerdao_eth_tvl.csv\n",
      "(2577, 2) uniswap_eth_tvl.csv\n",
      "(2107, 2) curve-dex_eth_tvl.csv\n",
      "(2978, 2) eth_chain_tvl.csv\n",
      "(1605, 5) layer2_tvl.csv\n",
      "macro_df last date: 2025-11-21 00:00:00\n",
      "sp500_df last date: 2025-11-20 00:00:00\n",
      "vix_df last date: 2025-11-21 00:00:00\n",
      "gold_df last date: 2025-11-21 00:00:00\n",
      "dxy_df last date: 2025-11-21 00:00:00\n",
      "fear_greed_df last date: 2025-11-21 00:00:00\n",
      "eth_funding_df last date: 2025-11-21 00:00:00\n",
      "usdt_eth_mcap_df last date: 2025-11-21 00:00:00\n",
      "aave_tvl_df last date: 2025-11-21 00:00:00\n",
      "lido_tvl_df last date: 2025-11-21 00:00:00\n",
      "makerdao_tvl_df last date: 2025-11-21 00:00:00\n",
      "uniswap_tvl_df last date: 2025-11-21 00:00:00\n",
      "curve_tvl_df last date: 2025-11-21 00:00:00\n",
      "eth_chain_tvl_df last date: 2025-11-21 00:00:00\n",
      "layer2_tvl_df last date: 2025-11-21 00:00:00\n",
      "Loaded 10 files\n",
      "2025-11-20 00:00:00\n",
      "\n",
      "================================================================================\n",
      "SENTIMENT FEATURES\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "DATA MERGING\n",
      "================================================================================\n",
      "Merged shape: (2351, 62)\n",
      "Missing before fill: 23,720\n",
      "\n",
      "================================================================================\n",
      "MISSING VALUE HANDLING\n",
      "================================================================================\n",
      "Missing after fill: 0\n",
      "Shape: (2351, 62)\n",
      "Period: 2019-06-15 ~ 2025-11-20\n",
      "Missing: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>BTC_Open</th>\n",
       "      <th>BTC_High</th>\n",
       "      <th>BTC_Low</th>\n",
       "      <th>BTC_Close</th>\n",
       "      <th>BTC_Volume</th>\n",
       "      <th>ETH_Open</th>\n",
       "      <th>ETH_High</th>\n",
       "      <th>ETH_Low</th>\n",
       "      <th>ETH_Close</th>\n",
       "      <th>...</th>\n",
       "      <th>chain_eth_chain_tvl</th>\n",
       "      <th>funding_fundingRate</th>\n",
       "      <th>l2_arbitrum_tvl</th>\n",
       "      <th>l2_optimism_tvl</th>\n",
       "      <th>l2_base_tvl</th>\n",
       "      <th>l2_zksync era_tvl</th>\n",
       "      <th>sp500_SP500</th>\n",
       "      <th>vix_VIX</th>\n",
       "      <th>gold_GOLD</th>\n",
       "      <th>dxy_DXY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>10462000.0</td>\n",
       "      <td>10600000.0</td>\n",
       "      <td>10311000.0</td>\n",
       "      <td>10528000.0</td>\n",
       "      <td>6509.174133</td>\n",
       "      <td>317900.0</td>\n",
       "      <td>326500.0</td>\n",
       "      <td>313000.0</td>\n",
       "      <td>319500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>484243010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-16</td>\n",
       "      <td>10523000.0</td>\n",
       "      <td>11150000.0</td>\n",
       "      <td>10451000.0</td>\n",
       "      <td>10710000.0</td>\n",
       "      <td>12029.902237</td>\n",
       "      <td>319500.0</td>\n",
       "      <td>330500.0</td>\n",
       "      <td>317000.0</td>\n",
       "      <td>320150.0</td>\n",
       "      <td>...</td>\n",
       "      <td>495664501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-17</td>\n",
       "      <td>10710000.0</td>\n",
       "      <td>11187000.0</td>\n",
       "      <td>10694000.0</td>\n",
       "      <td>11055000.0</td>\n",
       "      <td>8591.802320</td>\n",
       "      <td>320200.0</td>\n",
       "      <td>326050.0</td>\n",
       "      <td>319550.0</td>\n",
       "      <td>324100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>509130301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2889.669922</td>\n",
       "      <td>15.350000</td>\n",
       "      <td>1338.699951</td>\n",
       "      <td>97.559998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-18</td>\n",
       "      <td>11055000.0</td>\n",
       "      <td>11100000.0</td>\n",
       "      <td>10750000.0</td>\n",
       "      <td>10902000.0</td>\n",
       "      <td>7165.309059</td>\n",
       "      <td>324350.0</td>\n",
       "      <td>324900.0</td>\n",
       "      <td>314650.0</td>\n",
       "      <td>317800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>513188682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2917.750000</td>\n",
       "      <td>15.150000</td>\n",
       "      <td>1346.599976</td>\n",
       "      <td>97.639999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-19</td>\n",
       "      <td>10901000.0</td>\n",
       "      <td>11100000.0</td>\n",
       "      <td>10845000.0</td>\n",
       "      <td>11063000.0</td>\n",
       "      <td>5153.060822</td>\n",
       "      <td>317800.0</td>\n",
       "      <td>322500.0</td>\n",
       "      <td>316150.0</td>\n",
       "      <td>320400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>504467906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2926.459961</td>\n",
       "      <td>14.330000</td>\n",
       "      <td>1344.599976</td>\n",
       "      <td>97.120003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>2025-11-16</td>\n",
       "      <td>144265000.0</td>\n",
       "      <td>144888000.0</td>\n",
       "      <td>138663000.0</td>\n",
       "      <td>140320000.0</td>\n",
       "      <td>3306.730953</td>\n",
       "      <td>4786000.0</td>\n",
       "      <td>4876000.0</td>\n",
       "      <td>4500000.0</td>\n",
       "      <td>4613000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>149718439825</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>2.868912e+09</td>\n",
       "      <td>300706531.0</td>\n",
       "      <td>4.483150e+09</td>\n",
       "      <td>41005406.0</td>\n",
       "      <td>6734.109863</td>\n",
       "      <td>19.830000</td>\n",
       "      <td>4087.600098</td>\n",
       "      <td>99.269997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>2025-11-17</td>\n",
       "      <td>140320000.0</td>\n",
       "      <td>142926000.0</td>\n",
       "      <td>137127000.0</td>\n",
       "      <td>137706000.0</td>\n",
       "      <td>3402.729073</td>\n",
       "      <td>4613000.0</td>\n",
       "      <td>4799000.0</td>\n",
       "      <td>4461000.0</td>\n",
       "      <td>4528000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>146706008886</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>2.833770e+09</td>\n",
       "      <td>296461366.0</td>\n",
       "      <td>4.380960e+09</td>\n",
       "      <td>41025892.0</td>\n",
       "      <td>6672.410156</td>\n",
       "      <td>22.379999</td>\n",
       "      <td>4068.300049</td>\n",
       "      <td>99.589996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>2025-11-18</td>\n",
       "      <td>137706000.0</td>\n",
       "      <td>139184000.0</td>\n",
       "      <td>132200000.0</td>\n",
       "      <td>137750000.0</td>\n",
       "      <td>6342.520244</td>\n",
       "      <td>4528000.0</td>\n",
       "      <td>4695000.0</td>\n",
       "      <td>4386000.0</td>\n",
       "      <td>4627000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>143734941269</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>2.770454e+09</td>\n",
       "      <td>269449790.0</td>\n",
       "      <td>4.277518e+09</td>\n",
       "      <td>39182638.0</td>\n",
       "      <td>6617.319824</td>\n",
       "      <td>24.690001</td>\n",
       "      <td>4061.300049</td>\n",
       "      <td>99.550003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>2025-11-19</td>\n",
       "      <td>137750000.0</td>\n",
       "      <td>137807000.0</td>\n",
       "      <td>132449000.0</td>\n",
       "      <td>136500000.0</td>\n",
       "      <td>2862.635006</td>\n",
       "      <td>4629000.0</td>\n",
       "      <td>4635000.0</td>\n",
       "      <td>4301000.0</td>\n",
       "      <td>4510000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>146360583931</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>2.825563e+09</td>\n",
       "      <td>295610162.0</td>\n",
       "      <td>4.340401e+09</td>\n",
       "      <td>39802577.0</td>\n",
       "      <td>6642.160156</td>\n",
       "      <td>23.660000</td>\n",
       "      <td>4077.699951</td>\n",
       "      <td>100.230003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>2025-11-20</td>\n",
       "      <td>136500000.0</td>\n",
       "      <td>138621000.0</td>\n",
       "      <td>129800000.0</td>\n",
       "      <td>129896000.0</td>\n",
       "      <td>4303.832306</td>\n",
       "      <td>4510000.0</td>\n",
       "      <td>4561000.0</td>\n",
       "      <td>4212000.0</td>\n",
       "      <td>4243000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>143848669231</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>2.777513e+09</td>\n",
       "      <td>290218197.0</td>\n",
       "      <td>4.308060e+09</td>\n",
       "      <td>40361104.0</td>\n",
       "      <td>6538.759766</td>\n",
       "      <td>26.420000</td>\n",
       "      <td>4056.500000</td>\n",
       "      <td>100.160004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2351 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date     BTC_Open     BTC_High      BTC_Low    BTC_Close  \\\n",
       "0    2019-06-15   10462000.0   10600000.0   10311000.0   10528000.0   \n",
       "1    2019-06-16   10523000.0   11150000.0   10451000.0   10710000.0   \n",
       "2    2019-06-17   10710000.0   11187000.0   10694000.0   11055000.0   \n",
       "3    2019-06-18   11055000.0   11100000.0   10750000.0   10902000.0   \n",
       "4    2019-06-19   10901000.0   11100000.0   10845000.0   11063000.0   \n",
       "...         ...          ...          ...          ...          ...   \n",
       "2346 2025-11-16  144265000.0  144888000.0  138663000.0  140320000.0   \n",
       "2347 2025-11-17  140320000.0  142926000.0  137127000.0  137706000.0   \n",
       "2348 2025-11-18  137706000.0  139184000.0  132200000.0  137750000.0   \n",
       "2349 2025-11-19  137750000.0  137807000.0  132449000.0  136500000.0   \n",
       "2350 2025-11-20  136500000.0  138621000.0  129800000.0  129896000.0   \n",
       "\n",
       "        BTC_Volume   ETH_Open   ETH_High    ETH_Low  ETH_Close  ...  \\\n",
       "0      6509.174133   317900.0   326500.0   313000.0   319500.0  ...   \n",
       "1     12029.902237   319500.0   330500.0   317000.0   320150.0  ...   \n",
       "2      8591.802320   320200.0   326050.0   319550.0   324100.0  ...   \n",
       "3      7165.309059   324350.0   324900.0   314650.0   317800.0  ...   \n",
       "4      5153.060822   317800.0   322500.0   316150.0   320400.0  ...   \n",
       "...            ...        ...        ...        ...        ...  ...   \n",
       "2346   3306.730953  4786000.0  4876000.0  4500000.0  4613000.0  ...   \n",
       "2347   3402.729073  4613000.0  4799000.0  4461000.0  4528000.0  ...   \n",
       "2348   6342.520244  4528000.0  4695000.0  4386000.0  4627000.0  ...   \n",
       "2349   2862.635006  4629000.0  4635000.0  4301000.0  4510000.0  ...   \n",
       "2350   4303.832306  4510000.0  4561000.0  4212000.0  4243000.0  ...   \n",
       "\n",
       "      chain_eth_chain_tvl  funding_fundingRate  l2_arbitrum_tvl  \\\n",
       "0               484243010             0.000000     0.000000e+00   \n",
       "1               495664501             0.000000     0.000000e+00   \n",
       "2               509130301             0.000000     0.000000e+00   \n",
       "3               513188682             0.000000     0.000000e+00   \n",
       "4               504467906             0.000000     0.000000e+00   \n",
       "...                   ...                  ...              ...   \n",
       "2346         149718439825             0.000093     2.868912e+09   \n",
       "2347         146706008886             0.000087     2.833770e+09   \n",
       "2348         143734941269             0.000083     2.770454e+09   \n",
       "2349         146360583931             0.000066     2.825563e+09   \n",
       "2350         143848669231             0.000072     2.777513e+09   \n",
       "\n",
       "      l2_optimism_tvl   l2_base_tvl  l2_zksync era_tvl  sp500_SP500  \\\n",
       "0                 0.0  0.000000e+00                0.0     0.000000   \n",
       "1                 0.0  0.000000e+00                0.0     0.000000   \n",
       "2                 0.0  0.000000e+00                0.0  2889.669922   \n",
       "3                 0.0  0.000000e+00                0.0  2917.750000   \n",
       "4                 0.0  0.000000e+00                0.0  2926.459961   \n",
       "...               ...           ...                ...          ...   \n",
       "2346      300706531.0  4.483150e+09         41005406.0  6734.109863   \n",
       "2347      296461366.0  4.380960e+09         41025892.0  6672.410156   \n",
       "2348      269449790.0  4.277518e+09         39182638.0  6617.319824   \n",
       "2349      295610162.0  4.340401e+09         39802577.0  6642.160156   \n",
       "2350      290218197.0  4.308060e+09         40361104.0  6538.759766   \n",
       "\n",
       "        vix_VIX    gold_GOLD     dxy_DXY  \n",
       "0      0.000000     0.000000    0.000000  \n",
       "1      0.000000     0.000000    0.000000  \n",
       "2     15.350000  1338.699951   97.559998  \n",
       "3     15.150000  1346.599976   97.639999  \n",
       "4     14.330000  1344.599976   97.120003  \n",
       "...         ...          ...         ...  \n",
       "2346  19.830000  4087.600098   99.269997  \n",
       "2347  22.379999  4068.300049   99.589996  \n",
       "2348  24.690001  4061.300049   99.550003  \n",
       "2349  23.660000  4077.699951  100.230003  \n",
       "2350  26.420000  4056.500000  100.160004  \n",
       "\n",
       "[2351 rows x 62 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import warnings\n",
    "import gc\n",
    "import pickle\n",
    "import joblib\n",
    "import glob\n",
    "import traceback\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "from collections import Counter\n",
    "from numba import jit\n",
    "from sklearn.cluster import DBSCAN\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest, RFE,\n",
    "    mutual_info_classif, mutual_info_regression\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "    ,log_loss\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier,\n",
    "    GradientBoostingClassifier, HistGradientBoostingClassifier,\n",
    "    RandomForestClassifier, StackingClassifier, VotingClassifier,\n",
    "    AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor,\n",
    "    GradientBoostingRegressor, RandomForestRegressor,\n",
    "    StackingRegressor, VotingRegressor\n",
    ")\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from lightgbm.callback import early_stopping\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Flatten, Dropout, Activation,\n",
    "    LSTM, GRU, SimpleRNN, Bidirectional,\n",
    "    Conv1D, MaxPooling1D, AveragePooling1D,\n",
    "    GlobalAveragePooling1D, GlobalMaxPooling1D,\n",
    "    BatchNormalization, LayerNormalization,\n",
    "    Attention, MultiHeadAttention,\n",
    "    Concatenate, Add, Multiply, Lambda,\n",
    "    Reshape, Permute, RepeatVector, TimeDistributed\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "except ImportError:\n",
    "    pass\n",
    "# ============================================================================\n",
    "# 환경 설정 및 경고 무시\n",
    "# ============================================================================\n",
    "\n",
    "# GPU 메모리 증가 허용 설정\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "DATA_DIR_MAIN = './macro_data'\n",
    "DATA_DIR_NEW = './macro_data/macro_data'\n",
    "\n",
    "TRAIN_START_DATE = pd.to_datetime('2020-01-01')\n",
    "LOOKBACK_DAYS = 200\n",
    "LOOKBACK_START_DATE = TRAIN_START_DATE - timedelta(days=LOOKBACK_DAYS)\n",
    "\n",
    "\n",
    "def standardize_date_column(df,file_name):\n",
    "    \"\"\"날짜 컬럼 자동 탐지 + datetime 통일 + tz 제거 + 시각 제거\"\"\"\n",
    "\n",
    "    date_cols = [col for col in df.columns if 'date' in col.lower()]\n",
    "    if not date_cols:\n",
    "        print(\"[Warning] 날짜 컬럼을 찾을 수 없습니다.\")\n",
    "        return df\n",
    "    date_col = date_cols[0]\n",
    "    \n",
    "    if date_col != 'date':\n",
    "        df.rename(columns={date_col: 'date'}, inplace=True)\n",
    "    \n",
    "\n",
    "    if file_name == 'eth_onchain.csv':\n",
    "        df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d', errors='coerce')\n",
    "    else:\n",
    "        df['date'] = pd.to_datetime(df['date'], errors='coerce', infer_datetime_format=True)\n",
    "    \n",
    "    df = df.dropna(subset=['date'])\n",
    "    df['date'] = df['date'].dt.normalize()  \n",
    "    if pd.api.types.is_datetime64tz_dtype(df['date']):\n",
    "        df['date'] = df['date'].dt.tz_convert(None)\n",
    "    else:\n",
    "        df['date'] = df['date'].dt.tz_localize(None)\n",
    "    print(df.shape,file_name)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_csv(directory, filename):\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"[Warning] {filename} not found\")\n",
    "        return pd.DataFrame()\n",
    "    df = pd.read_csv(filepath)\n",
    "    return standardize_date_column(df, filename)\n",
    "\n",
    "\n",
    "def add_prefix(df, prefix):\n",
    "    if df.empty:\n",
    "        return df\n",
    "    df.columns = [f\"{prefix}_{col}\" if col != 'date' else col for col in df.columns]\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_sentiment_features(news_df):\n",
    "    if news_df.empty:\n",
    "        return pd.DataFrame(columns=['date'])\n",
    "    \n",
    "    agg = news_df.groupby('date').agg(\n",
    "        sentiment_mean=('label', 'mean'),\n",
    "        sentiment_std=('label', 'std'),\n",
    "        news_count=('label', 'count'),\n",
    "        positive_ratio=('label', lambda x: (x == 1).sum() / len(x)),\n",
    "        negative_ratio=('label', lambda x: (x == -1).sum() / len(x)),\n",
    "        extreme_positive_count=('label', lambda x: (x == 1).sum()),\n",
    "        extreme_negative_count=('label', lambda x: (x == -1).sum()),\n",
    "        sentiment_sum=('label', 'sum'),\n",
    "    ).reset_index().fillna(0)\n",
    "    \n",
    "    agg['sentiment_polarity'] = agg['positive_ratio'] - agg['negative_ratio']\n",
    "    agg['sentiment_intensity'] = agg['positive_ratio'] + agg['negative_ratio']\n",
    "    agg['sentiment_disagreement'] = agg['positive_ratio'] * agg['negative_ratio']\n",
    "    agg['bull_bear_ratio'] = agg['positive_ratio'] / (agg['negative_ratio'] + 1e-10)\n",
    "    agg['weighted_sentiment'] = agg['sentiment_mean'] * np.log1p(agg['news_count'])\n",
    "    agg['extremity_index'] = (agg['extreme_positive_count'] + agg['extreme_negative_count']) / (agg['news_count'] + 1e-10)\n",
    "    \n",
    "    for window in [3,7]:\n",
    "        agg[f'sentiment_ma{window}'] = agg['sentiment_mean'].rolling(window=window, min_periods=1).mean()\n",
    "        agg[f'sentiment_volatility_{window}'] = agg['sentiment_mean'].rolling(window=window, min_periods=1).std()\n",
    "    \n",
    "    agg['sentiment_trend'] = agg['sentiment_mean'].diff()\n",
    "    agg['sentiment_acceleration'] = agg['sentiment_trend'].diff()\n",
    "    agg['news_volume_change'] = agg['news_count'].pct_change()\n",
    "    \n",
    "    for window in [7, 14]:\n",
    "        agg[f'news_volume_ma{window}'] = agg['news_count'].rolling(window=window, min_periods=1).mean()\n",
    "    \n",
    "    return agg.fillna(0)\n",
    "\n",
    "\n",
    "def smart_fill_missing(df_merged):\n",
    "    REFERENCE_START_DATE = pd.to_datetime('2020-01-01')\n",
    "    \n",
    "    for col in df_merged.columns:\n",
    "        if col == 'date':\n",
    "            continue\n",
    "        \n",
    "        if df_merged[col].isnull().sum() == 0:\n",
    "            continue\n",
    "        \n",
    "        non_null_idx = df_merged[col].first_valid_index()\n",
    "        \n",
    "        if non_null_idx is None:\n",
    "            df_merged[col] = df_merged[col].fillna(0)\n",
    "            continue\n",
    "        \n",
    "        first_date = df_merged.loc[non_null_idx, 'date']\n",
    "        \n",
    "        before_mask = df_merged['date'] < first_date\n",
    "        after_mask = df_merged['date'] >= first_date\n",
    "        \n",
    "        df_merged.loc[before_mask, col] = df_merged.loc[before_mask, col].fillna(0)\n",
    "        df_merged.loc[after_mask, col] = df_merged.loc[after_mask, col].fillna(method='ffill')\n",
    "        \n",
    "        remaining = df_merged.loc[after_mask, col].isnull().sum()\n",
    "        if remaining > 0:\n",
    "            df_merged.loc[after_mask, col] = df_merged.loc[after_mask, col].fillna(0)\n",
    "    \n",
    "    return df_merged\n",
    "\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DATA LOADING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "#news_df = load_csv(DATA_DIR_MAIN, 'news_data.csv')\n",
    "#eth_onchain_df = load_csv(DATA_DIR_MAIN, 'eth_onchain.csv')\n",
    "macro_df = load_csv(DATA_DIR_NEW, 'macro_crypto_data.csv')\n",
    "sp500_df = load_csv(DATA_DIR_NEW, 'SP500.csv')\n",
    "vix_df = load_csv(DATA_DIR_NEW, 'VIX.csv')\n",
    "gold_df = load_csv(DATA_DIR_NEW, 'GOLD.csv')\n",
    "dxy_df = load_csv(DATA_DIR_NEW, 'DXY.csv')\n",
    "fear_greed_df = load_csv(DATA_DIR_NEW, 'fear_greed.csv')\n",
    "eth_funding_df = load_csv(DATA_DIR_NEW, 'eth_funding_rate.csv')\n",
    "usdt_eth_mcap_df = load_csv(DATA_DIR_NEW, 'usdt_eth_mcap.csv')\n",
    "aave_tvl_df = load_csv(DATA_DIR_NEW, 'aave_eth_tvl.csv')\n",
    "lido_tvl_df = load_csv(DATA_DIR_NEW, 'lido_eth_tvl.csv')\n",
    "makerdao_tvl_df = load_csv(DATA_DIR_NEW, 'makerdao_eth_tvl.csv')\n",
    "uniswap_tvl_df = load_csv(DATA_DIR_NEW, 'uniswap_eth_tvl.csv')\n",
    "curve_tvl_df = load_csv(DATA_DIR_NEW, 'curve-dex_eth_tvl.csv')\n",
    "eth_chain_tvl_df = load_csv(DATA_DIR_NEW, 'eth_chain_tvl.csv')\n",
    "layer2_tvl_df = load_csv(DATA_DIR_NEW, 'layer2_tvl.csv')\n",
    "\n",
    "print(f\"macro_df last date: {macro_df['date'].iloc[-1]}\")\n",
    "print(f\"sp500_df last date: {sp500_df['date'].iloc[-1]}\")\n",
    "print(f\"vix_df last date: {vix_df['date'].iloc[-1]}\")\n",
    "print(f\"gold_df last date: {gold_df['date'].iloc[-1]}\")\n",
    "print(f\"dxy_df last date: {dxy_df['date'].iloc[-1]}\")\n",
    "print(f\"fear_greed_df last date: {fear_greed_df['date'].iloc[-1]}\")\n",
    "print(f\"eth_funding_df last date: {eth_funding_df['date'].iloc[-1]}\")\n",
    "print(f\"usdt_eth_mcap_df last date: {usdt_eth_mcap_df['date'].iloc[-1]}\")\n",
    "print(f\"aave_tvl_df last date: {aave_tvl_df['date'].iloc[-1]}\")\n",
    "print(f\"lido_tvl_df last date: {lido_tvl_df['date'].iloc[-1]}\")\n",
    "print(f\"makerdao_tvl_df last date: {makerdao_tvl_df['date'].iloc[-1]}\")\n",
    "print(f\"uniswap_tvl_df last date: {uniswap_tvl_df['date'].iloc[-1]}\")\n",
    "print(f\"curve_tvl_df last date: {curve_tvl_df['date'].iloc[-1]}\")\n",
    "print(f\"eth_chain_tvl_df last date: {eth_chain_tvl_df['date'].iloc[-1]}\")\n",
    "print(f\"layer2_tvl_df last date: {layer2_tvl_df['date'].iloc[-1]}\")\n",
    "\n",
    "\n",
    "print(f\"Loaded {len([df for df in [fear_greed_df, eth_funding_df, usdt_eth_mcap_df, aave_tvl_df, lido_tvl_df, makerdao_tvl_df, uniswap_tvl_df, curve_tvl_df, eth_chain_tvl_df, layer2_tvl_df] if not df.empty])} files\")\n",
    "\n",
    "all_dataframes = [\n",
    "    macro_df, fear_greed_df, usdt_eth_mcap_df,\n",
    "    aave_tvl_df, lido_tvl_df, makerdao_tvl_df, uniswap_tvl_df, curve_tvl_df,\n",
    "    eth_chain_tvl_df, eth_funding_df, layer2_tvl_df, \n",
    "    sp500_df, vix_df, gold_df, dxy_df#,news_df, eth_onchain_df\n",
    "]\n",
    "\n",
    "last_dates = [\n",
    "    pd.to_datetime(df['date']).max() \n",
    "    for df in all_dataframes \n",
    "    if not df.empty and 'date' in df.columns\n",
    "]\n",
    "\n",
    "end_date = min(last_dates) if last_dates else pd.Timestamp.today()\n",
    "print(end_date)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SENTIMENT FEATURES\")\n",
    "print(\"=\"*80)\n",
    "#sentiment_features = create_sentiment_features(news_df)\n",
    "#print(f\"Generated {sentiment_features.shape[1]-1} features\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA MERGING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "#eth_onchain_df = add_prefix(eth_onchain_df, 'eth')\n",
    "fear_greed_df = add_prefix(fear_greed_df, 'fg')\n",
    "usdt_eth_mcap_df = add_prefix(usdt_eth_mcap_df, 'usdt')\n",
    "aave_tvl_df = add_prefix(aave_tvl_df, 'aave')\n",
    "lido_tvl_df = add_prefix(lido_tvl_df, 'lido')\n",
    "makerdao_tvl_df = add_prefix(makerdao_tvl_df, 'makerdao')\n",
    "uniswap_tvl_df = add_prefix(uniswap_tvl_df, 'uniswap')\n",
    "curve_tvl_df = add_prefix(curve_tvl_df, 'curve')\n",
    "eth_chain_tvl_df = add_prefix(eth_chain_tvl_df, 'chain')\n",
    "eth_funding_df = add_prefix(eth_funding_df, 'funding')\n",
    "layer2_tvl_df = add_prefix(layer2_tvl_df, 'l2')\n",
    "sp500_df = add_prefix(sp500_df, 'sp500')\n",
    "vix_df = add_prefix(vix_df, 'vix')\n",
    "gold_df = add_prefix(gold_df, 'gold')\n",
    "dxy_df = add_prefix(dxy_df, 'dxy')\n",
    "\n",
    "date_range = pd.date_range(start=LOOKBACK_START_DATE, end=end_date, freq='D')\n",
    "df_merged = pd.DataFrame(date_range, columns=['date'])\n",
    "\n",
    "dataframes_to_merge = [\n",
    "    macro_df,  fear_greed_df, usdt_eth_mcap_df,\n",
    "    aave_tvl_df, lido_tvl_df, makerdao_tvl_df, uniswap_tvl_df, curve_tvl_df,\n",
    "    eth_chain_tvl_df, eth_funding_df, layer2_tvl_df,\n",
    "    sp500_df, vix_df, gold_df, dxy_df#,sentiment_features,eth_onchain_df,\n",
    "]\n",
    "\n",
    "for df in dataframes_to_merge:\n",
    "    if not df.empty:\n",
    "        df_merged = pd.merge(df_merged, df, on='date', how='left')\n",
    "\n",
    "print(f\"Merged shape: {df_merged.shape}\")\n",
    "print(f\"Missing before fill: {df_merged.isnull().sum().sum():,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MISSING VALUE HANDLING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_merged = smart_fill_missing(df_merged)\n",
    "\n",
    "missing_after = df_merged.isnull().sum().sum()\n",
    "print(f\"Missing after fill: {missing_after:,}\")\n",
    "\n",
    "if missing_after > 0:\n",
    "    df_merged = df_merged.fillna(0)\n",
    "    print(f\"Remaining filled with 0\")\n",
    "\n",
    "lookback_df = df_merged[df_merged['date'] < TRAIN_START_DATE]\n",
    "cols_to_drop = [\n",
    "    col for col in lookback_df.columns \n",
    "    if lookback_df[col].isnull().all() and col != 'date'\n",
    "]\n",
    "\n",
    "if cols_to_drop:\n",
    "    print(f\"\\nDropping {len(cols_to_drop)} fully missing columns\")\n",
    "    df_merged = df_merged.drop(columns=cols_to_drop)\n",
    "\n",
    "print(f\"Shape: {df_merged.shape}\")\n",
    "print(f\"Period: {df_merged['date'].min().date()} ~ {df_merged['date'].max().date()}\")\n",
    "print(f\"Missing: {df_merged.isnull().sum().sum()}\")\n",
    "\n",
    "df_merged.to_csv(\"merge_data.csv\",index=False)\n",
    "\n",
    "display(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5dd7818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41e31cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching ETH 1H data: 2019-12-31 ~ 2025-11-22\n",
      "  Fetched 1000 candles... (last: 2020-02-10 16:00:00)\n",
      "  Fetched 2000 candles... (last: 2020-03-23 14:00:00)\n",
      "  Fetched 3000 candles... (last: 2020-05-04 08:00:00)\n",
      "  Fetched 4000 candles... (last: 2020-06-15 00:00:00)\n",
      "  Fetched 5000 candles... (last: 2020-07-26 19:00:00)\n",
      "  Fetched 6000 candles... (last: 2020-09-06 11:00:00)\n",
      "  Fetched 7000 candles... (last: 2020-10-18 03:00:00)\n",
      "  Fetched 8000 candles... (last: 2020-11-28 19:00:00)\n",
      "  Fetched 9000 candles... (last: 2021-01-09 17:00:00)\n",
      "  Fetched 10000 candles... (last: 2021-02-20 10:00:00)\n",
      "  Fetched 11000 candles... (last: 2021-04-03 03:00:00)\n",
      "  Fetched 12000 candles... (last: 2021-05-15 00:00:00)\n",
      "  Fetched 13000 candles... (last: 2021-06-25 16:00:00)\n",
      "  Fetched 14000 candles... (last: 2021-08-06 08:00:00)\n",
      "  Fetched 15000 candles... (last: 2021-09-17 04:00:00)\n",
      "  Fetched 16000 candles... (last: 2021-10-28 22:00:00)\n",
      "  Fetched 17000 candles... (last: 2021-12-09 14:00:00)\n",
      "  Fetched 18000 candles... (last: 2022-01-20 06:00:00)\n",
      "  Fetched 19000 candles... (last: 2022-03-02 22:00:00)\n",
      "  Fetched 20000 candles... (last: 2022-04-13 14:00:00)\n",
      "  Fetched 21000 candles... (last: 2022-05-25 06:00:00)\n",
      "  Fetched 22000 candles... (last: 2022-07-05 22:00:00)\n",
      "  Fetched 23000 candles... (last: 2022-08-16 14:00:00)\n",
      "  Fetched 24000 candles... (last: 2022-09-27 06:00:00)\n",
      "  Fetched 25000 candles... (last: 2022-11-07 22:00:00)\n",
      "  Fetched 26000 candles... (last: 2022-12-19 14:00:00)\n",
      "  Fetched 27000 candles... (last: 2023-01-30 06:00:00)\n",
      "  Fetched 28000 candles... (last: 2023-03-12 22:00:00)\n",
      "  Fetched 29000 candles... (last: 2023-04-23 15:00:00)\n",
      "  Fetched 30000 candles... (last: 2023-06-04 07:00:00)\n",
      "  Fetched 31000 candles... (last: 2023-07-15 23:00:00)\n",
      "  Fetched 32000 candles... (last: 2023-08-26 15:00:00)\n",
      "  Fetched 33000 candles... (last: 2023-10-07 07:00:00)\n",
      "  Fetched 34000 candles... (last: 2023-11-17 23:00:00)\n",
      "  Fetched 35000 candles... (last: 2023-12-29 15:00:00)\n",
      "  Fetched 36000 candles... (last: 2024-02-09 07:00:00)\n",
      "  Fetched 37000 candles... (last: 2024-03-21 23:00:00)\n",
      "  Fetched 38000 candles... (last: 2024-05-02 15:00:00)\n",
      "  Fetched 39000 candles... (last: 2024-06-13 07:00:00)\n",
      "  Fetched 40000 candles... (last: 2024-07-24 23:00:00)\n",
      "  Fetched 41000 candles... (last: 2024-09-04 15:00:00)\n",
      "  Fetched 42000 candles... (last: 2024-10-16 07:00:00)\n",
      "  Fetched 43000 candles... (last: 2024-11-26 23:00:00)\n",
      "  Fetched 44000 candles... (last: 2025-01-07 15:00:00)\n",
      "  Fetched 45000 candles... (last: 2025-02-18 07:00:00)\n",
      "  Fetched 46000 candles... (last: 2025-03-31 23:00:00)\n",
      "  Fetched 47000 candles... (last: 2025-05-12 15:00:00)\n",
      "  Fetched 48000 candles... (last: 2025-06-23 07:00:00)\n",
      "  Fetched 49000 candles... (last: 2025-08-03 23:00:00)\n",
      "  Fetched 50000 candles... (last: 2025-09-14 15:00:00)\n",
      "  Fetched 51000 candles... (last: 2025-10-26 07:00:00)\n",
      "  Fetched 51643 candles... (last: 2025-11-22 02:00:00)\n",
      "Done! Total 51643 hourly candles\n"
     ]
    }
   ],
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def fetch_eth_hourly_data(start_date='2019-12-31', end_date=None):\n",
    "    exchange = ccxt.binance({\n",
    "        'enableRateLimit': True,\n",
    "    })\n",
    "    \n",
    "    if end_date is None:\n",
    "        end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    start_ts = exchange.parse8601(f\"{start_date}T00:00:00Z\")\n",
    "    end_ts = exchange.parse8601(f\"{end_date}T23:59:59Z\")\n",
    "    \n",
    "    symbol = 'ETH/USDT'\n",
    "    timeframe = '1h'\n",
    "    limit = 1000\n",
    "    \n",
    "    all_data = []\n",
    "    current_ts = start_ts\n",
    "    \n",
    "    print(f\"Fetching ETH 1H data: {start_date} ~ {end_date}\")\n",
    "    \n",
    "    while current_ts < end_ts:\n",
    "        try:\n",
    "            ohlcv = exchange.fetch_ohlcv(symbol, timeframe, since=current_ts, limit=limit)\n",
    "            \n",
    "            if not ohlcv:\n",
    "                break\n",
    "                \n",
    "            all_data.extend(ohlcv)\n",
    "            current_ts = ohlcv[-1][0] + 1\n",
    "            \n",
    "            print(f\"  Fetched {len(all_data)} candles... (last: {pd.to_datetime(ohlcv[-1][0], unit='ms')})\")\n",
    "            \n",
    "            time.sleep(0.1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error: {e}, retrying in 5s...\")\n",
    "            time.sleep(5)\n",
    "    \n",
    "    df = pd.DataFrame(all_data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "    df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    df = df.drop_duplicates(subset='timestamp').reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Done! Total {len(df)} hourly candles\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 실행\n",
    "eth_hourly = fetch_eth_hourly_data('2019-12-31')\n",
    "eth_hourly.to_csv('eth_hour.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5217321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51608</th>\n",
       "      <td>1763740800000</td>\n",
       "      <td>2705.31</td>\n",
       "      <td>2764.00</td>\n",
       "      <td>2675.00</td>\n",
       "      <td>2762.80</td>\n",
       "      <td>60752.9527</td>\n",
       "      <td>2025-11-21 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51609</th>\n",
       "      <td>1763744400000</td>\n",
       "      <td>2762.81</td>\n",
       "      <td>2806.84</td>\n",
       "      <td>2754.89</td>\n",
       "      <td>2780.48</td>\n",
       "      <td>41775.1804</td>\n",
       "      <td>2025-11-21 17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51610</th>\n",
       "      <td>1763748000000</td>\n",
       "      <td>2780.49</td>\n",
       "      <td>2794.49</td>\n",
       "      <td>2716.49</td>\n",
       "      <td>2779.15</td>\n",
       "      <td>58923.6202</td>\n",
       "      <td>2025-11-21 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51611</th>\n",
       "      <td>1763751600000</td>\n",
       "      <td>2779.15</td>\n",
       "      <td>2787.96</td>\n",
       "      <td>2740.22</td>\n",
       "      <td>2752.24</td>\n",
       "      <td>24520.2215</td>\n",
       "      <td>2025-11-21 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51612</th>\n",
       "      <td>1763755200000</td>\n",
       "      <td>2752.23</td>\n",
       "      <td>2756.21</td>\n",
       "      <td>2708.55</td>\n",
       "      <td>2737.86</td>\n",
       "      <td>29540.1573</td>\n",
       "      <td>2025-11-21 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51613</th>\n",
       "      <td>1763758800000</td>\n",
       "      <td>2737.83</td>\n",
       "      <td>2777.01</td>\n",
       "      <td>2731.49</td>\n",
       "      <td>2767.23</td>\n",
       "      <td>22201.3102</td>\n",
       "      <td>2025-11-21 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51614</th>\n",
       "      <td>1763762400000</td>\n",
       "      <td>2767.22</td>\n",
       "      <td>2774.09</td>\n",
       "      <td>2720.72</td>\n",
       "      <td>2721.88</td>\n",
       "      <td>12754.9720</td>\n",
       "      <td>2025-11-21 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51615</th>\n",
       "      <td>1763766000000</td>\n",
       "      <td>2721.89</td>\n",
       "      <td>2769.80</td>\n",
       "      <td>2713.15</td>\n",
       "      <td>2765.85</td>\n",
       "      <td>17494.4632</td>\n",
       "      <td>2025-11-21 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51616</th>\n",
       "      <td>1763769600000</td>\n",
       "      <td>2765.86</td>\n",
       "      <td>2780.59</td>\n",
       "      <td>2758.21</td>\n",
       "      <td>2766.35</td>\n",
       "      <td>11148.7247</td>\n",
       "      <td>2025-11-22 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51617</th>\n",
       "      <td>1763773200000</td>\n",
       "      <td>2766.36</td>\n",
       "      <td>2784.12</td>\n",
       "      <td>2761.49</td>\n",
       "      <td>2781.77</td>\n",
       "      <td>5257.3860</td>\n",
       "      <td>2025-11-22 01:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           timestamp     open     high      low    close      volume  \\\n",
       "51608  1763740800000  2705.31  2764.00  2675.00  2762.80  60752.9527   \n",
       "51609  1763744400000  2762.81  2806.84  2754.89  2780.48  41775.1804   \n",
       "51610  1763748000000  2780.49  2794.49  2716.49  2779.15  58923.6202   \n",
       "51611  1763751600000  2779.15  2787.96  2740.22  2752.24  24520.2215   \n",
       "51612  1763755200000  2752.23  2756.21  2708.55  2737.86  29540.1573   \n",
       "51613  1763758800000  2737.83  2777.01  2731.49  2767.23  22201.3102   \n",
       "51614  1763762400000  2767.22  2774.09  2720.72  2721.88  12754.9720   \n",
       "51615  1763766000000  2721.89  2769.80  2713.15  2765.85  17494.4632   \n",
       "51616  1763769600000  2765.86  2780.59  2758.21  2766.35  11148.7247   \n",
       "51617  1763773200000  2766.36  2784.12  2761.49  2781.77   5257.3860   \n",
       "\n",
       "                 datetime  \n",
       "51608 2025-11-21 16:00:00  \n",
       "51609 2025-11-21 17:00:00  \n",
       "51610 2025-11-21 18:00:00  \n",
       "51611 2025-11-21 19:00:00  \n",
       "51612 2025-11-21 20:00:00  \n",
       "51613 2025-11-21 21:00:00  \n",
       "51614 2025-11-21 22:00:00  \n",
       "51615 2025-11-21 23:00:00  \n",
       "51616 2025-11-22 00:00:00  \n",
       "51617 2025-11-22 01:00:00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eth_hourly.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "129b253c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1577836800000</td>\n",
       "      <td>129.16</td>\n",
       "      <td>129.19</td>\n",
       "      <td>128.68</td>\n",
       "      <td>128.87</td>\n",
       "      <td>7769.17336</td>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1577840400000</td>\n",
       "      <td>128.87</td>\n",
       "      <td>130.65</td>\n",
       "      <td>128.78</td>\n",
       "      <td>130.64</td>\n",
       "      <td>11344.65516</td>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1577844000000</td>\n",
       "      <td>130.63</td>\n",
       "      <td>130.98</td>\n",
       "      <td>130.35</td>\n",
       "      <td>130.85</td>\n",
       "      <td>7603.35623</td>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1577847600000</td>\n",
       "      <td>130.85</td>\n",
       "      <td>130.89</td>\n",
       "      <td>129.94</td>\n",
       "      <td>130.20</td>\n",
       "      <td>4968.55433</td>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1577851200000</td>\n",
       "      <td>130.21</td>\n",
       "      <td>130.74</td>\n",
       "      <td>130.15</td>\n",
       "      <td>130.20</td>\n",
       "      <td>3397.90747</td>\n",
       "      <td>2020-01-01 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1577854800000</td>\n",
       "      <td>130.20</td>\n",
       "      <td>130.47</td>\n",
       "      <td>130.11</td>\n",
       "      <td>130.30</td>\n",
       "      <td>4243.60640</td>\n",
       "      <td>2020-01-01 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1577858400000</td>\n",
       "      <td>130.31</td>\n",
       "      <td>130.75</td>\n",
       "      <td>130.26</td>\n",
       "      <td>130.44</td>\n",
       "      <td>3668.90166</td>\n",
       "      <td>2020-01-01 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1577862000000</td>\n",
       "      <td>130.47</td>\n",
       "      <td>130.71</td>\n",
       "      <td>130.14</td>\n",
       "      <td>130.24</td>\n",
       "      <td>4147.17413</td>\n",
       "      <td>2020-01-01 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1577865600000</td>\n",
       "      <td>130.24</td>\n",
       "      <td>130.41</td>\n",
       "      <td>129.87</td>\n",
       "      <td>130.36</td>\n",
       "      <td>7541.44497</td>\n",
       "      <td>2020-01-01 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1577869200000</td>\n",
       "      <td>130.40</td>\n",
       "      <td>130.62</td>\n",
       "      <td>130.13</td>\n",
       "      <td>130.17</td>\n",
       "      <td>4808.20496</td>\n",
       "      <td>2020-01-01 09:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp    open    high     low   close       volume  \\\n",
       "0  1577836800000  129.16  129.19  128.68  128.87   7769.17336   \n",
       "1  1577840400000  128.87  130.65  128.78  130.64  11344.65516   \n",
       "2  1577844000000  130.63  130.98  130.35  130.85   7603.35623   \n",
       "3  1577847600000  130.85  130.89  129.94  130.20   4968.55433   \n",
       "4  1577851200000  130.21  130.74  130.15  130.20   3397.90747   \n",
       "5  1577854800000  130.20  130.47  130.11  130.30   4243.60640   \n",
       "6  1577858400000  130.31  130.75  130.26  130.44   3668.90166   \n",
       "7  1577862000000  130.47  130.71  130.14  130.24   4147.17413   \n",
       "8  1577865600000  130.24  130.41  129.87  130.36   7541.44497   \n",
       "9  1577869200000  130.40  130.62  130.13  130.17   4808.20496   \n",
       "\n",
       "             datetime  \n",
       "0 2020-01-01 00:00:00  \n",
       "1 2020-01-01 01:00:00  \n",
       "2 2020-01-01 02:00:00  \n",
       "3 2020-01-01 03:00:00  \n",
       "4 2020-01-01 04:00:00  \n",
       "5 2020-01-01 05:00:00  \n",
       "6 2020-01-01 06:00:00  \n",
       "7 2020-01-01 07:00:00  \n",
       "8 2020-01-01 08:00:00  \n",
       "9 2020-01-01 09:00:00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eth_hourly.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8da1a4a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Upbit KRW-ETH 1H data: 2020-01-01 ~ now\n",
      "  Fetched 200 candles... (oldest: 2025-11-19 07:00:00)\n",
      "  Fetched 400 candles... (oldest: 2025-11-11 08:00:00)\n",
      "  Fetched 600 candles... (oldest: 2025-11-03 09:00:00)\n",
      "  Fetched 800 candles... (oldest: 2025-10-26 10:00:00)\n",
      "  Fetched 1000 candles... (oldest: 2025-10-18 06:00:00)\n",
      "  Fetched 1200 candles... (oldest: 2025-10-10 07:00:00)\n",
      "  Fetched 1400 candles... (oldest: 2025-10-02 08:00:00)\n",
      "  Fetched 1600 candles... (oldest: 2025-09-24 09:00:00)\n",
      "  Fetched 1800 candles... (oldest: 2025-09-16 10:00:00)\n",
      "  Fetched 2000 candles... (oldest: 2025-09-08 11:00:00)\n",
      "  Fetched 2200 candles... (oldest: 2025-08-31 12:00:00)\n",
      "  Fetched 2400 candles... (oldest: 2025-08-23 13:00:00)\n",
      "  Fetched 2600 candles... (oldest: 2025-08-15 14:00:00)\n",
      "  Fetched 2800 candles... (oldest: 2025-08-07 15:00:00)\n",
      "  Fetched 3000 candles... (oldest: 2025-07-30 16:00:00)\n",
      "  Fetched 3200 candles... (oldest: 2025-07-22 17:00:00)\n",
      "  Fetched 3400 candles... (oldest: 2025-07-14 18:00:00)\n",
      "  Fetched 3600 candles... (oldest: 2025-07-06 19:00:00)\n",
      "  Fetched 3800 candles... (oldest: 2025-06-28 16:00:00)\n",
      "  Fetched 4000 candles... (oldest: 2025-06-20 17:00:00)\n",
      "  Fetched 4200 candles... (oldest: 2025-06-12 18:00:00)\n",
      "  Fetched 4400 candles... (oldest: 2025-06-04 19:00:00)\n",
      "  Fetched 4600 candles... (oldest: 2025-05-27 20:00:00)\n",
      "  Fetched 4800 candles... (oldest: 2025-05-19 21:00:00)\n",
      "  Fetched 5000 candles... (oldest: 2025-05-11 22:00:00)\n",
      "  Fetched 5200 candles... (oldest: 2025-05-03 23:00:00)\n",
      "  Fetched 5400 candles... (oldest: 2025-04-26 00:00:00)\n",
      "  Fetched 5600 candles... (oldest: 2025-04-18 01:00:00)\n",
      "  Fetched 5800 candles... (oldest: 2025-04-10 02:00:00)\n",
      "  Fetched 6000 candles... (oldest: 2025-04-02 03:00:00)\n",
      "  Fetched 6200 candles... (oldest: 2025-03-24 23:00:00)\n",
      "  Fetched 6400 candles... (oldest: 2025-03-17 00:00:00)\n",
      "  Fetched 6600 candles... (oldest: 2025-03-09 01:00:00)\n",
      "  Fetched 6800 candles... (oldest: 2025-03-01 02:00:00)\n",
      "  Fetched 7000 candles... (oldest: 2025-02-21 03:00:00)\n",
      "  Fetched 7200 candles... (oldest: 2025-02-13 04:00:00)\n",
      "  Fetched 7400 candles... (oldest: 2025-02-05 05:00:00)\n",
      "  Fetched 7600 candles... (oldest: 2025-01-28 06:00:00)\n",
      "  Fetched 7800 candles... (oldest: 2025-01-20 07:00:00)\n",
      "  Fetched 8000 candles... (oldest: 2025-01-12 08:00:00)\n",
      "  Fetched 8200 candles... (oldest: 2025-01-04 09:00:00)\n",
      "  Fetched 8400 candles... (oldest: 2024-12-27 06:00:00)\n",
      "  Fetched 8600 candles... (oldest: 2024-12-19 07:00:00)\n",
      "  Fetched 8800 candles... (oldest: 2024-12-11 08:00:00)\n",
      "  Fetched 9000 candles... (oldest: 2024-12-03 09:00:00)\n",
      "  Fetched 9200 candles... (oldest: 2024-11-25 10:00:00)\n",
      "  Fetched 9400 candles... (oldest: 2024-11-17 11:00:00)\n",
      "  Fetched 9600 candles... (oldest: 2024-11-09 12:00:00)\n",
      "  Fetched 9800 candles... (oldest: 2024-11-01 13:00:00)\n",
      "  Fetched 10000 candles... (oldest: 2024-10-24 14:00:00)\n",
      "  Fetched 10200 candles... (oldest: 2024-10-16 15:00:00)\n",
      "  Fetched 10400 candles... (oldest: 2024-10-08 12:00:00)\n",
      "  Fetched 10600 candles... (oldest: 2024-09-30 13:00:00)\n",
      "  Fetched 10800 candles... (oldest: 2024-09-22 14:00:00)\n",
      "  Fetched 11000 candles... (oldest: 2024-09-14 15:00:00)\n",
      "  Fetched 11200 candles... (oldest: 2024-09-06 16:00:00)\n",
      "  Fetched 11400 candles... (oldest: 2024-08-29 17:00:00)\n",
      "  Fetched 11600 candles... (oldest: 2024-08-21 18:00:00)\n",
      "  Fetched 11800 candles... (oldest: 2024-08-13 19:00:00)\n",
      "  Fetched 12000 candles... (oldest: 2024-08-05 20:00:00)\n",
      "  Fetched 12200 candles... (oldest: 2024-07-28 21:00:00)\n",
      "  Fetched 12400 candles... (oldest: 2024-07-20 22:00:00)\n",
      "  Fetched 12600 candles... (oldest: 2024-07-12 23:00:00)\n",
      "  Fetched 12800 candles... (oldest: 2024-07-05 00:00:00)\n",
      "  Fetched 13000 candles... (oldest: 2024-06-26 22:00:00)\n",
      "  Fetched 13200 candles... (oldest: 2024-06-18 23:00:00)\n",
      "  Fetched 13400 candles... (oldest: 2024-06-11 00:00:00)\n",
      "  Fetched 13600 candles... (oldest: 2024-06-03 01:00:00)\n",
      "  Fetched 13800 candles... (oldest: 2024-05-26 02:00:00)\n",
      "  Fetched 14000 candles... (oldest: 2024-05-18 03:00:00)\n",
      "  Fetched 14200 candles... (oldest: 2024-05-10 04:00:00)\n",
      "  Fetched 14400 candles... (oldest: 2024-05-02 05:00:00)\n",
      "  Fetched 14600 candles... (oldest: 2024-04-24 06:00:00)\n",
      "  Fetched 14800 candles... (oldest: 2024-04-16 07:00:00)\n",
      "  Fetched 15000 candles... (oldest: 2024-04-08 08:00:00)\n",
      "  Fetched 15200 candles... (oldest: 2024-03-31 06:00:00)\n",
      "  Fetched 15400 candles... (oldest: 2024-03-23 07:00:00)\n",
      "  Fetched 15600 candles... (oldest: 2024-03-15 08:00:00)\n",
      "  Fetched 15800 candles... (oldest: 2024-03-07 09:00:00)\n",
      "  Fetched 16000 candles... (oldest: 2024-02-28 10:00:00)\n",
      "  Fetched 16200 candles... (oldest: 2024-02-20 11:00:00)\n",
      "  Fetched 16400 candles... (oldest: 2024-02-12 12:00:00)\n",
      "  Fetched 16600 candles... (oldest: 2024-02-04 13:00:00)\n",
      "  Fetched 16800 candles... (oldest: 2024-01-27 14:00:00)\n",
      "  Fetched 17000 candles... (oldest: 2024-01-19 15:00:00)\n",
      "  Fetched 17200 candles... (oldest: 2024-01-11 16:00:00)\n",
      "  Fetched 17400 candles... (oldest: 2024-01-03 17:00:00)\n",
      "  Fetched 17600 candles... (oldest: 2023-12-26 15:00:00)\n",
      "  Fetched 17800 candles... (oldest: 2023-12-18 16:00:00)\n",
      "  Fetched 18000 candles... (oldest: 2023-12-10 17:00:00)\n",
      "  Fetched 18200 candles... (oldest: 2023-12-02 13:00:00)\n",
      "  Fetched 18400 candles... (oldest: 2023-11-24 14:00:00)\n",
      "  Fetched 18600 candles... (oldest: 2023-11-16 15:00:00)\n",
      "  Fetched 18800 candles... (oldest: 2023-11-08 16:00:00)\n",
      "  Fetched 19000 candles... (oldest: 2023-10-31 17:00:00)\n",
      "  Fetched 19200 candles... (oldest: 2023-10-23 18:00:00)\n",
      "  Fetched 19400 candles... (oldest: 2023-10-15 19:00:00)\n",
      "  Fetched 19600 candles... (oldest: 2023-10-07 20:00:00)\n",
      "  Fetched 19800 candles... (oldest: 2023-09-29 21:00:00)\n",
      "  Fetched 20000 candles... (oldest: 2023-09-21 22:00:00)\n",
      "  Fetched 20200 candles... (oldest: 2023-09-13 23:00:00)\n",
      "  Fetched 20400 candles... (oldest: 2023-09-06 00:00:00)\n",
      "  Fetched 20600 candles... (oldest: 2023-08-29 01:00:00)\n",
      "  Fetched 20800 candles... (oldest: 2023-08-21 02:00:00)\n",
      "  Fetched 21000 candles... (oldest: 2023-08-13 03:00:00)\n",
      "  Fetched 21200 candles... (oldest: 2023-08-05 01:00:00)\n",
      "  Fetched 21400 candles... (oldest: 2023-07-28 02:00:00)\n",
      "  Fetched 21600 candles... (oldest: 2023-07-20 03:00:00)\n",
      "  Fetched 21800 candles... (oldest: 2023-07-12 01:00:00)\n",
      "  Fetched 22000 candles... (oldest: 2023-07-03 23:00:00)\n",
      "  Fetched 22200 candles... (oldest: 2023-06-26 00:00:00)\n",
      "  Fetched 22400 candles... (oldest: 2023-06-18 01:00:00)\n",
      "  Fetched 22600 candles... (oldest: 2023-06-10 02:00:00)\n",
      "  Fetched 22800 candles... (oldest: 2023-06-02 03:00:00)\n",
      "  Fetched 23000 candles... (oldest: 2023-05-25 04:00:00)\n",
      "  Fetched 23200 candles... (oldest: 2023-05-17 05:00:00)\n",
      "  Fetched 23400 candles... (oldest: 2023-05-09 06:00:00)\n",
      "  Fetched 23600 candles... (oldest: 2023-05-01 07:00:00)\n",
      "  Fetched 23800 candles... (oldest: 2023-04-23 03:00:00)\n",
      "  Fetched 24000 candles... (oldest: 2023-04-15 04:00:00)\n",
      "  Fetched 24200 candles... (oldest: 2023-04-07 05:00:00)\n",
      "  Fetched 24400 candles... (oldest: 2023-03-30 03:00:00)\n",
      "  Fetched 24600 candles... (oldest: 2023-03-22 04:00:00)\n",
      "  Fetched 24800 candles... (oldest: 2023-03-14 05:00:00)\n",
      "  Fetched 25000 candles... (oldest: 2023-03-06 06:00:00)\n",
      "  Fetched 25200 candles... (oldest: 2023-02-26 07:00:00)\n",
      "  Fetched 25400 candles... (oldest: 2023-02-18 08:00:00)\n",
      "  Fetched 25600 candles... (oldest: 2023-02-10 09:00:00)\n",
      "  Fetched 25800 candles... (oldest: 2023-02-02 10:00:00)\n",
      "  Fetched 26000 candles... (oldest: 2023-01-25 11:00:00)\n",
      "  Fetched 26200 candles... (oldest: 2023-01-17 12:00:00)\n",
      "  Fetched 26400 candles... (oldest: 2023-01-09 13:00:00)\n",
      "  Fetched 26600 candles... (oldest: 2023-01-01 14:00:00)\n",
      "  Fetched 26800 candles... (oldest: 2022-12-24 13:00:00)\n",
      "  Fetched 27000 candles... (oldest: 2022-12-16 14:00:00)\n",
      "  Fetched 27200 candles... (oldest: 2022-12-08 15:00:00)\n",
      "  Fetched 27400 candles... (oldest: 2022-11-30 16:00:00)\n",
      "  Fetched 27600 candles... (oldest: 2022-11-22 17:00:00)\n",
      "  Fetched 27800 candles... (oldest: 2022-11-14 18:00:00)\n",
      "  Fetched 28000 candles... (oldest: 2022-11-06 19:00:00)\n",
      "  Fetched 28200 candles... (oldest: 2022-10-29 20:00:00)\n",
      "  Fetched 28400 candles... (oldest: 2022-10-21 21:00:00)\n",
      "  Fetched 28600 candles... (oldest: 2022-10-13 22:00:00)\n",
      "  Fetched 28800 candles... (oldest: 2022-10-05 23:00:00)\n",
      "  Fetched 29000 candles... (oldest: 2022-09-27 23:00:00)\n",
      "  Fetched 29200 candles... (oldest: 2022-09-20 00:00:00)\n",
      "  Fetched 29400 candles... (oldest: 2022-09-12 01:00:00)\n",
      "  Fetched 29600 candles... (oldest: 2022-09-04 02:00:00)\n",
      "  Fetched 29800 candles... (oldest: 2022-08-27 03:00:00)\n",
      "  Fetched 30000 candles... (oldest: 2022-08-19 04:00:00)\n",
      "  Fetched 30200 candles... (oldest: 2022-08-11 05:00:00)\n",
      "  Fetched 30400 candles... (oldest: 2022-08-03 06:00:00)\n",
      "  Fetched 30600 candles... (oldest: 2022-07-26 07:00:00)\n",
      "  Fetched 30800 candles... (oldest: 2022-07-18 08:00:00)\n",
      "  Fetched 31000 candles... (oldest: 2022-07-10 09:00:00)\n",
      "  Fetched 31200 candles... (oldest: 2022-07-02 10:00:00)\n",
      "  Fetched 31400 candles... (oldest: 2022-06-24 08:00:00)\n",
      "  Fetched 31600 candles... (oldest: 2022-06-16 09:00:00)\n",
      "  Fetched 31800 candles... (oldest: 2022-06-08 10:00:00)\n",
      "  Fetched 32000 candles... (oldest: 2022-05-31 11:00:00)\n",
      "  Fetched 32200 candles... (oldest: 2022-05-23 11:00:00)\n",
      "  Fetched 32400 candles... (oldest: 2022-05-15 12:00:00)\n",
      "  Fetched 32600 candles... (oldest: 2022-05-07 13:00:00)\n",
      "  Fetched 32800 candles... (oldest: 2022-04-29 14:00:00)\n",
      "  Fetched 33000 candles... (oldest: 2022-04-21 15:00:00)\n",
      "  Fetched 33200 candles... (oldest: 2022-04-13 16:00:00)\n",
      "  Fetched 33400 candles... (oldest: 2022-04-05 17:00:00)\n",
      "  Fetched 33600 candles... (oldest: 2022-03-28 18:00:00)\n",
      "  Fetched 33800 candles... (oldest: 2022-03-20 19:00:00)\n",
      "  Fetched 34000 candles... (oldest: 2022-03-12 20:00:00)\n",
      "  Fetched 34200 candles... (oldest: 2022-03-04 21:00:00)\n",
      "  Fetched 34400 candles... (oldest: 2022-02-24 22:00:00)\n",
      "  Fetched 34600 candles... (oldest: 2022-02-16 23:00:00)\n",
      "  Fetched 34800 candles... (oldest: 2022-02-08 23:00:00)\n",
      "  Fetched 35000 candles... (oldest: 2022-02-01 00:00:00)\n",
      "  Fetched 35200 candles... (oldest: 2022-01-24 01:00:00)\n",
      "  Fetched 35400 candles... (oldest: 2022-01-16 02:00:00)\n",
      "  Fetched 35600 candles... (oldest: 2022-01-08 03:00:00)\n",
      "  Fetched 35800 candles... (oldest: 2021-12-31 02:00:00)\n",
      "  Fetched 36000 candles... (oldest: 2021-12-23 03:00:00)\n",
      "  Fetched 36200 candles... (oldest: 2021-12-15 04:00:00)\n",
      "  Fetched 36400 candles... (oldest: 2021-12-07 05:00:00)\n",
      "  Fetched 36600 candles... (oldest: 2021-11-29 06:00:00)\n",
      "  Fetched 36800 candles... (oldest: 2021-11-21 07:00:00)\n",
      "  Fetched 37000 candles... (oldest: 2021-11-13 07:00:00)\n",
      "  Fetched 37200 candles... (oldest: 2021-11-05 08:00:00)\n",
      "  Fetched 37400 candles... (oldest: 2021-10-28 09:00:00)\n",
      "  Fetched 37600 candles... (oldest: 2021-10-20 10:00:00)\n",
      "  Fetched 37800 candles... (oldest: 2021-10-12 10:00:00)\n",
      "  Fetched 38000 candles... (oldest: 2021-10-04 11:00:00)\n",
      "  Fetched 38200 candles... (oldest: 2021-09-26 12:00:00)\n",
      "  Fetched 38400 candles... (oldest: 2021-09-18 13:00:00)\n",
      "  Fetched 38600 candles... (oldest: 2021-09-10 14:00:00)\n",
      "  Fetched 38800 candles... (oldest: 2021-09-02 15:00:00)\n",
      "  Fetched 39000 candles... (oldest: 2021-08-25 16:00:00)\n",
      "  Fetched 39200 candles... (oldest: 2021-08-17 17:00:00)\n",
      "  Fetched 39400 candles... (oldest: 2021-08-09 17:00:00)\n",
      "  Fetched 39600 candles... (oldest: 2021-08-01 18:00:00)\n",
      "  Fetched 39800 candles... (oldest: 2021-07-24 19:00:00)\n",
      "  Fetched 40000 candles... (oldest: 2021-07-16 20:00:00)\n",
      "  Fetched 40200 candles... (oldest: 2021-07-08 21:00:00)\n",
      "  Fetched 40400 candles... (oldest: 2021-06-30 20:00:00)\n",
      "  Fetched 40600 candles... (oldest: 2021-06-22 19:00:00)\n",
      "  Fetched 40800 candles... (oldest: 2021-06-14 20:00:00)\n",
      "  Fetched 41000 candles... (oldest: 2021-06-06 21:00:00)\n",
      "  Fetched 41200 candles... (oldest: 2021-05-29 21:00:00)\n",
      "  Fetched 41400 candles... (oldest: 2021-05-21 22:00:00)\n",
      "  Fetched 41600 candles... (oldest: 2021-05-13 23:00:00)\n",
      "  Fetched 41800 candles... (oldest: 2021-05-06 00:00:00)\n",
      "  Fetched 42000 candles... (oldest: 2021-04-28 01:00:00)\n",
      "  Fetched 42200 candles... (oldest: 2021-04-20 02:00:00)\n",
      "  Fetched 42400 candles... (oldest: 2021-04-12 02:00:00)\n",
      "  Fetched 42600 candles... (oldest: 2021-04-04 03:00:00)\n",
      "  Fetched 42800 candles... (oldest: 2021-03-27 04:00:00)\n",
      "  Fetched 43000 candles... (oldest: 2021-03-19 03:00:00)\n",
      "  Fetched 43200 candles... (oldest: 2021-03-11 03:00:00)\n",
      "  Fetched 43400 candles... (oldest: 2021-03-03 02:00:00)\n",
      "  Fetched 43600 candles... (oldest: 2021-02-23 01:00:00)\n",
      "  Fetched 43800 candles... (oldest: 2021-02-14 23:00:00)\n",
      "  Fetched 44000 candles... (oldest: 2021-02-07 00:00:00)\n",
      "  Fetched 44200 candles... (oldest: 2021-01-30 00:00:00)\n",
      "  Fetched 44400 candles... (oldest: 2021-01-22 01:00:00)\n",
      "  Fetched 44600 candles... (oldest: 2021-01-14 02:00:00)\n",
      "  Fetched 44800 candles... (oldest: 2021-01-06 03:00:00)\n",
      "  Fetched 45000 candles... (oldest: 2020-12-29 04:00:00)\n",
      "  Fetched 45200 candles... (oldest: 2020-12-21 05:00:00)\n",
      "  Fetched 45400 candles... (oldest: 2020-12-13 06:00:00)\n",
      "  Fetched 45600 candles... (oldest: 2020-12-05 07:00:00)\n",
      "  Fetched 45800 candles... (oldest: 2020-11-27 08:00:00)\n",
      "  Fetched 46000 candles... (oldest: 2020-11-19 09:00:00)\n",
      "  Fetched 46200 candles... (oldest: 2020-11-11 10:00:00)\n",
      "  Fetched 46400 candles... (oldest: 2020-11-03 11:00:00)\n",
      "  Fetched 46600 candles... (oldest: 2020-10-26 12:00:00)\n",
      "  Fetched 46800 candles... (oldest: 2020-10-18 13:00:00)\n",
      "  Fetched 47000 candles... (oldest: 2020-10-10 14:00:00)\n",
      "  Fetched 47200 candles... (oldest: 2020-10-02 15:00:00)\n",
      "  Fetched 47400 candles... (oldest: 2020-09-24 15:00:00)\n",
      "  Fetched 47600 candles... (oldest: 2020-09-16 16:00:00)\n",
      "  Fetched 47800 candles... (oldest: 2020-09-08 17:00:00)\n",
      "  Fetched 48000 candles... (oldest: 2020-08-31 18:00:00)\n",
      "  Fetched 48200 candles... (oldest: 2020-08-23 19:00:00)\n",
      "  Fetched 48400 candles... (oldest: 2020-08-15 20:00:00)\n",
      "  Fetched 48600 candles... (oldest: 2020-08-07 21:00:00)\n",
      "  Fetched 48800 candles... (oldest: 2020-07-30 22:00:00)\n",
      "  Fetched 49000 candles... (oldest: 2020-07-22 23:00:00)\n",
      "  Fetched 49200 candles... (oldest: 2020-07-14 23:00:00)\n",
      "  Fetched 49400 candles... (oldest: 2020-07-07 00:00:00)\n",
      "  Fetched 49600 candles... (oldest: 2020-06-29 01:00:00)\n",
      "  Fetched 49800 candles... (oldest: 2020-06-21 02:00:00)\n",
      "  Fetched 50000 candles... (oldest: 2020-06-12 23:00:00)\n",
      "  Fetched 50200 candles... (oldest: 2020-06-05 00:00:00)\n",
      "  Fetched 50400 candles... (oldest: 2020-05-28 01:00:00)\n",
      "  Fetched 50600 candles... (oldest: 2020-05-20 02:00:00)\n",
      "  Fetched 50800 candles... (oldest: 2020-05-12 03:00:00)\n",
      "  Fetched 51000 candles... (oldest: 2020-05-04 04:00:00)\n",
      "  Fetched 51200 candles... (oldest: 2020-04-26 05:00:00)\n",
      "  Fetched 51400 candles... (oldest: 2020-04-18 06:00:00)\n",
      "  Fetched 51600 candles... (oldest: 2020-04-10 07:00:00)\n",
      "  Fetched 51800 candles... (oldest: 2020-04-02 08:00:00)\n",
      "  Fetched 52000 candles... (oldest: 2020-03-25 09:00:00)\n",
      "  Fetched 52200 candles... (oldest: 2020-03-17 10:00:00)\n",
      "  Fetched 52400 candles... (oldest: 2020-03-09 11:00:00)\n",
      "  Fetched 52600 candles... (oldest: 2020-03-01 12:00:00)\n",
      "  Fetched 52800 candles... (oldest: 2020-02-22 13:00:00)\n",
      "  Fetched 53000 candles... (oldest: 2020-02-14 14:00:00)\n",
      "  Fetched 53200 candles... (oldest: 2020-02-06 15:00:00)\n",
      "  Fetched 53400 candles... (oldest: 2020-01-29 15:00:00)\n",
      "  Fetched 53600 candles... (oldest: 2020-01-21 16:00:00)\n",
      "  Fetched 53800 candles... (oldest: 2020-01-13 17:00:00)\n",
      "  Fetched 54000 candles... (oldest: 2020-01-05 18:00:00)\n",
      "  Fetched 54200 candles... (oldest: 2019-12-28 19:00:00)\n",
      "Done! Total 51700 hourly candles\n",
      "Period: 2020-01-01 00:00:00 ~ 2025-11-27 14:00:00\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def fetch_upbit_hourly(market='KRW-ETH', start_date='2020-01-01'):\n",
    "    all_data = []\n",
    "    to_date = pd.Timestamp.now()\n",
    "    start_ts = pd.to_datetime(start_date)\n",
    "    \n",
    "    print(f\"Fetching Upbit {market} 1H data: {start_date} ~ now\")\n",
    "    \n",
    "    while to_date > start_ts:\n",
    "        url = \"https://api.upbit.com/v1/candles/minutes/60\"\n",
    "        params = {\n",
    "            'market': market,\n",
    "            'to': to_date.strftime('%Y-%m-%dT%H:%M:%S'),\n",
    "            'count': 200\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, params=params)\n",
    "            data = response.json()\n",
    "            \n",
    "            if not data or isinstance(data, dict):\n",
    "                break\n",
    "            \n",
    "            all_data.extend(data)\n",
    "            \n",
    "            oldest = pd.to_datetime(data[-1]['candle_date_time_kst'])\n",
    "            to_date = oldest\n",
    "            \n",
    "            print(f\"  Fetched {len(all_data)} candles... (oldest: {oldest})\")\n",
    "            \n",
    "            time.sleep(0.15)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error: {e}, retrying...\")\n",
    "            time.sleep(1)\n",
    "    \n",
    "    df = pd.DataFrame(all_data)\n",
    "    df = df.rename(columns={\n",
    "        'candle_date_time_kst': 'datetime',\n",
    "        'opening_price': 'open',\n",
    "        'high_price': 'high',\n",
    "        'low_price': 'low',\n",
    "        'trade_price': 'close',\n",
    "        'candle_acc_trade_volume': 'volume'\n",
    "    })\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.sort_values('datetime').reset_index(drop=True)\n",
    "    df = df[['datetime', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    df = df.drop_duplicates(subset='datetime').reset_index(drop=True)\n",
    "    \n",
    "    mask = df['datetime'] >= start_date\n",
    "    df = df[mask].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Done! Total {len(df)} hourly candles\")\n",
    "    print(f\"Period: {df['datetime'].min()} ~ {df['datetime'].max()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "eth_hourly_krw = fetch_upbit_hourly('KRW-ETH', '2020-01-01')\n",
    "eth_hourly_krw.to_csv('eth_hour.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9ebc051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>149900.0</td>\n",
       "      <td>150100.0</td>\n",
       "      <td>148300.0</td>\n",
       "      <td>148550.0</td>\n",
       "      <td>3676.176695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    datetime      open      high       low     close       volume\n",
       "0 2020-01-01  149900.0  150100.0  148300.0  148550.0  3676.176695"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eth_hourly_krw.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71f46643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51585</th>\n",
       "      <td>2025-11-22 20:00:00</td>\n",
       "      <td>4077000.0</td>\n",
       "      <td>4119000.0</td>\n",
       "      <td>4062000.0</td>\n",
       "      <td>4106000.0</td>\n",
       "      <td>1373.884989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51586</th>\n",
       "      <td>2025-11-22 21:00:00</td>\n",
       "      <td>4105000.0</td>\n",
       "      <td>4110000.0</td>\n",
       "      <td>4075000.0</td>\n",
       "      <td>4091000.0</td>\n",
       "      <td>1138.311529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51587</th>\n",
       "      <td>2025-11-22 22:00:00</td>\n",
       "      <td>4091000.0</td>\n",
       "      <td>4110000.0</td>\n",
       "      <td>4077000.0</td>\n",
       "      <td>4087000.0</td>\n",
       "      <td>1126.442067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51588</th>\n",
       "      <td>2025-11-22 23:00:00</td>\n",
       "      <td>4087000.0</td>\n",
       "      <td>4134000.0</td>\n",
       "      <td>4087000.0</td>\n",
       "      <td>4122000.0</td>\n",
       "      <td>945.695091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 datetime       open       high        low      close  \\\n",
       "51585 2025-11-22 20:00:00  4077000.0  4119000.0  4062000.0  4106000.0   \n",
       "51586 2025-11-22 21:00:00  4105000.0  4110000.0  4075000.0  4091000.0   \n",
       "51587 2025-11-22 22:00:00  4091000.0  4110000.0  4077000.0  4087000.0   \n",
       "51588 2025-11-22 23:00:00  4087000.0  4134000.0  4087000.0  4122000.0   \n",
       "\n",
       "            volume  \n",
       "51585  1373.884989  \n",
       "51586  1138.311529  \n",
       "51587  1126.442067  \n",
       "51588   945.695091  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eth_hourly_krw.tail(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

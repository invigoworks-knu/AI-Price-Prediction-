{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46d5667d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 10:08:09.839415: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-22 10:08:09.839462: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-22 10:08:09.840854: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-22 10:08:09.847795: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-22 10:08:10.625654: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ‚öôÔ∏è Í∏∞Î≥∏ ÎùºÏù¥Î∏åÎü¨Î¶¨ Î∞è ÏãúÏä§ÌÖú Ïú†Ìã∏Î¶¨Ìã∞\n",
    "# ============================================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "import time\n",
    "import json\n",
    "import joblib\n",
    "import traceback\n",
    "from dotenv import load_dotenv\n",
    "from collections import Counter\n",
    "from numba import jit # JIT Ïª¥ÌååÏùºÎü¨\n",
    "from datetime import datetime, timedelta # ÎÇ†Ïßú/ÏãúÍ∞Ñ Ï≤òÎ¶¨\n",
    "\n",
    "# ============================================================================\n",
    "# üìä Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ Î∞è Î∂ÑÏÑù\n",
    "# ============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta # Í∏∞Ïà†Ï†Å Î∂ÑÏÑù ÎùºÏù¥Î∏åÎü¨Î¶¨\n",
    "\n",
    "# ============================================================================\n",
    "# üìà Î®∏Ïã†Îü¨Îãù (Scikit-learn)\n",
    "# ============================================================================\n",
    "\n",
    "# üìå Ï†ÑÏ≤òÎ¶¨ Î∞è ÏÑ†ÌÉù\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest, RFE,\n",
    "    mutual_info_classif, mutual_info_regression\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler,MinMaxScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight # ÌÅ¥ÎûòÏä§ Î∂àÍ∑†Ìòï Ï≤òÎ¶¨\n",
    "\n",
    "# üìå Î™®Îç∏ (Í∏∞Î≥∏)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neural_network import MLPClassifier # Multi-layer Perceptron\n",
    "\n",
    "# üìå Î™®Îç∏ (ÏïôÏÉÅÎ∏î)\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier, AdaBoostRegressor,\n",
    "    BaggingClassifier, BaggingRegressor,\n",
    "    ExtraTreesClassifier, ExtraTreesRegressor,\n",
    "    GradientBoostingClassifier, GradientBoostingRegressor,\n",
    "    HistGradientBoostingClassifier, # ÌûàÏä§ÌÜ†Í∑∏Îû® Í∏∞Î∞ò GB\n",
    "    RandomForestClassifier, RandomForestRegressor,\n",
    "    StackingClassifier, StackingRegressor,\n",
    "    VotingClassifier, VotingRegressor\n",
    ")\n",
    "\n",
    "# üìå ÌèâÍ∞Ä ÏßÄÌëú\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, # Î∂ÑÎ•ò\n",
    "    mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error, # ÌöåÍ∑Ä\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# üöÄ Î∂ÄÏä§ÌåÖ Í≥ÑÏó¥ Î™®Îç∏\n",
    "# ============================================================================\n",
    "import optuna # ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏµúÏ†ÅÌôî\n",
    "\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from lightgbm.callback import early_stopping\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "# ============================================================================\n",
    "# üß† Îî•Îü¨Îãù (TensorFlow/Keras)\n",
    "# ============================================================================\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    # Í∏∞Î≥∏\n",
    "    Input, Dense, Flatten, Dropout, Activation,\n",
    "    # RNN/ÏãúÌÄÄÏä§\n",
    "    LSTM, GRU, SimpleRNN, Bidirectional, TimeDistributed, RepeatVector,\n",
    "    # CNN\n",
    "    Conv1D, MaxPooling1D, AveragePooling1D,\n",
    "    GlobalAveragePooling1D, GlobalMaxPooling1D,\n",
    "    # Ï†ïÍ∑úÌôî\n",
    "    BatchNormalization, LayerNormalization,\n",
    "    # Ïú†Ìã∏Î¶¨Ìã∞\n",
    "    Concatenate, Add, Multiply, Lambda, Reshape, Permute\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1_l2, l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# ============================================================================\n",
    "# ‚è±Ô∏è ÏãúÍ≥ÑÏó¥ Î∂ÑÏÑù (Statsmodels)\n",
    "# ============================================================================\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "\n",
    "# ============================================================================\n",
    "# ‚ö° PyTorch (ÏÑ†ÌÉùÏ†Å)\n",
    "# ============================================================================\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "except ImportError:\n",
    "    # PyTorchÍ∞Ä ÏÑ§ÏπòÎêòÏßÄ ÏïäÏùÄ Í≤ΩÏö∞ Î¨¥Ïãú\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7d354a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================================\n",
    "# 1. Ïú†Ìã∏Î¶¨Ìã∞ Ìï®Ïàò (ÏßÄÌëú Ï∂îÍ∞ÄÏö©)\n",
    "# ==========================================================================\n",
    "\n",
    "def add_indicator_to_df(df_ta, indicator):\n",
    "    \"\"\"pandas_ta ÏßÄÌëú Í≤∞Í≥ºÎ•º DataFrameÏóê ÏïàÏ†ÑÌïòÍ≤å Ï∂îÍ∞Ä\"\"\"\n",
    "    if indicator is None:\n",
    "        return\n",
    "\n",
    "    if isinstance(indicator, pd.DataFrame) and not indicator.empty:\n",
    "        for col in indicator.columns:\n",
    "            df_ta[col] = indicator[col]\n",
    "    elif isinstance(indicator, pd.Series) and not indicator.empty:\n",
    "        colname = indicator.name if indicator.name else 'Unnamed'\n",
    "        df_ta[colname] = indicator\n",
    "\n",
    "def safe_add(df_ta, func, *args, **kwargs):\n",
    "    \"\"\"ÏßÄÌëú ÏÉùÏÑ± Ïãú Ïò§Î•ò Î∞©ÏßÄÎ•º ÏúÑÌïú ÎûòÌçº Ìï®Ïàò\"\"\"\n",
    "    try:\n",
    "        result = func(*args, **kwargs)\n",
    "        add_indicator_to_df(df_ta, result)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "# ==========================================================================\n",
    "# 2. Í∏∞Ïà†Ï†Å ÏßÄÌëú ÏÉùÏÑ± (Sniper Optimization)\n",
    "# ==========================================================================\n",
    "\n",
    "def calculate_technical_indicators(df):\n",
    "    \"\"\"\n",
    "    [1Ïñµ ÌòÑÎ¨º Ìà¨ÏûêÏö© ÏµúÏ†ÅÌôî ÏßÄÌëú]\n",
    "    - Ï§ëÎ≥µ ÏßÄÌëú(TEMA, DEMA Îì±) Ï†úÍ±∞\n",
    "    - Swing High/Low Breakout(ÎèåÌåå Îß§Îß§) ÏßÄÌëú Ï∂îÍ∞Ä\n",
    "    \"\"\"\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    df_ta = df.copy()\n",
    "\n",
    "    close = df['ETH_Close']\n",
    "    high = df.get('ETH_High', close)\n",
    "    low = df.get('ETH_Low', close)\n",
    "    volume = df.get('ETH_Volume', pd.Series(index=df.index, data=1))\n",
    "    open_ = df.get('ETH_Open', close)\n",
    "\n",
    "    # 1. [Î≥ÄÎèôÏÑ±] ATR Î∞è Î≥ºÎ¶∞Ï†Ä Î∞¥Îìú\n",
    "    df_ta['ATR_14'] = ta.atr(high, low, close, length=14)\n",
    "    bb = ta.bbands(close, length=20, std=2)\n",
    "    if bb is not None:\n",
    "        df_ta['BB_WIDTH'] = bb.iloc[:, 2]  # Bandwidth\n",
    "\n",
    "    # 2. [Ï∂îÏÑ∏] Ïã†Î¢∞ÎèÑ ÎÜíÏùÄ Ïù¥ÌèâÏÑ†Îßå Ïú†ÏßÄ\n",
    "    df_ta['SMA_20'] = ta.sma(close, length=20)\n",
    "    df_ta['SMA_50'] = ta.sma(close, length=50)\n",
    "    df_ta['EMA_12'] = ta.ema(close, length=12)\n",
    "    \n",
    "    # Ï∂îÏÑ∏ Ï†êÏàò (Ï†ïÎ∞∞Ïó¥ Ïó¨Î∂Ä)\n",
    "    df_ta['TREND_SCORE'] = (close > df_ta['SMA_20']).astype(int) + (df_ta['SMA_20'] > df_ta['SMA_50']).astype(int)\n",
    "\n",
    "    # 3. [Î™®Î©òÌÖÄ] RSI, MACD\n",
    "    df_ta['RSI_14'] = ta.rsi(close, length=14)\n",
    "    safe_add(df_ta, ta.macd, close, fast=12, slow=26, signal=9)\n",
    "\n",
    "    # 4. [Í±∞ÎûòÎüâ] OBV, MFI, ÏÉÅÎåÄ Í±∞ÎûòÎüâ\n",
    "    df_ta['OBV'] = ta.obv(close, volume)\n",
    "    df_ta['MFI_14'] = ta.mfi(high, low, close, volume, length=14)\n",
    "    df_ta['VOLUME_RATIO'] = volume / (volume.rolling(20).mean() + 1e-8)\n",
    "\n",
    "    # 5. [Ìå®ÌÑ¥] ÏúóÍº¨Î¶¨/ÏïÑÎû´Íº¨Î¶¨\n",
    "    df_ta['UPPER_SHADOW'] = (high - np.maximum(close, open_)) / (high - low + 1e-9)\n",
    "    df_ta['LOWER_SHADOW'] = (np.minimum(close, open_) - low) / (high - low + 1e-9)\n",
    "\n",
    "    # 6. [ÌïµÏã¨] Swing Breakout (Ï†ÄÌï≠/ÏßÄÏßÄ ÎèåÌåå)\n",
    "    for window in [5, 20, 60]:\n",
    "        swing_high = high.rolling(window).max().shift(1)\n",
    "        swing_low = low.rolling(window).min().shift(1)\n",
    "        \n",
    "        # ÏúÑÏπò (1.0 ÎèåÌåå Ïãú Îß§Ïàò Ïã†Ìò∏)\n",
    "        df_ta[f'PRICE_VS_HIGH_{window}d'] = close / (swing_high + 1e-9)\n",
    "        df_ta[f'PRICE_VS_LOW_{window}d'] = close / (swing_low + 1e-9)\n",
    "        \n",
    "        # ÎèåÌåå Í∞ïÎèÑ (ATR ÎåÄÎπÑ)\n",
    "        df_ta[f'BREAKOUT_STR_{window}d'] = (close - swing_high) / (df_ta['ATR_14'] + 1e-9)\n",
    "\n",
    "    return df_ta\n",
    "\n",
    "# ==========================================================================\n",
    "# 3. ÌååÏÉù Î≥ÄÏàò Î∞è Ï†ÑÏ≤òÎ¶¨ Ìï®Ïàò \n",
    "# ==========================================================================\n",
    "\n",
    "def add_enhanced_cross_crypto_features(df):\n",
    "    df_enhanced = df.copy()\n",
    "    df_enhanced['eth_return'] = df['ETH_Close'].pct_change().fillna(0)\n",
    "    \n",
    "    if 'BTC_Close' in df.columns:\n",
    "        df_enhanced['btc_return'] = df['BTC_Close'].pct_change().fillna(0)\n",
    "        # ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ\n",
    "        for window in [7, 30]:\n",
    "            df_enhanced[f'eth_btc_corr_{window}d'] = (\n",
    "                df_enhanced['eth_return'].rolling(window).corr(df_enhanced['btc_return'])\n",
    "            ).fillna(0)\n",
    "        # Ïä§ÌîÑÎ†àÎìú\n",
    "        df_enhanced['eth_btc_spread'] = df_enhanced['eth_return'] - df_enhanced['btc_return']\n",
    "        \n",
    "    return df_enhanced\n",
    "\n",
    "def add_price_lag_features_first(df):\n",
    "    \"\"\"Í∞ÄÍ≤© Ìå®ÌÑ¥ ÌïôÏäµÏö© Lag\"\"\"\n",
    "    df_new = df.copy()\n",
    "    close = df['ETH_Close']\n",
    "    # ÌïµÏã¨Ï†ÅÏù∏ 1, 2, 3, 5, 10Ïùº Ï†ÑÎßå ÌôïÏù∏\n",
    "    for lag in [1, 2, 3, 5, 10]:\n",
    "        df_new[f'return_lag{lag}'] = close.pct_change(periods=lag).shift(1)\n",
    "    return df_new\n",
    "\n",
    "def add_interaction_features(df):\n",
    "    df_interact = df.copy()\n",
    "    # Í±∞ÎûòÎüâ Ïã§Î¶∞ ÏßÄÌëú ÌôïÏù∏\n",
    "    if 'RSI_14' in df.columns and 'VOLUME_RATIO' in df.columns:\n",
    "        df_interact['RSI_Volume_Strength'] = df['RSI_14'] * df['VOLUME_RATIO']\n",
    "    return df_interact\n",
    "\n",
    "def add_volatility_regime_features(df):\n",
    "    df_regime = df.copy()\n",
    "    # Î≥ÄÎèôÏÑ± Ï≤¥Ï†ú ÌôïÏù∏\n",
    "    if 'ATR_14' in df.columns:\n",
    "        atr_ma = df['ATR_14'].rolling(20).mean()\n",
    "        df_regime['high_volatility_regime'] = (df['ATR_14'] > atr_ma).astype(int)\n",
    "    return df_regime\n",
    "\n",
    "def add_percentile_features(df):\n",
    "    df_pct = df.copy()\n",
    "    # ÌòÑÏû¨ Í∞ÄÍ≤© ÏúÑÏπò (Îû≠ÌÅ¨)\n",
    "    if 'ETH_Close' in df.columns:\n",
    "        df_pct['price_rank_250d'] = df['ETH_Close'].rolling(250).rank(pct=True)\n",
    "    return df_pct\n",
    "\n",
    "def preprocess_non_stationary_features(df):\n",
    "    \"\"\"Ïô∏Î∂Ä Îç∞Ïù¥ÌÑ∞(TVL Îì±) Ï†ïÍ∑úÌôî\"\"\"\n",
    "    df_proc = df.copy()\n",
    "    \n",
    "    prefixes_to_transform = [\n",
    "        'eth_', 'aave_', 'lido_', 'makerdao_', 'uniswap_', 'curve_', 'chain_',\n",
    "        'l2_', 'sp500_', 'gold_', 'dxy_', 'vix_', 'usdt_'\n",
    "    ]\n",
    "    \n",
    "    exclude_prefixes = ['fg_', 'funding_']\n",
    "    exclude_keywords = [\n",
    "        '_pct_', '_ratio', '_lag', '_volatility', '_corr', '_beta', '_spread',\n",
    "        'eth_return', 'btc_return', 'eth_log_return',\n",
    "        'RSI', 'MFI', 'CCI', 'ADX', 'BOP', 'AROON', 'PRICE_VS', 'BREAKOUT'\n",
    "    ]\n",
    "    \n",
    "    cols_to_transform = []\n",
    "    for col in df_proc.columns:\n",
    "        col_lower = col.lower()\n",
    "        if col.startswith(tuple(prefixes_to_transform)):\n",
    "            if not col.startswith(tuple(exclude_prefixes)):\n",
    "                if not any(k.lower() in col_lower for k in exclude_keywords):\n",
    "                    cols_to_transform.append(col)\n",
    "                    \n",
    "    cols_to_drop = []\n",
    "    for col in cols_to_transform:\n",
    "        series = df_proc[col].fillna(method='ffill').replace(0, 1e-9)\n",
    "        # 1Ïùº Î≥ÄÌôîÏú®\n",
    "        df_proc[f'{col}_pct_1d'] = series.pct_change(1)\n",
    "        # 30Ïùº Ïù¥ÎèôÌèâÍ∑† ÎåÄÎπÑ ÎπÑÏú®\n",
    "        ma_30 = series.rolling(window=30, min_periods=10).mean()\n",
    "        df_proc[f'{col}_ma30_ratio'] = series / (ma_30 + 1e-9)\n",
    "        cols_to_drop.append(col)\n",
    "\n",
    "    df_proc = df_proc.drop(columns=cols_to_drop, errors='ignore')\n",
    "    df_proc = df_proc.replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    \n",
    "    return df_proc\n",
    "\n",
    "# ==========================================================================\n",
    "# 4. Í≤∞Ï∏°Ïπò Î∞è Ï¥àÍ∏∞ Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ (Burn-in)\n",
    "# ==========================================================================\n",
    "\n",
    "def handle_missing_values_paper_based(df_clean, train_start_date, is_train=True, train_stats=None):\n",
    "    \"\"\"Ï¥àÍ∏∞ 200Ïùº Îç∞Ïù¥ÌÑ∞ Ï†úÍ±∞ (ÏïàÏ†ïÏÑ± ÌôïÎ≥¥)\"\"\"\n",
    "    burn_in_period = 200\n",
    "    if len(df_clean) > burn_in_period:\n",
    "        df_clean = df_clean.sort_values('date').reset_index(drop=True)\n",
    "        df_clean = df_clean.iloc[burn_in_period:].reset_index(drop=True)\n",
    "\n",
    "    if isinstance(train_start_date, str):\n",
    "        train_start_date = pd.to_datetime(train_start_date)\n",
    "    df_clean = df_clean[df_clean['date'] >= train_start_date].reset_index(drop=True)\n",
    "    \n",
    "    target_cols = ['next_log_return', 'next_direction', 'next_close','next_open', \n",
    "                   'take_profit_price', 'stop_loss_price', 'exit_reason']\n",
    "    feature_cols = [col for col in df_clean.columns if col not in target_cols + ['date']]\n",
    "    \n",
    "    df_clean[feature_cols] = df_clean[feature_cols].fillna(method='ffill').fillna(0)\n",
    "    df_clean[feature_cols] = df_clean[feature_cols].replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    if is_train:\n",
    "        return df_clean, {}\n",
    "    else:\n",
    "        return df_clean\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "# 5. Îç∞Ïù¥ÌÑ∞ ÎàÑÏàò Î∞©ÏßÄ Î∞è Ï†ïÏ†ú\n",
    "# ==========================================================================\n",
    "\n",
    "def remove_raw_prices_and_transform(df, target_type, method):\n",
    "    df_transformed = df.copy()\n",
    "    \n",
    "    if 'eth_log_return' not in df_transformed.columns:\n",
    "        df_transformed['eth_log_return'] = np.log(df['ETH_Close'] / df['ETH_Close'].shift(1))\n",
    "    \n",
    "    remove_patterns = ['_Close', '_Open', '_High', '_Low', '_Volume']\n",
    "    keep_keywords = [\n",
    "        '_lag', '_position', '_ratio', '_range', '_change', '_corr', '_volatility', '_obv',\n",
    "        'PRICE_VS', 'BREAKOUT', 'UPPER_SHADOW', 'LOWER_SHADOW', 'BB_WIDTH'\n",
    "    ]\n",
    "    \n",
    "    cols_to_remove = [\n",
    "        col for col in df_transformed.columns\n",
    "        if any(p in col for p in remove_patterns)\n",
    "        and not any(d in col.lower() for d in [k.lower() for k in keep_keywords])\n",
    "    ]\n",
    "    df_transformed.drop(cols_to_remove, axis=1, inplace=True)\n",
    "\n",
    "    return_cols = [col for col in df_transformed.columns if 'return' in col.lower() and 'next' not in col]\n",
    "    if return_cols:\n",
    "        df_transformed[return_cols] = df_transformed[return_cols].fillna(0)\n",
    "\n",
    "    return df_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2d34771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================================\n",
    "# 6. ÌÉÄÍ≤ü ÏÉùÏÑ± \n",
    "# ==========================================================================\n",
    "from numba import jit\n",
    "\n",
    "@jit(nopython=True)\n",
    "def compute_targets_real_entry_numba(\n",
    "    prices_close, prices_open, prices_high, prices_low, atr,\n",
    "    lookahead, risk_reward, stop_mult\n",
    "):\n",
    "    n = len(prices_close)\n",
    "    targets = np.zeros(n, dtype=np.int32) \n",
    "    \n",
    "    for i in range(n - lookahead - 1):\n",
    "        current_atr = atr[i]\n",
    "        if np.isnan(current_atr) or current_atr <= 0:\n",
    "            continue\n",
    "            \n",
    "        entry_price = prices_open[i + 1]\n",
    "        \n",
    "        stop_dist = current_atr * stop_mult\n",
    "        profit_dist = stop_dist * risk_reward\n",
    "        \n",
    "        upper = entry_price + profit_dist\n",
    "        lower = entry_price - stop_dist\n",
    "        \n",
    "        for j in range(1, lookahead + 1):\n",
    "            idx = i + j\n",
    "            \n",
    "            future_high = prices_high[idx]\n",
    "            future_low = prices_low[idx]\n",
    "\n",
    "            if future_low <= lower:\n",
    "                targets[i] = -1 \n",
    "                break\n",
    "            \n",
    "            if future_high >= upper:\n",
    "                targets[i] = 1 \n",
    "                break\n",
    "                \n",
    "    return targets\n",
    "\n",
    "def create_targets(df, lookahead=5, profit_mult=2.0, stop_mult=1.0, **kwargs):\n",
    "    df_target = df.copy()\n",
    "    \n",
    "    if 'ATR_14' not in df_target.columns:\n",
    "        df_target['ATR_14'] = ta.atr(\n",
    "            df_target['ETH_High'], df_target['ETH_Low'], df_target['ETH_Close'], length=14\n",
    "        )\n",
    "    \n",
    "    close = df_target['ETH_Close'].to_numpy()\n",
    "    open_p = df_target['ETH_Open'].to_numpy()\n",
    "    high = df_target['ETH_High'].to_numpy()\n",
    "    low = df_target['ETH_Low'].to_numpy()\n",
    "    atr = df_target['ATR_14'].fillna(method='ffill').fillna(0).to_numpy()\n",
    "    \n",
    "    rr_ratio = profit_mult / max(stop_mult, 0.1)\n",
    "    \n",
    "    targets = compute_targets_real_entry_numba(\n",
    "        close, open_p, high, low, atr, lookahead, rr_ratio, stop_mult\n",
    "    )\n",
    "    \n",
    "    df_target['next_direction'] = targets+1\n",
    "    \n",
    "    df_target['next_close'] = df_target['ETH_Close'].shift(-1) \n",
    "    df_target['next_open'] = df_target['ETH_Open'].shift(-1)   \n",
    "    \n",
    "    df_target['next_log_return'] = np.log(\n",
    "        df_target['next_close'] / (df_target['next_open'] + 1e-9)\n",
    "    )\n",
    "    \n",
    "    next_open = df_target['ETH_Open'].shift(-1)\n",
    "    df_target['real_entry_price'] = next_open\n",
    "    df_target['take_profit_price'] = next_open + (df_target['ATR_14'] * stop_mult * rr_ratio)\n",
    "    df_target['stop_loss_price'] = next_open - (df_target['ATR_14'] * stop_mult)\n",
    "    \n",
    "    df_target.iloc[-lookahead:, df_target.columns.get_loc('next_direction')] = np.nan\n",
    "    \n",
    "    return df_target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba073e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_verified(X_train, y_train, task='class', top_n=20, verbose=True):\n",
    "    if task == 'class':\n",
    "        mi_scores = mutual_info_classif(X_train, y_train, random_state=42, n_neighbors=3)\n",
    "    else:\n",
    "        mi_scores = mutual_info_regression(X_train, y_train, random_state=42, n_neighbors=3)\n",
    "    mi_idx = np.argsort(mi_scores)[::-1][:top_n]\n",
    "    mi_features = X_train.columns[mi_idx].tolist()\n",
    "    \n",
    "    estimator = LGBMClassifier(n_estimators=100, random_state=42, verbose=-1) if task == 'class' else LGBMRegressor(n_estimators=100, random_state=42, verbose=-1)\n",
    "    rfe = RFE(estimator=estimator, n_features_to_select=top_n, step=0.1, verbose=0)\n",
    "    rfe.fit(X_train, y_train)\n",
    "    rfe_features = X_train.columns[rfe.support_].tolist()\n",
    "\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42, n_jobs=-1) if task == 'class' else RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    rf_idx = np.argsort(rf_model.feature_importances_)[::-1][:top_n]\n",
    "    rf_features = X_train.columns[rf_idx].tolist()\n",
    "    \n",
    "    all_features = mi_features + rfe_features + rf_features\n",
    "    feature_votes = Counter(all_features)\n",
    "    selected_features = [feat for feat, _ in feature_votes.most_common(top_n)]\n",
    "    \n",
    "    if len(selected_features) < top_n:\n",
    "        remaining = top_n - len(selected_features)\n",
    "        for feat in mi_features:\n",
    "            if feat not in selected_features:\n",
    "                selected_features.append(feat)\n",
    "                remaining -= 1\n",
    "                if remaining == 0: break\n",
    "    \n",
    "    return selected_features, {}\n",
    "\n",
    "def select_features_multi_target(X_train, y_train, target_type='direction', top_n=20):\n",
    "    atr_col_name = 'ATR_14'\n",
    "    if target_type == 'direction':\n",
    "        selected, stats = select_features_verified(X_train, y_train['next_direction'], task='class', top_n=top_n)\n",
    "        \n",
    "        if atr_col_name not in selected and atr_col_name in X_train.columns:\n",
    "            if len(selected) > 0: selected.pop()\n",
    "            selected.insert(0, atr_col_name)\n",
    "            \n",
    "    print(f\"\\n[Feature Selection] Top {len(selected)} Features Selected:\")\n",
    "    print(f\" -> {', '.join(selected)}\")\n",
    "    return selected, stats\n",
    "\n",
    "def process_single_split(split_data, target_type='direction', top_n=20, fold_idx=None, trend_params=None): \n",
    "    \n",
    "    train_df = split_data['train'] \n",
    "    val_df = split_data['val'] \n",
    "    test_df = split_data['test'] \n",
    "    fold_type = split_data.get('fold_type', 'unknown')\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\" Processing Fold {fold_idx} ({fold_type})\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\" Train Period: {train_df['date'].min().date()} ~ {train_df['date'].max().date()} (N={len(train_df)})\")\n",
    "    print(f\" Val   Period: {val_df['date'].min().date()} ~ {val_df['date'].max().date()} (N={len(val_df)})\")\n",
    "    print(f\" Test  Period: {test_df['date'].min().date()} ~ {test_df['date'].max().date()} (N={len(test_df)})\")\n",
    "\n",
    "    train_processed, missing_stats = handle_missing_values_paper_based(train_df, train_df['date'].min(), is_train=True)\n",
    "    val_processed = handle_missing_values_paper_based(val_df, val_df['date'].min(), is_train=False, train_stats=missing_stats)\n",
    "    test_processed = handle_missing_values_paper_based(test_df, test_df['date'].min(), is_train=False, train_stats=missing_stats)\n",
    "\n",
    "    target_cols = [\n",
    "        'next_direction', 'next_log_return', 'next_close', 'next_open', \n",
    "        'take_profit_price', 'stop_loss_price', \n",
    "        'ATR_14', 'real_entry_price' \n",
    "    ]\n",
    "\n",
    "    train_processed = train_processed.dropna(subset=target_cols).reset_index(drop=True)\n",
    "    val_processed = val_processed.dropna(subset=target_cols).reset_index(drop=True)\n",
    "    test_processed = test_processed.dropna(subset=target_cols).reset_index(drop=True)\n",
    "\n",
    "    # [ÏàòÏ†ï 4] ATR_14Îäî ÌîºÏ≤òÎ°úÎèÑ Ïç®Ïïº ÌïòÎØÄÎ°ú exclude_colsÏóêÏÑú Ï†úÏô∏\n",
    "    exclude_cols = [col for col in target_cols if col != 'ATR_14'] + ['date']\n",
    "    feature_cols = [col for col in train_processed.columns if col not in exclude_cols]\n",
    "    \n",
    "    X_train = train_processed[feature_cols]\n",
    "    y_train = train_processed[target_cols]\n",
    "\n",
    "    X_val = val_processed[feature_cols]\n",
    "    y_val = val_processed[target_cols]\n",
    "\n",
    "    X_test = test_processed[feature_cols]\n",
    "    y_test = test_processed[target_cols]\n",
    "\n",
    "    balance = y_train['next_direction'].value_counts(normalize=True).to_dict()\n",
    "    print(f\"[Class Balance] Train Set: {balance}\")\n",
    "\n",
    "    selected_features, selection_stats = select_features_multi_target(\n",
    "        X_train, y_train, target_type=target_type, top_n=top_n\n",
    "    )\n",
    "\n",
    "    X_train_sel = X_train[selected_features]\n",
    "    X_val_sel = X_val[selected_features]\n",
    "    X_test_sel = X_test[selected_features]\n",
    "\n",
    "    # ==================================================================\n",
    "    # [ÏàòÏ†ï 1] MinMaxScaler (-1 ~ 1) Ï†ÅÏö©\n",
    "    # ==================================================================\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "    X_train_scaled = scaler.fit_transform(X_train_sel)\n",
    "    X_val_scaled = scaler.transform(X_val_sel)\n",
    "    X_test_scaled = scaler.transform(X_test_sel)\n",
    "\n",
    "    # ==================================================================\n",
    "    # [ÏàòÏ†ï 2] Numpy Î∞∞Ïó¥ÏùÑ DataFrameÏúºÎ°ú Î≥µÍµ¨ (LGBM Í≤ΩÍ≥† Ìï¥Í≤∞)\n",
    "    # ==================================================================\n",
    "    X_train_final = pd.DataFrame(X_train_scaled, columns=selected_features)\n",
    "    X_val_final = pd.DataFrame(X_val_scaled, columns=selected_features)\n",
    "    X_test_final = pd.DataFrame(X_test_scaled, columns=selected_features)\n",
    "\n",
    "    # MLÏö© Raw Îç∞Ïù¥ÌÑ∞ (ÌïÑÏöîÏãú ÏÇ¨Ïö©, Ïó¨Í∏∞ÏÑ† ÏÑ†ÌÉùÏÇ¨Ìï≠)\n",
    "    X_train_raw = X_train_sel \n",
    "\n",
    "    if trend_params is None:\n",
    "        trend_params = {}\n",
    "\n",
    "    result = {\n",
    "        'train': {\n",
    "            # [ÏàòÏ†ï 3] Î™®Îì† ÌÇ§Í∞Ä MinMax Scaled Îç∞Ïù¥ÌÑ∞Î•º Í∞ÄÎ¶¨ÌÇ§Í≤å Ìï®\n",
    "            'X_robust': X_train_final,   \n",
    "            'X_standard': X_train_final, \n",
    "            'X_minmax': X_train_final,\n",
    "            'X_raw': X_train_raw,\n",
    "            'y': y_train.reset_index(drop=True), \n",
    "            'dates': train_processed['date'].reset_index(drop=True) \n",
    "        },\n",
    "        'val': {\n",
    "            'X_robust': X_val_final,\n",
    "            'X_standard': X_val_final,\n",
    "            'X_minmax': X_val_final,\n",
    "            'X_raw': X_val_sel,\n",
    "            'y': y_val.reset_index(drop=True), \n",
    "            'dates': val_processed['date'].reset_index(drop=True)\n",
    "        },\n",
    "        'test': {\n",
    "            'X_robust': X_test_final,\n",
    "            'X_standard': X_test_final,\n",
    "            'X_minmax': X_test_final,\n",
    "            'X_raw': X_test_sel,\n",
    "            'y': y_test.reset_index(drop=True),\n",
    "            'dates': test_processed['date'].reset_index(drop=True)\n",
    "        },\n",
    "        'scaler': scaler, \n",
    "        'stats': {\n",
    "            'robust_scaler': scaler, \n",
    "            'standard_scaler': scaler,\n",
    "            'minmax_scaler': scaler,\n",
    "            'selected_features': selected_features,\n",
    "            'selection_stats': selection_stats,\n",
    "            'missing_stats': missing_stats,  \n",
    "            'target_type': target_type,\n",
    "            'target_cols': target_cols,\n",
    "            'fold_type': fold_type,\n",
    "            'fold_idx': fold_idx,\n",
    "            'trend_window': trend_params.get('trend_window', 120),\n",
    "            'trend_analysis_points': trend_params.get('trend_analysis_points', 5)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def split_walk_forward_method( df, train_start_date, final_test_start='2025-01-01', initial_train_size=800, val_size=150, test_size=150, step=150, gap_size=7 ):\n",
    "\n",
    "    df_period = df[df['date'] >= train_start_date].copy()\n",
    "    df_period = df_period.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "    if isinstance(final_test_start, str):\n",
    "        final_test_start = pd.to_datetime(final_test_start)\n",
    "\n",
    "    final_test_df = df_period[df_period['date'] >= final_test_start].copy()\n",
    "\n",
    "    total_days = len(df_period)\n",
    "\n",
    "    actual_step = test_size + gap_size\n",
    "    min_required_days = initial_train_size + val_size + (gap_size * 2) + test_size\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Reverse Rolling Walk-Forward \")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Total: {len(df_period)} days\")\n",
    "    print(f\"Rolling train size: {initial_train_size} days \")\n",
    "    print(f\"Val: {val_size} days | Test: {test_size} days\")\n",
    "    print(f\"Gap: {gap_size} days \")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "    folds = []\n",
    "    current_test_end = total_days\n",
    "\n",
    "    while True:\n",
    "        test_end_idx = current_test_end\n",
    "        test_start_idx = test_end_idx - test_size\n",
    "\n",
    "        val_end_idx = test_start_idx - gap_size\n",
    "        val_start_idx = val_end_idx - val_size\n",
    "\n",
    "        train_end_idx = val_start_idx - gap_size\n",
    "        train_start_idx = train_end_idx - initial_train_size\n",
    "\n",
    "        if train_start_idx < 0:\n",
    "            break\n",
    "\n",
    "        train_fold = df_period.iloc[train_start_idx:train_end_idx].copy()\n",
    "        val_fold = df_period.iloc[val_start_idx:val_end_idx].copy()\n",
    "        test_fold = df_period.iloc[test_start_idx:test_end_idx].copy()\n",
    "\n",
    "        folds.append({\n",
    "            'train': train_fold,\n",
    "            'val': val_fold,\n",
    "            'test': test_fold,\n",
    "            'fold_type': 'walk_forward_rolling_reverse'\n",
    "        })\n",
    "\n",
    "        current_test_end = test_start_idx - gap_size\n",
    "\n",
    "    folds.reverse()\n",
    "\n",
    "    for idx, fold in enumerate(folds):\n",
    "        fold['fold_idx'] = idx + 1\n",
    "        print(f\"Fold {fold['fold_idx']} (walk_forward_rolling)\")\n",
    "        print(f\"  Train: {len(fold['train']):4d}d  {fold['train']['date'].min().date()} ~ {fold['train']['date'].max().date()}\")\n",
    "        print(f\"  Val:   {len(fold['val']):4d}d  {fold['val']['date'].min().date()} ~ {fold['val']['date'].max().date()}\")\n",
    "        print(f\"  Test:  {len(fold['test']):4d}d  {fold['test']['date'].min().date()} ~ {fold['test']['date'].max().date()}\\n\")\n",
    "\n",
    "    if len(final_test_df) > 0:\n",
    "        pre_final_df = df_period[df_period['date'] < final_test_start].copy()\n",
    "\n",
    "        final_val_end_idx = len(pre_final_df)\n",
    "        final_val_start_idx = final_val_end_idx - val_size\n",
    "        final_train_end_idx = final_val_start_idx - gap_size\n",
    "        final_train_start_idx = final_train_end_idx - initial_train_size\n",
    "\n",
    "        if final_train_start_idx < 0:\n",
    "            final_train_start_idx = 0\n",
    "\n",
    "        final_train_data = pre_final_df.iloc[final_train_start_idx:final_train_end_idx].copy()\n",
    "        final_val_data = pre_final_df.iloc[final_val_start_idx:final_val_end_idx].copy()\n",
    "\n",
    "        print(f\"Fold {len(folds) + 1} (final_holdout)\")\n",
    "        print(f\"  Train: {len(final_train_data):4d}d  {final_train_data['date'].min().date()} ~ {final_train_data['date'].max().date()}\")\n",
    "        print(f\"  Val:   {len(final_val_data):4d}d  {final_val_data['date'].min().date()} ~ {final_val_data['date'].max().date()}\")\n",
    "        print(f\"  Test:  {len(final_test_df):4d}d  {final_test_df['date'].min().date()} ~ {final_test_df['date'].max().date()}\\n\")\n",
    "\n",
    "        folds.append({\n",
    "            'train': final_train_data,\n",
    "            'val': final_val_data,\n",
    "            'test': final_test_df,\n",
    "            'fold_idx': len(folds) + 1,\n",
    "            'fold_type': 'final_holdout'\n",
    "        })\n",
    "\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Created {len(folds)} folds total\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "    return folds\n",
    "\n",
    "\n",
    "def build_complete_pipeline_corrected(df_raw, train_start_date, **kwargs): \n",
    "    \n",
    "    \n",
    "    print(f\"\\n Pipeline Started... (Train Start: {train_start_date})\")\n",
    "\n",
    "    df = df_raw.copy()\n",
    "    lookahead = kwargs.get('lookahead_candles', kwargs.get('lookahead', 5))\n",
    "    profit_mult = kwargs.get('atr_multiplier_profit', 2.0)\n",
    "    stop_mult = kwargs.get('atr_multiplier_stop', 1.0)\n",
    "\n",
    "    df = add_price_lag_features_first(df)\n",
    "    df = calculate_technical_indicators(df)\n",
    "    df = add_enhanced_cross_crypto_features(df)\n",
    "    df = add_volatility_regime_features(df)\n",
    "    df = add_interaction_features(df)\n",
    "    df = add_percentile_features(df)\n",
    "    df = preprocess_non_stationary_features(df)\n",
    "\n",
    "    df = create_targets(\n",
    "        df, \n",
    "        lookahead=lookahead, \n",
    "        profit_mult=profit_mult, \n",
    "        stop_mult=stop_mult\n",
    "    )\n",
    "\n",
    "    df = remove_raw_prices_and_transform(df, 'direction', 'tvt')\n",
    "    print(df.shape)\n",
    "    splits = split_walk_forward_method(\n",
    "        df, \n",
    "        train_start_date=train_start_date,\n",
    "        final_test_start=kwargs.get('final_test_start', '2025-01-01'),\n",
    "        initial_train_size=800,\n",
    "        val_size=150,\n",
    "        test_size=150,\n",
    "        step=150,\n",
    "        gap_size=lookahead\n",
    "    )\n",
    "    print(f\" Data Split Completed. Total {len(splits)} folds generated.\")\n",
    "\n",
    "    result = []\n",
    "    for fold in splits:\n",
    "        res = process_single_split(\n",
    "            fold, \n",
    "            top_n=kwargs.get('top_n', 20), \n",
    "            fold_idx=fold['fold_idx']\n",
    "        )\n",
    "        result.append(res)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9953484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import tensorflow as tf\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "class DirectionModels:\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_class_weights(y_train):\n",
    "        classes = np.unique(y_train)\n",
    "        weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "        return dict(zip(classes, weights))\n",
    "\n",
    "    @staticmethod\n",
    "    def random_forest(X_train, y_train, X_val, y_val):\n",
    "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "        \n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 300, 1000),\n",
    "                'max_depth': trial.suggest_int('max_depth', 4, 12),\n",
    "                'min_samples_split': trial.suggest_int('min_samples_split', 20, 150),\n",
    "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 10, 60),\n",
    "                'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "                'ccp_alpha': trial.suggest_float('ccp_alpha', 1e-4, 1e-2, log=True),\n",
    "                'class_weight': 'balanced',\n",
    "                'random_state': 42,\n",
    "                'n_jobs': -1\n",
    "            }\n",
    "            \n",
    "            model = RandomForestClassifier(**params)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            val_preds = model.predict(X_val)\n",
    "            buy_precision = precision_score(y_val, val_preds, labels=[2], average='macro', zero_division=0)\n",
    "            return buy_precision\n",
    "\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(objective, n_trials=20)\n",
    "        \n",
    "        best_model = RandomForestClassifier(**study.best_params, class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "        best_model.fit(X_train, y_train)\n",
    "        return best_model\n",
    "\n",
    "    @staticmethod\n",
    "    def lightgbm(X_train, y_train, X_val, y_val):\n",
    "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'n_estimators': 1000,\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.05, log=True),\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "                'max_depth': trial.suggest_int('max_depth', 4, 10),\n",
    "                'min_child_samples': trial.suggest_int('min_child_samples', 30, 150),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 0.9),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.9),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 1e-2, 10.0, log=True),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 1e-2, 10.0, log=True),\n",
    "                'objective': 'multiclass',\n",
    "                'num_class': 3,\n",
    "                'metric': 'multi_logloss',\n",
    "                'class_weight': 'balanced',\n",
    "                'verbosity': -1,\n",
    "                'n_jobs': -1,\n",
    "                'random_state': 42\n",
    "            }\n",
    "            \n",
    "            model = LGBMClassifier(**params)\n",
    "            callbacks = [lgb.early_stopping(stopping_rounds=30, verbose=False)]\n",
    "            \n",
    "            model.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=callbacks)\n",
    "            \n",
    "            val_preds = model.predict(X_val)\n",
    "            buy_precision = precision_score(y_val, val_preds, labels=[2], average='macro', zero_division=0)\n",
    "            return buy_precision\n",
    "\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(objective, n_trials=25)\n",
    "        \n",
    "        best_params = study.best_params\n",
    "        best_params.update({\n",
    "            'n_estimators': 1000, 'objective': 'multiclass', 'num_class': 3,\n",
    "            'metric': 'multi_logloss', 'class_weight': 'balanced', 'verbosity': -1, \n",
    "            'n_jobs': -1, 'random_state': 42\n",
    "        })\n",
    "        \n",
    "        final_model = LGBMClassifier(**best_params)\n",
    "        final_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)])\n",
    "        return final_model\n",
    "\n",
    "    @staticmethod\n",
    "    def xgboost(X_train, y_train, X_val, y_val):\n",
    "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "        \n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'n_estimators': 1000,\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.05, log=True),\n",
    "                'max_depth': trial.suggest_int('max_depth', 4, 10),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 2, 15),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 0.9),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.9),\n",
    "                'gamma': trial.suggest_float('gamma', 0.5, 10.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 1e-2, 10.0, log=True),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 1e-2, 10.0, log=True),\n",
    "                'objective': 'multi:softprob',\n",
    "                'num_class': 3,\n",
    "                'eval_metric': 'mlogloss',\n",
    "                'tree_method': 'hist',\n",
    "                'early_stopping_rounds': 30,\n",
    "                'random_state': 42,\n",
    "                'n_jobs': -1\n",
    "            }\n",
    "            \n",
    "            model = XGBClassifier(**params)\n",
    "            model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "            \n",
    "            val_preds = model.predict(X_val)\n",
    "            buy_precision = precision_score(y_val, val_preds, labels=[2], average='macro', zero_division=0)\n",
    "            return buy_precision\n",
    "\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(objective, n_trials=25)\n",
    "        \n",
    "        best_params = study.best_params\n",
    "        best_params.update({\n",
    "            'n_estimators': 1000, 'objective': 'multi:softprob', 'num_class': 3,\n",
    "            'eval_metric': 'mlogloss', 'tree_method': 'hist', 'early_stopping_rounds': 50,\n",
    "            'random_state': 42, 'n_jobs': -1\n",
    "        })\n",
    "        \n",
    "        final_model = XGBClassifier(**best_params)\n",
    "        final_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "        return final_model\n",
    "\n",
    "    @staticmethod\n",
    "    def catboost(X_train, y_train, X_val, y_val):\n",
    "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "        \n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'iterations': 1000,\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.05, log=True),\n",
    "                'depth': trial.suggest_int('depth', 4, 9),\n",
    "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 2, 15),\n",
    "                'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "                'loss_function': 'MultiClass',\n",
    "                'eval_metric': 'MultiClass',\n",
    "                'auto_class_weights': 'Balanced',\n",
    "                'logging_level': 'Silent',\n",
    "                'random_seed': 42,\n",
    "                'od_type': 'Iter',\n",
    "                'od_wait': 30,\n",
    "                'allow_writing_files': False\n",
    "            }\n",
    "            \n",
    "            model = CatBoostClassifier(**params)\n",
    "            model.fit(X_train, y_train, eval_set=(X_val, y_val))\n",
    "            \n",
    "            val_preds = model.predict(X_val)\n",
    "            buy_precision = precision_score(y_val, val_preds, labels=[2], average='macro', zero_division=0)\n",
    "            return buy_precision\n",
    "\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(objective, n_trials=20)\n",
    "        \n",
    "        best_params = study.best_params\n",
    "        best_params.update({\n",
    "            'iterations': 1000, 'loss_function': 'MultiClass', 'eval_metric': 'MultiClass',\n",
    "            'auto_class_weights': 'Balanced', 'logging_level': 'Silent',\n",
    "            'random_seed': 42, 'od_type': 'Iter', 'od_wait': 50, 'allow_writing_files': False\n",
    "        })\n",
    "        \n",
    "        final_model = CatBoostClassifier(**best_params)\n",
    "        final_model.fit(X_train, y_train, eval_set=(X_val, y_val))\n",
    "        return final_model\n",
    "\n",
    "    @staticmethod\n",
    "    def lstm(X_train, y_train, X_val, y_val, input_shape):\n",
    "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "        class_weights = DirectionModels.get_class_weights(y_train)\n",
    "\n",
    "        def objective(trial):\n",
    "            tf.keras.backend.clear_session()\n",
    "            \n",
    "            units = trial.suggest_int('units', 32, 128, step=16)\n",
    "            dropout_rate = trial.suggest_float('dropout', 0.3, 0.6)\n",
    "            l2_reg = trial.suggest_float('l2_reg', 1e-4, 1e-1, log=True)\n",
    "            lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "            \n",
    "            model = Sequential([\n",
    "                Input(shape=input_shape),\n",
    "                LSTM(units, return_sequences=False, \n",
    "                     kernel_regularizer=l1_l2(l2=l2_reg),\n",
    "                     recurrent_regularizer=l1_l2(l2=l2_reg)),\n",
    "                BatchNormalization(),\n",
    "                Dropout(dropout_rate),\n",
    "                Dense(units // 2, activation='relu', kernel_regularizer=l1_l2(l2=l2_reg)),\n",
    "                Dropout(dropout_rate),\n",
    "                Dense(3, activation='softmax')\n",
    "            ])\n",
    "            \n",
    "            model.compile(\n",
    "                optimizer=Adam(learning_rate=lr),\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "            \n",
    "            es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "            \n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                validation_data=(X_val, y_val),\n",
    "                epochs=20,\n",
    "                batch_size=64,\n",
    "                class_weight=class_weights,\n",
    "                callbacks=[es],\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            val_probs = model.predict(X_val, verbose=0)\n",
    "            val_preds = np.argmax(val_probs, axis=1)\n",
    "            buy_precision = precision_score(y_val, val_preds, labels=[2], average='macro', zero_division=0)\n",
    "            return buy_precision\n",
    "\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(objective, n_trials=20)\n",
    "        \n",
    "        best = study.best_params\n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "        final_model = Sequential([\n",
    "            Input(shape=input_shape),\n",
    "            LSTM(best['units'], return_sequences=False,\n",
    "                 kernel_regularizer=l1_l2(l2=best['l2_reg']),\n",
    "                 recurrent_regularizer=l1_l2(l2=best['l2_reg'])),\n",
    "            BatchNormalization(),\n",
    "            Dropout(best['dropout']),\n",
    "            Dense(best['units'] // 2, activation='relu', kernel_regularizer=l1_l2(l2=best['l2_reg'])),\n",
    "            Dropout(best['dropout']),\n",
    "            Dense(3, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        final_model.compile(\n",
    "            optimizer=Adam(learning_rate=best['lr']),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        final_es = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "        final_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "        \n",
    "        final_model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=50,\n",
    "            batch_size=64,\n",
    "            class_weight=class_weights,\n",
    "            callbacks=[final_es, final_lr],\n",
    "            verbose=0\n",
    "        )\n",
    "        return final_model\n",
    "    \n",
    "    \n",
    "ML_MODELS_CLASSIFICATION = [\n",
    "    {'index': 1, 'name': 'CatBoost', 'func': DirectionModels.catboost, 'needs_val': True},\n",
    "    {'index': 2, 'name': 'RandomForest', 'func': DirectionModels.random_forest, 'needs_val': True},\n",
    "    {'index': 3, 'name': 'LightGBM', 'func': DirectionModels.lightgbm, 'needs_val': True},\n",
    "    {'index': 4, 'name': 'XGBoost', 'func': DirectionModels.xgboost, 'needs_val': True}\n",
    "]\n",
    "\n",
    "DL_MODELS_CLASSIFICATION = [\n",
    "    {'index': 9, 'name': 'LSTM', 'func': DirectionModels.lstm, 'needs_val': True},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89522f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    def __init__(self, save_models=False):\n",
    "        self.results = []\n",
    "        self.predictions = {}\n",
    "        self.models = {} if save_models else None\n",
    "        self.save_models = save_models\n",
    "        self.best_thresholds = {}\n",
    "\n",
    "    def optimize_threshold(self, y_true, adjusted_buy_prob, min_trades=5, reward_risk_ratio=2.0):\n",
    "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "        def objective(trial):\n",
    "            th = trial.suggest_float('threshold', 0.4, 0.95)\n",
    "            preds = np.where(adjusted_buy_prob >= th, 2, 1)\n",
    "            n_trades = np.sum(preds == 2)\n",
    "            \n",
    "            if n_trades < min_trades:\n",
    "                return -99999.0 \n",
    "            \n",
    "            real_wins = np.sum((preds == 2) & (y_true == 2))\n",
    "            real_losses = n_trades - real_wins\n",
    "            \n",
    "            total_return = (real_wins * reward_risk_ratio) - (real_losses * 1.0)\n",
    "            return total_return\n",
    "\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(objective, n_trials=30) \n",
    "        return study.best_params['threshold'], study.best_value\n",
    "\n",
    "    def _calculate_metrics(self, y_true, adjusted_buy_prob, dataset_name, optimal_threshold=None, reward_risk_ratio=2.0):\n",
    "        # y_trueÎäî Ïù¥Ï†ú ÌôïÏã§ÌïòÍ≤å 1Ï∞®Ïõê Ï†ïÏàò Î∞∞Ïó¥(0,1,2)ÏûÖÎãàÎã§.\n",
    "        \n",
    "        metrics = {}\n",
    "        if optimal_threshold is not None:\n",
    "            th_preds = np.where(adjusted_buy_prob >= optimal_threshold, 2, 1)\n",
    "            n_trades = np.sum(th_preds == 2)\n",
    "            \n",
    "            if n_trades > 0:\n",
    "                real_wins = np.sum((th_preds == 2) & (y_true == 2))\n",
    "                real_losses = n_trades - real_wins\n",
    "                \n",
    "                win_rate = real_wins / n_trades\n",
    "                total_return_r = (real_wins * reward_risk_ratio) - (real_losses * 1.0)\n",
    "                \n",
    "                gross_profit = real_wins * reward_risk_ratio\n",
    "                gross_loss = real_losses * 1.0\n",
    "                profit_factor = gross_profit / gross_loss if gross_loss > 0 else 99.0\n",
    "                \n",
    "                expectancy = total_return_r / n_trades\n",
    "            else:\n",
    "                win_rate = 0.0\n",
    "                expectancy = 0.0\n",
    "                total_return_r = 0.0\n",
    "                profit_factor = 0.0\n",
    "                \n",
    "            metrics[f'{dataset_name}_Opt_Threshold'] = optimal_threshold\n",
    "            metrics[f'{dataset_name}_Opt_Trades'] = n_trades\n",
    "            metrics[f'{dataset_name}_Opt_WinRate'] = win_rate\n",
    "            metrics[f'{dataset_name}_Opt_Expectancy'] = expectancy\n",
    "            metrics[f'{dataset_name}_Opt_Total_Return_R'] = total_return_r\n",
    "            metrics[f'{dataset_name}_Opt_Profit_Factor'] = profit_factor\n",
    "            \n",
    "        return metrics\n",
    "\n",
    "    def _extract_target_label(self, y_data):\n",
    "        \"\"\"\n",
    "        [ÏàòÏ†ïÎê®] y_dataÏóêÏÑú Ï†ïÎãµ ÎùºÎ≤®(next_direction)Îßå ÏïàÏ†ÑÌïòÍ≤å Ï∂îÏ∂úÌïòÎäî Ìó¨Ìçº Ìï®Ïàò\n",
    "        \"\"\"\n",
    "        if isinstance(y_data, pd.DataFrame):\n",
    "            if 'next_direction' in y_data.columns:\n",
    "                return y_data['next_direction'].values.astype(int)\n",
    "            else:\n",
    "                # Ïª¨ÎüºÎ™ÖÏù¥ ÏóÜÏúºÎ©¥ Ï≤´ Î≤àÏß∏ Ïª¨ÎüºÏùÑ ÌÉÄÍ≤üÏúºÎ°ú Í∞ÄÏ†ï\n",
    "                return y_data.iloc[:, 0].values.astype(int)\n",
    "        elif isinstance(y_data, pd.Series):\n",
    "            return y_data.values.astype(int)\n",
    "        elif isinstance(y_data, np.ndarray):\n",
    "            # Ï∞®ÏõêÏù¥ 2 Ïù¥ÏÉÅÏù¥Í≥† Ïª¨ÎüºÏù¥ Ïó¨Îü¨ Í∞úÎ©¥ Ï≤´ Î≤àÏß∏ Ïª¨Îüº(0Î≤à Ïù∏Îç±Ïä§)Ïù¥ ÌÉÄÍ≤üÏù¥ÎùºÍ≥† Í∞ÄÏ†ï\n",
    "            if y_data.ndim > 1 and y_data.shape[1] > 1:\n",
    "                return y_data[:, 0].astype(int)\n",
    "            return y_data.astype(int)\n",
    "        return np.array(y_data).astype(int)\n",
    "\n",
    "    def evaluate_classification_model(self, model, X_train, y_train, X_val, y_val, \n",
    "                                    X_test, y_test, test_dates, \n",
    "                                    test_prices, test_atr, \n",
    "                                    model_name,\n",
    "                                    is_deep_learning=False, profit_mult=2.0, stop_mult=1.0):\n",
    "        \n",
    "        rr_ratio = profit_mult / stop_mult if stop_mult > 0 else 2.0\n",
    "\n",
    "        # ÏòàÏ∏° ÌôïÎ•† Í≥ÑÏÇ∞\n",
    "        if is_deep_learning:\n",
    "            train_prob = model.predict(X_train, verbose=0)\n",
    "            val_prob = model.predict(X_val, verbose=0)\n",
    "            test_prob = model.predict(X_test, verbose=0)\n",
    "        else:\n",
    "            train_prob = model.predict_proba(X_train)\n",
    "            val_prob = model.predict_proba(X_val)\n",
    "            test_prob = model.predict_proba(X_test)\n",
    "            \n",
    "        def calculate_adjusted_prob(prob_matrix):\n",
    "            prob_sell = prob_matrix[:, 0]\n",
    "            prob_buy = prob_matrix[:, 2]\n",
    "            return prob_buy / (prob_buy + prob_sell + 1e-9)\n",
    "\n",
    "        train_adj_prob = calculate_adjusted_prob(train_prob)\n",
    "        val_adj_prob = calculate_adjusted_prob(val_prob)\n",
    "        test_adj_prob = calculate_adjusted_prob(test_prob)\n",
    "\n",
    "        # [ÏàòÏ†ï] Ï†ïÎãµ Îç∞Ïù¥ÌÑ∞(Label)Î•º ÏïàÏ†ÑÌïòÍ≤å Ï∂îÏ∂ú\n",
    "        y_train_fixed = self._extract_target_label(y_train)\n",
    "        y_val_fixed = self._extract_target_label(y_val)\n",
    "        y_test_fixed = self._extract_target_label(y_test)\n",
    "\n",
    "        # Threshold ÏµúÏ†ÅÌôî\n",
    "        best_th, best_val_return = self.optimize_threshold(\n",
    "            y_val_fixed, val_adj_prob, \n",
    "            min_trades=5, \n",
    "            reward_risk_ratio=rr_ratio\n",
    "        )\n",
    "        self.best_thresholds[model_name] = best_th\n",
    "        \n",
    "        # Î©îÌä∏Î¶≠ Í≥ÑÏÇ∞\n",
    "        train_metrics = self._calculate_metrics(y_train_fixed, train_adj_prob, 'Train', best_th, rr_ratio)\n",
    "        val_metrics = self._calculate_metrics(y_val_fixed, val_adj_prob, 'Val', best_th, rr_ratio)\n",
    "        test_metrics = self._calculate_metrics(y_test_fixed, test_adj_prob, 'Test', best_th, rr_ratio)\n",
    "        \n",
    "        result = {\n",
    "            'Model': model_name,\n",
    "            'Best_Threshold': best_th,\n",
    "            'Risk_Reward_Ratio': rr_ratio\n",
    "        }\n",
    "        result.update(train_metrics)\n",
    "        result.update(val_metrics)\n",
    "        result.update(test_metrics)\n",
    "        \n",
    "        self.results.append(result)\n",
    "        \n",
    "        test_pred_opt = np.where(test_adj_prob >= best_th, 2, 1)\n",
    "        test_pred_raw_argmax = np.argmax(test_prob, axis=1)\n",
    "        \n",
    "        # Í∞ÄÍ≤© Îç∞Ïù¥ÌÑ∞ ÌòïÏÉÅ ÎßûÏ∂îÍ∏∞\n",
    "        if hasattr(test_prices, 'values'): test_prices = test_prices.values\n",
    "        if hasattr(test_atr, 'values'): test_atr = test_atr.values\n",
    "        test_prices = test_prices.reshape(-1)\n",
    "        test_atr = test_atr.reshape(-1)\n",
    "\n",
    "        tp_prices = test_prices + (test_atr * profit_mult)\n",
    "        sl_prices = test_prices - (test_atr * stop_mult)\n",
    "        \n",
    "        print(f\"[{model_name}]\")\n",
    "        print(f\"  Optuna Threshold: {best_th:.4f} (Val Return: {best_val_return:.2f}R)\")\n",
    "        print(f\"  Test Performance -> Win Rate: {result['Test_Opt_WinRate']:.2%} | Trades: {result['Test_Opt_Trades']} | PF: {result['Test_Opt_Profit_Factor']:.2f}\")\n",
    "        print(f\"  Test Simulation  -> Expectancy: {result['Test_Opt_Expectancy']:.2f}R | Total Return: {result['Test_Opt_Total_Return_R']:.2f}R\")\n",
    "        \n",
    "        self.predictions[model_name] = pd.DataFrame({\n",
    "            'date': test_dates,\n",
    "            'actual': y_test_fixed, \n",
    "            'entry_price': test_prices,\n",
    "            'atr': test_atr,\n",
    "            'tp_price': tp_prices,\n",
    "            'sl_price': sl_prices,\n",
    "            'pred_raw': test_pred_raw_argmax,  \n",
    "            'pred_opt': test_pred_opt,    \n",
    "            'prob_sell': test_prob[:, 0],\n",
    "            'prob_hold': test_prob[:, 1],\n",
    "            'prob_buy': test_prob[:, 2],\n",
    "            'adj_prob_buy': test_adj_prob\n",
    "        })\n",
    "        \n",
    "        if self.save_models and self.models is not None:\n",
    "            self.models[model_name] = model\n",
    "        \n",
    "        return result\n",
    "\n",
    "    # ÎÇòÎ®∏ÏßÄ Î©îÏÑúÎìú ÎèôÏùº\n",
    "    def get_summary_dataframe(self):\n",
    "        return pd.DataFrame(self.results)\n",
    "    def get_predictions_dict(self):\n",
    "        return self.predictions\n",
    "    def get_models_dict(self):\n",
    "        return self.models or {}\n",
    "    \n",
    "    \n",
    "class ModelTrainer:\n",
    "    def __init__(self, evaluator, lookback=30):\n",
    "        self.evaluator = evaluator\n",
    "        self.lookback = lookback\n",
    "    \n",
    "    def create_sequences(self, X, y_target, lookback):\n",
    "        Xs, ys = [], []\n",
    "        for i in range(lookback, len(X)):\n",
    "            Xs.append(X[i-lookback:i])\n",
    "            ys.append(y_target[i])\n",
    "        return np.array(Xs), np.array(ys)\n",
    "    \n",
    "    def _prepare_target(self, y_data):\n",
    "        if isinstance(y_data, pd.DataFrame):\n",
    "            if 'next_direction' in y_data.columns:\n",
    "                return y_data['next_direction'].values.astype(int)\n",
    "            else:\n",
    "                return y_data.iloc[:, 0].values.astype(int)\n",
    "        elif isinstance(y_data, pd.Series):\n",
    "            return y_data.values.astype(int)\n",
    "        else:\n",
    "            return np.array(y_data).astype(int)\n",
    "\n",
    "    def train_all_models(self, X_train, y_train_input, X_val, y_val_input, X_test, y_test_input, \n",
    "                        test_dates, \n",
    "                        test_prices, test_atr, \n",
    "                        profit_mult, stop_mult, \n",
    "                        ml_models=None, dl_models=None):\n",
    "        \n",
    "        y_train_target = self._prepare_target(y_train_input)\n",
    "        y_val_target = self._prepare_target(y_val_input)\n",
    "        \n",
    "        if ml_models:\n",
    "            for config in ml_models:\n",
    "                try:\n",
    "                    if config['needs_val']:\n",
    "                        model = config['func'](X_train, y_train_target, X_val, y_val_target)\n",
    "                    else:\n",
    "                        model = config['func'](X_train, y_train_target)\n",
    "                        \n",
    "                    self.evaluator.evaluate_classification_model(\n",
    "                        model, X_train, y_train_target, X_val, y_val_target, X_test, y_test_input, \n",
    "                        test_dates, test_prices, test_atr, \n",
    "                        config['name'], \n",
    "                        is_deep_learning=False,\n",
    "                        profit_mult=profit_mult, \n",
    "                        stop_mult=stop_mult      \n",
    "                    )\n",
    "                    del model\n",
    "                    gc.collect()\n",
    "                except Exception as e:\n",
    "                    print(f\"Model {config['name']} Failed: {str(e)}\")\n",
    "                    traceback.print_exc()\n",
    "\n",
    "        if dl_models:\n",
    "            X_train_s, y_train_s = self.create_sequences(X_train, y_train_target, self.lookback)\n",
    "            X_val_s, y_val_s = self.create_sequences(X_val, y_val_target, self.lookback)\n",
    "            \n",
    "            y_test_target = self._prepare_target(y_test_input)\n",
    "            X_test_s, y_test_s = self.create_sequences(X_test, y_test_target, self.lookback)\n",
    "            \n",
    "            if isinstance(y_test_input, pd.DataFrame):\n",
    "                y_test_input_s = y_test_input.iloc[self.lookback:].reset_index(drop=True)\n",
    "            else:\n",
    "                y_test_input_s = y_test_input[self.lookback:]\n",
    "                \n",
    "            test_dates_s = test_dates[self.lookback:]\n",
    "            test_prices_s = test_prices[self.lookback:]\n",
    "            test_atr_s = test_atr[self.lookback:]\n",
    "            \n",
    "            input_shape = (X_train_s.shape[1], X_train_s.shape[2])\n",
    "            \n",
    "            for config in dl_models:\n",
    "                try:\n",
    "                    tf.keras.backend.clear_session()\n",
    "                    model = config['func'](X_train_s, y_train_s, X_val_s, y_val_s, input_shape)\n",
    "                    \n",
    "                    self.evaluator.evaluate_classification_model(\n",
    "                        model, X_train_s, y_train_s, X_val_s, y_val_s, X_test_s, y_test_input_s, \n",
    "                        test_dates_s, test_prices_s, test_atr_s, \n",
    "                        config['name'], \n",
    "                        is_deep_learning=True,\n",
    "                        profit_mult=profit_mult, \n",
    "                        stop_mult=stop_mult      \n",
    "                    )\n",
    "                    del model\n",
    "                    tf.keras.backend.clear_session()\n",
    "                    gc.collect()\n",
    "                except Exception as e:\n",
    "                    print(f\"DL Model {config['name']} Failed: {str(e)}\")\n",
    "                    traceback.print_exc()\n",
    "\n",
    "def save_fold_results(fold_idx, fold_type, evaluator, trial_name, fold_data):\n",
    "    base_dir = f\"model_results/{datetime.now().strftime('%Y-%m-%d')}/{trial_name}/fold_{fold_idx}_{fold_type}\"\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    \n",
    "    summary = evaluator.get_summary_dataframe()\n",
    "    summary.to_csv(f\"{base_dir}/fold_summary.csv\", index=False)\n",
    "    \n",
    "    for name, df in evaluator.get_predictions_dict().items():\n",
    "        df.to_csv(f\"{base_dir}/predictions_{name}.csv\", index=False)\n",
    "        \n",
    "    for name, model in evaluator.get_models_dict().items():\n",
    "        try:\n",
    "            if isinstance(model, tf.keras.Model):\n",
    "                model.save(f\"{base_dir}/model_{name}.h5\")\n",
    "            else:\n",
    "                joblib.dump(model, f\"{base_dir}/model_{name}.pkl\")\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] Failed to save model {name}: {e}\")\n",
    "            \n",
    "    if 'scaler' in fold_data:\n",
    "        joblib.dump(fold_data['scaler'], f\"{base_dir}/scaler.pkl\")\n",
    "        \n",
    "    meta_data = {\n",
    "        'selected_features': fold_data['stats']['selected_features'],\n",
    "        'target_cols': fold_data['stats']['target_cols'],\n",
    "        'fold_idx': fold_idx,\n",
    "        'fold_type': fold_type,\n",
    "        'trial_name': trial_name,\n",
    "        'best_thresholds': evaluator.best_thresholds\n",
    "    }\n",
    "    \n",
    "    with open(f\"{base_dir}/metadata.json\", 'w') as f:\n",
    "        json.dump(meta_data, f, indent=4)\n",
    "            \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7efef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_optuna_optimization(df_merged, n_trials=30):\n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    RESULT_DIR = f\"model_results/{TIMESTAMP}\"\n",
    "    os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "    with open(f\"{RESULT_DIR}/optuna_log.csv\", \"w\") as f:\n",
    "        f.write(\"trial,lookahead,profit_mult,stop_mult,score\\n\")\n",
    "\n",
    "    def objective(trial):\n",
    "        lookahead = trial.suggest_int('lookahead', 5, 15)\n",
    "        p_mult = trial.suggest_float('profit_mult',1.5,2.0, step=0.1)\n",
    "        s_mult = trial.suggest_float('stop_mult',1.5, 2.0, step=0.1)\n",
    "        \n",
    "        trial_name = f\"trial_{trial.number}_L{lookahead}_P{p_mult:.1f}_S{s_mult:.1f}\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\" Starting {trial_name}\")\n",
    "        \n",
    "        try:\n",
    "            pipeline_result = build_complete_pipeline_corrected(\n",
    "                df_raw=df_merged,\n",
    "                train_start_date='2020-01-01',\n",
    "                final_test_start='2025-01-01',\n",
    "                lookahead_candles=lookahead,\n",
    "                atr_multiplier_profit=p_mult,\n",
    "                atr_multiplier_stop=s_mult,\n",
    "                top_n=20\n",
    "            )\n",
    "            \n",
    "            fold_scores = []\n",
    "            \n",
    "            for i, fold_data in enumerate(pipeline_result):\n",
    "                fold_idx = fold_data['stats']['fold_idx']\n",
    "                fold_type = fold_data['stats']['fold_type']\n",
    "                \n",
    "                print(f\"\\n   >> Running Fold {fold_idx}/{len(pipeline_result)} ({fold_type})\")\n",
    "                \n",
    "                evaluator = ModelEvaluator(save_models=True)\n",
    "                trainer = ModelTrainer(evaluator, lookback=30)\n",
    "                \n",
    "                test_prices = fold_data['test']['y']['real_entry_price'].values\n",
    "                test_atr = fold_data['test']['y']['ATR_14'].values\n",
    "                \n",
    "                trainer.train_all_models(\n",
    "                    fold_data['train']['X_robust'],\n",
    "                    fold_data['train']['y'],\n",
    "                    fold_data['val']['X_robust'],\n",
    "                    fold_data['val']['y'],   \n",
    "                    fold_data['test']['X_robust'],\n",
    "                    fold_data['test']['y'],  \n",
    "                    fold_data['test']['dates'].values,\n",
    "                    test_prices,\n",
    "                    test_atr,\n",
    "                    p_mult,\n",
    "                    s_mult,\n",
    "                    ml_models=ML_MODELS_CLASSIFICATION,\n",
    "                    dl_models=DL_MODELS_CLASSIFICATION\n",
    "                )\n",
    "                \n",
    "                summary = save_fold_results(fold_idx, fold_type, evaluator, trial_name, fold_data)\n",
    "                \n",
    "                if 'Test_Opt_Expectancy' in summary.columns:\n",
    "                    score = summary['Test_Opt_Expectancy'].mean()\n",
    "                else:\n",
    "                    score = 0.0\n",
    "                    \n",
    "                fold_scores.append(score)\n",
    "                \n",
    "                del evaluator, trainer\n",
    "                gc.collect()\n",
    "            \n",
    "            final_score = np.mean(fold_scores) if fold_scores else 0.0\n",
    "            print(f\"\\n === Trial {trial.number} Finished. Final Score (Expectancy): {final_score:.4f}R ===\")\n",
    "            \n",
    "            with open(f\"{RESULT_DIR}/optuna_log.csv\", \"a\") as f:\n",
    "                f.write(f\"{trial.number},{lookahead},{p_mult},{s_mult},{final_score}\\n\")\n",
    "                \n",
    "            return final_score\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" [Error] Trial {trial.number} Failed: {e}\")\n",
    "            traceback.print_exc()\n",
    "            return 0.0\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    \n",
    "    print(\"\\n[Optuna] Optimization Completed!\")\n",
    "    print(\"Best Params:\", study.best_params)\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef0f030b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>BTC_Open</th>\n",
       "      <th>BTC_High</th>\n",
       "      <th>BTC_Low</th>\n",
       "      <th>BTC_Close</th>\n",
       "      <th>BTC_Volume</th>\n",
       "      <th>ETH_Open</th>\n",
       "      <th>ETH_High</th>\n",
       "      <th>ETH_Low</th>\n",
       "      <th>ETH_Close</th>\n",
       "      <th>...</th>\n",
       "      <th>chain_eth_chain_tvl</th>\n",
       "      <th>funding_fundingRate</th>\n",
       "      <th>l2_arbitrum_tvl</th>\n",
       "      <th>l2_optimism_tvl</th>\n",
       "      <th>l2_base_tvl</th>\n",
       "      <th>l2_zksync era_tvl</th>\n",
       "      <th>sp500_SP500</th>\n",
       "      <th>vix_VIX</th>\n",
       "      <th>gold_GOLD</th>\n",
       "      <th>dxy_DXY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>2025-11-20</td>\n",
       "      <td>136500000.0</td>\n",
       "      <td>138621000.0</td>\n",
       "      <td>129800000.0</td>\n",
       "      <td>129896000.0</td>\n",
       "      <td>4303.832306</td>\n",
       "      <td>4510000.0</td>\n",
       "      <td>4561000.0</td>\n",
       "      <td>4212000.0</td>\n",
       "      <td>4243000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>143848669231</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>2.777513e+09</td>\n",
       "      <td>290218197.0</td>\n",
       "      <td>4.308060e+09</td>\n",
       "      <td>40361104.0</td>\n",
       "      <td>6538.759766</td>\n",
       "      <td>26.42</td>\n",
       "      <td>4056.5</td>\n",
       "      <td>100.160004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows √ó 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date     BTC_Open     BTC_High      BTC_Low    BTC_Close  \\\n",
       "2350  2025-11-20  136500000.0  138621000.0  129800000.0  129896000.0   \n",
       "\n",
       "       BTC_Volume   ETH_Open   ETH_High    ETH_Low  ETH_Close  ...  \\\n",
       "2350  4303.832306  4510000.0  4561000.0  4212000.0  4243000.0  ...   \n",
       "\n",
       "      chain_eth_chain_tvl  funding_fundingRate  l2_arbitrum_tvl  \\\n",
       "2350         143848669231             0.000072     2.777513e+09   \n",
       "\n",
       "      l2_optimism_tvl   l2_base_tvl  l2_zksync era_tvl  sp500_SP500  vix_VIX  \\\n",
       "2350      290218197.0  4.308060e+09         40361104.0  6538.759766    26.42   \n",
       "\n",
       "      gold_GOLD     dxy_DXY  \n",
       "2350     4056.5  100.160004  \n",
       "\n",
       "[1 rows x 62 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import traceback\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score, \n",
    "    roc_auc_score, \n",
    "    classification_report\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "# ============================================================================\n",
    "# Í∏∞Î≥∏ ÎùºÏù¥Î∏åÎü¨Î¶¨ Î∞è Ïú†Ìã∏Î¶¨Ìã∞\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "# ÎÇ†Ïßú/ÏãúÍ∞Ñ\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "from collections import Counter\n",
    "from numba import jit\n",
    "# ============================================================================\n",
    "# ML/DL ÎùºÏù¥Î∏åÎü¨Î¶¨ Î∞è ÎèÑÍµ¨\n",
    "# ============================================================================\n",
    "\n",
    "# ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏµúÏ†ÅÌôî\n",
    "import optuna\n",
    "\n",
    "# Scikit-learn: Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest, RFE,\n",
    "    mutual_info_classif, mutual_info_regression\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "# Scikit-learn: Î™®Îç∏\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "# Scikit-learn: ÏïôÏÉÅÎ∏î Î™®Îç∏\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier, AdaBoostRegressor,\n",
    "    BaggingClassifier, BaggingRegressor,\n",
    "    ExtraTreesClassifier, ExtraTreesRegressor,\n",
    "    GradientBoostingClassifier, GradientBoostingRegressor,\n",
    "    HistGradientBoostingClassifier, \n",
    "    RandomForestClassifier, RandomForestRegressor,\n",
    "    StackingClassifier, StackingRegressor,\n",
    "    VotingClassifier, VotingRegressor\n",
    ")\n",
    "\n",
    "# Scikit-learn: ÌèâÍ∞Ä ÏßÄÌëú\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, # Î∂ÑÎ•ò ÏßÄÌëú\n",
    "    mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error # ÌöåÍ∑Ä ÏßÄÌëú\n",
    ")\n",
    "\n",
    "\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from lightgbm.callback import early_stopping \n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "# TensorFlow/Keras Îî•Îü¨Îãù\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    # Í∏∞Î≥∏ Î†àÏù¥Ïñ¥\n",
    "    Input, Dense, Flatten, Dropout, Activation,\n",
    "    # RNN Î†àÏù¥Ïñ¥\n",
    "    LSTM, GRU, SimpleRNN, Bidirectional,\n",
    "    # CNN Î†àÏù¥Ïñ¥\n",
    "    Conv1D, MaxPooling1D, AveragePooling1D,\n",
    "    GlobalAveragePooling1D, GlobalMaxPooling1D,\n",
    "    # Ï†ïÍ∑úÌôî Î†àÏù¥Ïñ¥\n",
    "    BatchNormalization, LayerNormalization,\n",
    "    # Attention Î†àÏù¥Ïñ¥\n",
    "    Attention, MultiHeadAttention,\n",
    "    # Ïú†Ìã∏Î¶¨Ìã∞ Î†àÏù¥Ïñ¥\n",
    "    Concatenate, Add, Multiply, Lambda,\n",
    "    Reshape, Permute, RepeatVector, TimeDistributed\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# ÏãúÍ≥ÑÏó¥ Î∂ÑÏÑù (Statsmodels)\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "\n",
    "# PyTorch \n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import optuna\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, AdaBoostClassifier, BaggingClassifier,\n",
    "    GradientBoostingClassifier, ExtraTreesClassifier, StackingClassifier,\n",
    "    VotingClassifier, HistGradientBoostingClassifier\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm.callback import early_stopping\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "df_merged=pd.read_csv(\"merge_data.csv\")\n",
    "\n",
    "df_merged.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35e3089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_merged.shape)\n",
    "# df_merged['date']=pd.to_datetime(df_merged['date'])\n",
    "# lookahead=5\n",
    "# p_mult=1.5\n",
    "# s_mult=1.0\n",
    "\n",
    "# pipeline_result = build_complete_pipeline_corrected(\n",
    "#     df_raw=df_merged,\n",
    "#     train_start_date='2020-01-01',\n",
    "#     final_test_start='2025-01-01',\n",
    "#     lookahead_candles=lookahead,\n",
    "#     atr_multiplier_profit=p_mult,\n",
    "#     atr_multiplier_stop=s_mult,\n",
    "#     top_n=20\n",
    "# )\n",
    "# print(pipeline_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44a0917d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#display(first_fold['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9febcea1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-22 10:08:13,669] A new study created in memory with name: no-name-8c6d4f8e-8c19-41f9-91e7-21fa197a777e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GPU Detected & Memory Growth Set!\n",
      "Loaded Data: 2351 rows (2019-06-15 ~ 2025-11-20)\n",
      "\n",
      "================================================================================\n",
      " Starting trial_0_L5_P1.5_S1.8\n",
      "\n",
      " Pipeline Started... (Train Start: 2020-01-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1556960/1210223439.py:54: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_ta['EMA_12'] = ta.ema(close, length=12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2351, 85)\n",
      "\n",
      "================================================================================\n",
      "Reverse Rolling Walk-Forward \n",
      "================================================================================\n",
      "Total: 2151 days\n",
      "Rolling train size: 800 days \n",
      "Val: 150 days | Test: 150 days\n",
      "Gap: 5 days \n",
      "================================================================================\n",
      "\n",
      "Fold 1 (walk_forward_rolling)\n",
      "  Train:  800d  2020-04-21 ~ 2022-06-29\n",
      "  Val:    150d  2022-07-05 ~ 2022-12-01\n",
      "  Test:   150d  2022-12-07 ~ 2023-05-05\n",
      "\n",
      "Fold 2 (walk_forward_rolling)\n",
      "  Train:  800d  2020-09-23 ~ 2022-12-01\n",
      "  Val:    150d  2022-12-07 ~ 2023-05-05\n",
      "  Test:   150d  2023-05-11 ~ 2023-10-07\n",
      "\n",
      "Fold 3 (walk_forward_rolling)\n",
      "  Train:  800d  2021-02-25 ~ 2023-05-05\n",
      "  Val:    150d  2023-05-11 ~ 2023-10-07\n",
      "  Test:   150d  2023-10-13 ~ 2024-03-10\n",
      "\n",
      "Fold 4 (walk_forward_rolling)\n",
      "  Train:  800d  2021-07-30 ~ 2023-10-07\n",
      "  Val:    150d  2023-10-13 ~ 2024-03-10\n",
      "  Test:   150d  2024-03-16 ~ 2024-08-12\n",
      "\n",
      "Fold 5 (walk_forward_rolling)\n",
      "  Train:  800d  2022-01-01 ~ 2024-03-10\n",
      "  Val:    150d  2024-03-16 ~ 2024-08-12\n",
      "  Test:   150d  2024-08-18 ~ 2025-01-14\n",
      "\n",
      "Fold 6 (walk_forward_rolling)\n",
      "  Train:  800d  2022-06-05 ~ 2024-08-12\n",
      "  Val:    150d  2024-08-18 ~ 2025-01-14\n",
      "  Test:   150d  2025-01-20 ~ 2025-06-18\n",
      "\n",
      "Fold 7 (walk_forward_rolling)\n",
      "  Train:  800d  2022-11-07 ~ 2025-01-14\n",
      "  Val:    150d  2025-01-20 ~ 2025-06-18\n",
      "  Test:   150d  2025-06-24 ~ 2025-11-20\n",
      "\n",
      "Fold 8 (final_holdout)\n",
      "  Train:  800d  2022-05-22 ~ 2024-07-29\n",
      "  Val:    150d  2024-08-04 ~ 2024-12-31\n",
      "  Test:   324d  2025-01-01 ~ 2025-11-20\n",
      "\n",
      "================================================================================\n",
      "Created 8 folds total\n",
      "================================================================================\n",
      "\n",
      " Data Split Completed. Total 8 folds generated.\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 1 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-04-21 ~ 2022-06-29 (N=800)\n",
      " Val   Period: 2022-07-05 ~ 2022-12-01 (N=150)\n",
      " Test  Period: 2022-12-07 ~ 2023-05-05 (N=150)\n",
      "[Class Balance] Train Set: {1.0: 0.5133333333333333, 2.0: 0.28, 0.0: 0.20666666666666667}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, BB_WIDTH, MACDS_12_26_9, curve_curve-dex_eth_tvl_ma30_ratio, usdt_totalUnreleased_ma30_ratio, ATR_14, gold_GOLD_ma30_ratio, SMA_20, EMA_12, MACD_12_26_9, eth_btc_corr_30d, lido_lido_eth_tvl_ma30_ratio, chain_eth_chain_tvl_ma30_ratio, MACDH_12_26_9, PRICE_VS_LOW_20d, PRICE_VS_LOW_60d, aave_aave_eth_tvl_ma30_ratio, dxy_DXY_ma30_ratio, l2_arbitrum_tvl_ma30_ratio, TREND_SCORE\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 2 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2020-09-23 ~ 2022-12-01 (N=800)\n",
      " Val   Period: 2022-12-07 ~ 2023-05-05 (N=150)\n",
      " Test  Period: 2023-05-11 ~ 2023-10-07 (N=150)\n",
      "[Class Balance] Train Set: {1.0: 0.5383333333333333, 2.0: 0.24, 0.0: 0.22166666666666668}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> EMA_12, MACDS_12_26_9, eth_btc_corr_7d, PRICE_VS_LOW_60d, aave_aave_eth_tvl_ma30_ratio, makerdao_makerdao_eth_tvl_ma30_ratio, MACDH_12_26_9, SMA_20, BB_WIDTH, MACD_12_26_9, l2_arbitrum_tvl_ma30_ratio, eth_btc_corr_30d, chain_eth_chain_tvl_ma30_ratio, BREAKOUT_STR_20d, usdt_totalMintedUSD_ma30_ratio, ATR_14, usdt_totalUnreleased_ma30_ratio, curve_curve-dex_eth_tvl_ma30_ratio, l2_optimism_tvl_ma30_ratio, SMA_50\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 3 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-02-25 ~ 2023-05-05 (N=800)\n",
      " Val   Period: 2023-05-11 ~ 2023-10-07 (N=150)\n",
      " Test  Period: 2023-10-13 ~ 2024-03-10 (N=150)\n",
      "[Class Balance] Train Set: {1.0: 0.5483333333333333, 2.0: 0.24666666666666667, 0.0: 0.205}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> BB_WIDTH, usdt_totalBridgedToUSD_ma30_ratio, l2_arbitrum_tvl_ma30_ratio, usdt_totalUnreleased_ma30_ratio, MACDH_12_26_9, PRICE_VS_LOW_60d, l2_optimism_tvl_ma30_ratio, ATR_14, dxy_DXY_ma30_ratio, SMA_50, SMA_20, EMA_12, usdt_totalCirculating_ma30_ratio, usdt_totalMintedUSD_ma30_ratio, MACD_12_26_9, usdt_totalCirculatingUSD_ma30_ratio, sp500_SP500_ma30_ratio, MACDS_12_26_9, l2_zksync era_tvl_pct_1d, return_lag5\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 4 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2021-07-30 ~ 2023-10-07 (N=800)\n",
      " Val   Period: 2023-10-13 ~ 2024-03-10 (N=150)\n",
      " Test  Period: 2024-03-16 ~ 2024-08-12 (N=150)\n",
      "[Class Balance] Train Set: {1.0: 0.5383333333333333, 2.0: 0.25333333333333335, 0.0: 0.20833333333333334}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> ATR_14, usdt_totalBridgedToUSD_ma30_ratio, BB_WIDTH, MACDS_12_26_9, usdt_totalUnreleased_ma30_ratio, eth_btc_corr_30d, PRICE_VS_LOW_60d, l2_optimism_tvl_ma30_ratio, OBV, sp500_SP500_ma30_ratio, SMA_50, SMA_20, usdt_totalMintedUSD_ma30_ratio, l2_arbitrum_tvl_ma30_ratio, EMA_12, usdt_totalCirculating_ma30_ratio, eth_btc_corr_7d, vix_VIX_ma30_ratio, gold_GOLD_ma30_ratio, dxy_DXY_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 5 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-01-01 ~ 2024-03-10 (N=800)\n",
      " Val   Period: 2024-03-16 ~ 2024-08-12 (N=150)\n",
      " Test  Period: 2024-08-18 ~ 2025-01-14 (N=150)\n",
      "[Class Balance] Train Set: {1.0: 0.5066666666666667, 2.0: 0.3233333333333333, 0.0: 0.17}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, MACD_12_26_9, eth_btc_corr_30d, usdt_totalCirculating_ma30_ratio, usdt_totalBridgedToUSD_ma30_ratio, gold_GOLD_ma30_ratio, curve_curve-dex_eth_tvl_ma30_ratio, PRICE_VS_LOW_60d, usdt_totalUnreleased_ma30_ratio, SMA_20, EMA_12, OBV, fg_fear_greed, usdt_totalCirculatingUSD_ma30_ratio, PRICE_VS_HIGH_20d, ATR_14, BREAKOUT_STR_20d, eth_btc_corr_7d, l2_arbitrum_tvl_ma30_ratio, dxy_DXY_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 6 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-06-05 ~ 2024-08-12 (N=800)\n",
      " Val   Period: 2024-08-18 ~ 2025-01-14 (N=150)\n",
      " Test  Period: 2025-01-20 ~ 2025-06-18 (N=150)\n",
      "[Class Balance] Train Set: {1.0: 0.49, 2.0: 0.31166666666666665, 0.0: 0.19833333333333333}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, SMA_20, eth_btc_corr_30d, usdt_totalBridgedToUSD_ma30_ratio, PRICE_VS_LOW_60d, gold_GOLD_ma30_ratio, ATR_14, dxy_DXY_ma30_ratio, EMA_12, BB_WIDTH, MACDS_12_26_9, MACD_12_26_9, OBV, l2_base_tvl_ma30_ratio, PRICE_VS_HIGH_20d, vix_VIX_ma30_ratio, usdt_totalCirculating_ma30_ratio, usdt_totalUnreleased_ma30_ratio, l2_zksync era_tvl_ma30_ratio, price_rank_250d\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 7 (walk_forward_rolling_reverse)\n",
      "================================================================================\n",
      " Train Period: 2022-11-07 ~ 2025-01-14 (N=800)\n",
      " Val   Period: 2025-01-20 ~ 2025-06-18 (N=150)\n",
      " Test  Period: 2025-06-24 ~ 2025-11-20 (N=150)\n",
      "[Class Balance] Train Set: {1.0: 0.4866666666666667, 2.0: 0.28833333333333333, 0.0: 0.225}\n",
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, MACDS_12_26_9, usdt_totalBridgedToUSD_ma30_ratio, eth_btc_corr_30d, ATR_14, l2_base_tvl_ma30_ratio, usdt_totalUnreleased_ma30_ratio, l2_zksync era_tvl_ma30_ratio, gold_GOLD_ma30_ratio, SMA_20, EMA_12, BB_WIDTH, usdt_totalMintedUSD_ma30_ratio, OBV, PRICE_VS_HIGH_20d, curve_curve-dex_eth_tvl_ma30_ratio, BREAKOUT_STR_20d, PRICE_VS_LOW_60d, usdt_totalCirculating_ma30_ratio, usdt_totalCirculatingUSD_ma30_ratio\n",
      "\n",
      "================================================================================\n",
      " Processing Fold 8 (final_holdout)\n",
      "================================================================================\n",
      " Train Period: 2022-05-22 ~ 2024-07-29 (N=800)\n",
      " Val   Period: 2024-08-04 ~ 2024-12-31 (N=150)\n",
      " Test  Period: 2025-01-01 ~ 2025-11-20 (N=324)\n",
      "[Class Balance] Train Set: {1.0: 0.49333333333333335, 2.0: 0.31166666666666665, 0.0: 0.195}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Feature Selection] Top 20 Features Selected:\n",
      " -> SMA_50, SMA_20, eth_btc_corr_30d, usdt_totalBridgedToUSD_ma30_ratio, PRICE_VS_HIGH_20d, gold_GOLD_ma30_ratio, ATR_14, EMA_12, BB_WIDTH, OBV, MACD_12_26_9, PRICE_VS_LOW_60d, l2_base_tvl_ma30_ratio, MACDH_12_26_9, MFI_14, return_lag10, usdt_totalUnreleased_ma30_ratio, curve_curve-dex_eth_tvl_ma30_ratio, vix_VIX_ma30_ratio, dxy_DXY_ma30_ratio\n",
      "\n",
      "   >> Running Fold 1/8 (walk_forward_rolling_reverse)\n",
      "[CatBoost]\n",
      "  Optuna Threshold: 0.4977 (Val Return: -60.00R)\n",
      "  Test Performance -> Win Rate: 37.16% | Trades: 148 | PF: 0.49\n",
      "  Test Simulation  -> Expectancy: -0.32R | Total Return: -47.17R\n",
      "[RandomForest]\n",
      "  Optuna Threshold: 0.7049 (Val Return: -1.33R)\n",
      "  Test Performance -> Win Rate: 27.27% | Trades: 11 | PF: 0.31\n",
      "  Test Simulation  -> Expectancy: -0.50R | Total Return: -5.50R\n",
      "[LightGBM]\n",
      "  Optuna Threshold: 0.5164 (Val Return: 0.17R)\n",
      "  Test Performance -> Win Rate: 32.35% | Trades: 34 | PF: 0.40\n",
      "  Test Simulation  -> Expectancy: -0.41R | Total Return: -13.83R\n",
      "[XGBoost]\n",
      "  Optuna Threshold: 0.6914 (Val Return: -4.17R)\n",
      "  Test Performance -> Win Rate: 22.22% | Trades: 9 | PF: 0.24\n",
      "  Test Simulation  -> Expectancy: -0.59R | Total Return: -5.33R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 10:09:52.095219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46589 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:1d:00.0, compute capability: 8.6\n",
      "2025-11-22 10:09:56.014753: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2025-11-22 10:09:57.852496: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f555c07ea20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-11-22 10:09:57.852533: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2025-11-22 10:09:57.862776: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1763773797.975422 1559133 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM]\n",
      "  Optuna Threshold: 0.5485 (Val Return: -9.83R)\n",
      "  Test Performance -> Win Rate: 41.67% | Trades: 84 | PF: 0.60\n",
      "  Test Simulation  -> Expectancy: -0.24R | Total Return: -19.83R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   >> Running Fold 2/8 (walk_forward_rolling_reverse)\n",
      "[CatBoost]\n",
      "  Optuna Threshold: 0.6121 (Val Return: -2.67R)\n",
      "  Test Performance -> Win Rate: 0.00% | Trades: 0 | PF: 0.00\n",
      "  Test Simulation  -> Expectancy: 0.00R | Total Return: 0.00R\n",
      "[RandomForest]\n",
      "  Optuna Threshold: 0.7249 (Val Return: 0.50R)\n",
      "  Test Performance -> Win Rate: 0.00% | Trades: 0 | PF: 0.00\n",
      "  Test Simulation  -> Expectancy: 0.00R | Total Return: 0.00R\n",
      "[LightGBM]\n",
      "  Optuna Threshold: 0.4119 (Val Return: -49.17R)\n",
      "  Test Performance -> Win Rate: 22.67% | Trades: 150 | PF: 0.24\n",
      "  Test Simulation  -> Expectancy: -0.58R | Total Return: -87.67R\n",
      "[XGBoost]\n",
      "  Optuna Threshold: 0.6219 (Val Return: -1.50R)\n",
      "  Test Performance -> Win Rate: 0.00% | Trades: 0 | PF: 0.00\n",
      "  Test Simulation  -> Expectancy: 0.00R | Total Return: 0.00R\n",
      "[LSTM]\n",
      "  Optuna Threshold: 0.7621 (Val Return: 5.33R)\n",
      "  Test Performance -> Win Rate: 41.67% | Trades: 12 | PF: 0.60\n",
      "  Test Simulation  -> Expectancy: -0.24R | Total Return: -2.83R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   >> Running Fold 3/8 (walk_forward_rolling_reverse)\n",
      "[CatBoost]\n",
      "  Optuna Threshold: 0.5453 (Val Return: -1.50R)\n",
      "  Test Performance -> Win Rate: 100.00% | Trades: 3 | PF: 99.00\n",
      "  Test Simulation  -> Expectancy: 0.83R | Total Return: 2.50R\n",
      "[RandomForest]\n",
      "  Optuna Threshold: 0.5454 (Val Return: -3.17R)\n",
      "  Test Performance -> Win Rate: 66.67% | Trades: 18 | PF: 1.67\n",
      "  Test Simulation  -> Expectancy: 0.22R | Total Return: 4.00R\n",
      "[LightGBM]\n",
      "  Optuna Threshold: 0.4719 (Val Return: -87.67R)\n",
      "  Test Performance -> Win Rate: 50.00% | Trades: 150 | PF: 0.83\n",
      "  Test Simulation  -> Expectancy: -0.08R | Total Return: -12.50R\n",
      "[XGBoost]\n",
      "  Optuna Threshold: 0.4625 (Val Return: -87.67R)\n",
      "  Test Performance -> Win Rate: 50.00% | Trades: 150 | PF: 0.83\n",
      "  Test Simulation  -> Expectancy: -0.08R | Total Return: -12.50R\n",
      "[LSTM]\n",
      "  Optuna Threshold: 0.7356 (Val Return: -1.50R)\n",
      "  Test Performance -> Win Rate: 17.39% | Trades: 46 | PF: 0.18\n",
      "  Test Simulation  -> Expectancy: -0.68R | Total Return: -31.33R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   >> Running Fold 4/8 (walk_forward_rolling_reverse)\n",
      "[CatBoost]\n",
      "  Optuna Threshold: 0.5010 (Val Return: 8.33R)\n",
      "  Test Performance -> Win Rate: 23.53% | Trades: 34 | PF: 0.26\n",
      "  Test Simulation  -> Expectancy: -0.57R | Total Return: -19.33R\n",
      "[RandomForest]\n",
      "  Optuna Threshold: 0.5652 (Val Return: 10.17R)\n",
      "  Test Performance -> Win Rate: 0.00% | Trades: 1 | PF: 0.00\n",
      "  Test Simulation  -> Expectancy: -1.00R | Total Return: -1.00R\n",
      "[LightGBM]\n",
      "  Optuna Threshold: 0.5008 (Val Return: 7.17R)\n",
      "  Test Performance -> Win Rate: 28.57% | Trades: 70 | PF: 0.33\n",
      "  Test Simulation  -> Expectancy: -0.48R | Total Return: -33.33R\n",
      "[XGBoost]\n",
      "  Optuna Threshold: 0.5206 (Val Return: 5.33R)\n",
      "  Test Performance -> Win Rate: 100.00% | Trades: 2 | PF: 99.00\n",
      "  Test Simulation  -> Expectancy: 0.83R | Total Return: 1.67R\n",
      "[LSTM]\n",
      "  Optuna Threshold: 0.5521 (Val Return: 1.33R)\n",
      "  Test Performance -> Win Rate: 0.00% | Trades: 0 | PF: 0.00\n",
      "  Test Simulation  -> Expectancy: 0.00R | Total Return: 0.00R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   >> Running Fold 5/8 (walk_forward_rolling_reverse)\n",
      "[CatBoost]\n",
      "  Optuna Threshold: 0.5091 (Val Return: -17.17R)\n",
      "  Test Performance -> Win Rate: 61.54% | Trades: 26 | PF: 1.33\n",
      "  Test Simulation  -> Expectancy: 0.13R | Total Return: 3.33R\n",
      "[RandomForest]\n",
      "  Optuna Threshold: 0.6651 (Val Return: -0.00R)\n",
      "  Test Performance -> Win Rate: 8.70% | Trades: 23 | PF: 0.08\n",
      "  Test Simulation  -> Expectancy: -0.84R | Total Return: -19.33R\n",
      "[LightGBM]\n",
      "  Optuna Threshold: 0.5273 (Val Return: -12.00R)\n",
      "  Test Performance -> Win Rate: 17.50% | Trades: 40 | PF: 0.18\n",
      "  Test Simulation  -> Expectancy: -0.68R | Total Return: -27.17R\n",
      "[XGBoost]\n",
      "  Optuna Threshold: 0.4036 (Val Return: -109.67R)\n",
      "  Test Performance -> Win Rate: 28.00% | Trades: 150 | PF: 0.32\n",
      "  Test Simulation  -> Expectancy: -0.49R | Total Return: -73.00R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-11-22 10:20:50,883] Trial 5 failed with parameters: {'units': 96, 'dropout': 0.5963305828536876, 'l2_reg': 0.0006843591194925379, 'lr': 0.001779530526219786} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_1556960/209885645.py\", line 217, in objective\n",
      "    model.fit(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1807, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 832, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 888, in _call\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 695, in _initialize\n",
      "    self._concrete_variable_creation_fn = tracing_compilation.trace_function(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 178, in trace_function\n",
      "    concrete_function = _maybe_define_function(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 283, in _maybe_define_function\n",
      "    concrete_function = _create_concrete_function(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 310, in _create_concrete_function\n",
      "    traced_func_graph = func_graph_module.func_graph_from_py_func(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py\", line 1059, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 598, in wrapped_fn\n",
      "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py\", line 41, in autograph_handler\n",
      "    return api.converted_call(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 439, in converted_call\n",
      "    result = converted_f(*effective_args, **kwargs)\n",
      "  File \"/tmp/__autograph_generated_file_4hh6sg7.py\", line 15, in tf__train_function\n",
      "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 377, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 460, in _call_unconverted\n",
      "    return f(*args)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n",
      "    outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 1681, in run\n",
      "    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 3271, in call_for_each_replica\n",
      "    return self._call_for_each_replica(fn, args, kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 4069, in _call_for_each_replica\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 690, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 377, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 459, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n",
      "    outputs = model.train_step(data)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1154, in train_step\n",
      "    self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 543, in minimize\n",
      "    grads_and_vars = self.compute_gradients(loss, var_list, tape)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 276, in compute_gradients\n",
      "    grads = tape.gradient(loss, var_list)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py\", line 1066, in gradient\n",
      "    flat_grad = imperative_grad.imperative_grad(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/imperative_grad.py\", line 67, in imperative_grad\n",
      "    return pywrap_tfe.TFE_Py_TapeGradient(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py\", line 148, in _gradient_function\n",
      "    return grad_fn(mock_op, *out_grads)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/ops/math_grad.py\", line 179, in _SumGrad\n",
      "    grad = array_ops.reshape(grad, new_shape)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py\", line 88, in wrapper\n",
      "    return op(*args, **kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py\", line 1260, in op_dispatch_handler\n",
      "    return dispatch_target(*args, **kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py\", line 201, in reshape\n",
      "    result = gen_array_ops.reshape(tensor, shape, name)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 8758, in reshape\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/op_def_library.py\", line 778, in _apply_op_helper\n",
      "    _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/op_def_library.py\", line 531, in _ExtractInputsAndAttrs\n",
      "    inferred = ops.convert_to_tensor(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 696, in convert_to_tensor\n",
      "    return tensor_conversion_registry.convert(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 234, in convert\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py\", line 335, in _constant_tensor_conversion_function\n",
      "    return constant(v, dtype=dtype, name=name)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py\", line 142, in wrapper\n",
      "    return op(*args, **kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py\", line 286, in _constant_impl\n",
      "    const_tensor = ops._create_graph_constant(  # pylint: disable=protected-access\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 268, in _create_graph_constant\n",
      "    const_tensor = g._create_op_internal(  # pylint: disable=protected-access\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py\", line 670, in _create_op_internal\n",
      "    return super()._create_op_internal(  # pylint: disable=protected-access\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 2652, in _create_op_internal\n",
      "    ret = Operation.from_node_def(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 1160, in from_node_def\n",
      "    c_op = _create_c_op(g, node_def, inputs, control_input_ops, op_def=op_def)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 1026, in _create_c_op\n",
      "    c_op, tf_stack.extract_stack(stacklevel=3)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/tf_stack.py\", line 162, in extract_stack\n",
      "    return _tf_stack.extract_stack(\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-11-22 10:20:50,905] Trial 5 failed with value None.\n",
      "[W 2025-11-22 10:20:50,906] Trial 0 failed with parameters: {'lookahead': 5, 'profit_mult': 1.5, 'stop_mult': 1.8} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_1556960/1343576181.py\", line 43, in objective\n",
      "    trainer.train_all_models(\n",
      "  File \"/tmp/ipykernel_1556960/2681119743.py\", line 261, in train_all_models\n",
      "    model = config['func'](X_train_s, y_train_s, X_val_s, y_val_s, input_shape)\n",
      "  File \"/tmp/ipykernel_1556960/209885645.py\", line 233, in lstm\n",
      "    study.optimize(objective, n_trials=20)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/optuna/study/study.py\", line 490, in optimize\n",
      "    _optimize(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 63, in _optimize\n",
      "    _optimize_sequential(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 160, in _optimize_sequential\n",
      "    frozen_trial_id = _run_trial(study, func, catch)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 258, in _run_trial\n",
      "    raise func_err\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_1556960/209885645.py\", line 217, in objective\n",
      "    model.fit(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1807, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 832, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 888, in _call\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 695, in _initialize\n",
      "    self._concrete_variable_creation_fn = tracing_compilation.trace_function(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 178, in trace_function\n",
      "    concrete_function = _maybe_define_function(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 283, in _maybe_define_function\n",
      "    concrete_function = _create_concrete_function(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 310, in _create_concrete_function\n",
      "    traced_func_graph = func_graph_module.func_graph_from_py_func(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py\", line 1059, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 598, in wrapped_fn\n",
      "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py\", line 41, in autograph_handler\n",
      "    return api.converted_call(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 439, in converted_call\n",
      "    result = converted_f(*effective_args, **kwargs)\n",
      "  File \"/tmp/__autograph_generated_file_4hh6sg7.py\", line 15, in tf__train_function\n",
      "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 377, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 460, in _call_unconverted\n",
      "    return f(*args)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n",
      "    outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 1681, in run\n",
      "    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 3271, in call_for_each_replica\n",
      "    return self._call_for_each_replica(fn, args, kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 4069, in _call_for_each_replica\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 690, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 377, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 459, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n",
      "    outputs = model.train_step(data)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1154, in train_step\n",
      "    self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 543, in minimize\n",
      "    grads_and_vars = self.compute_gradients(loss, var_list, tape)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 276, in compute_gradients\n",
      "    grads = tape.gradient(loss, var_list)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py\", line 1066, in gradient\n",
      "    flat_grad = imperative_grad.imperative_grad(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/imperative_grad.py\", line 67, in imperative_grad\n",
      "    return pywrap_tfe.TFE_Py_TapeGradient(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py\", line 148, in _gradient_function\n",
      "    return grad_fn(mock_op, *out_grads)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/ops/math_grad.py\", line 179, in _SumGrad\n",
      "    grad = array_ops.reshape(grad, new_shape)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py\", line 88, in wrapper\n",
      "    return op(*args, **kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py\", line 1260, in op_dispatch_handler\n",
      "    return dispatch_target(*args, **kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py\", line 201, in reshape\n",
      "    result = gen_array_ops.reshape(tensor, shape, name)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 8758, in reshape\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/op_def_library.py\", line 778, in _apply_op_helper\n",
      "    _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/op_def_library.py\", line 531, in _ExtractInputsAndAttrs\n",
      "    inferred = ops.convert_to_tensor(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 696, in convert_to_tensor\n",
      "    return tensor_conversion_registry.convert(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 234, in convert\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py\", line 335, in _constant_tensor_conversion_function\n",
      "    return constant(v, dtype=dtype, name=name)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py\", line 142, in wrapper\n",
      "    return op(*args, **kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py\", line 286, in _constant_impl\n",
      "    const_tensor = ops._create_graph_constant(  # pylint: disable=protected-access\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 268, in _create_graph_constant\n",
      "    const_tensor = g._create_op_internal(  # pylint: disable=protected-access\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py\", line 670, in _create_op_internal\n",
      "    return super()._create_op_internal(  # pylint: disable=protected-access\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 2652, in _create_op_internal\n",
      "    ret = Operation.from_node_def(\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 1160, in from_node_def\n",
      "    c_op = _create_c_op(g, node_def, inputs, control_input_ops, op_def=op_def)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 1026, in _create_c_op\n",
      "    c_op, tf_stack.extract_stack(stacklevel=3)\n",
      "  File \"/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/tf_stack.py\", line 162, in extract_stack\n",
      "    return _tf_stack.extract_stack(\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-11-22 10:20:50,908] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m df_merged \u001b[38;5;241m=\u001b[39m df_merged\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded Data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_merged)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_merged[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;241m.\u001b[39mdate()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ~ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_merged[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mdate()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m study \u001b[38;5;241m=\u001b[39m \u001b[43mrun_optuna_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_merged\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m==================================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Best Trial Value (Avg Buy Precision): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy\u001b[38;5;241m.\u001b[39mbest_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 85\u001b[0m, in \u001b[0;36mrun_optuna_optimization\u001b[0;34m(df_merged, n_trials)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     84\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 85\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[Optuna] Optimization Completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Params:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/optuna/study/study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial_id \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/optuna/study/_optimize.py:258\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    254\u001b[0m     updated_state \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    257\u001b[0m ):\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\u001b[38;5;241m.\u001b[39m_trial_id\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/optuna/study/_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[7], line 43\u001b[0m, in \u001b[0;36mrun_optuna_optimization.<locals>.objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     40\u001b[0m test_prices \u001b[38;5;241m=\u001b[39m fold_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreal_entry_price\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     41\u001b[0m test_atr \u001b[38;5;241m=\u001b[39m fold_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATR_14\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m---> 43\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_all_models\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mX_robust\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mX_robust\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mX_robust\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdates\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_prices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_atr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mp_mult\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43ms_mult\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mml_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mML_MODELS_CLASSIFICATION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdl_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDL_MODELS_CLASSIFICATION\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m summary \u001b[38;5;241m=\u001b[39m save_fold_results(fold_idx, fold_type, evaluator, trial_name, fold_data)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest_Opt_Expectancy\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m summary\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "Cell \u001b[0;32mIn[6], line 261\u001b[0m, in \u001b[0;36mModelTrainer.train_all_models\u001b[0;34m(self, X_train, y_train_input, X_val, y_val_input, X_test, y_test_input, test_dates, test_prices, test_atr, profit_mult, stop_mult, ml_models, dl_models)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    260\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mclear_session()\n\u001b[0;32m--> 261\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfunc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluator\u001b[38;5;241m.\u001b[39mevaluate_classification_model(\n\u001b[1;32m    264\u001b[0m         model, X_train_s, y_train_s, X_val_s, y_val_s, X_test_s, y_test_input_s, \n\u001b[1;32m    265\u001b[0m         test_dates_s, test_prices_s, test_atr_s, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m         stop_mult\u001b[38;5;241m=\u001b[39mstop_mult      \n\u001b[1;32m    270\u001b[0m     )\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m model\n",
      "Cell \u001b[0;32mIn[5], line 233\u001b[0m, in \u001b[0;36mDirectionModels.lstm\u001b[0;34m(X_train, y_train, X_val, y_val, input_shape)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buy_precision\n\u001b[1;32m    232\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 233\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m best \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[1;32m    236\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mclear_session()\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/optuna/study/study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial_id \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/optuna/study/_optimize.py:258\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    254\u001b[0m     updated_state \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    257\u001b[0m ):\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\u001b[38;5;241m.\u001b[39m_trial_id\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/optuna/study/_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[5], line 217\u001b[0m, in \u001b[0;36mDirectionModels.lstm.<locals>.objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    209\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m    210\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlr),\n\u001b[1;32m    211\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    212\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    213\u001b[0m )\n\u001b[1;32m    215\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 217\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m    225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m val_probs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    228\u001b[0m val_preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(val_probs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:888\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 888\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    890\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    891\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    892\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:695\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    691\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    692\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    693\u001b[0m )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    700\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:598\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 598\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file_4hh6sg7.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1380\u001b[0m     run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[1;32m   1381\u001b[0m         run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1382\u001b[0m     )\n\u001b[1;32m   1383\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m-> 1384\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[1;32m   1386\u001b[0m     outputs,\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[1;32m   1388\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_reduction_method,\n\u001b[1;32m   1389\u001b[0m )\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:1681\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m   1677\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1678\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1679\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   1680\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1681\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3271\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3269\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   3270\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 3271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:4069\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4067\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   4068\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 4069\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1373\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[0;32m-> 1373\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1154\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;66;03m# Run backwards pass.\u001b[39;00m\n\u001b[0;32m-> 1154\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py:543\u001b[0m, in \u001b[0;36m_BaseOptimizer.minimize\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mminimize\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss, var_list, tape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    523\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \n\u001b[1;32m    525\u001b[0m \u001b[38;5;124;03m    This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;124;03m      None\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_gradients(grads_and_vars)\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py:276\u001b[0m, in \u001b[0;36m_BaseOptimizer.compute_gradients\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(var_list):\n\u001b[1;32m    274\u001b[0m             var_list \u001b[38;5;241m=\u001b[39m var_list()\n\u001b[0;32m--> 276\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, var_list))\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:1066\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1060\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1061\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m   1062\u001b[0m           output_gradients))\n\u001b[1;32m   1063\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m   1064\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[0;32m-> 1066\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[1;32m   1075\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:148\u001b[0m, in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    146\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/ops/math_grad.py:179\u001b[0m, in \u001b[0;36m_SumGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m   new_shape \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m rank\n\u001b[0;32m--> 179\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[43marray_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# If shape is not fully defined (but rank is), we use Shape.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m input_0_shape:\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     87\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     90\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:201\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmanip.reshape\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     66\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreshape\u001b[39m(tensor, shape, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# pylint: disable=redefined-outer-name\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Reshapes a tensor.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m  Given `tensor`, this operation returns a new `tf.Tensor` that has the same\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m    A `Tensor`. Has the same type as `tensor`.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m   shape_util\u001b[38;5;241m.\u001b[39mmaybe_set_static_shape(result, shape)\n\u001b[1;32m    203\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/ops/gen_array_ops.py:8758\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   8756\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m   8757\u001b[0m \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m-> 8758\u001b[0m _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_op_def_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8759\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReshape\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   8760\u001b[0m _result \u001b[38;5;241m=\u001b[39m _outputs[:]\n\u001b[1;32m   8761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/op_def_library.py:778\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m g\u001b[38;5;241m.\u001b[39mas_default(), ops\u001b[38;5;241m.\u001b[39mname_scope(name) \u001b[38;5;28;01mas\u001b[39;00m scope:\n\u001b[1;32m    777\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m fallback:\n\u001b[0;32m--> 778\u001b[0m     \u001b[43m_ExtractInputsAndAttrs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowed_list_attr_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_type_attr_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m                           \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m     _ExtractRemainingAttrs(op_type_name, op_def, keywords,\n\u001b[1;32m    782\u001b[0m                            default_type_attr_map, attrs)\n\u001b[1;32m    783\u001b[0m     _ExtractAttrProto(op_type_name, op_def, attrs, attr_protos)\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/op_def_library.py:531\u001b[0m, in \u001b[0;36m_ExtractInputsAndAttrs\u001b[0;34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001b[0m\n\u001b[1;32m    529\u001b[0m inferred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 531\u001b[0m   inferred \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_arg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_arg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    534\u001b[0m   \u001b[38;5;66;03m# When converting a python object such as a list of Dimensions, we\u001b[39;00m\n\u001b[1;32m    535\u001b[0m   \u001b[38;5;66;03m# need a dtype to be specified, thus tensor conversion may throw\u001b[39;00m\n\u001b[1;32m    536\u001b[0m   \u001b[38;5;66;03m# an exception which we will ignore and try again below.\u001b[39;00m\n\u001b[1;32m    537\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:696\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[1;32m    695\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:335\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    333\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    334\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m--> 335\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:271\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconstant\u001b[39m(\n\u001b[1;32m    174\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ops\u001b[38;5;241m.\u001b[39mOperation, ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase]:\n\u001b[1;32m    176\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:286\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    283\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m    284\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 286\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_constant\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_broadcast\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:268\u001b[0m, in \u001b[0;36m_create_graph_constant\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    266\u001b[0m dtype_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mtensor_value\u001b[38;5;241m.\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    267\u001b[0m attrs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: tensor_value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: dtype_value}\n\u001b[0;32m--> 268\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConst\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdtype_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_callbacks\u001b[38;5;241m.\u001b[39mshould_invoke_op_callbacks():\n\u001b[1;32m    272\u001b[0m   \u001b[38;5;66;03m# TODO(b/147670703): Once the special-op creation code paths\u001b[39;00m\n\u001b[1;32m    273\u001b[0m   \u001b[38;5;66;03m# are unified. Remove this `if` block.\u001b[39;00m\n\u001b[1;32m    274\u001b[0m   callback_outputs \u001b[38;5;241m=\u001b[39m op_callbacks\u001b[38;5;241m.\u001b[39minvoke_op_callbacks(\n\u001b[1;32m    275\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtuple\u001b[39m(), attrs, (const_tensor,), op_name\u001b[38;5;241m=\u001b[39mname, graph\u001b[38;5;241m=\u001b[39mg)\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:670\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    668\u001b[0m   inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapture(inp)\n\u001b[1;32m    669\u001b[0m   captured_inputs\u001b[38;5;241m.\u001b[39mappend(inp)\n\u001b[0;32m--> 670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:2652\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   2649\u001b[0m \u001b[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[1;32m   2650\u001b[0m \u001b[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[1;32m   2651\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutation_lock():\n\u001b[0;32m-> 2652\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mOperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_node_def\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2653\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2654\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2655\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2656\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2657\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2658\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2659\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_original_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2660\u001b[0m \u001b[43m      \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2661\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2662\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_op_helper(ret, compute_device\u001b[38;5;241m=\u001b[39mcompute_device)\n\u001b[1;32m   2663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1160\u001b[0m, in \u001b[0;36mOperation.from_node_def\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1157\u001b[0m     control_input_ops\u001b[38;5;241m.\u001b[39mappend(control_op)\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;66;03m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[0;32m-> 1160\u001b[0m c_op \u001b[38;5;241m=\u001b[39m \u001b[43m_create_c_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_input_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m Operation(c_op, SymbolicTensor)\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init(g)\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1026\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# Record the current Python stack trace as the creating stacktrace of this\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;66;03m# TF_Operation.\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extract_traceback:\n\u001b[1;32m   1025\u001b[0m   pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_SetOpStackTrace(\n\u001b[0;32m-> 1026\u001b[0m       c_op, \u001b[43mtf_stack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstacklevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1027\u001b[0m   )\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c_op\n",
      "File \u001b[0;32m/raid/invigoworks/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/tf_stack.py:162\u001b[0m, in \u001b[0;36mextract_stack\u001b[0;34m(stacklevel)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"An eager-friendly alternative to traceback.extract_stack.\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m  line, meant to masquerade as traceback.FrameSummary objects.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m thread_key \u001b[38;5;241m=\u001b[39m _get_thread_key()\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_stack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_source_mapper_stacks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mthread_key\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minternal_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_source_filter_stacks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mthread_key\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minternal_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstacklevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if tf.config.list_physical_devices('GPU'):\n",
    "        try:\n",
    "            for gpu in tf.config.list_physical_devices('GPU'):\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(\" GPU Detected & Memory Growth Set!\")\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "    \n",
    "    if 'df_merged' in locals() and not df_merged.empty:\n",
    "        df_merged['date'] = pd.to_datetime(df_merged['date'])\n",
    "        df_merged = df_merged.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "        print(f\"Loaded Data: {len(df_merged)} rows ({df_merged['date'].min().date()} ~ {df_merged['date'].max().date()})\")\n",
    "\n",
    "        study = run_optuna_optimization(df_merged, n_trials=30)\n",
    "        \n",
    "        print(\"\\n==================================================\")\n",
    "        print(f\" Best Trial Value (Avg Buy Precision): {study.best_value:.4f}\")\n",
    "        print(f\" Best Parameters: {study.best_params}\")\n",
    "        print(\"==================================================\")\n",
    "    else:\n",
    "        print(\"[Error] 'df_merged' variable is not defined or empty. Please load data first.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

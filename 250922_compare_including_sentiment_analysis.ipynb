{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "274e0113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygooglenews==0.1.2 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: dateparser in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: tzlocal>=0.2 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from dateparser) (5.3.1)\n",
      "Requirement already satisfied: pytz>=2024.2 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from dateparser) (2025.2)\n",
      "Requirement already satisfied: regex>=2024.9.11 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from dateparser) (2025.9.18)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from dateparser) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.7.0->dateparser) (1.16.0)\n",
      "Requirement already satisfied: numpy in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: yfinance in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (0.2.65)\n",
      "Requirement already satisfied: scikit-learn in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (1.7.2)\n",
      "Requirement already satisfied: tensorflow in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (2.20.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from yfinance) (0.0.12)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from yfinance) (2.5.2)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: curl_cffi>=0.7 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from yfinance) (0.13.0)\n",
      "Requirement already satisfied: requests>=2.31 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from yfinance) (2.32.5)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from yfinance) (4.11.1)\n",
      "Requirement already satisfied: websockets>=13.0 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from yfinance) (15.0.1)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from yfinance) (3.18.2)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from yfinance) (5.29.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: setuptools in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from tensorflow) (65.6.3)\n",
      "Requirement already satisfied: keras>=3.10.0 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.75.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: packaging in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from tensorflow) (22.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.3.2.post1)\n",
      "Requirement already satisfied: cffi>=1.12.0 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from curl_cffi>=0.7->yfinance) (1.15.1)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from curl_cffi>=0.7->yfinance) (2025.8.3)\n",
      "Requirement already satisfied: namex in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: rich in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from requests>=2.31->yfinance) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from requests>=2.31->yfinance) (2.5.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: pillow in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (9.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pycparser in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.21)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (2.1.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Collecting git+https://github.com/aarigs/pandas-ta.git\n",
      "  Cloning https://github.com/aarigs/pandas-ta.git to /tmp/pip-req-build-rlck92x9\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/aarigs/pandas-ta.git /tmp/pip-req-build-rlck92x9\n",
      "  Resolved https://github.com/aarigs/pandas-ta.git to commit 7a2a4210c71334929c482366d255d57eed5bdbfc\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from pandas-ta==0.1.7a0) (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from pandas->pandas-ta==0.1.7a0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from pandas->pandas-ta==0.1.7a0) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from pandas->pandas-ta==0.1.7a0) (1.26.4)\n",
      "Requirement already satisfied: six>=1.5 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->pandas-ta==0.1.7a0) (1.16.0)\n",
      "Requirement already satisfied: xgboost in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (3.0.5)\n",
      "Requirement already satisfied: lightgbm in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (4.6.0)\n",
      "Requirement already satisfied: requests in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (2.32.5)\n",
      "Requirement already satisfied: pytrends in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (4.9.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from xgboost) (2.28.3)\n",
      "Requirement already satisfied: numpy in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from xgboost) (1.10.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: lxml in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from pytrends) (4.9.1)\n",
      "Requirement already satisfied: pandas>=0.25 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from pytrends) (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from pandas>=0.25->pytrends) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from pandas>=0.25->pytrends) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /raid/invigoworks/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=0.25->pytrends) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --no-deps pygooglenews==0.1.2\n",
    "\n",
    "!{sys.executable} -m pip install dateparser\n",
    "\n",
    "!pip install numpy pandas yfinance scikit-learn tensorflow\n",
    "\n",
    "!pip install git+https://github.com/aarigs/pandas-ta.git\n",
    "    \n",
    "!pip install xgboost lightgbm requests pytrends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eddad215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Feature Importances ---\n",
      "                   feature  importance\n",
      "7                      OBV    0.085548\n",
      "11          sentiment_ma_7    0.084113\n",
      "12  sentiment_x_volatility    0.082340\n",
      "5                   BBM_20    0.081892\n",
      "0                   RSI_14    0.081572\n",
      "10          sentiment_ma_3    0.078807\n",
      "6                   BBU_20    0.075885\n",
      "3            MACDS_12_26_9    0.074026\n",
      "8           volatility_14d    0.073414\n",
      "4                   BBL_20    0.072884\n",
      "2            MACDH_12_26_9    0.072358\n",
      "1             MACD_12_26_9    0.070011\n",
      "9                sentiment    0.067150\n",
      "\n",
      "Selected News Features (13): ['OBV', 'sentiment_ma_7', 'sentiment_x_volatility', 'BBM_20', 'RSI_14', 'sentiment_ma_3', 'BBU_20', 'MACDS_12_26_9', 'volatility_14d', 'BBL_20', 'MACDH_12_26_9', 'MACD_12_26_9', 'sentiment']\n",
      "Selected Price Features (9): ['OBV', 'BBM_20', 'RSI_14', 'BBU_20', 'MACDS_12_26_9', 'volatility_14d', 'BBL_20', 'MACDH_12_26_9', 'MACD_12_26_9']\n",
      "\n",
      "--- Starting GridSearchCV for XGBoost ---\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:08] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:10] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:10] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [16:19:11] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [16:19:11] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:11] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:11] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:11] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:11] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:14] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:14] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:14] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:14] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:15] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:15] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:15] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:15] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:16] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:16] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:18] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:18] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:19] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:19] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:19] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:19] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:20] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:20] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:21] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:21] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:23] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:23] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:25] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:25] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:25] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:25] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:25] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:25] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:31] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:31] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:33] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:33] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:33] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:33] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:34] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:34] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:40] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:40] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:40] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:40] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:41] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:41] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:42] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:42] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:42] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:42] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:42] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:42] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:43] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:43] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:45] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:45] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:46] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:46] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:46] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:46] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:48] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:48] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:49] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:49] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:50] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:50] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:51] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:51] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:51] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:51] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:52] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:52] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:52] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:52] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:53] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:53] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:53] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:53] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:54] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:54] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:54] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:54] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:55] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:55] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:55] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:55] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:56] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:56] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:59] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:19:59] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:20:00] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:20:00] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:20:00] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:20:00] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:20:01] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:20:01] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:20:03] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:20:03] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:20:04] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GridSearchCV Finished ---\n",
      "\n",
      "Best XGBoost Params: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Best XGBoost Accuracy on Train Set: 0.5078\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 945, number of negative: 859\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 1804, number of used features: 9\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA RTX A6000, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 9 dense feature groups (0.02 MB) transferred to GPU in 0.000919 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523836 -> initscore=0.095416\n",
      "[LightGBM] [Info] Start training from score 0.095416\n",
      "[LightGBM] [Info] Number of positive: 945, number of negative: 859\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 3222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1804, number of used features: 13\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA RTX A6000, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (0.03 MB) transferred to GPU in 0.000591 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523836 -> initscore=0.095416\n",
      "[LightGBM] [Info] Start training from score 0.095416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:20:07] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758698408.819754 3909568 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44923 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:1f:00.0, compute capability: 8.6\n",
      "2025-09-24 16:20:11.589618: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91300\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [16:20:25] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/raid/invigoworks/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRICE TEST (Selected Features)\n",
      "         Accuracy       MDE\n",
      "P_Logit  0.507634  0.492366\n",
      "P_ANN    0.557252  0.442748\n",
      "P_SVM    0.511450  0.488550\n",
      "P_LGBM   0.526718  0.473282\n",
      "P_XGB    0.496183  0.503817\n",
      "P_LSTM   0.525490  0.474510\n",
      "\n",
      "NEWS TEST (Selected Features)\n",
      "         Accuracy       MDE\n",
      "N_Logit  0.534351  0.465649\n",
      "N_ANN    0.503817  0.496183\n",
      "N_SVM    0.522901  0.477099\n",
      "N_LGBM   0.526718  0.473282\n",
      "N_XGB    0.503817  0.496183\n",
      "N_LSTM   0.537255  0.462745\n",
      "\n",
      "PRICE CBR k= 7  accuracy= 0.513725  MDE= 0.486275\n",
      "NEWS CBR k= 3  accuracy= 0.533333  MDE= 0.466667\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import yfinance as yf\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "START_DATE = \"2020-01-01\"\n",
    "END_DATE = \"2025-09-19\"\n",
    "TRAIN_END = \"2024-12-31\"\n",
    "SENTIMENT_CSV = \"daily_sentiment.csv\"\n",
    "TICKER = \"ETH-USD\"\n",
    "LSTM_LOOKBACK = 7\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def load_sentiment(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.normalize()\n",
    "    df = df[df['date'] >= pd.to_datetime(START_DATE)].copy()\n",
    "    sentiment_col = next((col for col in ['mean_sentiment', 'sentiment', 'label'] if col in df.columns), None)\n",
    "    df['sentiment'] = pd.to_numeric(df[sentiment_col], errors='coerce').fillna(0.0) if sentiment_col else 0.0\n",
    "    df = df[['date','sentiment']].drop_duplicates(subset=['date']).set_index('date')\n",
    "    return df\n",
    "\n",
    "def fetch_price(start_date, end_date, ticker=TICKER):\n",
    "    df = yf.download(ticker, start=start_date, end=(pd.to_datetime(end_date)+pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\"), progress=False, auto_adjust=False)\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns=df.columns.get_level_values(0)\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns={'Date':'date', 'Open': 'open', 'High':'high', 'Low':'low', 'Close':'close', 'Volume':'volume'})\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.normalize()\n",
    "    df = df[['date', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    df = df[df['date'] >= pd.to_datetime(START_DATE)].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def prepare_data(price_df, sentiment_df):\n",
    "    df = price_df.copy().set_index('date').sort_index()\n",
    "    \n",
    "    df.ta.rsi(close='close', length=14, append=True)\n",
    "    df.ta.macd(close='close', fast=12, slow=26, signal=9, append=True)\n",
    "    df.ta.bbands(close='close', length=20, append=True)\n",
    "    df.ta.obv(close='close', volume=df['volume'], append=True)\n",
    "    \n",
    "    df['return'] = df['close'].pct_change()\n",
    "    df['target'] = (df['return'] > 0).astype(int)\n",
    "    df['volatility_14d'] = df['return'].rolling(window=14).std()\n",
    "    \n",
    "    s = sentiment_df.copy()\n",
    "    s['sentiment_ma_3'] = s['sentiment'].rolling(window=3).mean()\n",
    "    s['sentiment_ma_7'] = s['sentiment'].rolling(window=7).mean()\n",
    "    \n",
    "    merged = df.merge(s, how='left', left_index=True, right_index=True)\n",
    "    merged['sentiment'] = merged['sentiment'].fillna(0.0)\n",
    "    merged['sentiment_ma_3'] = merged['sentiment_ma_3'].fillna(0.0)\n",
    "    merged['sentiment_ma_7'] = merged['sentiment_ma_7'].fillna(0.0)\n",
    "\n",
    "    merged['sentiment_x_volatility'] = merged['sentiment'] * merged['volatility_14d']\n",
    "    \n",
    "    feature_columns_to_shift = [col for col in merged.columns if col != 'target']\n",
    "    merged[feature_columns_to_shift] = merged[feature_columns_to_shift].shift(1)\n",
    "        \n",
    "    merged = merged.dropna().reset_index().rename(columns={'index':'date'})\n",
    "    \n",
    "    price_only_cols = [col for col in merged.columns if any(indicator in col for indicator in ['RSI', 'MACD', 'BB', 'OBV', 'volatility']) and 'sentiment' not in col]\n",
    "    feature_cols = price_only_cols + [col for col in merged.columns if col.startswith('sentiment')]\n",
    "\n",
    "    return merged, feature_cols, price_only_cols\n",
    "\n",
    "def create_lstm_dataset(X, y, lookback=LSTM_LOOKBACK):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - lookback):\n",
    "        X_seq.append(X[i:i+lookback])\n",
    "        y_seq.append(y[i+lookback])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "def train_classifiers_basic(X_train, y_train):\n",
    "    logit = LogisticRegression(max_iter=500, solver='liblinear', random_state=42).fit(X_train, y_train)\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, early_stopping=True, random_state=42, n_iter_no_change=20).fit(X_train, y_train)\n",
    "    svc = SVC(kernel='rbf', C=1.0, probability=True, random_state=42).fit(X_train, y_train)\n",
    "    lgbm = LGBMClassifier(random_state=42, device='gpu').fit(X_train, y_train)\n",
    "    return {'logit':logit, 'mlp':mlp, 'svc':svc, 'lgbm':lgbm}\n",
    "\n",
    "def train_lstm_classifier(X_train_seq, y_train_seq, units=64, epochs=30, batch_size=32):\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train_seq.shape[1], X_train_seq.shape[2])),\n",
    "        LSTM(units, activation='tanh', return_sequences=True),\n",
    "        Dropout(0.3),\n",
    "        LSTM(units // 2, activation='tanh'),\n",
    "        Dropout(0.3),\n",
    "        Dense(units // 4, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    model.fit(X_train_seq, y_train_seq, epochs=epochs, batch_size=batch_size, verbose=0, validation_split=0.15, callbacks=[early_stopping])\n",
    "    return model\n",
    "\n",
    "def predict_lstm_classifier(model, X_seq):\n",
    "    p = model.predict(X_seq, verbose=0).flatten()\n",
    "    return (p >= 0.5).astype(int)\n",
    "\n",
    "def build_casebase(pred_matrix, y_train):\n",
    "    return {'preds': np.array(pred_matrix), 'y': np.array(y_train)}\n",
    "\n",
    "def cbr_classify(casebase, query_vec, k):\n",
    "    n_neighbors = min(k, len(casebase['preds']))\n",
    "    if n_neighbors == 0: return 0\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors, metric='euclidean').fit(casebase['preds'])\n",
    "    _, idx = nbrs.kneighbors([query_vec])\n",
    "    neigh = casebase['y'][idx.flatten()]\n",
    "    return Counter(neigh).most_common(1)[0][0]\n",
    "\n",
    "def mde(y_true, y_pred):\n",
    "    return 1.0 - accuracy_score(y_true, y_pred)\n",
    "\n",
    "def evaluate_models(train_df, test_df, feature_cols, price_only_cols, best_xgb_model):\n",
    "    if len(test_df) < LSTM_LOOKBACK:\n",
    "        return {'error':'not enough test data'}\n",
    "\n",
    "    y_clf_train = train_df['target'].values\n",
    "    y_clf_test = test_df['target'].values\n",
    "    \n",
    "    scaler_p = StandardScaler().fit(train_df[price_only_cols])\n",
    "    Xp_train_scaled = scaler_p.transform(train_df[price_only_cols])\n",
    "    Xp_test_scaled = scaler_p.transform(test_df[price_only_cols])\n",
    "\n",
    "    scaler_n = StandardScaler().fit(train_df[feature_cols])\n",
    "    Xn_train_scaled = scaler_n.transform(train_df[feature_cols])\n",
    "    Xn_test_scaled = scaler_n.transform(test_df[feature_cols])\n",
    "\n",
    "    price_models = train_classifiers_basic(Xp_train_scaled, y_clf_train)\n",
    "    news_models = train_classifiers_basic(Xn_train_scaled, y_clf_train)\n",
    "    news_models['xgb'] = best_xgb_model\n",
    "    \n",
    "    xgb_price_only = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, tree_method='hist', device='cuda')\n",
    "    xgb_price_only.fit(Xp_train_scaled, y_clf_train)\n",
    "    price_models['xgb'] = xgb_price_only\n",
    "\n",
    "    Xp_train_seq, yp_train_seq = create_lstm_dataset(Xp_train_scaled, y_clf_train)\n",
    "    Xp_test_seq, yp_test_seq = create_lstm_dataset(Xp_test_scaled, y_clf_test)\n",
    "    Xn_train_seq, yn_train_seq = create_lstm_dataset(Xn_train_scaled, y_clf_train)\n",
    "    Xn_test_seq, yn_test_seq = create_lstm_dataset(Xn_test_scaled, y_clf_test)\n",
    "\n",
    "    lstm_price = train_lstm_classifier(Xp_train_seq, yp_train_seq)\n",
    "    p_lstm_test = predict_lstm_classifier(lstm_price, Xp_test_seq)\n",
    "    lstm_news = train_lstm_classifier(Xn_train_seq, yn_train_seq)\n",
    "    n_lstm_test = predict_lstm_classifier(lstm_news, Xn_test_seq)\n",
    "    \n",
    "    p_logit_test = price_models['logit'].predict(Xp_test_scaled)\n",
    "    p_mlp_test = price_models['mlp'].predict(Xp_test_scaled)\n",
    "    p_svc_test = price_models['svc'].predict(Xp_test_scaled)\n",
    "    p_lgbm_test = price_models['lgbm'].predict(Xp_test_scaled)\n",
    "    p_xgb_test = price_models['xgb'].predict(Xp_test_scaled)\n",
    "    \n",
    "    n_logit_test = news_models['logit'].predict(Xn_test_scaled)\n",
    "    n_mlp_test = news_models['mlp'].predict(Xn_test_scaled)\n",
    "    n_svc_test = news_models['svc'].predict(Xn_test_scaled)\n",
    "    n_lgbm_test = news_models['lgbm'].predict(Xn_test_scaled)\n",
    "    n_xgb_test = news_models['xgb'].predict(Xn_test_scaled)\n",
    "    \n",
    "    results = {}\n",
    "    results['price_test_acc'] = {\n",
    "        'P_Logit': accuracy_score(y_clf_test, p_logit_test), 'P_ANN': accuracy_score(y_clf_test, p_mlp_test),\n",
    "        'P_SVM': accuracy_score(y_clf_test, p_svc_test), 'P_LGBM': accuracy_score(y_clf_test, p_lgbm_test),\n",
    "        'P_XGB': accuracy_score(y_clf_test, p_xgb_test), 'P_LSTM': accuracy_score(yp_test_seq, p_lstm_test)\n",
    "    }\n",
    "    results['news_test_acc'] = {\n",
    "        'N_Logit': accuracy_score(y_clf_test, n_logit_test), 'N_ANN': accuracy_score(y_clf_test, n_mlp_test),\n",
    "        'N_SVM': accuracy_score(y_clf_test, n_svc_test), 'N_LGBM': accuracy_score(y_clf_test, n_lgbm_test),\n",
    "        'N_XGB': accuracy_score(y_clf_test, n_xgb_test), 'N_LSTM': accuracy_score(yn_test_seq, n_lstm_test)\n",
    "    }\n",
    "    \n",
    "    p_train_preds = np.column_stack([m.predict(Xp_train_scaled) for m in price_models.values()])\n",
    "    n_train_preds = np.column_stack([m.predict(Xn_train_scaled) for m in news_models.values()])\n",
    "    p_lstm_train = predict_lstm_classifier(lstm_price, Xp_train_seq)\n",
    "    n_lstm_train = predict_lstm_classifier(lstm_news, Xn_train_seq)\n",
    "    \n",
    "    p_train_preds_cbr = np.column_stack([p_train_preds[LSTM_LOOKBACK:], p_lstm_train])\n",
    "    n_train_preds_cbr = np.column_stack([n_train_preds[LSTM_LOOKBACK:], n_lstm_train])\n",
    "\n",
    "    p_test_preds_cbr = np.column_stack([p_logit_test[LSTM_LOOKBACK:], p_mlp_test[LSTM_LOOKBACK:], p_svc_test[LSTM_LOOKBACK:], p_lgbm_test[LSTM_LOOKBACK:], p_xgb_test[LSTM_LOOKBACK:], p_lstm_test])\n",
    "    n_test_preds_cbr = np.column_stack([n_logit_test[LSTM_LOOKBACK:], n_mlp_test[LSTM_LOOKBACK:], n_svc_test[LSTM_LOOKBACK:], n_lgbm_test[LSTM_LOOKBACK:], n_xgb_test[LSTM_LOOKBACK:], n_lstm_test])\n",
    "    \n",
    "    p_case = build_casebase(p_train_preds_cbr, yp_train_seq)\n",
    "    n_case = build_casebase(n_train_preds_cbr, yn_train_seq)\n",
    "    \n",
    "    best_k_p, best_acc_p, best_preds_p = 1, 0.0, None\n",
    "    for k in range(1, 12, 2):\n",
    "        ypreds = [cbr_classify(p_case, p_test_preds_cbr[i], k) for i in range(len(p_test_preds_cbr))]\n",
    "        acc = accuracy_score(yp_test_seq, ypreds)\n",
    "        if acc > best_acc_p:\n",
    "            best_acc_p, best_k_p, best_preds_p = acc, k, ypreds\n",
    "    \n",
    "    best_k_n, best_acc_n, best_preds_n = 1, 0.0, None\n",
    "    for k in range(1, 12, 2):\n",
    "        ypreds = [cbr_classify(n_case, n_test_preds_cbr[i], k) for i in range(len(n_test_preds_cbr))]\n",
    "        acc = accuracy_score(yn_test_seq, ypreds)\n",
    "        if acc > best_acc_n:\n",
    "            best_acc_n, best_k_n, best_preds_n = acc, k, ypreds\n",
    "\n",
    "    results['price_cbr'] = {'k': best_k_p, 'accuracy': best_acc_p, 'MDE': mde(yp_test_seq, np.array(best_preds_p)) if best_preds_p is not None else None}\n",
    "    results['news_cbr'] = {'k': best_k_n, 'accuracy': best_acc_n, 'MDE': mde(yn_test_seq, np.array(best_preds_n)) if best_preds_n is not None else None}\n",
    "    \n",
    "    df_price = pd.DataFrame.from_dict(results['price_test_acc'], orient='index', columns=['Accuracy'])\n",
    "    df_price['MDE'] = 1 - df_price['Accuracy']\n",
    "    df_news = pd.DataFrame.from_dict(results['news_test_acc'], orient='index', columns=['Accuracy'])\n",
    "    df_news['MDE'] = 1 - df_news['Accuracy']\n",
    "\n",
    "    print(\"PRICE TEST (Selected Features)\")\n",
    "    print(df_price.to_string())\n",
    "    print(\"\\nNEWS TEST (Selected Features)\")\n",
    "    print(df_news.to_string())\n",
    "    print(f\"\\nPRICE CBR k= {results['price_cbr']['k']}  accuracy= {results['price_cbr']['accuracy']:.6f}  MDE= {results['price_cbr']['MDE']:.6f}\")\n",
    "    print(f\"NEWS CBR k= {results['news_cbr']['k']}  accuracy= {results['news_cbr']['accuracy']:.6f}  MDE= {results['news_cbr']['MDE']:.6f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    sentiment_df = load_sentiment(SENTIMENT_CSV)\n",
    "    price_df = fetch_price(START_DATE, END_DATE)\n",
    "    data_df, all_feature_cols, all_price_cols = prepare_data(price_df, sentiment_df)\n",
    "\n",
    "    train_df = data_df[data_df['date'] <= pd.to_datetime(TRAIN_END)].copy()\n",
    "    test_df = data_df[data_df['date'] > pd.to_datetime(TRAIN_END)].copy()\n",
    "\n",
    "    X_train_all = train_df[all_feature_cols]\n",
    "    y_train = train_df['target']\n",
    "    \n",
    "    temp_xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, tree_method='hist', device='cuda')\n",
    "    temp_xgb.fit(X_train_all, y_train)\n",
    "    \n",
    "    importances = pd.DataFrame({\n",
    "        'feature': all_feature_cols,\n",
    "        'importance': temp_xgb.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"--- Feature Importances ---\")\n",
    "    print(importances)\n",
    "    \n",
    "    selected_features_news = importances[importances['importance'] > 0.01]['feature'].tolist()\n",
    "    if not selected_features_news:\n",
    "        selected_features_news = importances.head(10)['feature'].tolist()\n",
    "        \n",
    "    selected_features_price = [f for f in selected_features_news if f in all_price_cols]\n",
    "    \n",
    "    print(f\"\\nSelected News Features ({len(selected_features_news)}): {selected_features_news}\")\n",
    "    print(f\"Selected Price Features ({len(selected_features_price)}): {selected_features_price}\\n\")\n",
    "    \n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0]\n",
    "    }\n",
    "    \n",
    "    xgb_grid = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, tree_method='hist', device='cuda')\n",
    "    grid_search = GridSearchCV(estimator=xgb_grid, param_grid=param_grid, cv=3, n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "    \n",
    "    scaler_for_grid = StandardScaler().fit(train_df[selected_features_news])\n",
    "    X_train_scaled_for_grid = scaler_for_grid.transform(train_df[selected_features_news])\n",
    "    \n",
    "    print(\"--- Starting GridSearchCV for XGBoost ---\")\n",
    "    grid_search.fit(X_train_scaled_for_grid, y_train)\n",
    "    print(\"--- GridSearchCV Finished ---\")\n",
    "    \n",
    "    best_xgb = grid_search.best_estimator_\n",
    "    print(f\"\\nBest XGBoost Params: {grid_search.best_params_}\")\n",
    "    print(f\"Best XGBoost Accuracy on Train Set: {grid_search.best_score_:.4f}\\n\")\n",
    "\n",
    "    results = evaluate_models(train_df, test_df, selected_features_news, selected_features_price, best_xgb)\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79ae111e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sentiment data...\n",
      "Fetching price data...\n",
      "Preparing enhanced dataset with alternative data sources...\n",
      "Total features created: 78\n",
      "Technical indicators: 42\n",
      "Alternative & Market data features: 36\n",
      "\n",
      "--- COMPREHENSIVE MODEL COMPARISON ---\n",
      "\n",
      "Evaluating price_only with 45 features...\n",
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758643171.517736 3904924 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 45829 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:1f:00.0, compute capability: 8.6\n",
      "2025-09-24 00:59:34.295670: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating price_uncorr with 12 features...\n",
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      "\n",
      "Evaluating enhanced with 81 features...\n",
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f80e0788790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f80e0788790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "Evaluating enhanced_uncorr with 25 features...\n",
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      "\n",
      "--- FINAL COMPARISON RESULTS ---\n",
      "Model                           lgbm   logit    lstm     mlp     svc  \\\n",
      "Feature_Set     Num_Features                                           \n",
      "enhanced        81            0.4819  0.5542  0.5409  0.5904  0.5241   \n",
      "enhanced_uncorr 25            0.5060  0.5422  0.5346  0.5181  0.5241   \n",
      "price_only      45            0.5422  0.5422  0.5346  0.5181  0.5000   \n",
      "price_uncorr    12            0.5000  0.5241  0.5031  0.5241  0.4880   \n",
      "\n",
      "Model                         xgb_optimized  \n",
      "Feature_Set     Num_Features                 \n",
      "enhanced        81                   0.5542  \n",
      "enhanced_uncorr 25                   0.5181  \n",
      "price_only      45                   0.5120  \n",
      "price_uncorr    12                   0.4819  \n",
      "\n",
      "BEST PERFORMING COMBINATION:\n",
      "Feature Set: enhanced\n",
      "Model: mlp\n",
      "Number of Features: 81\n",
      "Accuracy: 0.5904\n",
      "MDE: 0.4096\n",
      "\n",
      "FEATURE IMPACT ANALYSIS:\n",
      "Best Price-Only Model Accuracy: 0.5422\n",
      "Best Enhanced Model Accuracy: 0.5904\n",
      "Improvement with Alternative Data: 0.0482 (8.89%)\n",
      "\n",
      "Process finished.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from pytrends.request import TrendReq\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "START_DATE = \"2020-01-01\"\n",
    "END_DATE = \"2025-09-19\"\n",
    "TRAIN_END = \"2024-12-31\"\n",
    "SENTIMENT_CSV = \"daily_sentiment.csv\"\n",
    "TICKER = \"ETH-USD\"\n",
    "LSTM_LOOKBACK = 7\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def load_sentiment(csv_path):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df['date'] = pd.to_datetime(df['date']).dt.normalize()\n",
    "        df = df[df['date'] >= pd.to_datetime(START_DATE)].copy()\n",
    "        sentiment_col = next((col for col in ['mean_sentiment', 'sentiment', 'label'] if col in df.columns), None)\n",
    "        df['sentiment'] = pd.to_numeric(df[sentiment_col], errors='coerce').fillna(0.0) if sentiment_col else 0.0\n",
    "        df = df[['date','sentiment']].drop_duplicates(subset=['date']).set_index('date')\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Sentiment file '{csv_path}' not found. Proceeding without sentiment data.\")\n",
    "        return pd.DataFrame(index=pd.to_datetime(pd.date_range(START_DATE, END_DATE)), columns=['sentiment']).fillna(0.0)\n",
    "\n",
    "def fetch_fear_greed_index():\n",
    "    try:\n",
    "        url = \"https://api.alternative.me/fng/?limit=2000\"\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        df_list = []\n",
    "        for item in data.get('data', []):\n",
    "            date = pd.to_datetime(item['timestamp'], unit='s').normalize()\n",
    "            value = float(item['value'])\n",
    "            df_list.append({'date': date, 'fear_greed': value})\n",
    "        \n",
    "        if not df_list:\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        df = pd.DataFrame(df_list)\n",
    "        df = df[df['date'] >= pd.to_datetime(START_DATE)]\n",
    "        df = df.set_index('date').sort_index()\n",
    "        return df\n",
    "    except requests.RequestException:\n",
    "        print(\"Warning: Could not fetch Fear & Greed Index.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def fetch_defi_data():\n",
    "    try:\n",
    "        url = \"https://api.llama.fi/charts\"\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        df_list = []\n",
    "        for item in data:\n",
    "            date = pd.to_datetime(item['date'], unit='s').normalize()\n",
    "            tvl = float(item.get('totalLiquidityUSD', 0))\n",
    "            df_list.append({'date': date, 'defi_tvl': tvl})\n",
    "            \n",
    "        if not df_list:\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        df = pd.DataFrame(df_list)\n",
    "        df = df[df['date'] >= pd.to_datetime(START_DATE)]\n",
    "        df = df.set_index('date').sort_index()\n",
    "        return df\n",
    "    except requests.RequestException:\n",
    "        print(\"Warning: Could not fetch DeFi TVL data.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def fetch_social_metrics():\n",
    "    try:\n",
    "        pytrends = TrendReq(hl='en-US', tz=360)\n",
    "        keyword = \"Ethereum\"\n",
    "        timeframe = f'{START_DATE} {END_DATE}'\n",
    "        \n",
    "        pytrends.build_payload([keyword], cat=0, timeframe=timeframe, geo='', gprop='')\n",
    "        google_trends_df = pytrends.interest_over_time()\n",
    "\n",
    "        if google_trends_df.empty or keyword not in google_trends_df.columns:\n",
    "            print(\"Warning: Could not fetch Google Trends data.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        google_trends_df = google_trends_df.rename(columns={keyword: 'google_trends'})\n",
    "        google_trends_df = google_trends_df[['google_trends']]\n",
    "        google_trends_df = google_trends_df.resample('D').interpolate(method='linear')\n",
    "        return google_trends_df\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: An error occurred while fetching Google Trends data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def fetch_traditional_markets():\n",
    "    tickers = ['^GSPC', '^DJI', '^IXIC', '^VIX', 'GLD', 'DX-Y.NYB']\n",
    "    market_dfs = []\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n",
    "            if not data.empty:\n",
    "                clean_ticker = ticker.replace('^', '').replace('-', '_').replace('.', '_')\n",
    "                temp_df = pd.DataFrame(index=data.index)\n",
    "                temp_df[f'{clean_ticker}_close'] = data['Close']\n",
    "                temp_df[f'{clean_ticker}_return'] = data['Close'].pct_change()\n",
    "                temp_df[f'{clean_ticker}_vol'] = data['Close'].pct_change().rolling(14).std()\n",
    "                market_dfs.append(temp_df)\n",
    "            time.sleep(0.1)\n",
    "        except Exception:\n",
    "            print(f\"Warning: Could not fetch data for traditional market ticker {ticker}.\")\n",
    "            continue\n",
    "    \n",
    "    if market_dfs:\n",
    "        df = pd.concat(market_dfs, axis=1)\n",
    "        df.index = pd.to_datetime(df.index).normalize()\n",
    "        return df\n",
    "    return pd.DataFrame()\n",
    "\n",
    "def fetch_price(start_date, end_date, ticker=TICKER):\n",
    "    df = yf.download(ticker, start=start_date, end=(pd.to_datetime(end_date)+pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\"), progress=False, auto_adjust=False)\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns=df.columns.get_level_values(0)\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns={'Date':'date', 'Open': 'open', 'High':'high', 'Low':'low', 'Close':'close', 'Volume':'volume'})\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.normalize()\n",
    "    df = df[['date', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    df = df[df['date'] >= pd.to_datetime(START_DATE)].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def add_advanced_technical_indicators(df):\n",
    "    df.ta.rsi(close='close', length=14, append=True)\n",
    "    df.ta.rsi(close='close', length=21, append=True)\n",
    "    df.ta.macd(close='close', fast=12, slow=26, signal=9, append=True)\n",
    "    df.ta.bbands(close='close', length=20, append=True)\n",
    "    df.ta.obv(close='close', volume=df['volume'], append=True)\n",
    "    df.ta.stoch(high='high', low='low', close='close', append=True)\n",
    "    df.ta.willr(high='high', low='low', close='close', append=True)\n",
    "    df.ta.cci(high='high', low='low', close='close', append=True)\n",
    "    df.ta.adx(high='high', low='low', close='close', append=True)\n",
    "    df.ta.atr(high='high', low='low', close='close', append=True)\n",
    "    \n",
    "    for period in [5, 10, 20, 50]:\n",
    "        df[f'sma_{period}'] = df['close'].rolling(window=period).mean()\n",
    "        df[f'ema_{period}'] = df['close'].ewm(span=period).mean()\n",
    "        df[f'price_vs_sma_{period}'] = df['close'] / df[f'sma_{period}'] - 1\n",
    "        df[f'price_vs_ema_{period}'] = df['close'] / df[f'ema_{period}'] - 1\n",
    "    \n",
    "    df['price_momentum_5'] = df['close'] / df['close'].shift(5) - 1\n",
    "    df['price_momentum_10'] = df['close'] / df['close'].shift(10) - 1\n",
    "    df['volume_sma_20'] = df['volume'].rolling(window=20).mean()\n",
    "    df['volume_ratio'] = df['volume'] / df['volume_sma_20']\n",
    "    df['hl_ratio'] = (df['high'] - df['low']) / df['close']\n",
    "    df['oc_ratio'] = abs(df['open'] - df['close']) / df['close']\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_data(price_df, sentiment_df):\n",
    "    df = price_df.copy().set_index('date').sort_index()\n",
    "    \n",
    "    df = add_advanced_technical_indicators(df)\n",
    "    \n",
    "    df['return'] = df['close'].pct_change()\n",
    "    df['target'] = (df['return'] > 0).astype(int)\n",
    "    df['volatility_7d'] = df['return'].rolling(window=7).std()\n",
    "    df['volatility_14d'] = df['return'].rolling(window=14).std()\n",
    "    df['volatility_30d'] = df['return'].rolling(window=30).std()\n",
    "    \n",
    "    fear_greed_df = fetch_fear_greed_index()\n",
    "    if not fear_greed_df.empty:\n",
    "        df = df.merge(fear_greed_df, how='left', left_index=True, right_index=True)\n",
    "        df['fear_greed'] = df['fear_greed'].fillna(method='ffill').fillna(50)\n",
    "        df['fear_greed_ma_3'] = df['fear_greed'].rolling(window=3).mean()\n",
    "        df['fear_greed_ma_7'] = df['fear_greed'].rolling(window=7).mean()\n",
    "        df['fear_greed_change'] = df['fear_greed'].diff()\n",
    "    \n",
    "    defi_df = fetch_defi_data()\n",
    "    if not defi_df.empty:\n",
    "        defi_df['defi_tvl_change'] = defi_df['defi_tvl'].pct_change()\n",
    "        defi_df['defi_tvl_ma_7'] = defi_df['defi_tvl'].rolling(window=7).mean()\n",
    "        df = df.merge(defi_df, how='left', left_index=True, right_index=True)\n",
    "        df['defi_tvl'] = df['defi_tvl'].fillna(method='ffill')\n",
    "        df['defi_tvl_change'] = df['defi_tvl_change'].fillna(0)\n",
    "        df['defi_tvl_ma_7'] = df['defi_tvl_ma_7'].fillna(method='ffill')\n",
    "\n",
    "    social_df = fetch_social_metrics()\n",
    "    if not social_df.empty:\n",
    "        for col in ['google_trends']:\n",
    "            social_df[f'{col}_ma_3'] = social_df[col].rolling(window=3).mean()\n",
    "            social_df[f'{col}_ma_7'] = social_df[col].rolling(window=7).mean()\n",
    "            social_df[f'{col}_change'] = social_df[col].pct_change()\n",
    "        df = df.merge(social_df, how='left', left_index=True, right_index=True)\n",
    "    \n",
    "    market_df = fetch_traditional_markets()\n",
    "    if not market_df.empty:\n",
    "        df = df.merge(market_df, how='left', left_index=True, right_index=True)\n",
    "\n",
    "    s = sentiment_df.copy()\n",
    "    s['sentiment_ma_3'] = s['sentiment'].rolling(window=3).mean()\n",
    "    s['sentiment_ma_7'] = s['sentiment'].rolling(window=7).mean()\n",
    "    s['sentiment_change'] = s['sentiment'].diff()\n",
    "    \n",
    "    merged = df.merge(s, how='left', left_index=True, right_index=True)\n",
    "    \n",
    "    merged['sentiment_x_volatility'] = merged['sentiment'] * merged['volatility_14d']\n",
    "    if 'fear_greed' in merged.columns and 'volume_ratio' in merged.columns:\n",
    "        merged['fear_greed_x_volume'] = merged['fear_greed'] / 100 * merged['volume_ratio']\n",
    "    \n",
    "    feature_columns_to_shift = [col for col in merged.columns if col != 'target']\n",
    "    merged[feature_columns_to_shift] = merged[feature_columns_to_shift].shift(1)\n",
    "        \n",
    "    merged = merged.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    merged = merged.reset_index().rename(columns={'index':'date'})\n",
    "    \n",
    "    price_technical_cols = [col for col in merged.columns if any(indicator in col.lower() for indicator in \n",
    "                           ['rsi', 'macd', 'bb', 'obv', 'stoch', 'willr', 'cci', 'adx', 'atr', 'sma', 'ema', \n",
    "                            'momentum', 'volume', 'volatility', 'ratio', 'price_vs', 'hl_ratio', 'oc_ratio']) and \n",
    "                           not any(external in col.lower() for external in \n",
    "                           ['sentiment', 'fear', 'greed', 'defi', 'google', 'gspc', 'dji', 'ixic', 'vix', 'gld', 'dx'])]\n",
    "    \n",
    "    alternative_data_cols = [col for col in merged.columns if any(indicator in col.lower() for external in \n",
    "                            ['sentiment', 'fear', 'greed', 'defi', 'google'] for indicator in [external])]\n",
    "    \n",
    "    market_data_cols = [col for col in merged.columns if any(market in col.lower() for market in \n",
    "                       ['gspc', 'dji', 'ixic', 'vix', 'gld', 'dx'])]\n",
    "    \n",
    "    all_feature_cols = price_technical_cols + alternative_data_cols + market_data_cols\n",
    "    \n",
    "    return merged, all_feature_cols, price_technical_cols\n",
    "\n",
    "def remove_correlated_features(df, feature_cols, threshold=0.8):\n",
    "    corr_matrix = df[feature_cols].corr().abs()\n",
    "    upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    \n",
    "    to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold)]\n",
    "    return [col for col in feature_cols if col not in to_drop]\n",
    "\n",
    "def create_lstm_dataset(X, y, lookback=LSTM_LOOKBACK):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - lookback):\n",
    "        X_seq.append(X[i:i+lookback])\n",
    "        y_seq.append(y[i+lookback])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "def train_classifiers_basic(X_train, y_train):\n",
    "    logit = LogisticRegression(max_iter=500, solver='liblinear', random_state=42).fit(X_train, y_train)\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, early_stopping=True, random_state=42, n_iter_no_change=20).fit(X_train, y_train)\n",
    "    svc = SVC(kernel='rbf', C=1.0, probability=True, random_state=42).fit(X_train, y_train)\n",
    "    lgbm = LGBMClassifier(random_state=42, device='gpu', verbose=-1).fit(X_train, y_train)\n",
    "    return {'logit':logit, 'mlp':mlp, 'svc':svc, 'lgbm':lgbm}\n",
    "\n",
    "def train_lstm_classifier(X_train_seq, y_train_seq, units=64, epochs=30, batch_size=32):\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train_seq.shape[1], X_train_seq.shape[2])),\n",
    "        LSTM(units, activation='tanh', return_sequences=True),\n",
    "        Dropout(0.3),\n",
    "        LSTM(units // 2, activation='tanh'),\n",
    "        Dropout(0.3),\n",
    "        Dense(units // 4, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    model.fit(X_train_seq, y_train_seq, epochs=epochs, batch_size=batch_size, verbose=0, validation_split=0.15, callbacks=[early_stopping])\n",
    "    return model\n",
    "\n",
    "def predict_lstm_classifier(model, X_seq):\n",
    "    p = model.predict(X_seq, verbose=0).flatten()\n",
    "    return (p >= 0.5).astype(int)\n",
    "\n",
    "def build_casebase(pred_matrix, y_train):\n",
    "    return {'preds': np.array(pred_matrix), 'y': np.array(y_train)}\n",
    "\n",
    "def cbr_classify(casebase, query_vec, k):\n",
    "    n_neighbors = min(k, len(casebase['preds']))\n",
    "    if n_neighbors == 0: return 0\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors, metric='euclidean').fit(casebase['preds'])\n",
    "    _, idx = nbrs.kneighbors([query_vec])\n",
    "    neigh = casebase['y'][idx.flatten()]\n",
    "    return Counter(neigh).most_common(1)[0][0]\n",
    "\n",
    "def mde(y_true, y_pred):\n",
    "    return 1.0 - accuracy_score(y_true, y_pred)\n",
    "\n",
    "def optimize_xgb_model(X_train, y_train):\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.05, 0.1, 0.2],\n",
    "        'subsample': [0.7, 0.8, 0.9],\n",
    "        'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "    }\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, tree_method='hist', device='cuda'),\n",
    "        param_grid=param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=3,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "def evaluate_feature_combinations(train_df, test_df):\n",
    "    results = {}\n",
    "    \n",
    "    price_technical_cols = [col for col in train_df.columns if any(indicator in col.lower() for indicator in \n",
    "                           ['rsi', 'macd', 'bb', 'obv', 'stoch', 'willr', 'cci', 'adx', 'atr', 'sma', 'ema', \n",
    "                            'momentum', 'volume', 'volatility', 'ratio', 'price_vs', 'hl_ratio', 'oc_ratio']) and \n",
    "                           col != 'target']\n",
    "    \n",
    "    alternative_data_cols = [col for col in train_df.columns if any(indicator in col.lower() for external in \n",
    "                            ['sentiment', 'fear', 'greed', 'defi', 'google'] for indicator in [external])]\n",
    "    \n",
    "    market_data_cols = [col for col in train_df.columns if any(market in col.lower() for market in \n",
    "                       ['gspc', 'dji', 'ixic', 'vix', 'gld', 'dx'])]\n",
    "    \n",
    "    all_features = price_technical_cols + alternative_data_cols + market_data_cols\n",
    "    \n",
    "    feature_combinations = {\n",
    "        'price_only': price_technical_cols,\n",
    "        'price_uncorr': remove_correlated_features(train_df, price_technical_cols, 0.8),\n",
    "        'enhanced': all_features,\n",
    "        'enhanced_uncorr': remove_correlated_features(train_df, all_features, 0.8)\n",
    "    }\n",
    "    \n",
    "    for combo_name, features in feature_combinations.items():\n",
    "        if len(features) == 0:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nEvaluating {combo_name} with {len(features)} features...\")\n",
    "        \n",
    "        X_train = train_df[features]\n",
    "        y_train = train_df['target']\n",
    "        X_test = test_df[features]\n",
    "        y_test = test_df['target']\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        best_xgb, best_params = optimize_xgb_model(X_train_scaled, y_train)\n",
    "        basic_models = train_classifiers_basic(X_train_scaled, y_train)\n",
    "        \n",
    "        combo_results = {}\n",
    "        \n",
    "        for model_name, model in basic_models.items():\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            combo_results[f'{model_name}'] = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        xgb_pred = best_xgb.predict(X_test_scaled)\n",
    "        combo_results['xgb_optimized'] = accuracy_score(y_test, xgb_pred)\n",
    "        \n",
    "        if len(X_train_scaled) >= LSTM_LOOKBACK:\n",
    "            X_train_seq, y_train_seq = create_lstm_dataset(X_train_scaled, y_train.values)\n",
    "            X_test_seq, y_test_seq = create_lstm_dataset(X_test_scaled, y_test.values)\n",
    "            \n",
    "            if len(X_train_seq) > 0 and len(X_test_seq) > 0:\n",
    "                lstm_model = train_lstm_classifier(X_train_seq, y_train_seq)\n",
    "                lstm_pred = predict_lstm_classifier(lstm_model, X_test_seq)\n",
    "                combo_results['lstm'] = accuracy_score(y_test_seq, lstm_pred)\n",
    "        \n",
    "        results[combo_name] = {\n",
    "            'features': features,\n",
    "            'num_features': len(features),\n",
    "            'accuracies': combo_results,\n",
    "            'best_xgb_params': best_params\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    print(\"Loading sentiment data...\")\n",
    "    sentiment_df = load_sentiment(SENTIMENT_CSV)\n",
    "    \n",
    "    print(\"Fetching price data...\")\n",
    "    price_df = fetch_price(START_DATE, END_DATE)\n",
    "    \n",
    "    print(\"Preparing enhanced dataset with alternative data sources...\")\n",
    "    data_df, all_feature_cols, price_cols = prepare_data(price_df, sentiment_df)\n",
    "\n",
    "    print(f\"Total features created: {len(all_feature_cols)}\")\n",
    "    print(f\"Technical indicators: {len(price_cols)}\")\n",
    "    print(f\"Alternative & Market data features: {len(all_feature_cols) - len(price_cols)}\")\n",
    "\n",
    "    train_df = data_df[data_df['date'] <= pd.to_datetime(TRAIN_END)].copy()\n",
    "    test_df = data_df[data_df['date'] > pd.to_datetime(TRAIN_END)].copy()\n",
    "    \n",
    "    if train_df.empty or test_df.empty:\n",
    "        print(\"Error: Not enough data for training or testing after processing. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n--- COMPREHENSIVE MODEL COMPARISON ---\")\n",
    "    results = evaluate_feature_combinations(train_df, test_df)\n",
    "    \n",
    "    print(\"\\n--- FINAL COMPARISON RESULTS ---\")\n",
    "    comparison_df = []\n",
    "    for combo_name, combo_results in results.items():\n",
    "        for model_name, accuracy in combo_results['accuracies'].items():\n",
    "            comparison_df.append({\n",
    "                'Feature_Set': combo_name,\n",
    "                'Model': model_name,\n",
    "                'Num_Features': combo_results['num_features'],\n",
    "                'Accuracy': accuracy,\n",
    "                'MDE': 1 - accuracy\n",
    "            })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_df)\n",
    "    print(comparison_df.pivot_table(index=['Feature_Set', 'Num_Features'], columns='Model', values='Accuracy').round(4))\n",
    "    \n",
    "    best_combo = comparison_df.loc[comparison_df['Accuracy'].idxmax()]\n",
    "    print(f\"\\nBEST PERFORMING COMBINATION:\")\n",
    "    print(f\"Feature Set: {best_combo['Feature_Set']}\")\n",
    "    print(f\"Model: {best_combo['Model']}\")\n",
    "    print(f\"Number of Features: {best_combo['Num_Features']}\")\n",
    "    print(f\"Accuracy: {best_combo['Accuracy']:.4f}\")\n",
    "    print(f\"MDE: {best_combo['MDE']:.4f}\")\n",
    "    \n",
    "    price_only_best = comparison_df[comparison_df['Feature_Set'] == 'price_only']['Accuracy'].max()\n",
    "    enhanced_best = comparison_df[comparison_df['Feature_Set'].str.contains('enhanced')]['Accuracy'].max()\n",
    "    \n",
    "    print(f\"\\nFEATURE IMPACT ANALYSIS:\")\n",
    "    print(f\"Best Price-Only Model Accuracy: {price_only_best:.4f}\")\n",
    "    print(f\"Best Enhanced Model Accuracy: {enhanced_best:.4f}\")\n",
    "    print(f\"Improvement with Alternative Data: {enhanced_best - price_only_best:.4f} ({((enhanced_best - price_only_best) / price_only_best * 100):.2f}%)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    final_results = main()\n",
    "    print(\"\\nProcess finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2361c48a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

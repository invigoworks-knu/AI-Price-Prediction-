{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ea5210",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==================== 1. 데이터 로드 함수 (사용자의 기존 코드) ====================\n",
    "\n",
    "def parse_date_from_filename(filename):\n",
    "    patterns = [\n",
    "        r'(\\d{4})-(\\d{2})-(\\d{2})',\n",
    "        r'(\\d{4})(\\d{2})(\\d{2})',\n",
    "        r'(\\d{2})-(\\d{2})-(\\d{4})',\n",
    "        r'(\\d{2})(\\d{2})(\\d{4})'\n",
    "    ]\n",
    "    basename = os.path.basename(filename)\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, basename)\n",
    "        if match:\n",
    "            try:\n",
    "                if len(match.group(1)) == 4:\n",
    "                    year, month, day = match.groups()\n",
    "                else:\n",
    "                    day, month, year = match.groups()\n",
    "                return pd.to_datetime(f\"{year}-{month}-{day}\")\n",
    "            except:\n",
    "                continue\n",
    "    return None\n",
    "\n",
    "def load_all_news_data(root_dir):\n",
    "    all_data = []\n",
    "    if not os.path.exists(root_dir):\n",
    "        print(f\"경고: 디렉토리가 존재하지 않습니다: {root_dir}\")\n",
    "        # 테스트용 더미 데이터 생성\n",
    "        dates = pd.date_range('2021-01-01', '2024-12-31', freq='D')\n",
    "        return pd.DataFrame({\n",
    "            'date': dates,\n",
    "            'news': ['test news'] * len(dates),\n",
    "            'label': np.random.choice([1, 0, -1], len(dates))\n",
    "        })\n",
    "    \n",
    "    csv_files = sorted([f for f in os.listdir(root_dir) if f.endswith('.csv')])\n",
    "    for filename in csv_files:\n",
    "        filepath = os.path.join(root_dir, filename)\n",
    "        file_date = parse_date_from_filename(filename)\n",
    "        for enc in ['utf-8', 'cp949', 'latin1']:\n",
    "            try:\n",
    "                df = pd.read_csv(filepath, encoding=enc)\n",
    "                break\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"읽기 실패: {filepath}\")\n",
    "            continue\n",
    "        df = df.loc[:,['news','label'] if 'date' not in df.columns else ['news','label','date']]\n",
    "        if 'date' not in df.columns:\n",
    "            df['date'] = file_date\n",
    "        else:\n",
    "            df['date'] = pd.to_datetime(df['date'],errors='coerce')\n",
    "            if file_date is not None:\n",
    "                df['date'] = df['date'].fillna(file_date)\n",
    "        all_data.append(df)\n",
    "    \n",
    "    if len(all_data) == 0:\n",
    "        print(\"경고: CSV 파일을 찾을 수 없습니다. 더미 데이터 생성\")\n",
    "        dates = pd.date_range('2021-01-01', '2024-12-31', freq='D')\n",
    "        return pd.DataFrame({\n",
    "            'date': dates,\n",
    "            'news': ['test news'] * len(dates),\n",
    "            'label': np.random.choice([1, 0, -1], len(dates))\n",
    "        })\n",
    "    \n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    combined_df['date'] = pd.to_datetime(combined_df['date'], errors='coerce')\n",
    "    return combined_df\n",
    "\n",
    "print(\"데이터 로드 함수 준비 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "455415e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 이더리움 데이터 컬럼이 MultiIndex입니다. 평탄화 중...\n",
      "✓ 이더리움 데이터: 2103일, 2020-01-01 00:00:00 ~ 2025-10-03 00:00:00\n",
      "\n",
      "상위 5개 암호화폐 데이터 다운로드 중...\n",
      "MultiIndex 컬럼 평탄화 및 이름 정리 중...\n",
      "✓ 상위 5개 암호화폐 데이터 통합 완료: (2103, 25)\n",
      "\n",
      "최종 데이터프레임 컬럼 예시:\n",
      "Index(['close_ada', 'close_bnb', 'close_btc', 'close_sol', 'close_xrp',\n",
      "       'high_ada', 'high_bnb', 'high_btc', 'high_sol', 'high_xrp'],\n",
      "      dtype='object')\n",
      "\n",
      "✓ 모든 암호화폐 데이터 통합 완료: (2103, 30)\n",
      "\n",
      "최종 데이터프레임 (all_crypto) 상위 5개 행:\n",
      "             close_eth    high_eth     low_eth    open_eth   volume_eth  \\\n",
      "date                                                                      \n",
      "2020-01-01  130.802002  132.835358  129.198288  129.630661   7935230330   \n",
      "2020-01-02  127.410179  130.820038  126.954910  130.820038   8032709256   \n",
      "2020-01-03  134.171707  134.554016  126.490021  127.411263  10476845358   \n",
      "2020-01-04  135.069366  136.052719  133.040558  134.168518   7430904515   \n",
      "2020-01-05  136.276779  139.410202  135.045624  135.072098   7526675353   \n",
      "\n",
      "            close_ada  close_bnb    close_btc  close_sol  close_xrp  ...  \\\n",
      "date                                                                 ...   \n",
      "2020-01-01   0.033458  13.689083  7200.174316        NaN   0.192667  ...   \n",
      "2020-01-02   0.032751  13.027011  6985.470215        NaN   0.188043  ...   \n",
      "2020-01-03   0.034180  13.660452  7344.884277        NaN   0.193521  ...   \n",
      "2020-01-04   0.034595  13.891512  7410.656738        NaN   0.194355  ...   \n",
      "2020-01-05   0.034721  14.111019  7411.317383        NaN   0.195537  ...   \n",
      "\n",
      "            open_ada   open_bnb     open_btc  open_sol  open_xrp  volume_ada  \\\n",
      "date                                                                           \n",
      "2020-01-01  0.032832  13.730962  7194.892090       NaN  0.192912    22948374   \n",
      "2020-01-02  0.033474  13.698126  7202.551270       NaN  0.192708    20843934   \n",
      "2020-01-03  0.032748  13.035329  6984.428711       NaN  0.187948    30162644   \n",
      "2020-01-04  0.034191  13.667442  7345.375488       NaN  0.193521    29535781   \n",
      "2020-01-05  0.034574  13.888340  7410.451660       NaN  0.194367    21479178   \n",
      "\n",
      "            volume_bnb   volume_btc  volume_sol  volume_xrp  \n",
      "date                                                         \n",
      "2020-01-01   172980718  18565664997         NaN  1041134003  \n",
      "2020-01-02   156376427  20802083465         NaN  1085351426  \n",
      "2020-01-03   173683857  28111481032         NaN  1270017043  \n",
      "2020-01-04   182230374  18444271275         NaN   999331594  \n",
      "2020-01-05   202552703  19725074095         NaN  1168067557  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "온체인 데이터 로드 시도...\n",
      "✓ 온체인 데이터: 3711일, 2015-08-07 00:00:00 ~ 2025-10-03 00:00:00\n",
      "  컬럼: ['tx_count', 'active_addresses', 'new_addresses', 'large_eth_transfers', 'token_transfers', 'contract_events', 'avg_gas_price', 'total_gas_used', 'avg_block_size', 'avg_block_difficulty']\n",
      "\n",
      "감정 분석 데이터 로드 시도...\n",
      "✓ 뉴스 데이터: 25910건, 2020-01-01 00:00:00 ~ 2025-10-01 00:00:00\n",
      "✓ 일별 감정 데이터: 2059일\n",
      "\n",
      "============================================================\n",
      "모든 데이터 로드 완료!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==================== 2. 실제 데이터 다운로드 (이더리움 가격 데이터) ====================\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "\n",
    "# 데이터 다운로드 기간 설정\n",
    "START_DATE = '2020-01-01'\n",
    "END_DATE = '2025-10-04' \n",
    "\n",
    "\n",
    "# --- 1. 이더리움 데이터 다운로드 및 정리 ---\n",
    "eth_price = yf.download('ETH-USD', start=START_DATE, end=END_DATE, progress=False)\n",
    "\n",
    "# MultiIndex 확인 및 처리: 컬럼이 MultiIndex일 경우 두 번째 레벨 (티커명)을 제거\n",
    "if isinstance(eth_price.columns, pd.MultiIndex):\n",
    "    print(\"⚠️ 이더리움 데이터 컬럼이 MultiIndex입니다. 평탄화 중...\")\n",
    "    # 두 번째 레벨(티커명)을 제거하여 첫 번째 레벨(Open, High, ...)만 남김\n",
    "    eth_price.columns = eth_price.columns.droplevel(1) \n",
    "\n",
    "# 컬럼 이름을 소문자로 변경 (이제 컬럼은 문자열입니다)\n",
    "eth_price.columns = [col.lower() for col in eth_price.columns]\n",
    "eth_price.index.name = 'date'\n",
    "print(f\"✓ 이더리움 데이터: {len(eth_price)}일, {eth_price.index.min()} ~ {eth_price.index.max()}\")\n",
    "\n",
    "# --- 2. 상위 5개 암호화폐 데이터 다운로드 (MultiIndex 처리) ---\n",
    "print(\"\\n상위 5개 암호화폐 데이터 다운로드 중...\")\n",
    "crypto_tickers = ['BTC-USD', 'BNB-USD', 'XRP-USD', 'ADA-USD', 'SOL-USD']\n",
    "top5_crypto_multi = yf.download(crypto_tickers, start=START_DATE, end=END_DATE, progress=False)\n",
    "\n",
    "# MultiIndex 컬럼 평탄화 및 이름 정리 (기존 로직 유지)\n",
    "if isinstance(top5_crypto_multi.columns, pd.MultiIndex):\n",
    "    print(\"MultiIndex 컬럼 평탄화 및 이름 정리 중...\")\n",
    "    \n",
    "    # 튜플의 원소를 '_'로 연결하여 단일 컬럼 이름 생성\n",
    "    new_cols = []\n",
    "    for col_tuple in top5_crypto_multi.columns:\n",
    "        # 예: ('Close', 'BTC-USD') -> 'close_btc'\n",
    "        col_name_joined = '_'.join(col_tuple) \n",
    "        new_name = col_name_joined.lower().replace('-usd', '').replace('adj close', 'adj_close').replace(' ', '_')\n",
    "        new_cols.append(new_name)\n",
    "    \n",
    "    top5_crypto = top5_crypto_multi.copy()\n",
    "    top5_crypto.columns = new_cols\n",
    "    top5_crypto.index.name = 'date'\n",
    "\n",
    "    print(f\"✓ 상위 5개 암호화폐 데이터 통합 완료: {top5_crypto.shape}\")\n",
    "    print(\"\\n최종 데이터프레임 컬럼 예시:\")\n",
    "    print(top5_crypto.columns[:10])\n",
    "else:\n",
    "    top5_crypto = top5_crypto_multi\n",
    "    print(\"MultiIndex가 아닙니다. 추가 정리 불필요.\")\n",
    "\n",
    "# --- 4. 모든 데이터 병합 (선택 사항) ---\n",
    "# 이더리움 데이터를 포함하여 하나의 DataFrame으로 통합\n",
    "all_crypto = pd.merge(eth_price, top5_crypto, on='date', how='inner', suffixes=('_eth', None))\n",
    "all_crypto = all_crypto.rename(columns={'open': 'open_eth', 'high': 'high_eth', 'low': 'low_eth', 'close': 'close_eth', 'volume': 'volume_eth', 'adj close': 'adj_close_eth'})\n",
    "\n",
    "print(f\"\\n✓ 모든 암호화폐 데이터 통합 완료: {all_crypto.shape}\")\n",
    "print(\"\\n최종 데이터프레임 (all_crypto) 상위 5개 행:\")\n",
    "print(all_crypto.head())\n",
    "\n",
    "# 온체인 데이터 로드 시도\n",
    "print(\"\\n온체인 데이터 로드 시도...\")\n",
    "try:\n",
    "    onchain = pd.read_csv('eth_onchain.csv', parse_dates=['date'])\n",
    "    onchain.set_index('date', inplace=True)\n",
    "    onchain.index = pd.to_datetime(onchain.index)\n",
    "    print(f\"✓ 온체인 데이터: {len(onchain)}일, {onchain.index.min()} ~ {onchain.index.max()}\")\n",
    "    print(f\"  컬럼: {list(onchain.columns)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"✗ eth_onchain.csv 파일을 찾을 수 없습니다.\")\n",
    "    print(\"  온체인 데이터 없이 진행합니다.\")\n",
    "    onchain = None\n",
    "\n",
    "# 뉴스 감정 데이터 로드\n",
    "print(\"\\n감정 분석 데이터 로드 시도...\")\n",
    "ROOT_DIR = \"./news_data\"  # 기본 경로\n",
    "news_df = load_all_news_data(ROOT_DIR)\n",
    "print(f\"✓ 뉴스 데이터: {len(news_df)}건, {news_df['date'].min()} ~ {news_df['date'].max()}\")\n",
    "\n",
    "# 일별 감정 점수 집계\n",
    "daily_sentiment = news_df.groupby('date').agg({\n",
    "    'label': ['mean', 'std', 'count']\n",
    "})\n",
    "daily_sentiment.columns = ['sentiment_mean', 'sentiment_std', 'sentiment_count']\n",
    "daily_sentiment['sentiment_std'] = daily_sentiment['sentiment_std'].fillna(0)\n",
    "print(f\"✓ 일별 감정 데이터: {len(daily_sentiment)}일\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"모든 데이터 로드 완료!\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5b5060f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>세계 최대 암호화폐인 비트코인(Bitcoin, BTC)은 전일대비 1.54% 하락한...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>업비트 암호화폐(가상화폐) 거래소 오전 9시 25분(한국시간) 기준으로 비트코인은 ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>지난 24시간 동안 세계 최대 암호화폐인 비트코인(Bitcoin, BTC)은 단기 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>업비트 암호화폐(가상화폐) 거래소 오전 9시 50분(한국시간) 기준으로 비트코인은 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>이더리움(Ethereum) 네트워크가 '빙하기'를 늦추기 위한 긴급 하드포크 ‘뮤어...</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news label       date\n",
       "0  세계 최대 암호화폐인 비트코인(Bitcoin, BTC)은 전일대비 1.54% 하락한...    -1 2020-01-01\n",
       "1  업비트 암호화폐(가상화폐) 거래소 오전 9시 25분(한국시간) 기준으로 비트코인은 ...    -1 2020-01-01\n",
       "2  지난 24시간 동안 세계 최대 암호화폐인 비트코인(Bitcoin, BTC)은 단기 ...     0 2020-01-02\n",
       "3  업비트 암호화폐(가상화폐) 거래소 오전 9시 50분(한국시간) 기준으로 비트코인은 ...     0 2020-01-02\n",
       "4  이더리움(Ethereum) 네트워크가 '빙하기'를 늦추기 위한 긴급 하드포크 ‘뮤어...     1 2020-01-03"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "593111cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tx_count</th>\n",
       "      <th>active_addresses</th>\n",
       "      <th>new_addresses</th>\n",
       "      <th>large_eth_transfers</th>\n",
       "      <th>token_transfers</th>\n",
       "      <th>contract_events</th>\n",
       "      <th>avg_gas_price</th>\n",
       "      <th>total_gas_used</th>\n",
       "      <th>avg_block_size</th>\n",
       "      <th>avg_block_difficulty</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-08-07</th>\n",
       "      <td>2050</td>\n",
       "      <td>784</td>\n",
       "      <td>784</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.046842e+11</td>\n",
       "      <td>49353826</td>\n",
       "      <td>632.63</td>\n",
       "      <td>1.470839e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-08</th>\n",
       "      <td>2881</td>\n",
       "      <td>605</td>\n",
       "      <td>430</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.227136e+11</td>\n",
       "      <td>376006093</td>\n",
       "      <td>667.59</td>\n",
       "      <td>1.586124e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-09</th>\n",
       "      <td>1329</td>\n",
       "      <td>462</td>\n",
       "      <td>252</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4.754671e+11</td>\n",
       "      <td>38863003</td>\n",
       "      <td>618.30</td>\n",
       "      <td>1.709480e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-10</th>\n",
       "      <td>2037</td>\n",
       "      <td>821</td>\n",
       "      <td>632</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>4.216549e+11</td>\n",
       "      <td>74070061</td>\n",
       "      <td>631.19</td>\n",
       "      <td>1.837696e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-11</th>\n",
       "      <td>4963</td>\n",
       "      <td>2132</td>\n",
       "      <td>1881</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>7.783882e+10</td>\n",
       "      <td>163481740</td>\n",
       "      <td>692.01</td>\n",
       "      <td>2.036391e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tx_count  active_addresses  new_addresses  large_eth_transfers  \\\n",
       "date                                                                         \n",
       "2015-08-07      2050               784            784                  283   \n",
       "2015-08-08      2881               605            430                  186   \n",
       "2015-08-09      1329               462            252                  124   \n",
       "2015-08-10      2037               821            632                  115   \n",
       "2015-08-11      4963              2132           1881                  150   \n",
       "\n",
       "            token_transfers  contract_events  avg_gas_price  total_gas_used  \\\n",
       "date                                                                          \n",
       "2015-08-07                0                0   6.046842e+11        49353826   \n",
       "2015-08-08                0                6   3.227136e+11       376006093   \n",
       "2015-08-09                0               11   4.754671e+11        38863003   \n",
       "2015-08-10                0               22   4.216549e+11        74070061   \n",
       "2015-08-11                0               42   7.783882e+10       163481740   \n",
       "\n",
       "            avg_block_size  avg_block_difficulty  \n",
       "date                                              \n",
       "2015-08-07          632.63          1.470839e+12  \n",
       "2015-08-08          667.59          1.586124e+12  \n",
       "2015-08-09          618.30          1.709480e+12  \n",
       "2015-08-10          631.19          1.837696e+12  \n",
       "2015-08-11          692.01          2.036391e+12  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onchain.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03febb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CryptoPulse 모델 클래스 구현 완료\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==================== 3. CryptoPulse 모델 완전 구현 ====================\n",
    "\n",
    "class CryptoPulseModel:\n",
    "    \"\"\"\n",
    "    CryptoPulse: Short-Term Cryptocurrency Forecasting with Dual-Prediction\n",
    "    and Cross-Correlated Market Indicators (2025)\n",
    "    \n",
    "    논문의 이중 예측 메커니즘을 정확히 구현\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sequence_length=7):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.macro_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.05, \n",
    "                                                      max_depth=5, random_state=42)\n",
    "        self.dynamics_model = Ridge(alpha=1.0)\n",
    "        self.fusion_model = GradientBoostingRegressor(n_estimators=50, learning_rate=0.1, \n",
    "                                                       max_depth=3, random_state=42)\n",
    "        \n",
    "        self.scaler_macro = StandardScaler()\n",
    "        self.scaler_dynamics = StandardScaler()\n",
    "        self.scaler_fusion = StandardScaler()\n",
    "        \n",
    "        self.trained = False\n",
    "        \n",
    "    def compute_technical_indicators(self, df):\n",
    "        \"\"\"\n",
    "        논문 Section III-A: 7개 기술적 지표 계산\n",
    "        \"\"\"\n",
    "        result = df.copy()\n",
    "        \n",
    "        # Stochastic %K (N=14)\n",
    "        result['lowest_14'] = result['low'].rolling(14, min_periods=1).min()\n",
    "        result['highest_14'] = result['high'].rolling(14, min_periods=1).max()\n",
    "        result['stochastic_k'] = ((result['close'] - result['lowest_14']) / \n",
    "                                 (result['highest_14'] - result['lowest_14'] + 1e-10)) * 100\n",
    "        \n",
    "        # Stochastic %D (3-day SMA of %K)\n",
    "        result['stochastic_d'] = result['stochastic_k'].rolling(3, min_periods=1).mean()\n",
    "        \n",
    "        # Williams %R (N=14)\n",
    "        result['williams_r'] = ((result['highest_14'] - result['close']) / \n",
    "                               (result['highest_14'] - result['lowest_14'] + 1e-10)) * 100\n",
    "        \n",
    "        # A/D Oscillator\n",
    "        result['ad_oscillator'] = ((result['close'].shift(1) - result['close']) / \n",
    "                                  (result['high'] - result['low'] + 1e-10))\n",
    "        result['ad_oscillator'] = result['ad_oscillator'].fillna(0)\n",
    "        \n",
    "        # Momentum (N=10)\n",
    "        result['momentum'] = result['close'] - result['close'].shift(10)\n",
    "        result['momentum'] = result['momentum'].fillna(0)\n",
    "        \n",
    "        # Disparity 7\n",
    "        result['ma_7'] = result['close'].rolling(7, min_periods=1).mean()\n",
    "        result['disparity_7'] = (result['close'] / (result['ma_7'] + 1e-10)) * 100\n",
    "        \n",
    "        # Rate of Change (N=12)\n",
    "        result['roc'] = (result['close'] / (result['close'].shift(12) + 1e-10)) * 100\n",
    "        result['roc'] = result['roc'].fillna(100)\n",
    "        \n",
    "        # 중간 계산 컬럼 제거\n",
    "        technical_cols = ['open', 'high', 'low', 'close', 'volume',\n",
    "                         'stochastic_k', 'stochastic_d', 'williams_r', \n",
    "                         'ad_oscillator', 'momentum', 'disparity_7', 'roc']\n",
    "        \n",
    "        return result[technical_cols]\n",
    "    \n",
    "    def create_sequences(self, price_data, macro_data, sentiment_data, onchain_data=None):\n",
    "        \"\"\"\n",
    "        논문의 시퀀스 구조 생성: L=7일 관찰 윈도우\n",
    "        \"\"\"\n",
    "        sequences = []\n",
    "        \n",
    "        # 공통 날짜 찾기\n",
    "        common_dates = sorted(set(price_data.index) & \n",
    "                            set(macro_data.index) & \n",
    "                            set(sentiment_data.index))\n",
    "        \n",
    "        if onchain_data is not None:\n",
    "            common_dates = sorted(set(common_dates) & set(onchain_data.index))\n",
    "        \n",
    "        print(f\"공통 날짜 범위: {len(common_dates)}일\")\n",
    "        \n",
    "        for i in range(self.sequence_length, len(common_dates)):\n",
    "            end_idx = i - 1\n",
    "            start_idx = i - self.sequence_length\n",
    "            target_idx = i\n",
    "            \n",
    "            end_date = common_dates[end_idx]\n",
    "            start_date = common_dates[start_idx]\n",
    "            target_date = common_dates[target_idx]\n",
    "            \n",
    "            # 시퀀스 데이터 추출\n",
    "            price_seq = price_data.loc[start_date:end_date]\n",
    "            macro_seq = macro_data.loc[start_date:end_date]\n",
    "            sentiment_seq = sentiment_data.loc[start_date:end_date]\n",
    "            \n",
    "            if len(price_seq) == self.sequence_length and len(macro_seq) == self.sequence_length:\n",
    "                # 기본 특성 (OHLCV) - 매크로 환경 예측용\n",
    "                basic_features = price_seq[['open', 'high', 'low', 'close', 'volume']].values.flatten()\n",
    "                \n",
    "                # 전체 특성 (OHLCV + 기술적 지표) - 가격 동역학 예측용\n",
    "                full_features = price_seq.values.flatten()\n",
    "                \n",
    "                # 매크로 환경 특성\n",
    "                macro_features = macro_seq.values.flatten()\n",
    "                \n",
    "                # 감정 특성\n",
    "                if 'sentiment_mean' in sentiment_seq.columns:\n",
    "                    sentiment_mean = sentiment_seq['sentiment_mean'].values\n",
    "                    sentiment_std = sentiment_seq['sentiment_std'].values\n",
    "                    sentiment_count = sentiment_seq['sentiment_count'].values\n",
    "                    sentiment_features = np.concatenate([sentiment_mean, sentiment_std, \n",
    "                                                        np.log1p(sentiment_count)])\n",
    "                else:\n",
    "                    sentiment_features = sentiment_seq.values.flatten()\n",
    "                \n",
    "                # 온체인 특성 추가\n",
    "                if onchain_data is not None:\n",
    "                    try:\n",
    "                        onchain_seq = onchain_data.loc[start_date:end_date]\n",
    "                        if len(onchain_seq) == self.sequence_length:\n",
    "                            onchain_features = onchain_seq.values.flatten()\n",
    "                            # 온체인 데이터를 full_features에 추가\n",
    "                            full_features = np.concatenate([full_features, onchain_features])\n",
    "                    except:\n",
    "                        pass\n",
    "                \n",
    "                # 타겟\n",
    "                current_price = price_data.loc[end_date, 'close']\n",
    "                target_price = price_data.loc[target_date, 'close']\n",
    "                \n",
    "                sequences.append({\n",
    "                    'basic_features': basic_features,\n",
    "                    'full_features': full_features,\n",
    "                    'macro_features': macro_features,\n",
    "                    'sentiment_features': sentiment_features,\n",
    "                    'current_price': current_price,\n",
    "                    'target_price': target_price,\n",
    "                    'date': target_date\n",
    "                })\n",
    "        \n",
    "        print(f\"생성된 시퀀스: {len(sequences)}개\")\n",
    "        return sequences\n",
    "    \n",
    "    def train(self, sequences):\n",
    "        \"\"\"\n",
    "        이중 예측 메커니즘으로 학습\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"CryptoPulse 모델 학습 시작\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # 데이터 준비\n",
    "        macro_X = np.array([seq['basic_features'] for seq in sequences])\n",
    "        dynamics_X = np.array([seq['full_features'] for seq in sequences])\n",
    "        sentiment_X = np.array([seq['sentiment_features'] for seq in sequences])\n",
    "        current_prices = np.array([seq['current_price'] for seq in sequences])\n",
    "        targets = np.array([seq['target_price'] for seq in sequences])\n",
    "        \n",
    "        # 변동량으로 변환 (논문의 핵심)\n",
    "        target_changes = targets - current_prices\n",
    "        \n",
    "        print(f\"\\n학습 데이터:\")\n",
    "        print(f\"  샘플 수: {len(sequences)}\")\n",
    "        print(f\"  매크로 특성 차원: {macro_X.shape[1]}\")\n",
    "        print(f\"  동역학 특성 차원: {dynamics_X.shape[1]}\")\n",
    "        print(f\"  감정 특성 차원: {sentiment_X.shape[1]}\")\n",
    "        print(f\"  평균 가격 변동: ${target_changes.mean():.2f} (±${target_changes.std():.2f})\")\n",
    "        \n",
    "        # 1. 매크로 환경 기반 예측 모델 학습\n",
    "        print(\"\\n[1/3] 매크로 환경 기반 예측 모델 학습 중...\")\n",
    "        macro_X_scaled = self.scaler_macro.fit_transform(macro_X)\n",
    "        self.macro_model.fit(macro_X_scaled, target_changes)\n",
    "        macro_train_pred = self.macro_model.predict(macro_X_scaled)\n",
    "        macro_train_mae = mean_absolute_error(target_changes, macro_train_pred)\n",
    "        print(f\"      훈련 MAE: ${macro_train_mae:.2f}\")\n",
    "        \n",
    "        # 2. 가격 동역학 기반 예측 모델 학습\n",
    "        print(\"\\n[2/3] 가격 동역학 기반 예측 모델 학습 중...\")\n",
    "        dynamics_X_scaled = self.scaler_dynamics.fit_transform(dynamics_X)\n",
    "        self.dynamics_model.fit(dynamics_X_scaled, target_changes)\n",
    "        dynamics_train_pred = self.dynamics_model.predict(dynamics_X_scaled)\n",
    "        dynamics_train_mae = mean_absolute_error(target_changes, dynamics_train_pred)\n",
    "        print(f\"      훈련 MAE: ${dynamics_train_mae:.2f}\")\n",
    "        \n",
    "        # 3. 융합 모델 학습 (감정 데이터로 두 예측 결합)\n",
    "        print(\"\\n[3/3] 감정 기반 융합 모델 학습 중...\")\n",
    "        fusion_features = np.column_stack([\n",
    "            macro_train_pred,\n",
    "            dynamics_train_pred,\n",
    "            sentiment_X,\n",
    "            np.mean(macro_X, axis=1),\n",
    "            np.std(macro_X, axis=1),\n",
    "            np.mean(dynamics_X, axis=1),\n",
    "            np.std(dynamics_X, axis=1)\n",
    "        ])\n",
    "        \n",
    "        fusion_X_scaled = self.scaler_fusion.fit_transform(fusion_features)\n",
    "        self.fusion_model.fit(fusion_X_scaled, target_changes)\n",
    "        fusion_train_pred = self.fusion_model.predict(fusion_X_scaled)\n",
    "        fusion_train_mae = mean_absolute_error(target_changes, fusion_train_pred)\n",
    "        print(f\"      훈련 MAE: ${fusion_train_mae:.2f}\")\n",
    "        \n",
    "        self.trained = True\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"모델 학습 완료!\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, sequences):\n",
    "        \"\"\"\n",
    "        이중 예측 + 감정 기반 융합으로 예측\n",
    "        \"\"\"\n",
    "        if not self.trained:\n",
    "            raise ValueError(\"모델이 학습되지 않았습니다. train() 먼저 실행하세요.\")\n",
    "        \n",
    "        # 데이터 준비\n",
    "        macro_X = np.array([seq['basic_features'] for seq in sequences])\n",
    "        dynamics_X = np.array([seq['full_features'] for seq in sequences])\n",
    "        sentiment_X = np.array([seq['sentiment_features'] for seq in sequences])\n",
    "        current_prices = np.array([seq['current_price'] for seq in sequences])\n",
    "        \n",
    "        # 스케일링\n",
    "        macro_X_scaled = self.scaler_macro.transform(macro_X)\n",
    "        dynamics_X_scaled = self.scaler_dynamics.transform(dynamics_X)\n",
    "        \n",
    "        # 개별 예측 (변동량)\n",
    "        macro_changes = self.macro_model.predict(macro_X_scaled)\n",
    "        dynamics_changes = self.dynamics_model.predict(dynamics_X_scaled)\n",
    "        \n",
    "        # 융합 예측\n",
    "        fusion_features = np.column_stack([\n",
    "            macro_changes,\n",
    "            dynamics_changes,\n",
    "            sentiment_X,\n",
    "            np.mean(macro_X, axis=1),\n",
    "            np.std(macro_X, axis=1),\n",
    "            np.mean(dynamics_X, axis=1),\n",
    "            np.std(dynamics_X, axis=1)\n",
    "        ])\n",
    "        fusion_X_scaled = self.scaler_fusion.transform(fusion_features)\n",
    "        final_changes = self.fusion_model.predict(fusion_X_scaled)\n",
    "        \n",
    "        # 최종 가격 예측\n",
    "        predictions = current_prices + final_changes\n",
    "        macro_predictions = current_prices + macro_changes\n",
    "        dynamics_predictions = current_prices + dynamics_changes\n",
    "        \n",
    "        # 방향성 예측\n",
    "        direction = np.sign(final_changes)\n",
    "        \n",
    "        return {\n",
    "            'predictions': predictions,\n",
    "            'macro_predictions': macro_predictions,\n",
    "            'dynamics_predictions': dynamics_predictions,\n",
    "            'price_changes': final_changes,\n",
    "            'direction': direction,  # 1: 상승, -1: 하락, 0: 변화없음\n",
    "            'dates': [seq['date'] for seq in sequences]\n",
    "        }\n",
    "\n",
    "print(\"✓ CryptoPulse 모델 클래스 구현 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a72a89e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CryptoPulse 전체 파이프라인 실행\n",
      "======================================================================\n",
      "\n",
      "[STEP 1] 기술적 지표 계산 중...\n",
      "✓ 기술적 지표 추가 완료: (2103, 12)\n",
      "  컬럼: ['open', 'high', 'low', 'close', 'volume', 'stochastic_k', 'stochastic_d', 'williams_r', 'ad_oscillator', 'momentum', 'disparity_7', 'roc']\n",
      "\n",
      "[STEP 2] 시퀀스 데이터 생성 중...\n",
      "공통 날짜 범위: 2059일\n",
      "생성된 시퀀스: 1825개\n",
      "\n",
      "[STEP 3] 데이터 분할 완료:\n",
      "  학습: 1277개 (70%)\n",
      "  검증: 182개 (10%)\n",
      "  테스트: 366개 (20%)\n",
      "\n",
      "[STEP 4] 모델 학습...\n",
      "\n",
      "======================================================================\n",
      "CryptoPulse 모델 학습 시작\n",
      "======================================================================\n",
      "\n",
      "학습 데이터:\n",
      "  샘플 수: 1277\n",
      "  매크로 특성 차원: 35\n",
      "  동역학 특성 차원: 154\n",
      "  감정 특성 차원: 21\n",
      "  평균 가격 변동: $1.98 (±$93.58)\n",
      "\n",
      "[1/3] 매크로 환경 기반 예측 모델 학습 중...\n",
      "      훈련 MAE: $36.12\n",
      "\n",
      "[2/3] 가격 동역학 기반 예측 모델 학습 중...\n",
      "      훈련 MAE: $55.03\n",
      "\n",
      "[3/3] 감정 기반 융합 모델 학습 중...\n",
      "      훈련 MAE: $25.18\n",
      "\n",
      "======================================================================\n",
      "모델 학습 완료!\n",
      "======================================================================\n",
      "\n",
      "[STEP 5] 검증 세트 평가...\n",
      "\n",
      "검증 세트 성능:\n",
      "  MAE:  $98.56\n",
      "  RMSE: $126.81\n",
      "  MAPE: 3.17%\n",
      "  R²:   0.9188\n",
      "\n",
      "[STEP 6] 테스트 세트 평가...\n",
      "\n",
      "======================================================================\n",
      "최종 테스트 세트 성능 (CryptoPulse)\n",
      "======================================================================\n",
      "\n",
      "융합 예측:\n",
      "  MAE:  $124.81\n",
      "  RMSE: $173.82\n",
      "  MAPE: 4.00%\n",
      "  R²:   0.9573\n",
      "\n",
      "개별 예측 성능 비교:\n",
      "  매크로 환경 예측 MAE:  $101.20\n",
      "  가격 동역학 예측 MAE:  $95.17\n",
      "  융합 예측 MAE:        $124.81 ⭐\n",
      "\n",
      "방향성 예측:\n",
      "  정확도: 54.10%\n",
      "  상승 예측: 178일\n",
      "  하락 예측: 188일\n",
      "  보합 예측: 0일\n",
      "\n",
      "======================================================================\n",
      "CryptoPulse 파이프라인 완료!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==================== 4. 전체 파이프라인 실행 ====================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CryptoPulse 전체 파이프라인 실행\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 1: 기술적 지표 계산\n",
    "print(\"\\n[STEP 1] 기술적 지표 계산 중...\")\n",
    "model = CryptoPulseModel(sequence_length=7)\n",
    "eth_with_indicators = model.compute_technical_indicators(eth_price)\n",
    "print(f\"✓ 기술적 지표 추가 완료: {eth_with_indicators.shape}\")\n",
    "print(f\"  컬럼: {list(eth_with_indicators.columns)}\")\n",
    "\n",
    "# Step 2: 시퀀스 생성\n",
    "print(\"\\n[STEP 2] 시퀀스 데이터 생성 중...\")\n",
    "sequences = model.create_sequences(\n",
    "    price_data=eth_with_indicators,\n",
    "    macro_data=top5_crypto,\n",
    "    sentiment_data=daily_sentiment,\n",
    "    onchain_data=onchain\n",
    ")\n",
    "\n",
    "# Step 3: 학습/테스트 분할 (시계열이므로 chronological split)\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.2\n",
    "\n",
    "train_size = int(len(sequences) * train_ratio)\n",
    "val_size = int(len(sequences) * val_ratio)\n",
    "\n",
    "train_sequences = sequences[:train_size]\n",
    "val_sequences = sequences[train_size:train_size+val_size]\n",
    "test_sequences = sequences[train_size+val_size:]\n",
    "\n",
    "print(f\"\\n[STEP 3] 데이터 분할 완료:\")\n",
    "print(f\"  학습: {len(train_sequences)}개 ({train_ratio*100:.0f}%)\")\n",
    "print(f\"  검증: {len(val_sequences)}개 ({val_ratio*100:.0f}%)\")\n",
    "print(f\"  테스트: {len(test_sequences)}개 ({test_ratio*100:.0f}%)\")\n",
    "\n",
    "# Step 4: 모델 학습\n",
    "print(f\"\\n[STEP 4] 모델 학습...\")\n",
    "model.train(train_sequences)\n",
    "\n",
    "# Step 5: 검증 세트 평가\n",
    "print(f\"\\n[STEP 5] 검증 세트 평가...\")\n",
    "val_results = model.predict(val_sequences)\n",
    "\n",
    "val_actual = np.array([seq['target_price'] for seq in val_sequences])\n",
    "val_pred = val_results['predictions']\n",
    "\n",
    "val_mae = mean_absolute_error(val_actual, val_pred)\n",
    "val_mse = mean_squared_error(val_actual, val_pred)\n",
    "val_rmse = np.sqrt(val_mse)\n",
    "val_r2 = r2_score(val_actual, val_pred)\n",
    "val_mape = np.mean(np.abs((val_actual - val_pred) / val_actual)) * 100\n",
    "\n",
    "print(f\"\\n검증 세트 성능:\")\n",
    "print(f\"  MAE:  ${val_mae:.2f}\")\n",
    "print(f\"  RMSE: ${val_rmse:.2f}\")\n",
    "print(f\"  MAPE: {val_mape:.2f}%\")\n",
    "print(f\"  R²:   {val_r2:.4f}\")\n",
    "\n",
    "# Step 6: 테스트 세트 평가\n",
    "print(f\"\\n[STEP 6] 테스트 세트 평가...\")\n",
    "test_results = model.predict(test_sequences)\n",
    "\n",
    "test_actual = np.array([seq['target_price'] for seq in test_sequences])\n",
    "test_pred = test_results['predictions']\n",
    "test_macro_pred = test_results['macro_predictions']\n",
    "test_dynamics_pred = test_results['dynamics_predictions']\n",
    "\n",
    "# 성능 지표 계산\n",
    "test_mae = mean_absolute_error(test_actual, test_pred)\n",
    "test_mse = mean_squared_error(test_actual, test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_r2 = r2_score(test_actual, test_pred)\n",
    "test_mape = np.mean(np.abs((test_actual - test_pred) / test_actual)) * 100\n",
    "\n",
    "# 개별 예측 성능\n",
    "macro_mae = mean_absolute_error(test_actual, test_macro_pred)\n",
    "dynamics_mae = mean_absolute_error(test_actual, test_dynamics_pred)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"최종 테스트 세트 성능 (CryptoPulse)\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\n융합 예측:\")\n",
    "print(f\"  MAE:  ${test_mae:.2f}\")\n",
    "print(f\"  RMSE: ${test_rmse:.2f}\")\n",
    "print(f\"  MAPE: {test_mape:.2f}%\")\n",
    "print(f\"  R²:   {test_r2:.4f}\")\n",
    "\n",
    "print(f\"\\n개별 예측 성능 비교:\")\n",
    "print(f\"  매크로 환경 예측 MAE:  ${macro_mae:.2f}\")\n",
    "print(f\"  가격 동역학 예측 MAE:  ${dynamics_mae:.2f}\")\n",
    "print(f\"  융합 예측 MAE:        ${test_mae:.2f} ⭐\")\n",
    "\n",
    "# 방향성 정확도\n",
    "actual_direction = np.sign(test_actual - np.array([seq['current_price'] for seq in test_sequences]))\n",
    "pred_direction = test_results['direction']\n",
    "direction_accuracy = np.mean(actual_direction == pred_direction) * 100\n",
    "\n",
    "print(f\"\\n방향성 예측:\")\n",
    "print(f\"  정확도: {direction_accuracy:.2f}%\")\n",
    "print(f\"  상승 예측: {np.sum(pred_direction == 1)}일\")\n",
    "print(f\"  하락 예측: {np.sum(pred_direction == -1)}일\")\n",
    "print(f\"  보합 예측: {np.sum(pred_direction == 0)}일\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"CryptoPulse 파이프라인 완료!\")\n",
    "print(f\"{'='*70}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
